{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.regression_model import DemoRegressionDGP\n",
    "from likelihoods import Gaussian\n",
    "from utils_training_demo import MCEM_demo, MCEM_windows_demo, MCEM_sampler_demo, MCEM_Q_maximizer_demo\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pods\n",
    "def get_mcycle_data(num_testing=100):\n",
    "    data = pods.datasets.mcycle()\n",
    "    X_train = data['X']\n",
    "    m = np.sqrt(X_train.var())\n",
    "    s = X_train.mean()\n",
    "    X_train = (X_train - m)/s\n",
    "    y = data['Y']\n",
    "    scale=np.sqrt(y.var())\n",
    "    offset=y.mean()\n",
    "    Y_train = (y - offset)/scale\n",
    "\n",
    "    X_test = np.linspace(-20., 80., num_testing)[:, None]\n",
    "    X_test = (X_test - m)/s\n",
    "    Y_test = np.zeros_like(X_test) #for compatibility\n",
    "    # print(f\"training size is {X_train.shape[0]}\")\n",
    "    return np.float32(X_train), np.float32(Y_train), np.float32(X_test), np.float32(Y_test)\n",
    "\n",
    "def load_demo_data(num_testing):\n",
    "    X_train, Y_train, X_test, Y_test = get_mcycle_data(num_testing)\n",
    "    ds_X_train = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "    ds_Y_train = tf.data.Dataset.from_tensor_slices(Y_train)\n",
    "    ds_train = tf.data.Dataset.zip((ds_X_train, ds_Y_train))\n",
    "    ds_X_test = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "    ds_Y_test = tf.data.Dataset.from_tensor_slices(Y_test)\n",
    "    ds_test = tf.data.Dataset.zip((ds_X_test, ds_Y_test))\n",
    "\n",
    "    ds_train = ds_train.shuffle(94)\n",
    "    # ds_test = ds_test.shuffle(num_testing)\n",
    "    ds_train = ds_train.batch(47) # not using full data as one batch\n",
    "    ds_test = ds_test.batch(num_testing)\n",
    "    return ds_train, ds_test, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6b746a96d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_testing = 100\n",
    "num_training = 94\n",
    "ds_train, ds_test, X_test = load_demo_data(num_testing)\n",
    "for x, y in ds_train:\n",
    "    plt.plot(x[:,0], y[:,0], '*',linewidth=0.5, label='training points')\n",
    "for x, y in ds_test:\n",
    "    plt.plot(x[:,0], y[:,0], label='ground truth')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-layer GPs (free kernel paramsï¼Œ using MCEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "d_in = 1\n",
    "d_out = 1\n",
    "model = DemoRegressionDGP(d_in, d_out, n_hidden_layers=1, n_rf=100, n_gp=1,\n",
    "                          likelihood=Gaussian(variance=0.01, trainable=True),\n",
    "                          kernel_type_list=['RBF'], kernel_trainable=True,\n",
    "                          random_fixed=True, input_cat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 08:07:50.483757: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Omega_hyperparams # as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# EM sampler settings\n",
    "lr_mcmc_0 = 0.01\n",
    "batch_size = 47\n",
    "sampler_EM = MCEM_sampler_demo(model, ds_train, ds_test, num_training, batch_size, X_test,\n",
    "                               lr_0=lr_mcmc_0, momentum_decay=0.99, resample_in_cycle_head=False,\n",
    "                               start_sampling_epoch=1000, epochs_per_cycle=50)\n",
    "\n",
    "# Maximizer setttings\n",
    "lr_maximizer = 0.01\n",
    "optimizer = optimizers.Adam(learning_rate=lr_maximizer)\n",
    "maximizer = MCEM_Q_maximizer_demo(model, num_training, optimizer)\n",
    "\n",
    "# sampler settings after fixing hyper-params\n",
    "lr_fixing_hyper_0 = 0.01\n",
    "sampler_fixing_hyper = MCEM_sampler_demo(model, ds_train, ds_test, num_training, batch_size, X_test,\n",
    "                                         lr_0=lr_fixing_hyper_0, momentum_decay=0.99, resample_in_cycle_head=False,\n",
    "                                         start_sampling_epoch=2000, epochs_per_cycle=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### EM step 1 of total 50 steps. E Step:  ###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 08:08:07.985973: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-25 08:08:08.567999: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-08-25 08:08:08.568062: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -37.514095306396484, -- test: -269.52252197265625 \n",
      "Root Mean Squared Error -- train: 0.8820174336433411, -- test: 2.327686309814453 \n",
      "\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -53.78580093383789, -- test: -345.5919494628906 \n",
      "Root Mean Squared Error -- train: 1.050423264503479, -- test: 2.6342954635620117 \n",
      "\n",
      "Sampling Epoch: 149\n",
      "Mean Log Likelihood -- train: -86.47693634033203, -- test: -194.93682861328125 \n",
      "Root Mean Squared Error -- train: 1.3255985975265503, -- test: 1.9815171957015991 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -55.35824203491211, -- test: -113.55960845947266 \n",
      "Root Mean Squared Error -- train: 1.0652875900268555, -- test: 1.5162009000778198 \n",
      "\n",
      "Sampling Epoch: 249\n",
      "Mean Log Likelihood -- train: -35.612449645996094, -- test: -222.4581298828125 \n",
      "Root Mean Squared Error -- train: 0.8601871132850647, -- test: 2.1158533096313477 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -30.659217834472656, -- test: -201.70069885253906 \n",
      "Root Mean Squared Error -- train: 0.8005356788635254, -- test: 2.015362501144409 \n",
      "\n",
      "Sampling Epoch: 349\n",
      "Mean Log Likelihood -- train: -42.68234634399414, -- test: -173.66958618164062 \n",
      "Root Mean Squared Error -- train: 0.9387863278388977, -- test: 1.8711131811141968 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -31.1510009765625, -- test: -201.51138305664062 \n",
      "Root Mean Squared Error -- train: 0.8066554069519043, -- test: 2.014423131942749 \n",
      "\n",
      "Sampling Epoch: 449\n",
      "Mean Log Likelihood -- train: -33.296104431152344, -- test: -198.02481079101562 \n",
      "Root Mean Squared Error -- train: 0.8328235745429993, -- test: 1.9970401525497437 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -50.473114013671875, -- test: -170.45614624023438 \n",
      "Root Mean Squared Error -- train: 1.0183982849121094, -- test: 1.853859782218933 \n",
      "\n",
      "Sampling Epoch: 549\n",
      "Mean Log Likelihood -- train: -43.36880111694336, -- test: -216.7462921142578 \n",
      "Root Mean Squared Error -- train: 0.9460702538490295, -- test: 2.0886833667755127 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -30.88384437561035, -- test: -195.72418212890625 \n",
      "Root Mean Squared Error -- train: 0.8033366203308105, -- test: 1.9854865074157715 \n",
      "\n",
      "Sampling Epoch: 649\n",
      "Mean Log Likelihood -- train: -42.71211624145508, -- test: -199.1689453125 \n",
      "Root Mean Squared Error -- train: 0.9391034245491028, -- test: 2.002761125564575 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -33.31610107421875, -- test: -211.89048767089844 \n",
      "Root Mean Squared Error -- train: 0.833063542842865, -- test: 2.0653045177459717 \n",
      "\n",
      "Sampling Epoch: 749\n",
      "Mean Log Likelihood -- train: -37.130516052246094, -- test: -226.31793212890625 \n",
      "Root Mean Squared Error -- train: 0.8776578903198242, -- test: 2.1340177059173584 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -33.78364944458008, -- test: -206.78173828125 \n",
      "Root Mean Squared Error -- train: 0.8386572003364563, -- test: 2.0404183864593506 \n",
      "\n",
      "Sampling Epoch: 849\n",
      "Mean Log Likelihood -- train: -31.89899253845215, -- test: -191.75057983398438 \n",
      "Root Mean Squared Error -- train: 0.8158754706382751, -- test: 1.9653713703155518 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -33.19587707519531, -- test: -199.7921905517578 \n",
      "Root Mean Squared Error -- train: 0.8316192030906677, -- test: 2.0058703422546387 \n",
      "\n",
      "Sampling Epoch: 949\n",
      "Mean Log Likelihood -- train: -34.82932662963867, -- test: -198.9499969482422 \n",
      "Root Mean Squared Error -- train: 0.8510342836380005, -- test: 2.0016674995422363 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -40.8347282409668, -- test: -198.49826049804688 \n",
      "Root Mean Squared Error -- train: 0.9188947081565857, -- test: 1.9994094371795654 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1049\n",
      "Mean Log Likelihood -- train: -34.670204162597656, -- test: -222.88597106933594 \n",
      "Root Mean Squared Error -- train: 0.8491625189781189, -- test: 2.1178746223449707 \n",
      "\n",
      "#################### Sample No.2 at Epoch 1099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1099\n",
      "Mean Log Likelihood -- train: -33.30120086669922, -- test: -156.92120361328125 \n",
      "Root Mean Squared Error -- train: 0.832884669303894, -- test: 1.7793530225753784 \n",
      "\n",
      "#################### Sample No.3 at Epoch 1149  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1149\n",
      "Mean Log Likelihood -- train: -32.02191925048828, -- test: -173.9367218017578 \n",
      "Root Mean Squared Error -- train: 0.8173807859420776, -- test: 1.8725401163101196 \n",
      "\n",
      "#################### Sample No.4 at Epoch 1199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1199\n",
      "Mean Log Likelihood -- train: -33.006492614746094, -- test: -174.8311309814453 \n",
      "Root Mean Squared Error -- train: 0.829338788986206, -- test: 1.8773106336593628 \n",
      "\n",
      "#################### Sample No.5 at Epoch 1249  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1249\n",
      "Mean Log Likelihood -- train: -31.00286293029785, -- test: -183.75714111328125 \n",
      "Root Mean Squared Error -- train: 0.8048168420791626, -- test: 1.9242702722549438 \n",
      "\n",
      "#################### Sample No.6 at Epoch 1299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1299\n",
      "Mean Log Likelihood -- train: -30.59046173095703, -- test: -164.5028839111328 \n",
      "Root Mean Squared Error -- train: 0.7996762990951538, -- test: 1.8214638233184814 \n",
      "\n",
      "#################### Sample No.7 at Epoch 1349  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1349\n",
      "Mean Log Likelihood -- train: -33.033546447753906, -- test: -230.98410034179688 \n",
      "Root Mean Squared Error -- train: 0.8296648859977722, -- test: 2.1557724475860596 \n",
      "\n",
      "#################### Sample No.8 at Epoch 1399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1399\n",
      "Mean Log Likelihood -- train: -31.180217742919922, -- test: -175.50253295898438 \n",
      "Root Mean Squared Error -- train: 0.8070175051689148, -- test: 1.8808836936950684 \n",
      "\n",
      "#################### Sample No.9 at Epoch 1449  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1449\n",
      "Mean Log Likelihood -- train: -31.182315826416016, -- test: -180.4490203857422 \n",
      "Root Mean Squared Error -- train: 0.8070434927940369, -- test: 1.9070011377334595 \n",
      "\n",
      "#################### Sample No.10 at Epoch 1499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1499\n",
      "Mean Log Likelihood -- train: -33.511329650878906, -- test: -182.5594482421875 \n",
      "Root Mean Squared Error -- train: 0.8354038000106812, -- test: 1.918035864830017 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -136.7350616455078\n",
      "Test Root MSE of all sampled models: 1.9288164377212524\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 1 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -33.97098159790039 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 2 of total 50 steps. E Step:  ###############\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -30.475486755371094, -- test: -221.07542419433594 \n",
      "Root Mean Squared Error -- train: 0.8021755218505859, -- test: 2.1198575496673584 \n",
      "\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -31.19198226928711, -- test: -217.57337951660156 \n",
      "Root Mean Squared Error -- train: 0.8111470341682434, -- test: 2.103105306625366 \n",
      "\n",
      "Sampling Epoch: 149\n",
      "Mean Log Likelihood -- train: -30.32957649230957, -- test: -189.83502197265625 \n",
      "Root Mean Squared Error -- train: 0.8003361821174622, -- test: 1.9653773307800293 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -30.320343017578125, -- test: -182.89306640625 \n",
      "Root Mean Squared Error -- train: 0.8002196550369263, -- test: 1.9293714761734009 \n",
      "\n",
      "Sampling Epoch: 249\n",
      "Mean Log Likelihood -- train: -30.4682674407959, -- test: -194.08169555664062 \n",
      "Root Mean Squared Error -- train: 0.8020846247673035, -- test: 1.9870822429656982 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -48.25706481933594, -- test: -218.9689483642578 \n",
      "Root Mean Squared Error -- train: 1.0013447999954224, -- test: 2.1097970008850098 \n",
      "\n",
      "Sampling Epoch: 349\n",
      "Mean Log Likelihood -- train: -30.466543197631836, -- test: -184.84535217285156 \n",
      "Root Mean Squared Error -- train: 0.8020629286766052, -- test: 1.9395649433135986 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -33.730342864990234, -- test: -183.94187927246094 \n",
      "Root Mean Squared Error -- train: 0.8421620726585388, -- test: 1.93485426902771 \n",
      "\n",
      "Sampling Epoch: 449\n",
      "Mean Log Likelihood -- train: -32.574214935302734, -- test: -188.9349365234375 \n",
      "Root Mean Squared Error -- train: 0.8281798958778381, -- test: 1.9607462882995605 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -41.241512298583984, -- test: -206.3533172607422 \n",
      "Root Mean Squared Error -- train: 0.9278847575187683, -- test: 2.0485103130340576 \n",
      "\n",
      "Sampling Epoch: 549\n",
      "Mean Log Likelihood -- train: -34.1181755065918, -- test: -187.8276824951172 \n",
      "Root Mean Squared Error -- train: 0.8468007445335388, -- test: 1.9550340175628662 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -31.335277557373047, -- test: -206.8822784423828 \n",
      "Root Mean Squared Error -- train: 0.8129293918609619, -- test: 2.051116943359375 \n",
      "\n",
      "Sampling Epoch: 649\n",
      "Mean Log Likelihood -- train: -32.26300048828125, -- test: -195.3114776611328 \n",
      "Root Mean Squared Error -- train: 0.824375569820404, -- test: 1.9933234453201294 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -49.52550506591797, -- test: -232.75831604003906 \n",
      "Root Mean Squared Error -- train: 1.0140588283538818, -- test: 2.1748111248016357 \n",
      "\n",
      "Sampling Epoch: 749\n",
      "Mean Log Likelihood -- train: -30.386260986328125, -- test: -184.47679138183594 \n",
      "Root Mean Squared Error -- train: 0.8010512590408325, -- test: 1.9376447200775146 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -31.591310501098633, -- test: -181.7199249267578 \n",
      "Root Mean Squared Error -- train: 0.8161042928695679, -- test: 1.9232200384140015 \n",
      "\n",
      "Sampling Epoch: 849\n",
      "Mean Log Likelihood -- train: -32.014774322509766, -- test: -201.2698974609375 \n",
      "Root Mean Squared Error -- train: 0.8213286399841309, -- test: 2.0232906341552734 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -30.40431785583496, -- test: -187.59140014648438 \n",
      "Root Mean Squared Error -- train: 0.8012788891792297, -- test: 1.953813076019287 \n",
      "\n",
      "Sampling Epoch: 949\n",
      "Mean Log Likelihood -- train: -35.8176383972168, -- test: -184.9702606201172 \n",
      "Root Mean Squared Error -- train: 0.8668347001075745, -- test: 1.9402153491973877 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -30.631433486938477, -- test: -180.26348876953125 \n",
      "Root Mean Squared Error -- train: 0.8041367530822754, -- test: 1.9155558347702026 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1049\n",
      "Mean Log Likelihood -- train: -33.1146125793457, -- test: -185.22145080566406 \n",
      "Root Mean Squared Error -- train: 0.8347446322441101, -- test: 1.941522479057312 \n",
      "\n",
      "#################### Sample No.2 at Epoch 1099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1099\n",
      "Mean Log Likelihood -- train: -32.9625358581543, -- test: -191.3028564453125 \n",
      "Root Mean Squared Error -- train: 0.8329024910926819, -- test: 1.9729063510894775 \n",
      "\n",
      "#################### Sample No.3 at Epoch 1149  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1149\n",
      "Mean Log Likelihood -- train: -30.685016632080078, -- test: -211.67628479003906 \n",
      "Root Mean Squared Error -- train: 0.8048095107078552, -- test: 2.0745902061462402 \n",
      "\n",
      "#################### Sample No.4 at Epoch 1199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1199\n",
      "Mean Log Likelihood -- train: -31.019432067871094, -- test: -167.9774627685547 \n",
      "Root Mean Squared Error -- train: 0.8089956045150757, -- test: 1.8496387004852295 \n",
      "\n",
      "#################### Sample No.5 at Epoch 1249  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1249\n",
      "Mean Log Likelihood -- train: -30.424711227416992, -- test: -198.19529724121094 \n",
      "Root Mean Squared Error -- train: 0.8015359044075012, -- test: 2.007883071899414 \n",
      "\n",
      "#################### Sample No.6 at Epoch 1299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1299\n",
      "Mean Log Likelihood -- train: -30.43632698059082, -- test: -196.8729705810547 \n",
      "Root Mean Squared Error -- train: 0.8016822934150696, -- test: 2.001220226287842 \n",
      "\n",
      "#################### Sample No.7 at Epoch 1349  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1349\n",
      "Mean Log Likelihood -- train: -30.42731285095215, -- test: -185.48435974121094 \n",
      "Root Mean Squared Error -- train: 0.8015687465667725, -- test: 1.94288969039917 \n",
      "\n",
      "#################### Sample No.8 at Epoch 1399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1399\n",
      "Mean Log Likelihood -- train: -30.811996459960938, -- test: -189.00306701660156 \n",
      "Root Mean Squared Error -- train: 0.8064014911651611, -- test: 1.961097240447998 \n",
      "\n",
      "#################### Sample No.9 at Epoch 1449  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1449\n",
      "Mean Log Likelihood -- train: -30.301069259643555, -- test: -204.69363403320312 \n",
      "Root Mean Squared Error -- train: 0.7999763488769531, -- test: 2.0403103828430176 \n",
      "\n",
      "#################### Sample No.10 at Epoch 1499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1499\n",
      "Mean Log Likelihood -- train: -31.39562225341797, -- test: -188.43072509765625 \n",
      "Root Mean Squared Error -- train: 0.8136788606643677, -- test: 1.9581471681594849 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -154.35589599609375\n",
      "Test Root MSE of all sampled models: 1.975888729095459\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 2 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -30.070873260498047 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 3 of total 50 steps. E Step:  ###############\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -30.50257682800293, -- test: -204.0409698486328 \n",
      "Root Mean Squared Error -- train: 0.8064566850662231, -- test: 2.047213554382324 \n",
      "\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -30.38050079345703, -- test: -194.75314331054688 \n",
      "Root Mean Squared Error -- train: 0.8049109578132629, -- test: 2.0003960132598877 \n",
      "\n",
      "Sampling Epoch: 149\n",
      "Mean Log Likelihood -- train: -38.33380889892578, -- test: -208.16888427734375 \n",
      "Root Mean Squared Error -- train: 0.9000852108001709, -- test: 2.067681074142456 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -29.986328125, -- test: -189.1792449951172 \n",
      "Root Mean Squared Error -- train: 0.7998996376991272, -- test: 1.971765398979187 \n",
      "\n",
      "Sampling Epoch: 249\n",
      "Mean Log Likelihood -- train: -50.19465637207031, -- test: -190.75399780273438 \n",
      "Root Mean Squared Error -- train: 1.025744080543518, -- test: 1.9798963069915771 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -34.767364501953125, -- test: -191.1859130859375 \n",
      "Root Mean Squared Error -- train: 0.8587124347686768, -- test: 1.982120394706726 \n",
      "\n",
      "Sampling Epoch: 349\n",
      "Mean Log Likelihood -- train: -59.425437927246094, -- test: -223.6730499267578 \n",
      "Root Mean Squared Error -- train: 1.1137714385986328, -- test: 2.142810583114624 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -38.403079986572266, -- test: -188.86068725585938 \n",
      "Root Mean Squared Error -- train: 0.9008700251579285, -- test: 1.9701166152954102 \n",
      "\n",
      "Sampling Epoch: 449\n",
      "Mean Log Likelihood -- train: -31.30436897277832, -- test: -203.94158935546875 \n",
      "Root Mean Squared Error -- train: 0.8165361881256104, -- test: 2.0467183589935303 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -39.450199127197266, -- test: -203.74456787109375 \n",
      "Root Mean Squared Error -- train: 0.9126506447792053, -- test: 2.045736074447632 \n",
      "\n",
      "Sampling Epoch: 549\n",
      "Mean Log Likelihood -- train: -30.833824157714844, -- test: -187.78431701660156 \n",
      "Root Mean Squared Error -- train: 0.8106361031532288, -- test: 1.964535117149353 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -50.97860336303711, -- test: -222.62017822265625 \n",
      "Root Mean Squared Error -- train: 1.0335112810134888, -- test: 2.1377923488616943 \n",
      "\n",
      "Sampling Epoch: 649\n",
      "Mean Log Likelihood -- train: -36.15863800048828, -- test: -175.5223846435547 \n",
      "Root Mean Squared Error -- train: 0.8750847578048706, -- test: 1.899794101715088 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -40.2280158996582, -- test: -221.81768798828125 \n",
      "Root Mean Squared Error -- train: 0.921303927898407, -- test: 2.1339592933654785 \n",
      "\n",
      "Sampling Epoch: 749\n",
      "Mean Log Likelihood -- train: -31.989492416381836, -- test: -231.62152099609375 \n",
      "Root Mean Squared Error -- train: 0.825051486492157, -- test: 2.180323362350464 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -31.09910011291504, -- test: -197.55020141601562 \n",
      "Root Mean Squared Error -- train: 0.8139676451683044, -- test: 2.0146095752716064 \n",
      "\n",
      "Sampling Epoch: 849\n",
      "Mean Log Likelihood -- train: -30.692325592041016, -- test: -206.65093994140625 \n",
      "Root Mean Squared Error -- train: 0.8088534474372864, -- test: 2.060178518295288 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -30.012996673583984, -- test: -200.11097717285156 \n",
      "Root Mean Squared Error -- train: 0.8002396821975708, -- test: 2.0275354385375977 \n",
      "\n",
      "Sampling Epoch: 949\n",
      "Mean Log Likelihood -- train: -30.021392822265625, -- test: -196.64222717285156 \n",
      "Root Mean Squared Error -- train: 0.8003467321395874, -- test: 2.0100066661834717 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -30.161977767944336, -- test: -194.5447235107422 \n",
      "Root Mean Squared Error -- train: 0.8021366596221924, -- test: 1.9993325471878052 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1049\n",
      "Mean Log Likelihood -- train: -30.51193618774414, -- test: -174.52000427246094 \n",
      "Root Mean Squared Error -- train: 0.8065750598907471, -- test: 1.8944038152694702 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_225975/1972857042.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# MCEM settings and training\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mtotal_EM_steps\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m50\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m _, _, lines, W = MCEM_demo(sampler_EM, maximizer, sampler_fixing_hyper, total_EM_steps, ds_train, \n\u001B[0m\u001B[1;32m      4\u001B[0m                       \u001B[0mnum_samples_EM\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_samples_fixing_hyper\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                       print_epoch_cycle_EM=50, print_epoch_cycle_fixing=100)\n",
      "\u001B[0;32m~/autodl-tmp/DGP_RF_MCMC/experiments/utils_training_demo.py\u001B[0m in \u001B[0;36mMCEM_demo\u001B[0;34m(sampler_EM, maximizer, sampler_fixing_hyper, total_EM_steps, ds_train, num_samples_EM, num_samples_fixing_hyper, print_epoch_cycle_EM, print_epoch_cycle_fixing)\u001B[0m\n\u001B[1;32m    200\u001B[0m         \u001B[0;31m# E step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"#\"\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;36m15\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"EM step {em_step} of total {total_EM_steps} steps. E Step: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"#\"\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;36m15\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 202\u001B[0;31m         W_samples, _, _ = sampler_EM(num_samples=num_samples_EM, return_lines_Wdict=False,\n\u001B[0m\u001B[1;32m    203\u001B[0m                                      print_epoch_cycle=print_epoch_cycle_EM)\n\u001B[1;32m    204\u001B[0m         \u001B[0;31m# M step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/autodl-tmp/DGP_RF_MCMC/experiments/utils_training_demo.py\u001B[0m in \u001B[0;36msampler\u001B[0;34m(num_samples, return_lines_Wdict, print_epoch_cycle)\u001B[0m\n\u001B[1;32m    123\u001B[0m                     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m                         \u001B[0mis_new_cycle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m                     model_demo.sgmcmc_update(img_batch, label_batch, train_size, lr=lr, momentum_decay=momentum_decay,\n\u001B[0m\u001B[1;32m    126\u001B[0m                                              resample_moments=is_new_cycle, temperature=1., full_bayesian=False)\n\u001B[1;32m    127\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mis_end\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# sampling the model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/autodl-tmp/DGP_RF_MCMC/experiments/../models/dgp.py\u001B[0m in \u001B[0;36msgmcmc_update\u001B[0;34m(self, X_batch, Y_batch, data_size, lr, momentum_decay, resample_moments, temperature, full_bayesian)\u001B[0m\n\u001B[1;32m    194\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGradientTape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwatch_accessed_variables\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    195\u001B[0m                 \u001B[0mtape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mW_mcmc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 196\u001B[0;31m                 U = self.U(X_batch, Y_batch, data_size,\n\u001B[0m\u001B[1;32m    197\u001B[0m                            full_bayesian=False, allow_gradient_from_W=True)\n\u001B[1;32m    198\u001B[0m             \u001B[0mgrads\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mU\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwatched_variables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/autodl-tmp/DGP_RF_MCMC/experiments/../models/dgp.py\u001B[0m in \u001B[0;36mU\u001B[0;34m(self, X_batch, Y_batch, data_size, full_bayesian, allow_gradient_from_W)\u001B[0m\n\u001B[1;32m    172\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m                 \u001B[0mlog_prior_sum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.\u001B[0m \u001B[0;31m# fixing W, their priors are not related to Omegas\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 174\u001B[0;31m             \u001B[0mlog_likelihood\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduce_sum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_likelihood\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_gradient_from_W\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mallow_gradient_from_W\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    175\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# Or full Bayesian way:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0mallow_gradient_from_W\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Full Bayes should allow gradients from W!\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/autodl-tmp/DGP_RF_MCMC/experiments/../models/dgp.py\u001B[0m in \u001B[0;36mlog_likelihood\u001B[0;34m(self, X, Y, allow_gradient_from_W)\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0;34m:\u001B[0m\u001B[0;32mreturn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mN\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m         \"\"\"\n\u001B[0;32m--> 125\u001B[0;31m         \u001B[0mF\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBNN\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_gradient_from_W\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mallow_gradient_from_W\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m         \u001B[0mlog_likelihood\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlikelihood\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_prob\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mlog_likelihood\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/autodl-tmp/DGP_RF_MCMC/experiments/../utils.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, X, allow_gradient_from_W)\u001B[0m\n\u001B[1;32m     13\u001B[0m                 \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_gradient_from_W\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mallow_gradient_from_W\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m                 \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/autodl-tmp/DGP_RF_MCMC/experiments/../layers/rf_layers.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     40\u001B[0m             \u001B[0mz_resampled\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0min_feature\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout_feature\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m             \u001B[0mOmega\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpand_dims\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkernel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minv_length_scale\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mz_resampled\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m         \u001B[0minner_prod\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mOmega\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     43\u001B[0m         \u001B[0mrandom_feature\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcos\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minner_prod\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minner_prod\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m         \u001B[0mrandom_feature\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkernel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mamplitude\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout_feature\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mrandom_feature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    203\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 205\u001B[0;31m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    206\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    207\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# MCEM settings and training\n",
    "total_EM_steps = 50\n",
    "_, _, lines, W = MCEM_demo(sampler_EM, maximizer, sampler_fixing_hyper, total_EM_steps, ds_train, \n",
    "                      num_samples_EM=10, num_samples_fixing_hyper=100,\n",
    "                      print_epoch_cycle_EM=50, print_epoch_cycle_fixing=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.27986756>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.28996453], dtype=float32)>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Omega_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efaf8587700>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print sampled lines\n",
    "fig, ax = plt.subplots(1, model.n_hidden_layers+1, figsize=((model.n_hidden_layers+1)*5, 5))\n",
    "ax = ax.flatten()\n",
    "for i in range(model.n_hidden_layers):\n",
    "    for model_line in lines[5:]: # hidden outputs of each sampled model\n",
    "        line = model_line[i]\n",
    "        ax[i].plot(X_test[:,0], line.numpy()[:,0])\n",
    "    # for model_line in lines[690:701]: # hidden outputs of each sampled model\n",
    "    #     line = model_line[i]\n",
    "    #     ax[i].plot(X_test.numpy()[:,0], line.numpy()[:,0], 'b')\n",
    "for x, y in ds_train:\n",
    "    ax[-2].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "# for x, y in ds_test:\n",
    "    # ax[-1].plot(x[:,0], y[:,0], '*', label='ground truth')\n",
    "ax[-2].legend()\n",
    "\n",
    "# compute the mean of the sampled lines\n",
    "line_output = []\n",
    "for model_line in lines[5:]:\n",
    "    line_output.append(model_line[-1]) #the final layer\n",
    "line_mean = tf.reduce_mean(tf.concat(line_output, axis=-1), axis=-1)\n",
    "ax[-1].plot(X_test[:,0], line_mean.numpy(), label='mean')\n",
    "for x, y in ds_train:\n",
    "    ax[-1].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "ax[-1].legend()\n",
    "# fig.savefig('1layer-sin-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEvCAYAAADYR30zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAScklEQVR4nO3df2xd9X3G8fen+UGkLUtx4nXFTnCqpVujpFORoTSZVraCEmBKWrWdSDcKA5pVG9XaoGmZStNBKw06aZuq0dKModBKg1I2dRmkTdaWCmkOAaNSQohoA2XEHmuckFKhKkDGZ3/4gi6OnXtiH/va+b5f0hX3nPO95zy+uTw6P+6xIzORpBK8qd0BJGmqWHiSimHhSSqGhSepGBaepGJYeJKKMbtdG160aFH29PS0a/OSTlOPPPLI4czsHG1Z2wqvp6eH/v7+dm1e0mkqIv57rGUe0koqhoUnqRgWnqRitO0c3mheeeUVBgYGOHbsWLujTIp58+bR3d3NnDlz2h1FKtK0KryBgQHmz59PT08PEdHuOLXKTI4cOcLAwABLly5tdxypSNPqkPbYsWMsXLjwtCs7gIhg4cKFp+3eqzQTTKvCA07LsnvN6fyzSTPBtCs8SZos0+oc3kg9m++rdX3P3HRpyzGf+tSnOPvss/nkJz8JwJo1a1i8eDG33XYbANdddx1dXV1s2rTphNfecccdfP7znwfg+uuv54orrqgvvKQJcw9vhNWrV9PX1wfAq6++yuHDh9m3b9/ry/v6+li1atUJr3v++ee54YYb2LNnDw899BA33HADR48enbLcklqz8EZYtWoVu3fvBmDfvn2sWLGC+fPnc/ToUV566SX279/POeecc8Lrdu7cyUUXXURHRwdnnnkmF110Ed/+9renOr6kk5jWh7TtcNZZZzF79myeffZZ+vr6eM973sPg4CC7d+9mwYIFrFy5krlz557wusHBQRYvXvz6dHd3N4ODg1MZfVKMPK1Q5bSATg+n47+9hTeKVatW0dfXR19fH5s2bWJwcJC+vj4WLFjA6tWr2x1P0jh5SDuK187j7d27lxUrVnD++eeze/fuMc/fAXR1dXHw4MHXpwcGBujq6pqqyJIqsPBGsWrVKu699146OjqYNWsWHR0d/OxnP2P37t1jFt6aNWvYtWsXR48e5ejRo+zatYs1a9ZMcXJJJzOtD2nbdc5g5cqVHD58mI985CNvmPfiiy+yaNGiUV/T0dHBZz7zGc4991wAtmzZQkdHx5TklVTNtC68dpk1axY///nP3zBv27ZtLV931VVXcdVVV01SKkkT5SGtpGK4h3eK9u7dy+WXX/6GeWeccQZ79uxpUyJJVVl4p2jlypU8+uij7Y4haRym3SFtZrY7wqQ5nX82aSaYVoU3b948jhw5cloWw2u/AHTevHntjiIVa1od0nZ3dzMwMMDQ0FC7o0yK137Fu6T2aFl4EXE78PvAocxccZJx5wK7gcsy857xhJkzZ46//lzSpKlySLsNWHuyARExC7gZ2FVDJkmaFC0LLzMfAJ5vMewTwL8Ch+oIJUmTYcIXLSKiC/gA8OUKYzdGRH9E9J+u5+kkTV91XKX9B+AvM/PVVgMzc2tm9mZmb2dnZw2blqTq6rhK2wvc1fiLXIuASyLieGZ+s4Z1S1JtJlx4mfn6ZdWI2Abca9lJmo6qfC3lTuACYFFEDACfBeYAZOatk5pOkmrUsvAyc0PVlWXmlRNKI0mTaFrdWiZJk8nCk1QMC09SMSw8ScWw8CQVw8KTVAwLT1IxLDxJxbDwJBXDwpNUDAtPUjEsPEnFsPAkFcPCk1QMC09SMSw8ScWw8CQVw8KTVAwLT1IxLDxJxbDwJBXDwpNUDAtPUjEsPEnFsPAkFaNl4UXE7RFxKCIeH2P5H0bEYxGxNyL6IuK36o8pSRNXZQ9vG7D2JMt/Arw3M1cCnwO21pBLkmo3u9WAzHwgInpOsryvafJBoLuGXJJUu7rP4V0NfKvmdUpSLVru4VUVEb/LcOH99knGbAQ2AixZsqSuTUtSJbXs4UXEO4HbgPWZeWSscZm5NTN7M7O3s7Ozjk1LUmUTLryIWAL8G3B5Zv5o4pEkaXK0PKSNiDuBC4BFETEAfBaYA5CZtwJbgIXAlyIC4Hhm9k5WYEkarypXaTe0WH4NcE1tiSRpkninhaRiWHiSimHhSSqGhSepGBaepGJYeJKKYeFJKoaFJ6kYFp6kYlh4koph4UkqhoUnqRgWnqRiWHiSimHhSSqGhSepGBaepGJYeJKKYeFJKoaFJ6kYFp6kYlh4koph4UkqhoUnqRgWnqRiWHiSitGy8CLi9og4FBGPj7E8IuKLEXEgIh6LiHPqjylJE1dlD28bsPYkyy8GljUeG4EvTzyWJNWvZeFl5gPA8ycZsh74ag57EHhzRLy1roCSVJc6zuF1AQebpgca8yRpWpnSixYRsTEi+iOif2hoaCo3LUnMrmEdg8DipunuxrwTZOZWYCtAb29v1rBtnYZ6Nt93wrxnbrq0DUmmh5Hvx3R9L+r4d5vsf/s69vC2Ax9tXK09H3ghM5+rYb2SVKuWe3gRcSdwAbAoIgaAzwJzADLzVmAHcAlwAPgF8MeTFVaSJqJl4WXmhhbLE/iz2hJJ0iTxTgtJxbDwJBXDwpNUDAtPUjEsPEnFsPAkFcPCk1QMC09SMSw8ScWw8CQVw8KTVAwLT1IxLDxJxbDwJBXDwpNUDAtPUjEsPEnFsPAkFcPCk1QMC09SMSw8ScWw8CQVw8KTVAwLT1IxLDxJxbDwJBWjUuFFxNqIeDIiDkTE5lGWL4mI+yPiBxHxWERcUn9USZqYloUXEbOAW4CLgeXAhohYPmLY9cDdmfku4DLgS3UHlaSJqrKHdx5wIDOfzsyXgbuA9SPGJPArjecLgP+pL6Ik1WN2hTFdwMGm6QHg3SPG/DWwKyI+AfwScGEt6SSpRnVdtNgAbMvMbuAS4GsRccK6I2JjRPRHRP/Q0FBNm5akaqoU3iCwuGm6uzGv2dXA3QCZuRuYBywauaLM3JqZvZnZ29nZOb7EkjROVQrvYWBZRCyNiLkMX5TYPmLMs8D7ACLiHQwXnrtwkqaVloWXmceBa4GdwH6Gr8bui4gbI2JdY9h1wMci4ofAncCVmZmTFVqSxqPKRQsycwewY8S8LU3PnwBW1xtNkurlnRaSimHhSSqGhSepGBaepGJUumghnYqezfeddPkzN106RUlOzcjc48lZxzomw3TNNdXcw5NUDAtPUjEsPEnFsPAkFcPCk1QMC09SMSw8ScWw8CQVw8KTVAwLT1IxLDxJxbDwJBXDwpNUDAtPUjEsPEnFsPAkFcPCk1QMC09SMSw8ScWw8CQVw8KTVIxKhRcRayPiyYg4EBGbxxjzBxHxRETsi4h/qTemJE1cyz/TGBGzgFuAi4AB4OGI2J6ZTzSNWQb8FbA6M49GxK9OVmBJGq8qe3jnAQcy8+nMfBm4C1g/YszHgFsy8yhAZh6qN6YkTVyVwusCDjZNDzTmNXs78PaI+K+IeDAi1o62oojYGBH9EdE/NDQ0vsSSNE51XbSYDSwDLgA2AP8UEW8eOSgzt2Zmb2b2dnZ21rRpSaqmSuENAoubprsb85oNANsz85XM/AnwI4YLUJKmjSqF9zCwLCKWRsRc4DJg+4gx32R4746IWMTwIe7T9cWUpIlrWXiZeRy4FtgJ7Afuzsx9EXFjRKxrDNsJHImIJ4D7gb/IzCOTFVqSxqPl11IAMnMHsGPEvC1NzxPY1HhI0rTknRaSimHhSSqGhSepGBaepGJYeJKKYeFJKoaFJ6kYFp6kYlh4koph4UkqhoUnqRgWnqRiWHiSilHpt6VoYno233fCvGduunTKt1tlm6NlPZXl4zGedbb62abqPT/V7FXGT8Vnow6T8VmYbO7hSSqGhSepGBaepGJYeJKKYeFJKoaFJ6kYFp6kYlh4koph4UkqhoUnqRgWnqRiVCq8iFgbEU9GxIGI2HyScR+MiIyI3voiSlI9WhZeRMwCbgEuBpYDGyJi+Sjj5gN/DuypO6Qk1aHKHt55wIHMfDozXwbuAtaPMu5zwM3AsRrzSVJtqhReF3CwaXqgMe91EXEOsDgzZ97vi5FUjAlftIiINwF/B1xXYezGiOiPiP6hoaGJblqSTkmVwhsEFjdNdzfmvWY+sAL4fkQ8A5wPbB/twkVmbs3M3szs7ezsHH9qSRqHKoX3MLAsIpZGxFzgMmD7awsz84XMXJSZPZnZAzwIrMvM/klJLEnj1LLwMvM4cC2wE9gP3J2Z+yLixohYN9kBJakulf6mRWbuAHaMmLdljLEXTDyWJNXPOy0kFcPCk1QMC09SMSw8ScWw8CQVw8KTVAwLT1IxLDxJxbDwJBXDwpNUDAtPUjEsPEnFsPAkFcPCk1QMC09SMSw8ScWw8CQVw8KTVAwLT1IxLDxJxbDwJBXDwpNUjMjMtmy4t7c3+/tP7W9192y+7w3Tz9x06Sm/ZqRW62j1+irrrGMd49Hq/RpPrtLNlPdwuuRslaNKzlP9fyEiHsnM3tGWuYcnqRgWnqRiWHiSilGp8CJibUQ8GREHImLzKMs3RcQTEfFYRHw3Is6uP6okTUzLwouIWcAtwMXAcmBDRCwfMewHQG9mvhO4B/hC3UElaaKq7OGdBxzIzKcz82XgLmB984DMvD8zf9GYfBDorjemJE1clcLrAg42TQ805o3lauBbEwklSZNhdp0ri4g/AnqB946xfCOwEWDJkiV1blqSWqqyhzcILG6a7m7Me4OIuBD4NLAuM18abUWZuTUzezOzt7Ozczx5JWncqhTew8CyiFgaEXOBy4DtzQMi4l3AVxguu0P1x5SkiWtZeJl5HLgW2AnsB+7OzH0RcWNErGsM+1vgl4FvRMSjEbF9jNVJUttUOoeXmTuAHSPmbWl6fmHNuSSpdt5pIakYFp6kYlh4koph4UkqhoUnqRgWnqRiWHiSimHhSSqGhSepGBaepGJYeJKKYeFJKoaFJ6kYFp6kYlh4koph4UkqhoUnqRgWnqRiWHiSimHhSSqGhSepGBaepGJYeJKKYeFJKoaFJ6kYFp6kYlQqvIhYGxFPRsSBiNg8yvIzIuLrjeV7IqKn9qSSNEEtCy8iZgG3ABcDy4ENEbF8xLCrgaOZ+evA3wM31x1Ukiaqyh7eecCBzHw6M18G7gLWjxizHrij8fwe4H0REfXFlKSJq1J4XcDBpumBxrxRx2TmceAFYGEdASWpLpGZJx8Q8SFgbWZe05i+HHh3Zl7bNObxxpiBxvRTjTGHR6xrI7CxMfkbwJN1/SBTbBFwuOWo6WkmZ4eZnd/sU+PszOwcbcHsCi8eBBY3TXc35o02ZiAiZgMLgCMjV5SZW4GtVRJPZxHRn5m97c4xHjM5O8zs/GZvvyqHtA8DyyJiaUTMBS4Dto8Ysx24ovH8Q8D3stWuoyRNsZZ7eJl5PCKuBXYCs4DbM3NfRNwI9GfmduCfga9FxAHgeYZLUZKmlSqHtGTmDmDHiHlbmp4fAz5cb7RpbSYfls/k7DCz85u9zVpetJCk04W3lkkqhoVXQUR8OCL2RcSrETHmlapWt+C1Q0R0RMR/RsSPG/89c4xx/xcRjzYeIy9KTamZfCtjhexXRsRQ03t9TTtyjiYibo+IQ42vmY22PCLii42f7bGIOGeqM05YZvpo8QDewfD3Br8P9I4xZhbwFPA2YC7wQ2D5NMj+BWBz4/lm4OYxxr3Y7qxV30fgT4FbG88vA77e7tynkP1K4B/bnXWM/L8DnAM8PsbyS4BvAQGcD+xpd+ZTfbiHV0Fm7s/MVl+SrnILXjs03/Z3B/D+9kWpZCbfyjhdPwOVZOYDDH/LYizrga/msAeBN0fEW6cmXT0svPpUuQWvHd6Smc81nv8v8JYxxs2LiP6IeDAi3j810UY1k29lrPoZ+GDjkPCeiFg8yvLparp+xiur9LWUEkTEd4BfG2XRpzPz36c6z6k4WfbmiczMiBjrsvzZmTkYEW8DvhcRezPzqbqziv8A7szMlyLiTxjeU/29NmcqhoXXkJkXTnAVVW7BmxQnyx4RP42It2bmc43Dj0NjrGOw8d+nI+L7wLsYPh811Wq7lbENWmbPzOactzF8jnWmaNtnvC4e0tanyi147dB8298VwAl7qxFxZkSc0Xi+CFgNPDFlCd9oJt/K2DL7iHNe64D9U5hvorYDH21crT0feKHpdMnM0O6rJjPhAXyA4fMVLwE/BXY25p8F7GgadwnwI4b3jD7d7tyNTAuB7wI/Br4DdDTm9wK3NZ6vAvYyfFVxL3B1mzOf8D4CNwLrGs/nAd8ADgAPAW9r9/t8Ctn/BtjXeK/vB36z3Zmbst8JPAe80vi8Xw18HPh4Y3kw/MuAn2p8Tkb9xsJ0fninhaRieEgrqRgWnqRiWHiSimHhSSqGhSepGBaepGJYeJKKYeFJKsb/A1D/LFDQeA7oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_index = (25,0)\n",
    "fig, ax = plt.subplots(1, model.n_hidden_layers, figsize=(model.n_hidden_layers*5,5))\n",
    "for i in range(model.n_hidden_layers):\n",
    "    W_print = []\n",
    "    for W_model in W['W_'+str(i)][10:]:\n",
    "        W_print.append(W_model[print_index])\n",
    "    ax.hist(W_print, bins=60, density=True, label='W_'+str(i))\n",
    "    ax.legend()\n",
    "# fig.savefig('2w-sin-2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-layer DGPs (MCEM with Moving Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "d_in = 1\n",
    "d_out = 1\n",
    "model = DemoRegressionDGP(d_in, d_out, n_hidden_layers=1, n_rf=100, n_gp=1,\n",
    "                          likelihood=Gaussian(variance=0.01, trainable=True),\n",
    "                          kernel_type_list=['RBF'], kernel_trainable=True,\n",
    "                          random_fixed=True, input_cat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Omega_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM sampler settings\n",
    "lr_mcmc_0 = 0.01\n",
    "sampler_EM = MCEM_sampler_demo(model, ds_train, ds_test, num_training, batch_size, X_test,\n",
    "                               lr_0=lr_mcmc_0, momentum_decay=0.9, resample_in_cycle_head=False,\n",
    "                               start_sampling_epoch=0, epochs_per_cycle=50)\n",
    "\n",
    "# Maximizer setttings\n",
    "lr_maximizer = 0.01\n",
    "optimizer = optimizers.Adam(learning_rate=lr_maximizer)\n",
    "maximizer = MCEM_Q_maximizer_demo(model, num_training, optimizer)\n",
    "\n",
    "# sampler settings after fixing hyper-params\n",
    "lr_fixing_hyper_0 = 0.01\n",
    "sampler_fixing_hyper = MCEM_sampler_demo(model, ds_train, ds_test, num_training, batch_size, X_test,\n",
    "                                         lr_0=lr_fixing_hyper_0, momentum_decay=0.9, resample_in_cycle_head=False,\n",
    "                                         start_sampling_epoch=0, epochs_per_cycle=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### EM step 1 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -3.765904664993286, -- test: -88.61419677734375 \n",
      "Root Mean Squared Error -- train: 0.3209221363067627, -- test: 1.3416247367858887 \n",
      "\n",
      "#################### Sample No.2 at Epoch 99  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.590348720550537, -- test: -116.5424575805664 \n",
      "Root Mean Squared Error -- train: 0.31540435552597046, -- test: 1.5357481241226196 \n",
      "\n",
      "#################### Sample No.3 at Epoch 149  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 149\n",
      "Mean Log Likelihood -- train: -3.546091318130493, -- test: -103.41983032226562 \n",
      "Root Mean Squared Error -- train: 0.3139980137348175, -- test: 1.447780966758728 \n",
      "\n",
      "#################### Sample No.4 at Epoch 199  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.5266458988189697, -- test: -102.35615539550781 \n",
      "Root Mean Squared Error -- train: 0.31337812542915344, -- test: 1.4404151439666748 \n",
      "\n",
      "#################### Sample No.5 at Epoch 249  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 249\n",
      "Mean Log Likelihood -- train: -3.41542911529541, -- test: -120.5938491821289 \n",
      "Root Mean Squared Error -- train: 0.3098088204860687, -- test: 1.561905860900879 \n",
      "\n",
      "#################### Sample No.6 at Epoch 299  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.3823864459991455, -- test: -129.3571319580078 \n",
      "Root Mean Squared Error -- train: 0.30874043703079224, -- test: 1.6170392036437988 \n",
      "\n",
      "#################### Sample No.7 at Epoch 349  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 349\n",
      "Mean Log Likelihood -- train: -3.1894547939300537, -- test: -186.77908325195312 \n",
      "Root Mean Squared Error -- train: 0.30242690443992615, -- test: 1.9399110078811646 \n",
      "\n",
      "#################### Sample No.8 at Epoch 399  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.1521756649017334, -- test: -195.0595703125 \n",
      "Root Mean Squared Error -- train: 0.30119168758392334, -- test: 1.9821362495422363 \n",
      "\n",
      "#################### Sample No.9 at Epoch 449  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 449\n",
      "Mean Log Likelihood -- train: -3.1057581901550293, -- test: -199.83982849121094 \n",
      "Root Mean Squared Error -- train: 0.29964661598205566, -- test: 2.006108045578003 \n",
      "\n",
      "#################### Sample No.10 at Epoch 499  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.9407706260681152, -- test: -259.75885009765625 \n",
      "Root Mean Squared Error -- train: 0.2940889894962311, -- test: 2.285355567932129 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -66.06105041503906\n",
      "Test Root MSE of all sampled models: 1.74135422706604\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -66.06105041503906\n",
      "Test Root MSE of all models in window: 1.74135422706604\n",
      "\n",
      "############### EM step 1 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.659336090087891 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 2 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -2.6991326808929443, -- test: -294.9085998535156 \n",
      "Root Mean Squared Error -- train: 0.28701087832450867, -- test: 2.4464874267578125 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -294.9085998535156\n",
      "Test Root MSE of all sampled models: 2.4464874267578125\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -83.68909454345703\n",
      "Test Root MSE of all models in window: 1.857646107673645\n",
      "\n",
      "############### EM step 2 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.6859477162361145 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 3 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -2.633711814880371, -- test: -321.7552795410156 \n",
      "Root Mean Squared Error -- train: 0.2857288718223572, -- test: 2.565464973449707 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -321.7552795410156\n",
      "Test Root MSE of all sampled models: 2.565464973449707\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -89.41281127929688\n",
      "Test Root MSE of all models in window: 1.968034029006958\n",
      "\n",
      "############### EM step 3 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.4426677227020264 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 4 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -2.5717077255249023, -- test: -314.0816345214844 \n",
      "Root Mean Squared Error -- train: 0.28456997871398926, -- test: 2.5456557273864746 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -314.0816345214844\n",
      "Test Root MSE of all sampled models: 2.5456557273864746\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -91.2475357055664\n",
      "Test Root MSE of all models in window: 2.0764360427856445\n",
      "\n",
      "############### EM step 4 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.0422451496124268 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 5 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -2.4287056922912598, -- test: -369.6069641113281 \n",
      "Root Mean Squared Error -- train: 0.2804414629936218, -- test: 2.7729084491729736 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -369.6069641113281\n",
      "Test Root MSE of all sampled models: 2.7729084491729736\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -111.17174530029297\n",
      "Test Root MSE of all models in window: 2.207489490509033\n",
      "\n",
      "############### EM step 5 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.2161645889282227 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 6 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -2.2172770500183105, -- test: -381.15179443359375 \n",
      "Root Mean Squared Error -- train: 0.2735656201839447, -- test: 2.8283116817474365 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -381.15179443359375\n",
      "Test Root MSE of all sampled models: 2.8283116817474365\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -120.7955093383789\n",
      "Test Root MSE of all models in window: 2.330019235610962\n",
      "\n",
      "############### EM step 6 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.884502649307251 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 7 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -2.1461570262908936, -- test: -431.0025329589844 \n",
      "Root Mean Squared Error -- train: 0.27186745405197144, -- test: 3.0203449726104736 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -431.0025329589844\n",
      "Test Root MSE of all sampled models: 3.0203449726104736\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -175.7079620361328\n",
      "Test Root MSE of all models in window: 2.4657161235809326\n",
      "\n",
      "############### EM step 7 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.843268096446991 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 8 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -2.078226327896118, -- test: -463.5205993652344 \n",
      "Root Mean Squared Error -- train: 0.2702024281024933, -- test: 3.1452534198760986 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -463.5205993652344\n",
      "Test Root MSE of all sampled models: 3.1452534198760986\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -180.62353515625\n",
      "Test Root MSE of all models in window: 2.587023973464966\n",
      "\n",
      "############### EM step 8 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.2187583446502686 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 9 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -2.031052589416504, -- test: -444.4897766113281 \n",
      "Root Mean Squared Error -- train: 0.2693331837654114, -- test: 3.0935914516448975 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -444.4897766113281\n",
      "Test Root MSE of all sampled models: 3.0935914516448975\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -190.7349853515625\n",
      "Test Root MSE of all models in window: 2.6938517093658447\n",
      "\n",
      "############### EM step 9 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.2904136180877686 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 10 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -1.935917615890503, -- test: -440.0581970214844 \n",
      "Root Mean Squared Error -- train: 0.26652881503105164, -- test: 3.0920329093933105 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -440.0581970214844\n",
      "Test Root MSE of all sampled models: 3.0920329093933105\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -243.03204345703125\n",
      "Test Root MSE of all models in window: 2.7947194576263428\n",
      "\n",
      "############### EM step 10 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.621532440185547 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 11 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -1.95766019821167, -- test: -401.41741943359375 \n",
      "Root Mean Squared Error -- train: 0.268464058637619, -- test: 2.9672927856445312 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -401.41741943359375\n",
      "Test Root MSE of all sampled models: 2.9672927856445312\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -274.8302001953125\n",
      "Test Root MSE of all models in window: 2.8580856323242188\n",
      "\n",
      "############### EM step 11 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7208030223846436 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 12 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -1.9141820669174194, -- test: -374.48187255859375 \n",
      "Root Mean Squared Error -- train: 0.2677214443683624, -- test: 2.879467010498047 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -374.48187255859375\n",
      "Test Root MSE of all sampled models: 2.879467010498047\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -292.5643615722656\n",
      "Test Root MSE of all models in window: 2.8981471061706543\n",
      "\n",
      "############### EM step 12 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.5201767086982727 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 13 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -1.6945077180862427, -- test: -430.2198486328125 \n",
      "Root Mean Squared Error -- train: 0.25945308804512024, -- test: 3.0990662574768066 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -430.2198486328125\n",
      "Test Root MSE of all sampled models: 3.0990662574768066\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -292.305419921875\n",
      "Test Root MSE of all models in window: 2.949833631515503\n",
      "\n",
      "############### EM step 13 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.8457362055778503 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 14 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -1.556128978729248, -- test: -450.0570373535156 \n",
      "Root Mean Squared Error -- train: 0.25433439016342163, -- test: 3.182882308959961 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -450.0570373535156\n",
      "Test Root MSE of all sampled models: 3.182882308959961\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -320.4477844238281\n",
      "Test Root MSE of all models in window: 3.0110721588134766\n",
      "\n",
      "############### EM step 14 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.0854837894439697 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 15 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -1.4884166717529297, -- test: -414.8836669921875 \n",
      "Root Mean Squared Error -- train: 0.2522130608558655, -- test: 3.0694215297698975 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -414.8836669921875\n",
      "Test Root MSE of all sampled models: 3.0694215297698975\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -336.1815490722656\n",
      "Test Root MSE of all models in window: 3.0397019386291504\n",
      "\n",
      "############### EM step 15 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.6861209869384766 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 16 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -1.421501636505127, -- test: -382.5408630371094 \n",
      "Root Mean Squared Error -- train: 0.2500630021095276, -- test: 2.9603383541107178 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -382.5408630371094\n",
      "Test Root MSE of all sampled models: 2.9603383541107178\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -334.06231689453125\n",
      "Test Root MSE of all models in window: 3.0522472858428955\n",
      "\n",
      "############### EM step 16 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.0088706016540527 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 17 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -1.2415825128555298, -- test: -420.7470703125 \n",
      "Root Mean Squared Error -- train: 0.24254897236824036, -- test: 3.1175453662872314 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -420.7470703125\n",
      "Test Root MSE of all sampled models: 3.1175453662872314\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -335.7884521484375\n",
      "Test Root MSE of all models in window: 3.062005043029785\n",
      "\n",
      "############### EM step 17 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2589772939682007 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 18 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -1.2295202016830444, -- test: -408.3553466796875 \n",
      "Root Mean Squared Error -- train: 0.24280193448066711, -- test: 3.0844860076904297 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -408.3553466796875\n",
      "Test Root MSE of all sampled models: 3.0844860076904297\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -311.86688232421875\n",
      "Test Root MSE of all models in window: 3.055817127227783\n",
      "\n",
      "############### EM step 18 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.5906206369400024 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 19 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -1.1306359767913818, -- test: -390.8744201660156 \n",
      "Root Mean Squared Error -- train: 0.23880182206630707, -- test: 3.0303263664245605 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -390.8744201660156\n",
      "Test Root MSE of all sampled models: 3.0303263664245605\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -311.07891845703125\n",
      "Test Root MSE of all models in window: 3.049471378326416\n",
      "\n",
      "############### EM step 19 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.7886115312576294 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 20 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.9826000332832336, -- test: -432.0657958984375 \n",
      "Root Mean Squared Error -- train: 0.23215366899967194, -- test: 3.198228120803833 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -432.0657958984375\n",
      "Test Root MSE of all sampled models: 3.198228120803833\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -308.9820251464844\n",
      "Test Root MSE of all models in window: 3.0604043006896973\n",
      "\n",
      "############### EM step 20 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7456305027008057 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 21 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.9831619262695312, -- test: -396.911376953125 \n",
      "Root Mean Squared Error -- train: 0.23291631042957306, -- test: 3.0781681537628174 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -396.911376953125\n",
      "Test Root MSE of all sampled models: 3.0781681537628174\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -300.127197265625\n",
      "Test Root MSE of all models in window: 3.071335792541504\n",
      "\n",
      "############### EM step 21 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.3672286570072174 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 22 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.8830697536468506, -- test: -405.0572204589844 \n",
      "Root Mean Squared Error -- train: 0.2284286469221115, -- test: 3.1215758323669434 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -405.0572204589844\n",
      "Test Root MSE of all sampled models: 3.1215758323669434\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -324.9049072265625\n",
      "Test Root MSE of all models in window: 3.094898223876953\n",
      "\n",
      "############### EM step 22 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1370924711227417 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 23 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.9454748630523682, -- test: -335.056884765625 \n",
      "Root Mean Squared Error -- train: 0.2323768585920334, -- test: 2.8509793281555176 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -335.056884765625\n",
      "Test Root MSE of all sampled models: 2.8509793281555176\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -300.1547546386719\n",
      "Test Root MSE of all models in window: 3.070957899093628\n",
      "\n",
      "############### EM step 23 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.326277732849121 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 24 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.7400140166282654, -- test: -362.57244873046875 \n",
      "Root Mean Squared Error -- train: 0.22208301723003387, -- test: 2.976795196533203 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -362.57244873046875\n",
      "Test Root MSE of all sampled models: 2.976795196533203\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -294.6377868652344\n",
      "Test Root MSE of all models in window: 3.0502192974090576\n",
      "\n",
      "############### EM step 24 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.16877540946006775 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 25 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.6487175226211548, -- test: -366.8988342285156 \n",
      "Root Mean Squared Error -- train: 0.21761548519134521, -- test: 3.005525588989258 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -366.8988342285156\n",
      "Test Root MSE of all sampled models: 3.005525588989258\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -294.17108154296875\n",
      "Test Root MSE of all models in window: 3.0438497066497803\n",
      "\n",
      "############### EM step 25 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3659462928771973 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 26 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.5376899838447571, -- test: -395.65386962890625 \n",
      "Root Mean Squared Error -- train: 0.2118372917175293, -- test: 3.1323599815368652 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -395.65386962890625\n",
      "Test Root MSE of all sampled models: 3.1323599815368652\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -299.5653381347656\n",
      "Test Root MSE of all models in window: 3.0610177516937256\n",
      "\n",
      "############### EM step 26 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.049923211336135864 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 27 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.5282495021820068, -- test: -396.08575439453125 \n",
      "Root Mean Squared Error -- train: 0.21182729303836823, -- test: 3.1451668739318848 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -396.08575439453125\n",
      "Test Root MSE of all sampled models: 3.1451668739318848\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -309.0560607910156\n",
      "Test Root MSE of all models in window: 3.0638420581817627\n",
      "\n",
      "############### EM step 27 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.4525609016418457 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 28 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.32879841327667236, -- test: -449.13055419921875 \n",
      "Root Mean Squared Error -- train: 0.20023852586746216, -- test: 3.360085964202881 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -449.13055419921875\n",
      "Test Root MSE of all sampled models: 3.360085964202881\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -309.5594482421875\n",
      "Test Root MSE of all models in window: 3.092691421508789\n",
      "\n",
      "############### EM step 28 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.10125801712274551 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 29 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.0809336006641388, -- test: -494.7324523925781 \n",
      "Root Mean Squared Error -- train: 0.1844552755355835, -- test: 3.537761688232422 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -494.7324523925781\n",
      "Test Root MSE of all sampled models: 3.537761688232422\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -311.0328063964844\n",
      "Test Root MSE of all models in window: 3.146113157272339\n",
      "\n",
      "############### EM step 29 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.0768098384141922 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 30 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.03967409208416939, -- test: -514.155029296875 \n",
      "Root Mean Squared Error -- train: 0.17634393274784088, -- test: 3.617825508117676 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -514.155029296875\n",
      "Test Root MSE of all sampled models: 3.617825508117676\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -312.36041259765625\n",
      "Test Root MSE of all models in window: 3.191242218017578\n",
      "\n",
      "############### EM step 30 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.20267896354198456 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 31 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.0018032471416518092, -- test: -502.5201416015625 \n",
      "Root Mean Squared Error -- train: 0.1796397566795349, -- test: 3.587782382965088 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -502.5201416015625\n",
      "Test Root MSE of all sampled models: 3.587782382965088\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -313.1681213378906\n",
      "Test Root MSE of all models in window: 3.244030714035034\n",
      "\n",
      "############### EM step 31 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.5087048411369324 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 32 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.04791293293237686, -- test: -425.0932922363281 \n",
      "Root Mean Squared Error -- train: 0.18321257829666138, -- test: 3.31001353263855 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -425.0932922363281\n",
      "Test Root MSE of all sampled models: 3.31001353263855\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -313.111572265625\n",
      "Test Root MSE of all models in window: 3.2626566886901855\n",
      "\n",
      "############### EM step 32 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.5692095756530762 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 33 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: -0.009023181162774563, -- test: -414.32891845703125 \n",
      "Root Mean Squared Error -- train: 0.18077737092971802, -- test: 3.277315616607666 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -414.32891845703125\n",
      "Test Root MSE of all sampled models: 3.277315616607666\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -339.979736328125\n",
      "Test Root MSE of all models in window: 3.3024537563323975\n",
      "\n",
      "############### EM step 33 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.01983671821653843 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 34 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.2038741260766983, -- test: -452.9917907714844 \n",
      "Root Mean Squared Error -- train: 0.16509594023227692, -- test: 3.4358153343200684 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -452.9917907714844\n",
      "Test Root MSE of all sampled models: 3.4358153343200684\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -337.7021179199219\n",
      "Test Root MSE of all models in window: 3.3467228412628174\n",
      "\n",
      "############### EM step 34 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.3572825491428375 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 35 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.31947049498558044, -- test: -499.11993408203125 \n",
      "Root Mean Squared Error -- train: 0.15591946244239807, -- test: 3.615394353866577 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -499.11993408203125\n",
      "Test Root MSE of all sampled models: 3.615394353866577\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -349.6545715332031\n",
      "Test Root MSE of all models in window: 3.406514883041382\n",
      "\n",
      "############### EM step 35 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.1460452377796173 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 36 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.38597238063812256, -- test: -491.9701843261719 \n",
      "Root Mean Squared Error -- train: 0.15040238201618195, -- test: 3.598390817642212 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -491.9701843261719\n",
      "Test Root MSE of all sampled models: 3.598390817642212\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -348.8778991699219\n",
      "Test Root MSE of all models in window: 3.4522478580474854\n",
      "\n",
      "############### EM step 36 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.5372219681739807 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 37 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.5525649189949036, -- test: -530.0247802734375 \n",
      "Root Mean Squared Error -- train: 0.13516981899738312, -- test: 3.7432472705841064 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -530.0247802734375\n",
      "Test Root MSE of all sampled models: 3.7432472705841064\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -372.3157958984375\n",
      "Test Root MSE of all models in window: 3.5114097595214844\n",
      "\n",
      "############### EM step 37 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.4816604554653168 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 38 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.45459529757499695, -- test: -490.3610534667969 \n",
      "Root Mean Squared Error -- train: 0.14452609419822693, -- test: 3.608572244644165 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -490.3610534667969\n",
      "Test Root MSE of all sampled models: 3.608572244644165\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -374.9101257324219\n",
      "Test Root MSE of all models in window: 3.5359809398651123\n",
      "\n",
      "############### EM step 38 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.6278740167617798 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 39 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.5911909937858582, -- test: -486.1607360839844 \n",
      "Root Mean Squared Error -- train: 0.13147445023059845, -- test: 3.600269079208374 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -486.1607360839844\n",
      "Test Root MSE of all sampled models: 3.600269079208374\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -376.969970703125\n",
      "Test Root MSE of all models in window: 3.5422842502593994\n",
      "\n",
      "############### EM step 39 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.5545300245285034 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 40 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.7192644476890564, -- test: -527.4676513671875 \n",
      "Root Mean Squared Error -- train: 0.11782030016183853, -- test: 3.75666880607605 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -527.4676513671875\n",
      "Test Root MSE of all sampled models: 3.75666880607605\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -372.8270568847656\n",
      "Test Root MSE of all models in window: 3.5567076206207275\n",
      "\n",
      "############### EM step 40 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.6444749236106873 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 41 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.7024931311607361, -- test: -473.5556640625 \n",
      "Root Mean Squared Error -- train: 0.11971872299909592, -- test: 3.5660595893859863 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -473.5556640625\n",
      "Test Root MSE of all sampled models: 3.5660595893859863\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -371.6016845703125\n",
      "Test Root MSE of all models in window: 3.5545222759246826\n",
      "\n",
      "############### EM step 41 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.6213353276252747 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 42 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.6931869983673096, -- test: -427.79632568359375 \n",
      "Root Mean Squared Error -- train: 0.12077053636312485, -- test: 3.3952128887176514 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -427.79632568359375\n",
      "Test Root MSE of all sampled models: 3.3952128887176514\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -371.37823486328125\n",
      "Test Root MSE of all models in window: 3.562549114227295\n",
      "\n",
      "############### EM step 42 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.8387762308120728 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 43 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.7255668640136719, -- test: -423.1886291503906 \n",
      "Root Mean Squared Error -- train: 0.11711646616458893, -- test: 3.381701946258545 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -423.1886291503906\n",
      "Test Root MSE of all sampled models: 3.381701946258545\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -387.0287780761719\n",
      "Test Root MSE of all models in window: 3.572291374206543\n",
      "\n",
      "############### EM step 43 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.8647210001945496 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 44 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.685500979423523, -- test: -383.32196044921875 \n",
      "Root Mean Squared Error -- train: 0.12165158987045288, -- test: 3.22300124168396 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -383.32196044921875\n",
      "Test Root MSE of all sampled models: 3.22300124168396\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -360.9639587402344\n",
      "Test Root MSE of all models in window: 3.552401542663574\n",
      "\n",
      "############### EM step 44 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.9106237292289734 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 45 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.8016102313995361, -- test: -377.3978271484375 \n",
      "Root Mean Squared Error -- train: 0.10797514766454697, -- test: 3.201597213745117 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -377.3978271484375\n",
      "Test Root MSE of all sampled models: 3.201597213745117\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -351.2611999511719\n",
      "Test Root MSE of all models in window: 3.5124738216400146\n",
      "\n",
      "############### EM step 45 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.5919885635375977 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 46 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.8955567479133606, -- test: -421.6138000488281 \n",
      "Root Mean Squared Error -- train: 0.09542611241340637, -- test: 3.3868730068206787 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -421.6138000488281\n",
      "Test Root MSE of all sampled models: 3.3868730068206787\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -348.0828857421875\n",
      "Test Root MSE of all models in window: 3.49137806892395\n",
      "\n",
      "############### EM step 46 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.9648555517196655 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 47 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.9361724257469177, -- test: -415.7510070800781 \n",
      "Root Mean Squared Error -- train: 0.08941172063350677, -- test: 3.3662850856781006 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -415.7510070800781\n",
      "Test Root MSE of all sampled models: 3.3662850856781006\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -322.18243408203125\n",
      "Test Root MSE of all models in window: 3.4527840614318848\n",
      "\n",
      "############### EM step 47 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 1.0206058025360107 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 48 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.9844457507133484, -- test: -367.93707275390625 \n",
      "Root Mean Squared Error -- train: 0.08168482035398483, -- test: 3.1697347164154053 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -367.93707275390625\n",
      "Test Root MSE of all sampled models: 3.1697347164154053\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -294.1571044921875\n",
      "Test Root MSE of all models in window: 3.409437417984009\n",
      "\n",
      "############### EM step 48 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.8293519020080566 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 49 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.9287732243537903, -- test: -309.6260986328125 \n",
      "Root Mean Squared Error -- train: 0.09044665098190308, -- test: 2.910517930984497 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -309.6260986328125\n",
      "Test Root MSE of all sampled models: 2.910517930984497\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -271.2933654785156\n",
      "Test Root MSE of all models in window: 3.3429298400878906\n",
      "\n",
      "############### EM step 49 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.9067522883415222 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 50 of total 50 steps. E Step:  ###############\n",
      "#################### Sample No.1 at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Sampling Epoch: 49\n",
      "Mean Log Likelihood -- train: 0.9561519026756287, -- test: -330.6441650390625 \n",
      "Root Mean Squared Error -- train: 0.08618458360433578, -- test: 3.0089306831359863 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -330.6441650390625\n",
      "Test Root MSE of all sampled models: 3.0089306831359863\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -270.4502868652344\n",
      "Test Root MSE of all models in window: 3.266387701034546\n",
      "\n",
      "############### EM step 50 of total 50 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is 0.8839739561080933 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### After 50 EM steps, fixing hyperparams and sample from posterior. ###############\n",
      "#################### Sample No.1 at Epoch 99  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: 0.9154055118560791, -- test: -269.2406921386719 \n",
      "Root Mean Squared Error -- train: 0.09238360077142715, -- test: 2.717578172683716 \n",
      "\n",
      "#################### Sample No.2 at Epoch 199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: 0.8611863255500793, -- test: -255.72225952148438 \n",
      "Root Mean Squared Error -- train: 0.10007596760988235, -- test: 2.6487932205200195 \n",
      "\n",
      "#################### Sample No.3 at Epoch 299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: 0.901749312877655, -- test: -318.3948974609375 \n",
      "Root Mean Squared Error -- train: 0.09438017755746841, -- test: 2.9542176723480225 \n",
      "\n",
      "#################### Sample No.4 at Epoch 399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: 0.8037601113319397, -- test: -298.4291687011719 \n",
      "Root Mean Squared Error -- train: 0.10762547701597214, -- test: 2.860460042953491 \n",
      "\n",
      "#################### Sample No.5 at Epoch 499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: 0.7525544762611389, -- test: -260.425048828125 \n",
      "Root Mean Squared Error -- train: 0.11393607407808304, -- test: 2.6729230880737305 \n",
      "\n",
      "#################### Sample No.6 at Epoch 599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: 0.8319166898727417, -- test: -263.6063537597656 \n",
      "Root Mean Squared Error -- train: 0.10399238765239716, -- test: 2.6891229152679443 \n",
      "\n",
      "#################### Sample No.7 at Epoch 699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: 0.9464312195777893, -- test: -371.333740234375 \n",
      "Root Mean Squared Error -- train: 0.08767874538898468, -- test: 3.189500570297241 \n",
      "\n",
      "#################### Sample No.8 at Epoch 799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: 0.8798387050628662, -- test: -316.7038269042969 \n",
      "Root Mean Squared Error -- train: 0.09749817103147507, -- test: 2.946392059326172 \n",
      "\n",
      "#################### Sample No.9 at Epoch 899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: 0.8635699152946472, -- test: -324.883056640625 \n",
      "Root Mean Squared Error -- train: 0.09975027292966843, -- test: 2.984051465988159 \n",
      "\n",
      "#################### Sample No.10 at Epoch 999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: 0.9488725662231445, -- test: -389.6211242675781 \n",
      "Root Mean Squared Error -- train: 0.08729776740074158, -- test: 3.2668416500091553 \n",
      "\n",
      "#################### Sample No.11 at Epoch 1099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 1099\n",
      "Mean Log Likelihood -- train: 0.8079479336738586, -- test: -338.2593688964844 \n",
      "Root Mean Squared Error -- train: 0.10709290951490402, -- test: 3.044635772705078 \n",
      "\n",
      "#################### Sample No.12 at Epoch 1199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 1199\n",
      "Mean Log Likelihood -- train: 0.6974403858184814, -- test: -302.840576171875 \n",
      "Root Mean Squared Error -- train: 0.12035918980836868, -- test: 2.8814380168914795 \n",
      "\n",
      "#################### Sample No.13 at Epoch 1299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 1299\n",
      "Mean Log Likelihood -- train: 0.7893759608268738, -- test: -341.30255126953125 \n",
      "Root Mean Squared Error -- train: 0.10943493247032166, -- test: 3.05825138092041 \n",
      "\n",
      "#################### Sample No.14 at Epoch 1399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 1399\n",
      "Mean Log Likelihood -- train: 0.8727551102638245, -- test: -359.7054748535156 \n",
      "Root Mean Squared Error -- train: 0.0984850823879242, -- test: 3.139331102371216 \n",
      "\n",
      "#################### Sample No.15 at Epoch 1499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 1499\n",
      "Mean Log Likelihood -- train: 0.9209916591644287, -- test: -366.40899658203125 \n",
      "Root Mean Squared Error -- train: 0.09155435115098953, -- test: 3.1683499813079834 \n",
      "\n",
      "#################### Sample No.16 at Epoch 1599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 1599\n",
      "Mean Log Likelihood -- train: 0.8827452063560486, -- test: -343.459716796875 \n",
      "Root Mean Squared Error -- train: 0.09709031134843826, -- test: 3.067866325378418 \n",
      "\n",
      "#################### Sample No.17 at Epoch 1699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 1699\n",
      "Mean Log Likelihood -- train: 0.9934882521629333, -- test: -401.6370849609375 \n",
      "Root Mean Squared Error -- train: 0.08001659065485, -- test: 3.316678285598755 \n",
      "\n",
      "#################### Sample No.18 at Epoch 1799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 1799\n",
      "Mean Log Likelihood -- train: 0.9467769861221313, -- test: -351.3584899902344 \n",
      "Root Mean Squared Error -- train: 0.08762489259243011, -- test: 3.102818727493286 \n",
      "\n",
      "#################### Sample No.19 at Epoch 1899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 1899\n",
      "Mean Log Likelihood -- train: 0.961520254611969, -- test: -382.0015869140625 \n",
      "Root Mean Squared Error -- train: 0.08529684692621231, -- test: 3.234841823577881 \n",
      "\n",
      "#################### Sample No.20 at Epoch 1999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 1999\n",
      "Mean Log Likelihood -- train: 0.9291061162948608, -- test: -349.3925476074219 \n",
      "Root Mean Squared Error -- train: 0.09033621102571487, -- test: 3.09415602684021 \n",
      "\n",
      "#################### Sample No.21 at Epoch 2099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 2099\n",
      "Mean Log Likelihood -- train: 0.7988736629486084, -- test: -329.5164489746094 \n",
      "Root Mean Squared Error -- train: 0.10824355483055115, -- test: 3.0051753520965576 \n",
      "\n",
      "#################### Sample No.22 at Epoch 2199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 2199\n",
      "Mean Log Likelihood -- train: 0.9072631597518921, -- test: -371.2100524902344 \n",
      "Root Mean Squared Error -- train: 0.09357915073633194, -- test: 3.1889708042144775 \n",
      "\n",
      "#################### Sample No.23 at Epoch 2299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 2299\n",
      "Mean Log Likelihood -- train: 0.8749691247940063, -- test: -335.1353759765625 \n",
      "Root Mean Squared Error -- train: 0.09817768633365631, -- test: 3.030595064163208 \n",
      "\n",
      "#################### Sample No.24 at Epoch 2399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 2399\n",
      "Mean Log Likelihood -- train: 0.9240598082542419, -- test: -374.1033630371094 \n",
      "Root Mean Squared Error -- train: 0.09109567105770111, -- test: 3.201333999633789 \n",
      "\n",
      "#################### Sample No.25 at Epoch 2499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 2499\n",
      "Mean Log Likelihood -- train: 0.9615684747695923, -- test: -357.4005126953125 \n",
      "Root Mean Squared Error -- train: 0.0852891281247139, -- test: 3.12929105758667 \n",
      "\n",
      "#################### Sample No.26 at Epoch 2599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 2599\n",
      "Mean Log Likelihood -- train: 0.9215647578239441, -- test: -358.06817626953125 \n",
      "Root Mean Squared Error -- train: 0.09146884083747864, -- test: 3.132202386856079 \n",
      "\n",
      "#################### Sample No.27 at Epoch 2699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 2699\n",
      "Mean Log Likelihood -- train: 0.8813279271125793, -- test: -379.8958740234375 \n",
      "Root Mean Squared Error -- train: 0.09728939831256866, -- test: 3.2259421348571777 \n",
      "\n",
      "#################### Sample No.28 at Epoch 2799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 2799\n",
      "Mean Log Likelihood -- train: 0.9864046573638916, -- test: -369.4942626953125 \n",
      "Root Mean Squared Error -- train: 0.08121621608734131, -- test: 3.18161678314209 \n",
      "\n",
      "#################### Sample No.29 at Epoch 2899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 2899\n",
      "Mean Log Likelihood -- train: 0.9545912146568298, -- test: -353.47991943359375 \n",
      "Root Mean Squared Error -- train: 0.08639878034591675, -- test: 3.1121389865875244 \n",
      "\n",
      "#################### Sample No.30 at Epoch 2999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 2999\n",
      "Mean Log Likelihood -- train: 1.0120463371276855, -- test: -369.3810119628906 \n",
      "Root Mean Squared Error -- train: 0.07678490877151489, -- test: 3.181130886077881 \n",
      "\n",
      "#################### Sample No.31 at Epoch 3099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 3099\n",
      "Mean Log Likelihood -- train: 1.0281622409820557, -- test: -407.03582763671875 \n",
      "Root Mean Squared Error -- train: 0.07386387884616852, -- test: 3.338827610015869 \n",
      "\n",
      "#################### Sample No.32 at Epoch 3199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 3199\n",
      "Mean Log Likelihood -- train: 0.9314711689949036, -- test: -389.6213684082031 \n",
      "Root Mean Squared Error -- train: 0.08997804671525955, -- test: 3.266842842102051 \n",
      "\n",
      "#################### Sample No.33 at Epoch 3299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 3299\n",
      "Mean Log Likelihood -- train: 0.8144832849502563, -- test: -372.4203796386719 \n",
      "Root Mean Squared Error -- train: 0.10625649243593216, -- test: 3.1941487789154053 \n",
      "\n",
      "#################### Sample No.34 at Epoch 3399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 3399\n",
      "Mean Log Likelihood -- train: 0.707369863986969, -- test: -313.5173645019531 \n",
      "Root Mean Squared Error -- train: 0.11922754347324371, -- test: 2.9315898418426514 \n",
      "\n",
      "#################### Sample No.35 at Epoch 3499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 3499\n",
      "Mean Log Likelihood -- train: 0.7858836054801941, -- test: -304.128173828125 \n",
      "Root Mean Squared Error -- train: 0.10986976325511932, -- test: 2.8875324726104736 \n",
      "\n",
      "#################### Sample No.36 at Epoch 3599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 3599\n",
      "Mean Log Likelihood -- train: 0.761205792427063, -- test: -279.96124267578125 \n",
      "Root Mean Squared Error -- train: 0.11289464682340622, -- test: 2.7709128856658936 \n",
      "\n",
      "#################### Sample No.37 at Epoch 3699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 3699\n",
      "Mean Log Likelihood -- train: 0.7776265740394592, -- test: -314.7395324707031 \n",
      "Root Mean Squared Error -- train: 0.11089105159044266, -- test: 2.9372763633728027 \n",
      "\n",
      "#################### Sample No.38 at Epoch 3799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 3799\n",
      "Mean Log Likelihood -- train: 0.8839629888534546, -- test: -374.82733154296875 \n",
      "Root Mean Squared Error -- train: 0.09691892564296722, -- test: 3.2044198513031006 \n",
      "\n",
      "#################### Sample No.39 at Epoch 3899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 3899\n",
      "Mean Log Likelihood -- train: 0.9035596251487732, -- test: -348.4910888671875 \n",
      "Root Mean Squared Error -- train: 0.09411793202161789, -- test: 3.0901763439178467 \n",
      "\n",
      "#################### Sample No.40 at Epoch 3999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 3999\n",
      "Mean Log Likelihood -- train: 0.8873327970504761, -- test: -397.8632507324219 \n",
      "Root Mean Squared Error -- train: 0.0964430645108223, -- test: 3.301107168197632 \n",
      "\n",
      "#################### Sample No.41 at Epoch 4099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 4099\n",
      "Mean Log Likelihood -- train: 0.8941953778266907, -- test: -392.4641418457031 \n",
      "Root Mean Squared Error -- train: 0.09546664357185364, -- test: 3.2787017822265625 \n",
      "\n",
      "#################### Sample No.42 at Epoch 4199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 4199\n",
      "Mean Log Likelihood -- train: 0.7760359048843384, -- test: -345.062744140625 \n",
      "Root Mean Squared Error -- train: 0.11108671873807907, -- test: 3.0749919414520264 \n",
      "\n",
      "#################### Sample No.43 at Epoch 4299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 4299\n",
      "Mean Log Likelihood -- train: 0.7885790467262268, -- test: -332.2103271484375 \n",
      "Root Mean Squared Error -- train: 0.10953430086374283, -- test: 3.0173888206481934 \n",
      "\n",
      "#################### Sample No.44 at Epoch 4399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 4399\n",
      "Mean Log Likelihood -- train: 0.8801385164260864, -- test: -337.51116943359375 \n",
      "Root Mean Squared Error -- train: 0.0974561795592308, -- test: 3.041278839111328 \n",
      "\n",
      "#################### Sample No.45 at Epoch 4499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 4499\n",
      "Mean Log Likelihood -- train: 0.8900330662727356, -- test: -342.6160888671875 \n",
      "Root Mean Squared Error -- train: 0.09606003761291504, -- test: 3.0641095638275146 \n",
      "\n",
      "#################### Sample No.46 at Epoch 4599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 4599\n",
      "Mean Log Likelihood -- train: 0.9430274963378906, -- test: -326.61053466796875 \n",
      "Root Mean Squared Error -- train: 0.08820714801549911, -- test: 2.9919447898864746 \n",
      "\n",
      "#################### Sample No.47 at Epoch 4699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 4699\n",
      "Mean Log Likelihood -- train: 0.9921424388885498, -- test: -362.604248046875 \n",
      "Root Mean Squared Error -- train: 0.08024589717388153, -- test: 3.1519124507904053 \n",
      "\n",
      "#################### Sample No.48 at Epoch 4799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 4799\n",
      "Mean Log Likelihood -- train: 0.8977682590484619, -- test: -309.6542663574219 \n",
      "Root Mean Squared Error -- train: 0.09495430439710617, -- test: 2.913543701171875 \n",
      "\n",
      "#################### Sample No.49 at Epoch 4899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 4899\n",
      "Mean Log Likelihood -- train: 0.9669564366340637, -- test: -350.4097595214844 \n",
      "Root Mean Squared Error -- train: 0.08442223072052002, -- test: 3.0986413955688477 \n",
      "\n",
      "#################### Sample No.50 at Epoch 4999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 4999\n",
      "Mean Log Likelihood -- train: 0.8593297600746155, -- test: -327.4774475097656 \n",
      "Root Mean Squared Error -- train: 0.10032893717288971, -- test: 2.9958977699279785 \n",
      "\n",
      "#################### Sample No.51 at Epoch 5099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 5099\n",
      "Mean Log Likelihood -- train: 0.8884144425392151, -- test: -321.007080078125 \n",
      "Root Mean Squared Error -- train: 0.09628981351852417, -- test: 2.9662652015686035 \n",
      "\n",
      "#################### Sample No.52 at Epoch 5199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 5199\n",
      "Mean Log Likelihood -- train: 0.8967472314834595, -- test: -293.08367919921875 \n",
      "Root Mean Squared Error -- train: 0.095100998878479, -- test: 2.834831476211548 \n",
      "\n",
      "#################### Sample No.53 at Epoch 5299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 5299\n",
      "Mean Log Likelihood -- train: 0.8952316045761108, -- test: -339.1082763671875 \n",
      "Root Mean Squared Error -- train: 0.09531831741333008, -- test: 3.0484399795532227 \n",
      "\n",
      "#################### Sample No.54 at Epoch 5399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 5399\n",
      "Mean Log Likelihood -- train: 0.9362510442733765, -- test: -361.2218017578125 \n",
      "Root Mean Squared Error -- train: 0.08924984931945801, -- test: 3.145918607711792 \n",
      "\n",
      "#################### Sample No.55 at Epoch 5499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 5499\n",
      "Mean Log Likelihood -- train: 0.9247984290122986, -- test: -363.1483154296875 \n",
      "Root Mean Squared Error -- train: 0.09098489582538605, -- test: 3.154268264770508 \n",
      "\n",
      "#################### Sample No.56 at Epoch 5599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 5599\n",
      "Mean Log Likelihood -- train: 0.9737720489501953, -- test: -392.9925842285156 \n",
      "Root Mean Squared Error -- train: 0.0833127349615097, -- test: 3.2809014320373535 \n",
      "\n",
      "#################### Sample No.57 at Epoch 5699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 5699\n",
      "Mean Log Likelihood -- train: 0.9822845458984375, -- test: -393.26800537109375 \n",
      "Root Mean Squared Error -- train: 0.08190590143203735, -- test: 3.2820475101470947 \n",
      "\n",
      "#################### Sample No.58 at Epoch 5799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 5799\n",
      "Mean Log Likelihood -- train: 0.9166194796562195, -- test: -372.9766540527344 \n",
      "Root Mean Squared Error -- train: 0.0922040194272995, -- test: 3.1965250968933105 \n",
      "\n",
      "#################### Sample No.59 at Epoch 5899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 5899\n",
      "Mean Log Likelihood -- train: 0.9027506113052368, -- test: -359.92437744140625 \n",
      "Root Mean Squared Error -- train: 0.09423521161079407, -- test: 3.1402831077575684 \n",
      "\n",
      "#################### Sample No.60 at Epoch 5999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 5999\n",
      "Mean Log Likelihood -- train: 0.8992012143135071, -- test: -367.40545654296875 \n",
      "Root Mean Squared Error -- train: 0.09474805742502213, -- test: 3.1726410388946533 \n",
      "\n",
      "#################### Sample No.61 at Epoch 6099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 6099\n",
      "Mean Log Likelihood -- train: 0.9317263960838318, -- test: -387.5866394042969 \n",
      "Root Mean Squared Error -- train: 0.08993932604789734, -- test: 3.258328437805176 \n",
      "\n",
      "#################### Sample No.62 at Epoch 6199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 6199\n",
      "Mean Log Likelihood -- train: 0.8436068296432495, -- test: -401.447509765625 \n",
      "Root Mean Squared Error -- train: 0.10244614630937576, -- test: 3.3158979415893555 \n",
      "\n",
      "#################### Sample No.63 at Epoch 6299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 6299\n",
      "Mean Log Likelihood -- train: 0.8114668726921082, -- test: -330.7549133300781 \n",
      "Root Mean Squared Error -- train: 0.10664336383342743, -- test: 3.010796546936035 \n",
      "\n",
      "#################### Sample No.64 at Epoch 6399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 6399\n",
      "Mean Log Likelihood -- train: 0.8312036395072937, -- test: -342.18218994140625 \n",
      "Root Mean Squared Error -- train: 0.10408595949411392, -- test: 3.062175989151001 \n",
      "\n",
      "#################### Sample No.65 at Epoch 6499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 6499\n",
      "Mean Log Likelihood -- train: 0.9364067912101746, -- test: -391.108642578125 \n",
      "Root Mean Squared Error -- train: 0.08922602981328964, -- test: 3.273052453994751 \n",
      "\n",
      "#################### Sample No.66 at Epoch 6599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 6599\n",
      "Mean Log Likelihood -- train: 0.930450975894928, -- test: -386.3305969238281 \n",
      "Root Mean Squared Error -- train: 0.09013272821903229, -- test: 3.253061532974243 \n",
      "\n",
      "#################### Sample No.67 at Epoch 6699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 6699\n",
      "Mean Log Likelihood -- train: 0.8571584820747375, -- test: -336.3816833496094 \n",
      "Root Mean Squared Error -- train: 0.1006239727139473, -- test: 3.0362045764923096 \n",
      "\n",
      "#################### Sample No.68 at Epoch 6799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 6799\n",
      "Mean Log Likelihood -- train: 0.7783666849136353, -- test: -323.14727783203125 \n",
      "Root Mean Squared Error -- train: 0.11079990118741989, -- test: 2.9760994911193848 \n",
      "\n",
      "#################### Sample No.69 at Epoch 6899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 6899\n",
      "Mean Log Likelihood -- train: 0.8298189043998718, -- test: -367.4756164550781 \n",
      "Root Mean Squared Error -- train: 0.1042674332857132, -- test: 3.172942876815796 \n",
      "\n",
      "#################### Sample No.70 at Epoch 6999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 6999\n",
      "Mean Log Likelihood -- train: 0.7847257256507874, -- test: -332.2452697753906 \n",
      "Root Mean Squared Error -- train: 0.11001355946063995, -- test: 3.017547130584717 \n",
      "\n",
      "#################### Sample No.71 at Epoch 7099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 7099\n",
      "Mean Log Likelihood -- train: 0.8046007752418518, -- test: -319.7337646484375 \n",
      "Root Mean Squared Error -- train: 0.107518769800663, -- test: 2.9603984355926514 \n",
      "\n",
      "#################### Sample No.72 at Epoch 7199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 7199\n",
      "Mean Log Likelihood -- train: 0.9571049809455872, -- test: -364.1103820800781 \n",
      "Root Mean Squared Error -- train: 0.08600064367055893, -- test: 3.1584298610687256 \n",
      "\n",
      "#################### Sample No.73 at Epoch 7299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 7299\n",
      "Mean Log Likelihood -- train: 0.901925802230835, -- test: -355.644287109375 \n",
      "Root Mean Squared Error -- train: 0.09435463696718216, -- test: 3.121619462966919 \n",
      "\n",
      "#################### Sample No.74 at Epoch 7399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 7399\n",
      "Mean Log Likelihood -- train: 0.8877001404762268, -- test: -360.9810485839844 \n",
      "Root Mean Squared Error -- train: 0.09639103710651398, -- test: 3.1448733806610107 \n",
      "\n",
      "#################### Sample No.75 at Epoch 7499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 7499\n",
      "Mean Log Likelihood -- train: 0.9683235287666321, -- test: -411.030029296875 \n",
      "Root Mean Squared Error -- train: 0.08420087397098541, -- test: 3.3551204204559326 \n",
      "\n",
      "#################### Sample No.76 at Epoch 7599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 7599\n",
      "Mean Log Likelihood -- train: 1.0046513080596924, -- test: -398.4349365234375 \n",
      "Root Mean Squared Error -- train: 0.07808869332075119, -- test: 3.3034708499908447 \n",
      "\n",
      "#################### Sample No.77 at Epoch 7699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 7699\n",
      "Mean Log Likelihood -- train: 0.954321026802063, -- test: -368.0538635253906 \n",
      "Root Mean Squared Error -- train: 0.08644147217273712, -- test: 3.1754300594329834 \n",
      "\n",
      "#################### Sample No.78 at Epoch 7799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 7799\n",
      "Mean Log Likelihood -- train: 0.854243814945221, -- test: -324.92633056640625 \n",
      "Root Mean Squared Error -- train: 0.10101865231990814, -- test: 2.9842493534088135 \n",
      "\n",
      "#################### Sample No.79 at Epoch 7899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 7899\n",
      "Mean Log Likelihood -- train: 0.8598034381866455, -- test: -308.02618408203125 \n",
      "Root Mean Squared Error -- train: 0.10026445239782333, -- test: 2.9059042930603027 \n",
      "\n",
      "#################### Sample No.80 at Epoch 7999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 7999\n",
      "Mean Log Likelihood -- train: 1.0012327432632446, -- test: -374.2095031738281 \n",
      "Root Mean Squared Error -- train: 0.07868409901857376, -- test: 3.201786518096924 \n",
      "\n",
      "#################### Sample No.81 at Epoch 8099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 8099\n",
      "Mean Log Likelihood -- train: 0.8252642750740051, -- test: -352.29229736328125 \n",
      "Root Mean Squared Error -- train: 0.10486211627721786, -- test: 3.1069247722625732 \n",
      "\n",
      "#################### Sample No.82 at Epoch 8199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 8199\n",
      "Mean Log Likelihood -- train: 0.8814563155174255, -- test: -374.0431213378906 \n",
      "Root Mean Squared Error -- train: 0.0972713828086853, -- test: 3.2010772228240967 \n",
      "\n",
      "#################### Sample No.83 at Epoch 8299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 8299\n",
      "Mean Log Likelihood -- train: 0.9126399755477905, -- test: -360.5035400390625 \n",
      "Root Mean Squared Error -- train: 0.09279139339923859, -- test: 3.1428000926971436 \n",
      "\n",
      "#################### Sample No.84 at Epoch 8399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 8399\n",
      "Mean Log Likelihood -- train: 0.9124241471290588, -- test: -343.7832336425781 \n",
      "Root Mean Squared Error -- train: 0.09282314777374268, -- test: 3.069305896759033 \n",
      "\n",
      "#################### Sample No.85 at Epoch 8499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 8499\n",
      "Mean Log Likelihood -- train: 0.9810056686401367, -- test: -334.8579406738281 \n",
      "Root Mean Squared Error -- train: 0.08211880177259445, -- test: 3.0293447971343994 \n",
      "\n",
      "#################### Sample No.86 at Epoch 8599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 8599\n",
      "Mean Log Likelihood -- train: 0.930096447467804, -- test: -337.8677978515625 \n",
      "Root Mean Squared Error -- train: 0.09018640965223312, -- test: 3.042879581451416 \n",
      "\n",
      "#################### Sample No.87 at Epoch 8699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 8699\n",
      "Mean Log Likelihood -- train: 0.8864977955818176, -- test: -294.7281494140625 \n",
      "Root Mean Squared Error -- train: 0.09656117856502533, -- test: 2.842740297317505 \n",
      "\n",
      "#################### Sample No.88 at Epoch 8799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 8799\n",
      "Mean Log Likelihood -- train: 0.8845149874687195, -- test: -321.75030517578125 \n",
      "Root Mean Squared Error -- train: 0.09684114158153534, -- test: 2.9696836471557617 \n",
      "\n",
      "#################### Sample No.89 at Epoch 8899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 8899\n",
      "Mean Log Likelihood -- train: 0.9588474631309509, -- test: -377.61273193359375 \n",
      "Root Mean Squared Error -- train: 0.08572357892990112, -- test: 3.2162654399871826 \n",
      "\n",
      "#################### Sample No.90 at Epoch 8999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 8999\n",
      "Mean Log Likelihood -- train: 0.8382348418235779, -- test: -330.8462829589844 \n",
      "Root Mean Squared Error -- train: 0.10315956920385361, -- test: 3.0112106800079346 \n",
      "\n",
      "#################### Sample No.91 at Epoch 9099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 9099\n",
      "Mean Log Likelihood -- train: 0.7599066495895386, -- test: -283.1850891113281 \n",
      "Root Mean Squared Error -- train: 0.113051638007164, -- test: 2.7867519855499268 \n",
      "\n",
      "#################### Sample No.92 at Epoch 9199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 9199\n",
      "Mean Log Likelihood -- train: 0.7962318658828735, -- test: -301.29241943359375 \n",
      "Root Mean Squared Error -- train: 0.10857626050710678, -- test: 2.874093532562256 \n",
      "\n",
      "#################### Sample No.93 at Epoch 9299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 9299\n",
      "Mean Log Likelihood -- train: 0.892412543296814, -- test: -342.66143798828125 \n",
      "Root Mean Squared Error -- train: 0.09572125226259232, -- test: 3.0643117427825928 \n",
      "\n",
      "#################### Sample No.94 at Epoch 9399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 9399\n",
      "Mean Log Likelihood -- train: 0.9120768308639526, -- test: -314.86358642578125 \n",
      "Root Mean Squared Error -- train: 0.0928742066025734, -- test: 2.937852621078491 \n",
      "\n",
      "#################### Sample No.95 at Epoch 9499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 9499\n",
      "Mean Log Likelihood -- train: 0.8929529786109924, -- test: -326.0106506347656 \n",
      "Root Mean Squared Error -- train: 0.09564414620399475, -- test: 2.989205837249756 \n",
      "\n",
      "#################### Sample No.96 at Epoch 9599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 9599\n",
      "Mean Log Likelihood -- train: 0.9823364019393921, -- test: -385.7769775390625 \n",
      "Root Mean Squared Error -- train: 0.08189724385738373, -- test: 3.250736951828003 \n",
      "\n",
      "#################### Sample No.97 at Epoch 9699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 9699\n",
      "Mean Log Likelihood -- train: 0.8146483302116394, -- test: -296.2483215332031 \n",
      "Root Mean Squared Error -- train: 0.10623528063297272, -- test: 2.850032329559326 \n",
      "\n",
      "#################### Sample No.98 at Epoch 9799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 9799\n",
      "Mean Log Likelihood -- train: 0.9483323693275452, -- test: -375.0958557128906 \n",
      "Root Mean Squared Error -- train: 0.08738221973180771, -- test: 3.205563545227051 \n",
      "\n",
      "#################### Sample No.99 at Epoch 9899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 9899\n",
      "Mean Log Likelihood -- train: 0.997460663318634, -- test: -373.0946044921875 \n",
      "Root Mean Squared Error -- train: 0.07933592051267624, -- test: 3.197028875350952 \n",
      "\n",
      "#################### Sample No.100 at Epoch 9999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 9999\n",
      "Mean Log Likelihood -- train: 0.8092782497406006, -- test: -275.8796081542969 \n",
      "Root Mean Squared Error -- train: 0.1069231852889061, -- test: 2.7507286071777344 \n",
      "\n",
      "#################### Sample No.101 at Epoch 10099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 10099\n",
      "Mean Log Likelihood -- train: 0.8563870191574097, -- test: -296.1425476074219 \n",
      "Root Mean Squared Error -- train: 0.1007285863161087, -- test: 2.8495254516601562 \n",
      "\n",
      "#################### Sample No.102 at Epoch 10199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 10199\n",
      "Mean Log Likelihood -- train: 0.844931960105896, -- test: -330.1268005371094 \n",
      "Root Mean Squared Error -- train: 0.10226941108703613, -- test: 3.0079469680786133 \n",
      "\n",
      "#################### Sample No.103 at Epoch 10299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 10299\n",
      "Mean Log Likelihood -- train: 0.8918571472167969, -- test: -325.006103515625 \n",
      "Root Mean Squared Error -- train: 0.09580042958259583, -- test: 2.984614372253418 \n",
      "\n",
      "#################### Sample No.104 at Epoch 10399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 10399\n",
      "Mean Log Likelihood -- train: 0.8556485772132874, -- test: -339.0359802246094 \n",
      "Root Mean Squared Error -- train: 0.100828617811203, -- test: 3.048116445541382 \n",
      "\n",
      "#################### Sample No.105 at Epoch 10499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 10499\n",
      "Mean Log Likelihood -- train: 0.8675928711891174, -- test: -319.8146057128906 \n",
      "Root Mean Squared Error -- train: 0.0991981253027916, -- test: 2.960771322250366 \n",
      "\n",
      "#################### Sample No.106 at Epoch 10599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 10599\n",
      "Mean Log Likelihood -- train: 0.7891476154327393, -- test: -293.1561279296875 \n",
      "Root Mean Squared Error -- train: 0.1094634085893631, -- test: 2.8351807594299316 \n",
      "\n",
      "#################### Sample No.107 at Epoch 10699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 10699\n",
      "Mean Log Likelihood -- train: 0.9413899779319763, -- test: -329.20977783203125 \n",
      "Root Mean Squared Error -- train: 0.08846024423837662, -- test: 3.003781795501709 \n",
      "\n",
      "#################### Sample No.108 at Epoch 10799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 10799\n",
      "Mean Log Likelihood -- train: 0.94722580909729, -- test: -351.2542724609375 \n",
      "Root Mean Squared Error -- train: 0.0875549241900444, -- test: 3.1023597717285156 \n",
      "\n",
      "#################### Sample No.109 at Epoch 10899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 10899\n",
      "Mean Log Likelihood -- train: 0.8915318846702576, -- test: -339.80291748046875 \n",
      "Root Mean Squared Error -- train: 0.09584678709506989, -- test: 3.0515494346618652 \n",
      "\n",
      "#################### Sample No.110 at Epoch 10999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 10999\n",
      "Mean Log Likelihood -- train: 0.964600145816803, -- test: -365.4600524902344 \n",
      "Root Mean Squared Error -- train: 0.08480244129896164, -- test: 3.1642580032348633 \n",
      "\n",
      "#################### Sample No.111 at Epoch 11099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 11099\n",
      "Mean Log Likelihood -- train: 0.9714614748954773, -- test: -357.1465759277344 \n",
      "Root Mean Squared Error -- train: 0.08369052410125732, -- test: 3.128182888031006 \n",
      "\n",
      "#################### Sample No.112 at Epoch 11199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 11199\n",
      "Mean Log Likelihood -- train: 0.9397557377815247, -- test: -343.10577392578125 \n",
      "Root Mean Squared Error -- train: 0.08871211111545563, -- test: 3.066291093826294 \n",
      "\n",
      "#################### Sample No.113 at Epoch 11299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 11299\n",
      "Mean Log Likelihood -- train: 0.883385419845581, -- test: -319.46759033203125 \n",
      "Root Mean Squared Error -- train: 0.09700024873018265, -- test: 2.9591708183288574 \n",
      "\n",
      "#################### Sample No.114 at Epoch 11399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 11399\n",
      "Mean Log Likelihood -- train: 0.9383708238601685, -- test: -350.15582275390625 \n",
      "Root Mean Squared Error -- train: 0.08892498910427094, -- test: 3.097522258758545 \n",
      "\n",
      "#################### Sample No.115 at Epoch 11499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 11499\n",
      "Mean Log Likelihood -- train: 0.9123908877372742, -- test: -376.664306640625 \n",
      "Root Mean Squared Error -- train: 0.09282803535461426, -- test: 3.2122368812561035 \n",
      "\n",
      "#################### Sample No.116 at Epoch 11599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 11599\n",
      "Mean Log Likelihood -- train: 0.8925849199295044, -- test: -305.1409912109375 \n",
      "Root Mean Squared Error -- train: 0.09569666534662247, -- test: 2.892317295074463 \n",
      "\n",
      "#################### Sample No.117 at Epoch 11699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 11699\n",
      "Mean Log Likelihood -- train: 0.9498105645179749, -- test: -338.9616394042969 \n",
      "Root Mean Squared Error -- train: 0.08715096861124039, -- test: 3.047783374786377 \n",
      "\n",
      "#################### Sample No.118 at Epoch 11799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 11799\n",
      "Mean Log Likelihood -- train: 0.890061616897583, -- test: -302.2389831542969 \n",
      "Root Mean Squared Error -- train: 0.09605598449707031, -- test: 2.8785862922668457 \n",
      "\n",
      "#################### Sample No.119 at Epoch 11899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 11899\n",
      "Mean Log Likelihood -- train: 0.9254499077796936, -- test: -309.9613037109375 \n",
      "Root Mean Squared Error -- train: 0.09088709950447083, -- test: 2.9149820804595947 \n",
      "\n",
      "#################### Sample No.120 at Epoch 11999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 11999\n",
      "Mean Log Likelihood -- train: 0.9908745288848877, -- test: -331.0199890136719 \n",
      "Root Mean Squared Error -- train: 0.08046131581068039, -- test: 3.011998414993286 \n",
      "\n",
      "#################### Sample No.121 at Epoch 12099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 12099\n",
      "Mean Log Likelihood -- train: 0.8913148045539856, -- test: -276.771484375 \n",
      "Root Mean Squared Error -- train: 0.09587770700454712, -- test: 2.7551517486572266 \n",
      "\n",
      "#################### Sample No.122 at Epoch 12199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 12199\n",
      "Mean Log Likelihood -- train: 0.9961298108100891, -- test: -342.01885986328125 \n",
      "Root Mean Squared Error -- train: 0.07956461608409882, -- test: 3.0614476203918457 \n",
      "\n",
      "#################### Sample No.123 at Epoch 12299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 12299\n",
      "Mean Log Likelihood -- train: 0.9030312299728394, -- test: -323.7387390136719 \n",
      "Root Mean Squared Error -- train: 0.09419454634189606, -- test: 2.978811502456665 \n",
      "\n",
      "#################### Sample No.124 at Epoch 12399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 12399\n",
      "Mean Log Likelihood -- train: 0.8123869299888611, -- test: -267.3326110839844 \n",
      "Root Mean Squared Error -- train: 0.10652550309896469, -- test: 2.707975149154663 \n",
      "\n",
      "#################### Sample No.125 at Epoch 12499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 12499\n",
      "Mean Log Likelihood -- train: 0.9120076894760132, -- test: -302.0698547363281 \n",
      "Root Mean Squared Error -- train: 0.0928843691945076, -- test: 2.877784252166748 \n",
      "\n",
      "#################### Sample No.126 at Epoch 12599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 12599\n",
      "Mean Log Likelihood -- train: 0.8777567148208618, -- test: -366.3493347167969 \n",
      "Root Mean Squared Error -- train: 0.09778927266597748, -- test: 3.168092966079712 \n",
      "\n",
      "#################### Sample No.127 at Epoch 12699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 12699\n",
      "Mean Log Likelihood -- train: 0.8438639044761658, -- test: -405.2049255371094 \n",
      "Root Mean Squared Error -- train: 0.10241188853979111, -- test: 3.3313326835632324 \n",
      "\n",
      "#################### Sample No.128 at Epoch 12799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 12799\n",
      "Mean Log Likelihood -- train: 0.9159740209579468, -- test: -428.50921630859375 \n",
      "Root Mean Squared Error -- train: 0.09229954332113266, -- test: 3.425508499145508 \n",
      "\n",
      "#################### Sample No.129 at Epoch 12899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 12899\n",
      "Mean Log Likelihood -- train: 0.8347499966621399, -- test: -432.0985107421875 \n",
      "Root Mean Squared Error -- train: 0.10361975431442261, -- test: 3.439783811569214 \n",
      "\n",
      "#################### Sample No.130 at Epoch 12999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 12999\n",
      "Mean Log Likelihood -- train: 0.8224740624427795, -- test: -440.9544982910156 \n",
      "Root Mean Squared Error -- train: 0.10522476583719254, -- test: 3.4747560024261475 \n",
      "\n",
      "#################### Sample No.131 at Epoch 13099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 13099\n",
      "Mean Log Likelihood -- train: 0.8420021533966064, -- test: -384.1981201171875 \n",
      "Root Mean Squared Error -- train: 0.10265977680683136, -- test: 3.2440991401672363 \n",
      "\n",
      "#################### Sample No.132 at Epoch 13199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 13199\n",
      "Mean Log Likelihood -- train: 0.8197070956230164, -- test: -347.2343444824219 \n",
      "Root Mean Squared Error -- train: 0.10558315366506577, -- test: 3.084618091583252 \n",
      "\n",
      "#################### Sample No.133 at Epoch 13299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 13299\n",
      "Mean Log Likelihood -- train: 0.9644917249679565, -- test: -405.0619812011719 \n",
      "Root Mean Squared Error -- train: 0.08481989800930023, -- test: 3.330746650695801 \n",
      "\n",
      "#################### Sample No.134 at Epoch 13399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 13399\n",
      "Mean Log Likelihood -- train: 0.7078127264976501, -- test: -340.9795227050781 \n",
      "Root Mean Squared Error -- train: 0.11917681246995926, -- test: 3.056809186935425 \n",
      "\n",
      "#################### Sample No.135 at Epoch 13499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 13499\n",
      "Mean Log Likelihood -- train: 0.7169424891471863, -- test: -337.9766845703125 \n",
      "Root Mean Squared Error -- train: 0.1181262955069542, -- test: 3.043367862701416 \n",
      "\n",
      "#################### Sample No.136 at Epoch 13599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 13599\n",
      "Mean Log Likelihood -- train: 0.8808522820472717, -- test: -408.8975830078125 \n",
      "Root Mean Squared Error -- train: 0.09735612571239471, -- test: 3.3464314937591553 \n",
      "\n",
      "#################### Sample No.137 at Epoch 13699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 13699\n",
      "Mean Log Likelihood -- train: 0.8481405973434448, -- test: -364.3113708496094 \n",
      "Root Mean Squared Error -- train: 0.10184015333652496, -- test: 3.1592981815338135 \n",
      "\n",
      "#################### Sample No.138 at Epoch 13799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 13799\n",
      "Mean Log Likelihood -- train: 0.8049391508102417, -- test: -282.4745788574219 \n",
      "Root Mean Squared Error -- train: 0.10747580975294113, -- test: 2.783268928527832 \n",
      "\n",
      "#################### Sample No.139 at Epoch 13899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 13899\n",
      "Mean Log Likelihood -- train: 0.8673099279403687, -- test: -298.8941650390625 \n",
      "Root Mean Squared Error -- train: 0.09923706203699112, -- test: 2.8626785278320312 \n",
      "\n",
      "#################### Sample No.140 at Epoch 13999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 13999\n",
      "Mean Log Likelihood -- train: 0.8871978521347046, -- test: -284.56878662109375 \n",
      "Root Mean Squared Error -- train: 0.09646214544773102, -- test: 2.793522834777832 \n",
      "\n",
      "#################### Sample No.141 at Epoch 14099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 14099\n",
      "Mean Log Likelihood -- train: 0.9182774424552917, -- test: -325.18914794921875 \n",
      "Root Mean Squared Error -- train: 0.09195820242166519, -- test: 2.9854514598846436 \n",
      "\n",
      "#################### Sample No.142 at Epoch 14199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 14199\n",
      "Mean Log Likelihood -- train: 0.8863793015480042, -- test: -357.5599670410156 \n",
      "Root Mean Squared Error -- train: 0.09657793492078781, -- test: 3.12998628616333 \n",
      "\n",
      "#################### Sample No.143 at Epoch 14299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 14299\n",
      "Mean Log Likelihood -- train: 0.7575397491455078, -- test: -300.8374328613281 \n",
      "Root Mean Squared Error -- train: 0.11333711445331573, -- test: 2.871931314468384 \n",
      "\n",
      "#################### Sample No.144 at Epoch 14399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 14399\n",
      "Mean Log Likelihood -- train: 0.8423391580581665, -- test: -304.345947265625 \n",
      "Root Mean Squared Error -- train: 0.10261496156454086, -- test: 2.888561964035034 \n",
      "\n",
      "#################### Sample No.145 at Epoch 14499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 14499\n",
      "Mean Log Likelihood -- train: 0.8893182873725891, -- test: -354.9862060546875 \n",
      "Root Mean Squared Error -- train: 0.09616157412528992, -- test: 3.1187400817871094 \n",
      "\n",
      "#################### Sample No.146 at Epoch 14599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 14599\n",
      "Mean Log Likelihood -- train: 0.9939032793045044, -- test: -429.2304992675781 \n",
      "Root Mean Squared Error -- train: 0.07994575053453445, -- test: 3.42838191986084 \n",
      "\n",
      "#################### Sample No.147 at Epoch 14699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 14699\n",
      "Mean Log Likelihood -- train: 0.8935826420783997, -- test: -336.09686279296875 \n",
      "Root Mean Squared Error -- train: 0.09555423259735107, -- test: 3.0349230766296387 \n",
      "\n",
      "#################### Sample No.148 at Epoch 14799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 14799\n",
      "Mean Log Likelihood -- train: 0.9225084781646729, -- test: -320.6923522949219 \n",
      "Root Mean Squared Error -- train: 0.09132786840200424, -- test: 2.964816093444824 \n",
      "\n",
      "#################### Sample No.149 at Epoch 14899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 14899\n",
      "Mean Log Likelihood -- train: 0.8844687342643738, -- test: -311.9985656738281 \n",
      "Root Mean Squared Error -- train: 0.09684765338897705, -- test: 2.9245083332061768 \n",
      "\n",
      "#################### Sample No.150 at Epoch 14999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 14999\n",
      "Mean Log Likelihood -- train: 0.9147608280181885, -- test: -300.1524353027344 \n",
      "Root Mean Squared Error -- train: 0.09247881919145584, -- test: 2.868673086166382 \n",
      "\n",
      "#################### Sample No.151 at Epoch 15099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 15099\n",
      "Mean Log Likelihood -- train: 0.971562922000885, -- test: -342.0246887207031 \n",
      "Root Mean Squared Error -- train: 0.08367396891117096, -- test: 3.061473846435547 \n",
      "\n",
      "#################### Sample No.152 at Epoch 15199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 15199\n",
      "Mean Log Likelihood -- train: 0.781268835067749, -- test: -272.1171569824219 \n",
      "Root Mean Squared Error -- train: 0.11044172942638397, -- test: 2.7319908142089844 \n",
      "\n",
      "#################### Sample No.153 at Epoch 15299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 15299\n",
      "Mean Log Likelihood -- train: 0.8602321147918701, -- test: -305.0185852050781 \n",
      "Root Mean Squared Error -- train: 0.10020606964826584, -- test: 2.8917393684387207 \n",
      "\n",
      "#################### Sample No.154 at Epoch 15399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 15399\n",
      "Mean Log Likelihood -- train: 0.8851428627967834, -- test: -320.4684753417969 \n",
      "Root Mean Squared Error -- train: 0.0967525765299797, -- test: 2.963785171508789 \n",
      "\n",
      "#################### Sample No.155 at Epoch 15499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 15499\n",
      "Mean Log Likelihood -- train: 0.7126684784889221, -- test: -312.2972717285156 \n",
      "Root Mean Squared Error -- train: 0.11861924827098846, -- test: 2.9259023666381836 \n",
      "\n",
      "#################### Sample No.156 at Epoch 15599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 15599\n",
      "Mean Log Likelihood -- train: 0.8773584961891174, -- test: -315.650146484375 \n",
      "Root Mean Squared Error -- train: 0.09784484654664993, -- test: 2.9415056705474854 \n",
      "\n",
      "#################### Sample No.157 at Epoch 15699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 15699\n",
      "Mean Log Likelihood -- train: 0.8302618861198425, -- test: -306.2826843261719 \n",
      "Root Mean Squared Error -- train: 0.10420942306518555, -- test: 2.8977015018463135 \n",
      "\n",
      "#################### Sample No.158 at Epoch 15799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 15799\n",
      "Mean Log Likelihood -- train: 0.9564317464828491, -- test: -366.3807373046875 \n",
      "Root Mean Squared Error -- train: 0.08610746264457703, -- test: 3.1682281494140625 \n",
      "\n",
      "#################### Sample No.159 at Epoch 15899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 15899\n",
      "Mean Log Likelihood -- train: 0.926491379737854, -- test: -321.9092712402344 \n",
      "Root Mean Squared Error -- train: 0.09073052555322647, -- test: 2.970414638519287 \n",
      "\n",
      "#################### Sample No.160 at Epoch 15999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 15999\n",
      "Mean Log Likelihood -- train: 0.8662770986557007, -- test: -315.1243896484375 \n",
      "Root Mean Squared Error -- train: 0.0993790477514267, -- test: 2.9390642642974854 \n",
      "\n",
      "#################### Sample No.161 at Epoch 16099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 16099\n",
      "Mean Log Likelihood -- train: 1.026865839958191, -- test: -383.5456237792969 \n",
      "Root Mean Squared Error -- train: 0.07410310953855515, -- test: 3.241352081298828 \n",
      "\n",
      "#################### Sample No.162 at Epoch 16199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 16199\n",
      "Mean Log Likelihood -- train: 0.9009010195732117, -- test: -296.7422180175781 \n",
      "Root Mean Squared Error -- train: 0.09450279921293259, -- test: 2.8523969650268555 \n",
      "\n",
      "#################### Sample No.163 at Epoch 16299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 16299\n",
      "Mean Log Likelihood -- train: 0.864209771156311, -- test: -266.9455871582031 \n",
      "Root Mean Squared Error -- train: 0.0996626615524292, -- test: 2.7060234546661377 \n",
      "\n",
      "#################### Sample No.164 at Epoch 16399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 16399\n",
      "Mean Log Likelihood -- train: 0.8266032934188843, -- test: -271.1353454589844 \n",
      "Root Mean Squared Error -- train: 0.1046876311302185, -- test: 2.7270801067352295 \n",
      "\n",
      "#################### Sample No.165 at Epoch 16499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 16499\n",
      "Mean Log Likelihood -- train: 0.8399071097373962, -- test: -353.5259704589844 \n",
      "Root Mean Squared Error -- train: 0.10293802618980408, -- test: 3.1123409271240234 \n",
      "\n",
      "#################### Sample No.166 at Epoch 16599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 16599\n",
      "Mean Log Likelihood -- train: 0.7949278354644775, -- test: -354.6572265625 \n",
      "Root Mean Squared Error -- train: 0.10874010622501373, -- test: 3.1172995567321777 \n",
      "\n",
      "#################### Sample No.167 at Epoch 16699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 16699\n",
      "Mean Log Likelihood -- train: 0.7895540595054626, -- test: -292.0179748535156 \n",
      "Root Mean Squared Error -- train: 0.10941270738840103, -- test: 2.8296945095062256 \n",
      "\n",
      "#################### Sample No.168 at Epoch 16799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 16799\n",
      "Mean Log Likelihood -- train: 0.7330924868583679, -- test: -307.2089538574219 \n",
      "Root Mean Squared Error -- train: 0.11624474823474884, -- test: 2.90206241607666 \n",
      "\n",
      "#################### Sample No.169 at Epoch 16899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 16899\n",
      "Mean Log Likelihood -- train: 0.7147711515426636, -- test: -319.72247314453125 \n",
      "Root Mean Squared Error -- train: 0.11837700009346008, -- test: 2.9603464603424072 \n",
      "\n",
      "#################### Sample No.170 at Epoch 16999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 16999\n",
      "Mean Log Likelihood -- train: 0.680594801902771, -- test: -290.9934997558594 \n",
      "Root Mean Squared Error -- train: 0.12225509434938431, -- test: 2.824747323989868 \n",
      "\n",
      "#################### Sample No.171 at Epoch 17099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 17099\n",
      "Mean Log Likelihood -- train: 0.6647164821624756, -- test: -290.20855712890625 \n",
      "Root Mean Squared Error -- train: 0.12401560693979263, -- test: 2.820950984954834 \n",
      "\n",
      "#################### Sample No.172 at Epoch 17199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 17199\n",
      "Mean Log Likelihood -- train: 0.8210986256599426, -- test: -359.46258544921875 \n",
      "Root Mean Squared Error -- train: 0.10540305823087692, -- test: 3.138274669647217 \n",
      "\n",
      "#################### Sample No.173 at Epoch 17299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 17299\n",
      "Mean Log Likelihood -- train: 0.93339604139328, -- test: -393.2039489746094 \n",
      "Root Mean Squared Error -- train: 0.08968552201986313, -- test: 3.281780958175659 \n",
      "\n",
      "#################### Sample No.174 at Epoch 17399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 17399\n",
      "Mean Log Likelihood -- train: 0.8695828914642334, -- test: -388.2547302246094 \n",
      "Root Mean Squared Error -- train: 0.09892386943101883, -- test: 3.261126756668091 \n",
      "\n",
      "#################### Sample No.175 at Epoch 17499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 17499\n",
      "Mean Log Likelihood -- train: 0.9295324087142944, -- test: -362.9335632324219 \n",
      "Root Mean Squared Error -- train: 0.09027175605297089, -- test: 3.1533384323120117 \n",
      "\n",
      "#################### Sample No.176 at Epoch 17599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 17599\n",
      "Mean Log Likelihood -- train: 0.8527488708496094, -- test: -312.3533935546875 \n",
      "Root Mean Squared Error -- train: 0.10122048854827881, -- test: 2.926164150238037 \n",
      "\n",
      "#################### Sample No.177 at Epoch 17699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 17699\n",
      "Mean Log Likelihood -- train: 0.9126275777816772, -- test: -329.2325744628906 \n",
      "Root Mean Squared Error -- train: 0.09279321134090424, -- test: 3.003885269165039 \n",
      "\n",
      "#################### Sample No.178 at Epoch 17799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 17799\n",
      "Mean Log Likelihood -- train: 0.8381765484809875, -- test: -317.1783142089844 \n",
      "Root Mean Squared Error -- train: 0.10316729545593262, -- test: 2.94858980178833 \n",
      "\n",
      "#################### Sample No.179 at Epoch 17899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 17899\n",
      "Mean Log Likelihood -- train: 0.8609973788261414, -- test: -321.630615234375 \n",
      "Root Mean Squared Error -- train: 0.10010173916816711, -- test: 2.9691336154937744 \n",
      "\n",
      "#################### Sample No.180 at Epoch 17999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 17999\n",
      "Mean Log Likelihood -- train: 0.7785158753395081, -- test: -279.6219787597656 \n",
      "Root Mean Squared Error -- train: 0.11078150570392609, -- test: 2.7692408561706543 \n",
      "\n",
      "#################### Sample No.181 at Epoch 18099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 18099\n",
      "Mean Log Likelihood -- train: 0.913722574710846, -- test: -304.74200439453125 \n",
      "Root Mean Squared Error -- train: 0.0926319807767868, -- test: 2.8904333114624023 \n",
      "\n",
      "#################### Sample No.182 at Epoch 18199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 18199\n",
      "Mean Log Likelihood -- train: 0.886326014995575, -- test: -271.40179443359375 \n",
      "Root Mean Squared Error -- train: 0.0965854749083519, -- test: 2.7284133434295654 \n",
      "\n",
      "#################### Sample No.183 at Epoch 18299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 18299\n",
      "Mean Log Likelihood -- train: 0.8363739848136902, -- test: -255.52357482910156 \n",
      "Root Mean Squared Error -- train: 0.10340556502342224, -- test: 2.647768974304199 \n",
      "\n",
      "#################### Sample No.184 at Epoch 18399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 18399\n",
      "Mean Log Likelihood -- train: 0.9058919548988342, -- test: -290.73211669921875 \n",
      "Root Mean Squared Error -- train: 0.09377899765968323, -- test: 2.823483943939209 \n",
      "\n",
      "#################### Sample No.185 at Epoch 18499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 18499\n",
      "Mean Log Likelihood -- train: 0.9431287050247192, -- test: -288.29998779296875 \n",
      "Root Mean Squared Error -- train: 0.08819147944450378, -- test: 2.8116989135742188 \n",
      "\n",
      "#################### Sample No.186 at Epoch 18599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 18599\n",
      "Mean Log Likelihood -- train: 0.9065017700195312, -- test: -285.755615234375 \n",
      "Root Mean Squared Error -- train: 0.0936901718378067, -- test: 2.799316883087158 \n",
      "\n",
      "#################### Sample No.187 at Epoch 18699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 18699\n",
      "Mean Log Likelihood -- train: 0.972492516040802, -- test: -362.11993408203125 \n",
      "Root Mean Squared Error -- train: 0.08352215588092804, -- test: 3.149813652038574 \n",
      "\n",
      "#################### Sample No.188 at Epoch 18799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 18799\n",
      "Mean Log Likelihood -- train: 0.8718482851982117, -- test: -297.8807678222656 \n",
      "Root Mean Squared Error -- train: 0.09861069917678833, -- test: 2.8578412532806396 \n",
      "\n",
      "#################### Sample No.189 at Epoch 18899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 18899\n",
      "Mean Log Likelihood -- train: 0.9251571297645569, -- test: -344.10137939453125 \n",
      "Root Mean Squared Error -- train: 0.09093106538057327, -- test: 3.070720672607422 \n",
      "\n",
      "#################### Sample No.190 at Epoch 18999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 18999\n",
      "Mean Log Likelihood -- train: 0.9100706577301025, -- test: -359.3095703125 \n",
      "Root Mean Squared Error -- train: 0.09316866099834442, -- test: 3.137608766555786 \n",
      "\n",
      "#################### Sample No.191 at Epoch 19099  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 19099\n",
      "Mean Log Likelihood -- train: 0.7554576396942139, -- test: -316.39154052734375 \n",
      "Root Mean Squared Error -- train: 0.11358765512704849, -- test: 2.9449448585510254 \n",
      "\n",
      "#################### Sample No.192 at Epoch 19199  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 19199\n",
      "Mean Log Likelihood -- train: 0.895977258682251, -- test: -311.1336975097656 \n",
      "Root Mean Squared Error -- train: 0.0952114686369896, -- test: 2.9204678535461426 \n",
      "\n",
      "#################### Sample No.193 at Epoch 19299  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 19299\n",
      "Mean Log Likelihood -- train: 0.8290191888809204, -- test: -308.1843566894531 \n",
      "Root Mean Squared Error -- train: 0.10437209904193878, -- test: 2.9066474437713623 \n",
      "\n",
      "#################### Sample No.194 at Epoch 19399  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 19399\n",
      "Mean Log Likelihood -- train: 0.884393572807312, -- test: -310.5299072265625 \n",
      "Root Mean Squared Error -- train: 0.09685824811458588, -- test: 2.9176437854766846 \n",
      "\n",
      "#################### Sample No.195 at Epoch 19499  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 19499\n",
      "Mean Log Likelihood -- train: 0.9052229523658752, -- test: -294.363037109375 \n",
      "Root Mean Squared Error -- train: 0.09387633949518204, -- test: 2.840986728668213 \n",
      "\n",
      "#################### Sample No.196 at Epoch 19599  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 19599\n",
      "Mean Log Likelihood -- train: 0.9145946502685547, -- test: -308.2435302734375 \n",
      "Root Mean Squared Error -- train: 0.09250334650278091, -- test: 2.9069254398345947 \n",
      "\n",
      "#################### Sample No.197 at Epoch 19699  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 19699\n",
      "Mean Log Likelihood -- train: 0.8828172087669373, -- test: -288.84149169921875 \n",
      "Root Mean Squared Error -- train: 0.09708020091056824, -- test: 2.8143270015716553 \n",
      "\n",
      "#################### Sample No.198 at Epoch 19799  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 19799\n",
      "Mean Log Likelihood -- train: 1.051093578338623, -- test: -325.8566589355469 \n",
      "Root Mean Squared Error -- train: 0.06949622184038162, -- test: 2.9885027408599854 \n",
      "\n",
      "#################### Sample No.199 at Epoch 19899  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 19899\n",
      "Mean Log Likelihood -- train: 0.8862088322639465, -- test: -261.84112548828125 \n",
      "Root Mean Squared Error -- train: 0.09660203754901886, -- test: 2.6801462173461914 \n",
      "\n",
      "#################### Sample No.200 at Epoch 19999  lr = 7.51754214434186e-12 ####################\n",
      "Sampling Epoch: 19999\n",
      "Mean Log Likelihood -- train: 0.7012268304824829, -- test: -218.41517639160156 \n",
      "Root Mean Squared Error -- train: 0.11992891132831573, -- test: 2.4489638805389404 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 200 \n",
      "Test Log Likelihood of all sampled models: -104.15293884277344\n",
      "Test Root MSE of all sampled models: 3.0357718467712402\n",
      "********************************************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MCEM with Moving Windows settings and training\n",
    "total_EM_steps = 50\n",
    "_, _, lines, W = MCEM_windows_demo(sampler_EM, maximizer, sampler_fixing_hyper, total_EM_steps, ds_train, window_size=10,\n",
    "                             print_epoch_cycle_EM=50, print_epoch_cycle_fixing=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.15686728>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.3210245], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Omega_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efaf808ebe0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print sampled lines\n",
    "fig, ax = plt.subplots(1, model.n_hidden_layers+1, figsize=((model.n_hidden_layers+1)*5, 5))\n",
    "ax = ax.flatten()\n",
    "for i in range(model.n_hidden_layers):\n",
    "    for model_line in lines[5:]: # hidden outputs of each sampled model\n",
    "        line = model_line[i]\n",
    "        ax[i].plot(X_test[:,0], line.numpy()[:,0])\n",
    "    # for model_line in lines[690:701]: # hidden outputs of each sampled model\n",
    "    #     line = model_line[i]\n",
    "    #     ax[i].plot(X_test.numpy()[:,0], line.numpy()[:,0], 'b')\n",
    "for x, y in ds_train:\n",
    "    ax[-2].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "# for x, y in ds_test:\n",
    "    # ax[-1].plot(x[:,0], y[:,0], '*', label='ground truth')\n",
    "ax[-2].legend()\n",
    "\n",
    "# compute the mean of the sampled lines\n",
    "line_output = []\n",
    "for model_line in lines[5:]:\n",
    "    line_output.append(model_line[-1]) #the final layer\n",
    "line_mean = tf.reduce_mean(tf.concat(line_output, axis=-1), axis=-1)\n",
    "ax[-1].plot(X_test[:,0], line_mean.numpy(), label='mean')\n",
    "for x, y in ds_train:\n",
    "    ax[-1].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "ax[-1].legend()\n",
    "# fig.savefig('1layer-sin-2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-layer DGPs (MCEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "d_in = 1\n",
    "d_out = 1\n",
    "model = DemoRegressionDGP(d_in, d_out, n_hidden_layers=2, n_rf=100, n_gp=1,\n",
    "                          likelihood=Gaussian(variance=0.01, trainable=True),\n",
    "                          kernel_type_list=['RBF' for i in range(2)], kernel_trainable=True,\n",
    "                          random_fixed=True, input_cat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 08:10:39.095822: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Omega_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM sampler settings\n",
    "batch_size = 47\n",
    "lr_mcmc_0 = 0.01\n",
    "sampler_EM = MCEM_sampler_demo(model, ds_train, ds_test, num_training, batch_size, X_test,\n",
    "                               lr_0=lr_mcmc_0, momentum_decay=0.95, resample_in_cycle_head=False,\n",
    "                               start_sampling_epoch=500, epochs_per_cycle=50)\n",
    "\n",
    "# Maximizer setttings\n",
    "lr_maximizer = 0.01\n",
    "optimizer = optimizers.Adam(learning_rate=lr_maximizer)\n",
    "maximizer = MCEM_Q_maximizer_demo(model, num_training, optimizer)\n",
    "\n",
    "# sampler settings after fixing hyper-params\n",
    "lr_fixing_hyper_0 = 0.01\n",
    "sampler_fixing_hyper = MCEM_sampler_demo(model, ds_train, ds_test, num_training, batch_size, X_test,\n",
    "                                         lr_0=lr_fixing_hyper_0, momentum_decay=0.95, resample_in_cycle_head=False,\n",
    "                                         start_sampling_epoch=1000, epochs_per_cycle=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### EM step 1 of total 100 steps. E Step:  ###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 08:12:22.810072: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-25 08:12:23.400432: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-08-25 08:12:23.400489: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -7.072976589202881, -- test: -24.773157119750977 \n",
      "Root Mean Squared Error -- train: 0.41125717759132385, -- test: 0.7232814431190491 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -7.10526704788208, -- test: -27.11935806274414 \n",
      "Root Mean Squared Error -- train: 0.4120416045188904, -- test: 0.755023181438446 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.369865417480469, -- test: -20.421611785888672 \n",
      "Root Mean Squared Error -- train: 0.418413907289505, -- test: 0.6603825688362122 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.205226898193359, -- test: -22.394174575805664 \n",
      "Root Mean Squared Error -- train: 0.4144604802131653, -- test: 0.6896059513092041 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -7.057804107666016, -- test: -26.62289810180664 \n",
      "Root Mean Squared Error -- train: 0.41088807582855225, -- test: 0.748418927192688 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.9785261154174805, -- test: -25.368553161621094 \n",
      "Root Mean Squared Error -- train: 0.40895408391952515, -- test: 0.7314670085906982 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -7.0782647132873535, -- test: -28.16216468811035 \n",
      "Root Mean Squared Error -- train: 0.41138574481010437, -- test: 0.7687107920646667 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -7.045954704284668, -- test: -24.78717041015625 \n",
      "Root Mean Squared Error -- train: 0.41059958934783936, -- test: 0.7234751582145691 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -7.102034568786621, -- test: -21.937971115112305 \n",
      "Root Mean Squared Error -- train: 0.4119631052017212, -- test: 0.6829584836959839 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -7.065908432006836, -- test: -23.698637008666992 \n",
      "Root Mean Squared Error -- train: 0.4110852777957916, -- test: 0.708269476890564 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -20.94678497314453\n",
      "Test Root MSE of all sampled models: 0.7212827205657959\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 1 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.51968240737915 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 2 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -7.178768157958984, -- test: -23.764636993408203 \n",
      "Root Mean Squared Error -- train: 0.41577446460723877, -- test: 0.7126848101615906 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.918360233306885, -- test: -24.387958526611328 \n",
      "Root Mean Squared Error -- train: 0.4093994200229645, -- test: 0.7214647531509399 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.239304542541504, -- test: -23.796222686767578 \n",
      "Root Mean Squared Error -- train: 0.41724246740341187, -- test: 0.7131323218345642 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.979334354400635, -- test: -25.27657699584961 \n",
      "Root Mean Squared Error -- train: 0.4109009802341461, -- test: 0.7337998747825623 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -8.698647499084473, -- test: -23.850147247314453 \n",
      "Root Mean Squared Error -- train: 0.45118895173072815, -- test: 0.7138956189155579 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.964725017547607, -- test: -23.56499481201172 \n",
      "Root Mean Squared Error -- train: 0.41054171323776245, -- test: 0.7098497152328491 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -7.026973724365234, -- test: -23.558246612548828 \n",
      "Root Mean Squared Error -- train: 0.4120703637599945, -- test: 0.709753692150116 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.999206066131592, -- test: -23.266359329223633 \n",
      "Root Mean Squared Error -- train: 0.41138917207717896, -- test: 0.70558762550354 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -7.019372940063477, -- test: -24.902080535888672 \n",
      "Root Mean Squared Error -- train: 0.41188400983810425, -- test: 0.7286268472671509 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -7.018927574157715, -- test: -24.959299087524414 \n",
      "Root Mean Squared Error -- train: 0.41187313199043274, -- test: 0.7294197082519531 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -21.29131507873535\n",
      "Test Root MSE of all sampled models: 0.7200867533683777\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 2 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -8.601006507873535 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 3 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.900150299072266, -- test: -25.076601028442383 \n",
      "Root Mean Squared Error -- train: 0.4108595550060272, -- test: 0.7346071004867554 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -8.027985572814941, -- test: -27.921491622924805 \n",
      "Root Mean Squared Error -- train: 0.43796807527542114, -- test: 0.7731041312217712 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.225487232208252, -- test: -26.828807830810547 \n",
      "Root Mean Squared Error -- train: 0.41885942220687866, -- test: 0.7585490942001343 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.131961822509766, -- test: -24.139942169189453 \n",
      "Root Mean Squared Error -- train: 0.41657543182373047, -- test: 0.7214828729629517 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.960068702697754, -- test: -25.200302124023438 \n",
      "Root Mean Squared Error -- train: 0.4123445749282837, -- test: 0.7363228797912598 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.813157081604004, -- test: -26.254638671875 \n",
      "Root Mean Squared Error -- train: 0.40869390964508057, -- test: 0.7507877945899963 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.869461536407471, -- test: -24.323148727416992 \n",
      "Root Mean Squared Error -- train: 0.4100968837738037, -- test: 0.7240685820579529 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.943276882171631, -- test: -26.828706741333008 \n",
      "Root Mean Squared Error -- train: 0.4119289815425873, -- test: 0.7585476636886597 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.9107866287231445, -- test: -25.72652816772461 \n",
      "Root Mean Squared Error -- train: 0.4111235737800598, -- test: 0.7435775399208069 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.872377872467041, -- test: -28.748455047607422 \n",
      "Root Mean Squared Error -- train: 0.41016942262649536, -- test: 0.7839399576187134 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -23.354145050048828\n",
      "Test Root MSE of all sampled models: 0.7508097887039185\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 3 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.467711925506592 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 4 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -7.131500720977783, -- test: -23.090087890625 \n",
      "Root Mean Squared Error -- train: 0.4184901714324951, -- test: 0.7098828554153442 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -8.776317596435547, -- test: -26.516366958618164 \n",
      "Root Mean Squared Error -- train: 0.45718997716903687, -- test: 0.757975161075592 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.938173770904541, -- test: -23.62778091430664 \n",
      "Root Mean Squared Error -- train: 0.4137038290500641, -- test: 0.7176433801651001 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.170693397521973, -- test: -24.340045928955078 \n",
      "Root Mean Squared Error -- train: 0.41945382952690125, -- test: 0.7277959585189819 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -7.1212663650512695, -- test: -28.858102798461914 \n",
      "Root Mean Squared Error -- train: 0.41823819279670715, -- test: 0.7891602516174316 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.74008321762085, -- test: -26.273975372314453 \n",
      "Root Mean Squared Error -- train: 0.4087413549423218, -- test: 0.7546736598014832 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.907912731170654, -- test: -25.25509262084961 \n",
      "Root Mean Squared Error -- train: 0.4129496216773987, -- test: 0.7406347990036011 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.879597187042236, -- test: -28.476560592651367 \n",
      "Root Mean Squared Error -- train: 0.4122426211833954, -- test: 0.7841638326644897 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.788382530212402, -- test: -27.161054611206055 \n",
      "Root Mean Squared Error -- train: 0.4099569022655487, -- test: 0.7666870951652527 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.757800102233887, -- test: -26.44715118408203 \n",
      "Root Mean Squared Error -- train: 0.4091876745223999, -- test: 0.7570338249206543 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -21.111770629882812\n",
      "Test Root MSE of all sampled models: 0.7567058205604553\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 4 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -7.933829307556152 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 5 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -14.960342407226562, -- test: -21.279542922973633 \n",
      "Root Mean Squared Error -- train: 0.5828210711479187, -- test: 0.6864203810691833 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.844423294067383, -- test: -25.33554458618164 \n",
      "Root Mean Squared Error -- train: 0.4132806360721588, -- test: 0.7453669905662537 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -8.318674087524414, -- test: -26.626028060913086 \n",
      "Root Mean Squared Error -- train: 0.4488627016544342, -- test: 0.763167679309845 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.659976959228516, -- test: -24.216283798217773 \n",
      "Root Mean Squared Error -- train: 0.4333258271217346, -- test: 0.7295765280723572 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -7.299821376800537, -- test: -25.773334503173828 \n",
      "Root Mean Squared Error -- train: 0.4245903789997101, -- test: 0.7514530420303345 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.737776756286621, -- test: -27.405786514282227 \n",
      "Root Mean Squared Error -- train: 0.4105870723724365, -- test: 0.7737250328063965 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.693793296813965, -- test: -27.32086944580078 \n",
      "Root Mean Squared Error -- train: 0.4094710052013397, -- test: 0.7725823521614075 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.660666465759277, -- test: -26.898391723632812 \n",
      "Root Mean Squared Error -- train: 0.4086284339427948, -- test: 0.7668717503547668 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.743040561676025, -- test: -26.913593292236328 \n",
      "Root Mean Squared Error -- train: 0.4107204079627991, -- test: 0.7670780420303345 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.750718116760254, -- test: -26.302095413208008 \n",
      "Root Mean Squared Error -- train: 0.4109148383140564, -- test: 0.75873863697052 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -23.98272705078125\n",
      "Test Root MSE of all sampled models: 0.7690824270248413\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 5 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -8.322237014770508 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 6 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -7.024433612823486, -- test: -23.993772506713867 \n",
      "Root Mean Squared Error -- train: 0.41975295543670654, -- test: 0.7299585938453674 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -8.36501693725586, -- test: -28.39080047607422 \n",
      "Root Mean Squared Error -- train: 0.45207056403160095, -- test: 0.7907291054725647 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.689666748046875, -- test: -26.142349243164062 \n",
      "Root Mean Squared Error -- train: 0.4112866520881653, -- test: 0.7602608799934387 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.739891529083252, -- test: -26.062013626098633 \n",
      "Root Mean Squared Error -- train: 0.4125679135322571, -- test: 0.7591495513916016 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -8.976999282836914, -- test: -25.455224990844727 \n",
      "Root Mean Squared Error -- train: 0.4660792946815491, -- test: 0.7507030367851257 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.756972312927246, -- test: -27.87914276123047 \n",
      "Root Mean Squared Error -- train: 0.41300278902053833, -- test: 0.7838999032974243 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.591394424438477, -- test: -25.9552059173584 \n",
      "Root Mean Squared Error -- train: 0.40876802802085876, -- test: 0.7576696872711182 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.666338920593262, -- test: -28.188098907470703 \n",
      "Root Mean Squared Error -- train: 0.41069018840789795, -- test: 0.788030743598938 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.5844526290893555, -- test: -26.80816650390625 \n",
      "Root Mean Squared Error -- train: 0.40858954191207886, -- test: 0.7694090008735657 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.597275257110596, -- test: -27.11040496826172 \n",
      "Root Mean Squared Error -- train: 0.40891918540000916, -- test: 0.7735258936882019 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -22.12374496459961\n",
      "Test Root MSE of all sampled models: 0.778252124786377\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 6 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.0830979347229 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 7 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.666989803314209, -- test: -24.758153915405273 \n",
      "Root Mean Squared Error -- train: 0.4125976264476776, -- test: 0.7444493174552917 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.531521320343018, -- test: -26.916851043701172 \n",
      "Root Mean Squared Error -- train: 0.4090985655784607, -- test: 0.7746103405952454 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.846587657928467, -- test: -24.594589233398438 \n",
      "Root Mean Squared Error -- train: 0.41719135642051697, -- test: 0.7421141266822815 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.692252159118652, -- test: -26.94961166381836 \n",
      "Root Mean Squared Error -- train: 0.41324689984321594, -- test: 0.7750590443611145 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.585303783416748, -- test: -25.5646915435791 \n",
      "Root Mean Squared Error -- train: 0.41049128770828247, -- test: 0.7558590173721313 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.616236209869385, -- test: -24.723310470581055 \n",
      "Root Mean Squared Error -- train: 0.4112901985645294, -- test: 0.7439525127410889 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.580124855041504, -- test: -26.988540649414062 \n",
      "Root Mean Squared Error -- train: 0.41035741567611694, -- test: 0.7755918502807617 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.544329643249512, -- test: -26.865530014038086 \n",
      "Root Mean Squared Error -- train: 0.40943068265914917, -- test: 0.773906946182251 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.604841709136963, -- test: -30.236072540283203 \n",
      "Root Mean Squared Error -- train: 0.41099607944488525, -- test: 0.818821370601654 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.595489978790283, -- test: -27.23666763305664 \n",
      "Root Mean Squared Error -- train: 0.41075456142425537, -- test: 0.7789794206619263 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -22.886259078979492\n",
      "Test Root MSE of all sampled models: 0.7802981734275818\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 7 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.330733299255371 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 8 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -7.765440464019775, -- test: -25.993467330932617 \n",
      "Root Mean Squared Error -- train: 0.44198355078697205, -- test: 0.7655245661735535 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -7.144104480743408, -- test: -24.276573181152344 \n",
      "Root Mean Squared Error -- train: 0.4266526401042938, -- test: 0.7411004900932312 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.543124675750732, -- test: -25.515504837036133 \n",
      "Root Mean Squared Error -- train: 0.41128063201904297, -- test: 0.7588042616844177 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.521748065948486, -- test: -25.280048370361328 \n",
      "Root Mean Squared Error -- train: 0.4107232689857483, -- test: 0.7554715871810913 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.480254650115967, -- test: -24.77399253845215 \n",
      "Root Mean Squared Error -- train: 0.4096391797065735, -- test: 0.7482587099075317 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.546828269958496, -- test: -24.032060623168945 \n",
      "Root Mean Squared Error -- train: 0.4113771319389343, -- test: 0.7375563979148865 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.4987897872924805, -- test: -25.106992721557617 \n",
      "Root Mean Squared Error -- train: 0.4101237952709198, -- test: 0.7530127763748169 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 08:14:55.685991: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.538516998291016, -- test: -27.928333282470703 \n",
      "Root Mean Squared Error -- train: 0.41116055846214294, -- test: 0.7921474575996399 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.44998025894165, -- test: -27.65966033935547 \n",
      "Root Mean Squared Error -- train: 0.4088464379310608, -- test: 0.788504421710968 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.518942832946777, -- test: -25.123327255249023 \n",
      "Root Mean Squared Error -- train: 0.4106500744819641, -- test: 0.7532452344894409 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -22.283193588256836\n",
      "Test Root MSE of all sampled models: 0.7667301297187805\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 8 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.722256660461426 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 9 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.490525245666504, -- test: -26.8216609954834 \n",
      "Root Mean Squared Error -- train: 0.4117952883243561, -- test: 0.7807861566543579 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.490874767303467, -- test: -24.596895217895508 \n",
      "Root Mean Squared Error -- train: 0.4118044674396515, -- test: 0.7493155598640442 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.156312465667725, -- test: -24.092031478881836 \n",
      "Root Mean Squared Error -- train: 0.4289356768131256, -- test: 0.7419881224632263 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.483327865600586, -- test: -27.027353286743164 \n",
      "Root Mean Squared Error -- train: 0.411606103181839, -- test: 0.7836319804191589 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.686233997344971, -- test: -28.38237762451172 \n",
      "Root Mean Squared Error -- train: 0.41690686345100403, -- test: 0.802126944065094 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.495880126953125, -- test: -26.3380184173584 \n",
      "Root Mean Squared Error -- train: 0.4119360148906708, -- test: 0.7740536332130432 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.523629665374756, -- test: -26.320085525512695 \n",
      "Root Mean Squared Error -- train: 0.41266438364982605, -- test: 0.7738028764724731 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.48974084854126, -- test: -27.806501388549805 \n",
      "Root Mean Squared Error -- train: 0.4117746651172638, -- test: 0.7943192720413208 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.441686630249023, -- test: -25.72121810913086 \n",
      "Root Mean Squared Error -- train: 0.41050979495048523, -- test: 0.7653815746307373 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.382051467895508, -- test: -26.093809127807617 \n",
      "Root Mean Squared Error -- train: 0.408934623003006, -- test: 0.770631730556488 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -21.514020919799805\n",
      "Test Root MSE of all sampled models: 0.7729325890541077\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 9 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.076779365539551 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 10 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.6516594886779785, -- test: -27.98678207397461 \n",
      "Root Mean Squared Error -- train: 0.4179203510284424, -- test: 0.8006119132041931 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.421551704406738, -- test: -24.978052139282227 \n",
      "Root Mean Squared Error -- train: 0.4118591547012329, -- test: 0.7584310173988342 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -8.422687530517578, -- test: -23.09795379638672 \n",
      "Root Mean Squared Error -- train: 0.461916446685791, -- test: 0.7308380603790283 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.476440906524658, -- test: -24.489416122436523 \n",
      "Root Mean Squared Error -- train: 0.41331303119659424, -- test: 0.7513569593429565 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.316975116729736, -- test: -26.28786849975586 \n",
      "Root Mean Squared Error -- train: 0.4090748429298401, -- test: 0.7770754098892212 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.356614589691162, -- test: -26.67825698852539 \n",
      "Root Mean Squared Error -- train: 0.4101324677467346, -- test: 0.7825464606285095 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.341926097869873, -- test: -26.743776321411133 \n",
      "Root Mean Squared Error -- train: 0.4097408950328827, -- test: 0.7834609746932983 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.366229057312012, -- test: -26.097734451293945 \n",
      "Root Mean Squared Error -- train: 0.4103885591030121, -- test: 0.7743968367576599 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.333961486816406, -- test: -30.11349868774414 \n",
      "Root Mean Squared Error -- train: 0.40952837467193604, -- test: 0.829133927822113 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.366436958312988, -- test: -23.810325622558594 \n",
      "Root Mean Squared Error -- train: 0.4103941023349762, -- test: 0.7414138913154602 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -21.322792053222656\n",
      "Test Root MSE of all sampled models: 0.7793154716491699\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 10 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.500937461853027 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 11 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -7.100213050842285, -- test: -28.861326217651367 \n",
      "Root Mean Squared Error -- train: 0.4314729571342468, -- test: 0.8163841962814331 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.22119665145874, -- test: -25.194387435913086 \n",
      "Root Mean Squared Error -- train: 0.40837129950523376, -- test: 0.7652097344398499 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.2792768478393555, -- test: -25.492145538330078 \n",
      "Root Mean Squared Error -- train: 0.4360288977622986, -- test: 0.7694920897483826 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.924395561218262, -- test: -25.164918899536133 \n",
      "Root Mean Squared Error -- train: 0.4269522428512573, -- test: 0.7647846341133118 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -7.522796154022217, -- test: -25.520078659057617 \n",
      "Root Mean Squared Error -- train: 0.4421495199203491, -- test: 0.7698925733566284 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.327427864074707, -- test: -28.38115692138672 \n",
      "Root Mean Squared Error -- train: 0.4112321436405182, -- test: 0.8098670244216919 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.257744789123535, -- test: -25.206802368164062 \n",
      "Root Mean Squared Error -- train: 0.40935784578323364, -- test: 0.7653887867927551 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.270549297332764, -- test: -24.816926956176758 \n",
      "Root Mean Squared Error -- train: 0.4097028970718384, -- test: 0.7597464323043823 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.274936676025391, -- test: -25.952129364013672 \n",
      "Root Mean Squared Error -- train: 0.4098210334777832, -- test: 0.7760611176490784 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.22767972946167, -- test: -24.621732711791992 \n",
      "Root Mean Squared Error -- train: 0.408546507358551, -- test: 0.7569056749343872 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -21.0700740814209\n",
      "Test Root MSE of all sampled models: 0.772867739200592\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 11 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -9.23110294342041 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 12 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.135312557220459, -- test: -24.700580596923828 \n",
      "Root Mean Squared Error -- train: 0.40793463587760925, -- test: 0.7617658376693726 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.515634536743164, -- test: -24.684001922607422 \n",
      "Root Mean Squared Error -- train: 0.4181975722312927, -- test: 0.7615231871604919 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.31799840927124, -- test: -25.346479415893555 \n",
      "Root Mean Squared Error -- train: 0.4128962457180023, -- test: 0.7711590528488159 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.695815563201904, -- test: -25.482421875 \n",
      "Root Mean Squared Error -- train: 0.42297282814979553, -- test: 0.7731215357780457 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.318808555603027, -- test: -23.909204483032227 \n",
      "Root Mean Squared Error -- train: 0.4129181206226349, -- test: 0.7500966787338257 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.178617000579834, -- test: -24.785078048706055 \n",
      "Root Mean Squared Error -- train: 0.4091162085533142, -- test: 0.7630012631416321 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.199277400970459, -- test: -26.847131729125977 \n",
      "Root Mean Squared Error -- train: 0.40967869758605957, -- test: 0.7925530076026917 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.221408367156982, -- test: -26.643102645874023 \n",
      "Root Mean Squared Error -- train: 0.41028037667274475, -- test: 0.7896783947944641 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.153846740722656, -- test: -25.249046325683594 \n",
      "Root Mean Squared Error -- train: 0.4084407687187195, -- test: 0.7697494626045227 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.39681339263916, -- test: -25.86363983154297 \n",
      "Root Mean Squared Error -- train: 0.4150184690952301, -- test: 0.7785983085632324 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -23.149375915527344\n",
      "Test Root MSE of all sampled models: 0.7737891674041748\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 12 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.995330572128296 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 13 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.725673675537109, -- test: -25.95977783203125 \n",
      "Root Mean Squared Error -- train: 0.42566296458244324, -- test: 0.7836418747901917 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.724085807800293, -- test: -22.557641983032227 \n",
      "Root Mean Squared Error -- train: 0.4256209433078766, -- test: 0.7331589460372925 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.132537364959717, -- test: -25.861682891845703 \n",
      "Root Mean Squared Error -- train: 0.43628692626953125, -- test: 0.7822319269180298 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.308693885803223, -- test: -25.532432556152344 \n",
      "Root Mean Squared Error -- train: 0.41449233889579773, -- test: 0.7774806618690491 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.101426601409912, -- test: -23.255537033081055 \n",
      "Root Mean Squared Error -- train: 0.40882623195648193, -- test: 0.7437941431999207 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.125866413116455, -- test: -24.70551109313965 \n",
      "Root Mean Squared Error -- train: 0.4094984233379364, -- test: 0.7654178738594055 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.226383209228516, -- test: -29.08365249633789 \n",
      "Root Mean Squared Error -- train: 0.41225147247314453, -- test: 0.8272872567176819 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.193917274475098, -- test: -27.169919967651367 \n",
      "Root Mean Squared Error -- train: 0.4113643169403076, -- test: 0.8008317351341248 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.260120868682861, -- test: -25.637557983398438 \n",
      "Root Mean Squared Error -- train: 0.4131714403629303, -- test: 0.7790008783340454 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.101646900177002, -- test: -24.59490394592285 \n",
      "Root Mean Squared Error -- train: 0.408832311630249, -- test: 0.7637898921966553 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -22.097238540649414\n",
      "Test Root MSE of all sampled models: 0.7801327705383301\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 13 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.990837097167969 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 14 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -7.415240287780762, -- test: -22.860458374023438 \n",
      "Root Mean Squared Error -- train: 0.4455379843711853, -- test: 0.7412813901901245 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.419655799865723, -- test: -26.481975555419922 \n",
      "Root Mean Squared Error -- train: 0.41937968134880066, -- test: 0.79485684633255 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.1493048667907715, -- test: -22.926284790039062 \n",
      "Root Mean Squared Error -- train: 0.41198983788490295, -- test: 0.7422897219657898 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -8.996867179870605, -- test: -22.229421615600586 \n",
      "Root Mean Squared Error -- train: 0.4841969609260559, -- test: 0.7315447330474854 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.08989953994751, -- test: -22.570444107055664 \n",
      "Root Mean Squared Error -- train: 0.41034814715385437, -- test: 0.7368226051330566 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.058144569396973, -- test: -24.702421188354492 \n",
      "Root Mean Squared Error -- train: 0.409467875957489, -- test: 0.768997311592102 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.043821811676025, -- test: -25.70043182373047 \n",
      "Root Mean Squared Error -- train: 0.4090702533721924, -- test: 0.7836049795150757 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.0724687576293945, -- test: -23.70464324951172 \n",
      "Root Mean Squared Error -- train: 0.40986520051956177, -- test: 0.7541102766990662 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.120969772338867, -- test: -21.998924255371094 \n",
      "Root Mean Squared Error -- train: 0.4112075865268707, -- test: 0.7279558181762695 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.093362808227539, -- test: -24.08873748779297 \n",
      "Root Mean Squared Error -- train: 0.410444051027298, -- test: 0.7598755955696106 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -19.480426788330078\n",
      "Test Root MSE of all sampled models: 0.7571496367454529\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 14 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.498955249786377 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 15 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.318204402923584, -- test: -26.02782440185547 \n",
      "Root Mean Squared Error -- train: 0.4184887707233429, -- test: 0.79204922914505 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -7.75072717666626, -- test: -22.703205108642578 \n",
      "Root Mean Squared Error -- train: 0.4560702443122864, -- test: 0.7423363924026489 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.184784412384033, -- test: -23.753978729248047 \n",
      "Root Mean Squared Error -- train: 0.4148153066635132, -- test: 0.7584009170532227 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.017368316650391, -- test: -23.12485122680664 \n",
      "Root Mean Squared Error -- train: 0.41015923023223877, -- test: 0.7488240599632263 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.654134750366211, -- test: -23.412446975708008 \n",
      "Root Mean Squared Error -- train: 0.4275982975959778, -- test: 0.7532170414924622 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.124459743499756, -- test: -22.20073699951172 \n",
      "Root Mean Squared Error -- train: 0.4131436347961426, -- test: 0.7345303893089294 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.010878562927246, -- test: -23.665332794189453 \n",
      "Root Mean Squared Error -- train: 0.4099777042865753, -- test: 0.7570587992668152 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.07703161239624, -- test: -22.254989624023438 \n",
      "Root Mean Squared Error -- train: 0.4118245840072632, -- test: 0.735377311706543 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.029794692993164, -- test: -21.628917694091797 \n",
      "Root Mean Squared Error -- train: 0.41050663590431213, -- test: 0.7255449295043945 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.999715805053711, -- test: -22.682453155517578 \n",
      "Root Mean Squared Error -- train: 0.40966522693634033, -- test: 0.7420157194137573 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -19.77443504333496\n",
      "Test Root MSE of all sampled models: 0.7387341260910034\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 15 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.1552734375 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 16 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.12365198135376, -- test: -23.848451614379883 \n",
      "Root Mean Squared Error -- train: 0.4149700403213501, -- test: 0.7634021043777466 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.249764442443848, -- test: -20.99811363220215 \n",
      "Root Mean Squared Error -- train: 0.41847512125968933, -- test: 0.7188578248023987 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.040372371673584, -- test: -23.879789352416992 \n",
      "Root Mean Squared Error -- train: 0.4126390814781189, -- test: 0.7638773322105408 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.034822940826416, -- test: -22.781274795532227 \n",
      "Root Mean Squared Error -- train: 0.4124833047389984, -- test: 0.7470356822013855 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.464259147644043, -- test: -25.545148849487305 \n",
      "Root Mean Squared Error -- train: 0.4243701994419098, -- test: 0.7887240052223206 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.931200981140137, -- test: -24.525592803955078 \n",
      "Root Mean Squared Error -- train: 0.4095633625984192, -- test: 0.7736073136329651 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.970738887786865, -- test: -21.83896255493164 \n",
      "Root Mean Squared Error -- train: 0.4106799066066742, -- test: 0.7322801947593689 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.935362339019775, -- test: -22.761524200439453 \n",
      "Root Mean Squared Error -- train: 0.4096810221672058, -- test: 0.7467294335365295 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.001232624053955, -- test: -22.134321212768555 \n",
      "Root Mean Squared Error -- train: 0.4115390479564667, -- test: 0.7369369864463806 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.955710411071777, -- test: -22.02831268310547 \n",
      "Root Mean Squared Error -- train: 0.41025587916374207, -- test: 0.7352690100669861 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -19.901887893676758\n",
      "Test Root MSE of all sampled models: 0.7546764612197876\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 16 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.459862232208252 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 17 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.401063442230225, -- test: -23.49496078491211 \n",
      "Root Mean Squared Error -- train: 0.42452651262283325, -- test: 0.7615621089935303 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.236095905303955, -- test: -21.834999084472656 \n",
      "Root Mean Squared Error -- train: 0.419958233833313, -- test: 0.7356340289115906 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.413568496704102, -- test: -23.485036849975586 \n",
      "Root Mean Squared Error -- train: 0.4248708486557007, -- test: 0.7614098191261292 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.888983726501465, -- test: -23.50750160217285 \n",
      "Root Mean Squared Error -- train: 0.4101797044277191, -- test: 0.7617546916007996 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.106730937957764, -- test: -23.249893188476562 \n",
      "Root Mean Squared Error -- train: 0.41634073853492737, -- test: 0.7577900886535645 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.873829364776611, -- test: -23.547998428344727 \n",
      "Root Mean Squared Error -- train: 0.40974748134613037, -- test: 0.762376070022583 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.876939296722412, -- test: -24.931655883789062 \n",
      "Root Mean Squared Error -- train: 0.4098362326622009, -- test: 0.7833103537559509 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.909643173217773, -- test: -25.318796157836914 \n",
      "Root Mean Squared Error -- train: 0.4107682406902313, -- test: 0.7890682220458984 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.960719108581543, -- test: -23.889293670654297 \n",
      "Root Mean Squared Error -- train: 0.4122196137905121, -- test: 0.7675927877426147 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.105221271514893, -- test: -22.983726501464844 \n",
      "Root Mean Squared Error -- train: 0.4162983298301697, -- test: 0.7536718845367432 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -19.270545959472656\n",
      "Test Root MSE of all sampled models: 0.7666923403739929\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 17 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.968940258026123 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 18 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.296687126159668, -- test: -22.545377731323242 \n",
      "Root Mean Squared Error -- train: 0.42352017760276794, -- test: 0.7503271102905273 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.024203777313232, -- test: -21.623010635375977 \n",
      "Root Mean Squared Error -- train: 0.4158559739589691, -- test: 0.735672652721405 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.7588982582092285, -- test: -22.241609573364258 \n",
      "Root Mean Squared Error -- train: 0.408255398273468, -- test: 0.7455326318740845 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.701052188873291, -- test: -22.87285804748535 \n",
      "Root Mean Squared Error -- train: 0.434644877910614, -- test: 0.7554616928100586 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.363462924957275, -- test: -19.679025650024414 \n",
      "Root Mean Squared Error -- train: 0.42537733912467957, -- test: 0.7037882804870605 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.833835601806641, -- test: -21.621915817260742 \n",
      "Root Mean Squared Error -- train: 0.41041651368141174, -- test: 0.7356551289558411 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.046471118927002, -- test: -20.475732803344727 \n",
      "Root Mean Squared Error -- train: 0.41648760437965393, -- test: 0.7170270681381226 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.859280109405518, -- test: -22.845308303833008 \n",
      "Root Mean Squared Error -- train: 0.41114771366119385, -- test: 0.7550311088562012 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.910774230957031, -- test: -20.774877548217773 \n",
      "Root Mean Squared Error -- train: 0.4126235246658325, -- test: 0.7219352126121521 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.828986167907715, -- test: -21.360694885253906 \n",
      "Root Mean Squared Error -- train: 0.41027700901031494, -- test: 0.7314514517784119 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -18.003087997436523\n",
      "Test Root MSE of all sampled models: 0.7370066046714783\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 18 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.833667278289795 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 19 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.772843837738037, -- test: -22.027542114257812 \n",
      "Root Mean Squared Error -- train: 0.4104670286178589, -- test: 0.7455943822860718 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.973138809204102, -- test: -22.84673500061035 \n",
      "Root Mean Squared Error -- train: 0.41624176502227783, -- test: 0.7585752606391907 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.736912727355957, -- test: -23.509370803833008 \n",
      "Root Mean Squared Error -- train: 0.40942248702049255, -- test: 0.7689149379730225 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.713341236114502, -- test: -23.383312225341797 \n",
      "Root Mean Squared Error -- train: 0.4087357819080353, -- test: 0.7669587135314941 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.716305255889893, -- test: -23.22140121459961 \n",
      "Root Mean Squared Error -- train: 0.4088222086429596, -- test: 0.7644387483596802 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.744453430175781, -- test: -22.243186950683594 \n",
      "Root Mean Squared Error -- train: 0.40964192152023315, -- test: 0.7490333318710327 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.8828630447387695, -- test: -20.397310256958008 \n",
      "Root Mean Squared Error -- train: 0.4136489927768707, -- test: 0.7190651893615723 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.717155933380127, -- test: -23.291332244873047 \n",
      "Root Mean Squared Error -- train: 0.40884700417518616, -- test: 0.76552814245224 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.048189163208008, -- test: -24.589366912841797 \n",
      "Root Mean Squared Error -- train: 0.41838496923446655, -- test: 0.785475492477417 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.7253546714782715, -- test: -23.053213119506836 \n",
      "Root Mean Squared Error -- train: 0.4090859293937683, -- test: 0.761812150478363 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -18.430917739868164\n",
      "Test Root MSE of all sampled models: 0.7452736496925354\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 19 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -7.102439880371094 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 20 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.806326866149902, -- test: -22.73611068725586 \n",
      "Root Mean Squared Error -- train: 0.4132794737815857, -- test: 0.7604038119316101 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -7.167426109313965, -- test: -25.721345901489258 \n",
      "Root Mean Squared Error -- train: 0.45117032527923584, -- test: 0.8062588572502136 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.0078864097595215, -- test: -20.922510147094727 \n",
      "Root Mean Squared Error -- train: 0.41910672187805176, -- test: 0.7311428189277649 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.788370132446289, -- test: -24.329486846923828 \n",
      "Root Mean Squared Error -- train: 0.4127563238143921, -- test: 0.7852124571800232 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.853013038635254, -- test: -23.08576011657715 \n",
      "Root Mean Squared Error -- train: 0.414636492729187, -- test: 0.7659165859222412 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.719419956207275, -- test: -22.756059646606445 \n",
      "Root Mean Squared Error -- train: 0.41074138879776, -- test: 0.7607194185256958 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.774055004119873, -- test: -20.851442337036133 \n",
      "Root Mean Squared Error -- train: 0.41233882308006287, -- test: 0.7299723625183105 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.717855453491211, -- test: -23.692201614379883 \n",
      "Root Mean Squared Error -- train: 0.4106955826282501, -- test: 0.7753852605819702 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.7256951332092285, -- test: -21.019330978393555 \n",
      "Root Mean Squared Error -- train: 0.4109252095222473, -- test: 0.7327345013618469 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.712108135223389, -- test: -19.807327270507812 \n",
      "Root Mean Squared Error -- train: 0.41052716970443726, -- test: 0.712553858757019 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -18.91864585876465\n",
      "Test Root MSE of all sampled models: 0.7491794228553772\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 20 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.421198844909668 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 21 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.327417850494385, -- test: -19.583921432495117 \n",
      "Root Mean Squared Error -- train: 0.43007421493530273, -- test: 0.7120434045791626 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.586454391479492, -- test: -21.606691360473633 \n",
      "Root Mean Squared Error -- train: 0.4086116850376129, -- test: 0.7457515001296997 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.906564235687256, -- test: -22.742229461669922 \n",
      "Root Mean Squared Error -- train: 0.4180191457271576, -- test: 0.764022946357727 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.716578006744385, -- test: -22.770524978637695 \n",
      "Root Mean Squared Error -- train: 0.44092831015586853, -- test: 0.7644726037979126 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.939790725708008, -- test: -22.621665954589844 \n",
      "Root Mean Squared Error -- train: 0.41898348927497864, -- test: 0.7621037364006042 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.605111598968506, -- test: -22.097902297973633 \n",
      "Root Mean Squared Error -- train: 0.4091659486293793, -- test: 0.7537096738815308 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.601691722869873, -- test: -22.77260971069336 \n",
      "Root Mean Squared Error -- train: 0.4090644121170044, -- test: 0.7645058035850525 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.682140827178955, -- test: -24.960458755493164 \n",
      "Root Mean Squared Error -- train: 0.41144630312919617, -- test: 0.7985103130340576 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.648365497589111, -- test: -23.95438003540039 \n",
      "Root Mean Squared Error -- train: 0.41044795513153076, -- test: 0.7830567955970764 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.607107162475586, -- test: -23.259048461914062 \n",
      "Root Mean Squared Error -- train: 0.409225195646286, -- test: 0.7721956372261047 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -20.07524871826172\n",
      "Test Root MSE of all sampled models: 0.7799773216247559\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 21 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.509366035461426 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 22 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.866513729095459, -- test: -22.2659969329834 \n",
      "Root Mean Squared Error -- train: 0.4186997711658478, -- test: 0.7599393725395203 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.580418586730957, -- test: -24.68410873413086 \n",
      "Root Mean Squared Error -- train: 0.41023528575897217, -- test: 0.7980051040649414 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.673520565032959, -- test: -24.671123504638672 \n",
      "Root Mean Squared Error -- train: 0.4130088686943054, -- test: 0.7978056073188782 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.609065055847168, -- test: -21.768964767456055 \n",
      "Root Mean Squared Error -- train: 0.4110907018184662, -- test: 0.7518763542175293 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.187275409698486, -- test: -21.279760360717773 \n",
      "Root Mean Squared Error -- train: 0.4279909133911133, -- test: 0.7438549995422363 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.650018692016602, -- test: -21.833772659301758 \n",
      "Root Mean Squared Error -- train: 0.41231051087379456, -- test: 0.752932608127594 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.58026647567749, -- test: -23.00194549560547 \n",
      "Root Mean Squared Error -- train: 0.41023075580596924, -- test: 0.7717234492301941 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.540161609649658, -- test: -22.606828689575195 \n",
      "Root Mean Squared Error -- train: 0.4090302288532257, -- test: 0.7654193043708801 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.588219165802002, -- test: -23.088651657104492 \n",
      "Root Mean Squared Error -- train: 0.4104683995246887, -- test: 0.773099958896637 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.627586364746094, -- test: -20.046371459960938 \n",
      "Root Mean Squared Error -- train: 0.411642849445343, -- test: 0.7232367396354675 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -18.221080780029297\n",
      "Test Root MSE of all sampled models: 0.7652438282966614\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 22 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.665360450744629 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 23 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.291360378265381, -- test: -22.329517364501953 \n",
      "Root Mean Squared Error -- train: 0.4328530728816986, -- test: 0.7644621729850769 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.573418617248535, -- test: -22.571104049682617 \n",
      "Root Mean Squared Error -- train: 0.41181114315986633, -- test: 0.7683639526367188 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.492804527282715, -- test: -21.36724090576172 \n",
      "Root Mean Squared Error -- train: 0.4093809127807617, -- test: 0.7487190365791321 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.297981262207031, -- test: -19.593286514282227 \n",
      "Root Mean Squared Error -- train: 0.43304234743118286, -- test: 0.7187935709953308 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.832322597503662, -- test: -22.324007034301758 \n",
      "Root Mean Squared Error -- train: 0.41952094435691833, -- test: 0.7643728852272034 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.514923572540283, -- test: -24.058246612548828 \n",
      "Root Mean Squared Error -- train: 0.410049170255661, -- test: 0.7919588088989258 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.514791488647461, -- test: -21.744522094726562 \n",
      "Root Mean Squared Error -- train: 0.41004517674446106, -- test: 0.7549306154251099 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.509646892547607, -- test: -23.858802795410156 \n",
      "Root Mean Squared Error -- train: 0.4098898470401764, -- test: 0.7888354659080505 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.505561828613281, -- test: -21.869115829467773 \n",
      "Root Mean Squared Error -- train: 0.40976646542549133, -- test: 0.7569707036018372 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.569313049316406, -- test: -20.219829559326172 \n",
      "Root Mean Squared Error -- train: 0.4116877317428589, -- test: 0.7295031547546387 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -18.59313201904297\n",
      "Test Root MSE of all sampled models: 0.7676954865455627\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 23 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.503494739532471 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 24 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.52630615234375, -- test: -20.27875518798828 \n",
      "Root Mean Squared Error -- train: 0.4121738076210022, -- test: 0.7338454723358154 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.429574489593506, -- test: -22.387418746948242 \n",
      "Root Mean Squared Error -- train: 0.409231036901474, -- test: 0.7689092755317688 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.964780807495117, -- test: -19.93260383605957 \n",
      "Root Mean Squared Error -- train: 0.45368775725364685, -- test: 0.727928102016449 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.40250825881958, -- test: -21.019729614257812 \n",
      "Root Mean Squared Error -- train: 0.4084038734436035, -- test: 0.7463544607162476 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.885575771331787, -- test: -21.88561248779297 \n",
      "Root Mean Squared Error -- train: 0.4229241907596588, -- test: 0.7607116103172302 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.502507209777832, -- test: -22.000743865966797 \n",
      "Root Mean Squared Error -- train: 0.4114517271518707, -- test: 0.7626002430915833 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.474674224853516, -- test: -21.58789825439453 \n",
      "Root Mean Squared Error -- train: 0.41060566902160645, -- test: 0.7558059692382812 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.438016891479492, -- test: -22.251760482788086 \n",
      "Root Mean Squared Error -- train: 0.4094887375831604, -- test: 0.7667018175125122 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.498171329498291, -- test: -23.205778121948242 \n",
      "Root Mean Squared Error -- train: 0.4113200604915619, -- test: 0.7820941209793091 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.46555233001709, -- test: -20.916648864746094 \n",
      "Root Mean Squared Error -- train: 0.4103280007839203, -- test: 0.7446268796920776 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -18.70842933654785\n",
      "Test Root MSE of all sampled models: 0.7637001276016235\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 24 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.823466777801514 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 25 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.401352405548096, -- test: -22.27914047241211 \n",
      "Root Mean Squared Error -- train: 0.4101407825946808, -- test: 0.7706709504127502 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.369537353515625, -- test: -22.223072052001953 \n",
      "Root Mean Squared Error -- train: 0.4091612696647644, -- test: 0.7697529196739197 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.576237678527832, -- test: -20.95486068725586 \n",
      "Root Mean Squared Error -- train: 0.41548365354537964, -- test: 0.7486859560012817 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.5200066566467285, -- test: -22.371536254882812 \n",
      "Root Mean Squared Error -- train: 0.4137732684612274, -- test: 0.7721814513206482 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.413911819458008, -- test: -22.90291976928711 \n",
      "Root Mean Squared Error -- train: 0.41052675247192383, -- test: 0.78081214427948 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.398682117462158, -- test: -21.627368927001953 \n",
      "Root Mean Squared Error -- train: 0.4100586175918579, -- test: 0.7599300742149353 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.390080451965332, -- test: -20.832433700561523 \n",
      "Root Mean Squared Error -- train: 0.40979400277137756, -- test: 0.746620774269104 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.3917670249938965, -- test: -21.964014053344727 \n",
      "Root Mean Squared Error -- train: 0.40984591841697693, -- test: 0.765496551990509 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.391782760620117, -- test: -20.566692352294922 \n",
      "Root Mean Squared Error -- train: 0.40984639525413513, -- test: 0.7421183586120605 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.452781677246094, -- test: -20.105636596679688 \n",
      "Root Mean Squared Error -- train: 0.4117191731929779, -- test: 0.7342411875724792 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -17.000883102416992\n",
      "Test Root MSE of all sampled models: 0.7533690929412842\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 25 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.3472981452941895 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 26 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.467737197875977, -- test: -21.173255920410156 \n",
      "Root Mean Squared Error -- train: 0.41396012902259827, -- test: 0.7557936906814575 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.3154096603393555, -- test: -21.30109214782715 \n",
      "Root Mean Squared Error -- train: 0.4092489778995514, -- test: 0.7579438090324402 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.369459629058838, -- test: -22.291275024414062 \n",
      "Root Mean Squared Error -- train: 0.41092681884765625, -- test: 0.7743958234786987 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.311150550842285, -- test: -22.035818099975586 \n",
      "Root Mean Squared Error -- train: 0.4091164767742157, -- test: 0.7701849937438965 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.693500995635986, -- test: -21.154052734375 \n",
      "Root Mean Squared Error -- train: 0.42084547877311707, -- test: 0.7554701566696167 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.377486228942871, -- test: -19.635868072509766 \n",
      "Root Mean Squared Error -- train: 0.411175400018692, -- test: 0.7294397354125977 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.329850673675537, -- test: -23.261762619018555 \n",
      "Root Mean Squared Error -- train: 0.40969792008399963, -- test: 0.790188193321228 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.4013166427612305, -- test: -19.22869300842285 \n",
      "Root Mean Squared Error -- train: 0.4119125306606293, -- test: 0.7222989201545715 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.3136749267578125, -- test: -22.227121353149414 \n",
      "Root Mean Squared Error -- train: 0.4091950058937073, -- test: 0.7733405232429504 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.403148651123047, -- test: -22.133634567260742 \n",
      "Root Mean Squared Error -- train: 0.4119691252708435, -- test: 0.7718000411987305 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -17.67673110961914\n",
      "Test Root MSE of all sampled models: 0.7665318250656128\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 26 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.010150909423828 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 27 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.320894241333008, -- test: -21.917341232299805 \n",
      "Root Mean Squared Error -- train: 0.41117459535598755, -- test: 0.7717116475105286 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.241817474365234, -- test: -21.981151580810547 \n",
      "Root Mean Squared Error -- train: 0.40869611501693726, -- test: 0.7727733254432678 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.433556079864502, -- test: -22.641447067260742 \n",
      "Root Mean Squared Error -- train: 0.4146800935268402, -- test: 0.7836747169494629 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.306484222412109, -- test: -21.85236358642578 \n",
      "Root Mean Squared Error -- train: 0.41072407364845276, -- test: 0.7706290483474731 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.779728889465332, -- test: -21.263042449951172 \n",
      "Root Mean Squared Error -- train: 0.42527058720588684, -- test: 0.7607401013374329 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.295572280883789, -- test: -21.476591110229492 \n",
      "Root Mean Squared Error -- train: 0.41038256883621216, -- test: 0.7643383145332336 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.410102367401123, -- test: -19.167329788208008 \n",
      "Root Mean Squared Error -- train: 0.4139527678489685, -- test: 0.7244808077812195 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.300896167755127, -- test: -21.6557559967041 \n",
      "Root Mean Squared Error -- train: 0.41054919362068176, -- test: 0.7673441767692566 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.349437236785889, -- test: -21.31835174560547 \n",
      "Root Mean Squared Error -- train: 0.4120655357837677, -- test: 0.7616737484931946 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.303032875061035, -- test: -21.021921157836914 \n",
      "Root Mean Squared Error -- train: 0.41061607003211975, -- test: 0.7566567063331604 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -18.056961059570312\n",
      "Test Root MSE of all sampled models: 0.7648141980171204\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 27 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.133961200714111 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 28 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.24617338180542, -- test: -21.723613739013672 \n",
      "Root Mean Squared Error -- train: 0.4105536937713623, -- test: 0.771907389163971 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.213104248046875, -- test: -20.98993492126465 \n",
      "Root Mean Squared Error -- train: 0.40950798988342285, -- test: 0.7594837546348572 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.469535827636719, -- test: -21.493314743041992 \n",
      "Root Mean Squared Error -- train: 0.41754817962646484, -- test: 0.7680293321609497 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.301305294036865, -- test: -19.81798553466797 \n",
      "Root Mean Squared Error -- train: 0.41229116916656494, -- test: 0.7392057180404663 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.4371137619018555, -- test: -22.599231719970703 \n",
      "Root Mean Squared Error -- train: 0.4165402054786682, -- test: 0.7864776849746704 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.1971025466918945, -- test: -19.401968002319336 \n",
      "Root Mean Squared Error -- train: 0.40900102257728577, -- test: 0.7318723201751709 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.290143966674805, -- test: -19.81707191467285 \n",
      "Root Mean Squared Error -- train: 0.4119400084018707, -- test: 0.739189624786377 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.24691915512085, -- test: -19.636716842651367 \n",
      "Root Mean Squared Error -- train: 0.4105772376060486, -- test: 0.7360192537307739 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.300412178039551, -- test: -20.445436477661133 \n",
      "Root Mean Squared Error -- train: 0.41226309537887573, -- test: 0.7501305341720581 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.314090251922607, -- test: -19.867942810058594 \n",
      "Root Mean Squared Error -- train: 0.4126930236816406, -- test: 0.7400813698768616 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -16.067337036132812\n",
      "Test Root MSE of all sampled models: 0.735098123550415\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 28 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.375701427459717 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 29 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.302785873413086, -- test: -20.709251403808594 \n",
      "Root Mean Squared Error -- train: 0.41409510374069214, -- test: 0.7580798864364624 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.579855918884277, -- test: -21.794570922851562 \n",
      "Root Mean Squared Error -- train: 0.42276009917259216, -- test: 0.7765883803367615 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.156309604644775, -- test: -20.96682357788086 \n",
      "Root Mean Squared Error -- train: 0.40944015979766846, -- test: 0.7625131011009216 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.035423278808594, -- test: -19.44103240966797 \n",
      "Root Mean Squared Error -- train: 0.4366336762905121, -- test: 0.7358627319335938 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.43897008895874, -- test: -21.66876792907715 \n",
      "Root Mean Squared Error -- train: 0.41837647557258606, -- test: 0.7744657397270203 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.17824649810791, -- test: -22.090471267700195 \n",
      "Root Mean Squared Error -- train: 0.41014066338539124, -- test: 0.7815585136413574 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.298427581787109, -- test: -21.194231033325195 \n",
      "Root Mean Squared Error -- train: 0.4139573574066162, -- test: 0.7664057016372681 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.129901885986328, -- test: -21.530380249023438 \n",
      "Root Mean Squared Error -- train: 0.4085952937602997, -- test: 0.7721239328384399 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.184657096862793, -- test: -20.6003475189209 \n",
      "Root Mean Squared Error -- train: 0.4103451371192932, -- test: 0.7561976909637451 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.1769561767578125, -- test: -19.28898048400879 \n",
      "Root Mean Squared Error -- train: 0.41009947657585144, -- test: 0.7331538796424866 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -17.456066131591797\n",
      "Test Root MSE of all sampled models: 0.7632806897163391\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 29 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.934130668640137 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 30 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.100796222686768, -- test: -19.322628021240234 \n",
      "Root Mean Squared Error -- train: 0.40942350029945374, -- test: 0.7371124029159546 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.236600399017334, -- test: -20.78958511352539 \n",
      "Root Mean Squared Error -- train: 0.41378164291381836, -- test: 0.7629470825195312 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.11228609085083, -- test: -20.714282989501953 \n",
      "Root Mean Squared Error -- train: 0.40979400277137756, -- test: 0.7616422176361084 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.301573276519775, -- test: -20.293027877807617 \n",
      "Root Mean Squared Error -- train: 0.41585052013397217, -- test: 0.7543012499809265 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.11550760269165, -- test: -22.13128662109375 \n",
      "Root Mean Squared Error -- train: 0.4098978638648987, -- test: 0.7858325242996216 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.161404132843018, -- test: -21.707839965820312 \n",
      "Root Mean Squared Error -- train: 0.41137421131134033, -- test: 0.7786824107170105 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.161652088165283, -- test: -21.153623580932617 \n",
      "Root Mean Squared Error -- train: 0.41138213872909546, -- test: 0.7692238092422485 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.151928424835205, -- test: -20.296934127807617 \n",
      "Root Mean Squared Error -- train: 0.4110698401927948, -- test: 0.7543696761131287 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.132177352905273, -- test: -20.57585906982422 \n",
      "Root Mean Squared Error -- train: 0.41043466329574585, -- test: 0.7592378854751587 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.240367412567139, -- test: -21.4095458984375 \n",
      "Root Mean Squared Error -- train: 0.4139018654823303, -- test: 0.7736058831214905 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -18.00782012939453\n",
      "Test Root MSE of all sampled models: 0.773309588432312\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 30 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.809974193572998 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 31 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.146399021148682, -- test: -22.106666564941406 \n",
      "Root Mean Squared Error -- train: 0.4126283526420593, -- test: 0.7889426946640015 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.949190139770508, -- test: -20.29195785522461 \n",
      "Root Mean Squared Error -- train: 0.43779557943344116, -- test: 0.7576606273651123 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.030444622039795, -- test: -21.073768615722656 \n",
      "Root Mean Squared Error -- train: 0.4088652431964874, -- test: 0.7712931036949158 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.270458698272705, -- test: -23.25182342529297 \n",
      "Root Mean Squared Error -- train: 0.41661694645881653, -- test: 0.8080599904060364 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.0804314613342285, -- test: -21.049842834472656 \n",
      "Root Mean Squared Error -- train: 0.4104917347431183, -- test: 0.7708795070648193 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.047107696533203, -- test: -20.24799156188965 \n",
      "Root Mean Squared Error -- train: 0.4094081521034241, -- test: 0.7568866014480591 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.049727916717529, -- test: -19.50804901123047 \n",
      "Root Mean Squared Error -- train: 0.40949344635009766, -- test: 0.7437407374382019 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.071371078491211, -- test: -20.584678649902344 \n",
      "Root Mean Squared Error -- train: 0.4101974070072174, -- test: 0.762793242931366 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.107661247253418, -- test: -20.048873901367188 \n",
      "Root Mean Squared Error -- train: 0.4113750457763672, -- test: 0.7533716559410095 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.066839218139648, -- test: -20.582380294799805 \n",
      "Root Mean Squared Error -- train: 0.41005006432533264, -- test: 0.7627531290054321 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -16.846477508544922\n",
      "Test Root MSE of all sampled models: 0.7571064829826355\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 31 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.890133380889893 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 32 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.9823503494262695, -- test: -21.23589515686035 \n",
      "Root Mean Squared Error -- train: 0.40900036692619324, -- test: 0.7775381207466125 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.014320373535156, -- test: -21.59528160095215 \n",
      "Root Mean Squared Error -- train: 0.41005051136016846, -- test: 0.7837311625480652 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.201148986816406, -- test: -22.71123504638672 \n",
      "Root Mean Squared Error -- train: 0.41613438725471497, -- test: 0.8026568293571472 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.093043327331543, -- test: -19.980958938598633 \n",
      "Root Mean Squared Error -- train: 0.4126250147819519, -- test: 0.7555149793624878 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.9792280197143555, -- test: -20.746536254882812 \n",
      "Root Mean Squared Error -- train: 0.40889763832092285, -- test: 0.7690253257751465 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.035820007324219, -- test: -20.277732849121094 \n",
      "Root Mean Squared Error -- train: 0.4107552170753479, -- test: 0.7607806324958801 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.992242813110352, -- test: -21.97027015686035 \n",
      "Root Mean Squared Error -- train: 0.40932562947273254, -- test: 0.790141224861145 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.055358409881592, -- test: -21.21847152709961 \n",
      "Root Mean Squared Error -- train: 0.4113945960998535, -- test: 0.7772366404533386 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.1661763191223145, -- test: -18.050920486450195 \n",
      "Root Mean Squared Error -- train: 0.41500234603881836, -- test: 0.7203313112258911 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.067049503326416, -- test: -21.528579711914062 \n",
      "Root Mean Squared Error -- train: 0.41177672147750854, -- test: 0.7825853824615479 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -16.718982696533203\n",
      "Test Root MSE of all sampled models: 0.7667106986045837\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 32 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.0271830558776855 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 33 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.567060947418213, -- test: -19.797866821289062 \n",
      "Root Mean Squared Error -- train: 0.4295979142189026, -- test: 0.755580723285675 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.916672229766846, -- test: -20.98223114013672 \n",
      "Root Mean Squared Error -- train: 0.40853047370910645, -- test: 0.7765669226646423 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.940759658813477, -- test: -19.39509391784668 \n",
      "Root Mean Squared Error -- train: 0.4093300700187683, -- test: 0.7483097910881042 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.459400653839111, -- test: -20.87008285522461 \n",
      "Root Mean Squared Error -- train: 0.42618250846862793, -- test: 0.7746040225028992 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.934323310852051, -- test: -20.144298553466797 \n",
      "Root Mean Squared Error -- train: 0.40911656618118286, -- test: 0.7617791295051575 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.94645357131958, -- test: -21.354835510253906 \n",
      "Root Mean Squared Error -- train: 0.409518837928772, -- test: 0.783052921295166 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.987982749938965, -- test: -19.177988052368164 \n",
      "Root Mean Squared Error -- train: 0.41089311242103577, -- test: 0.7443610429763794 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.958327770233154, -- test: -19.598312377929688 \n",
      "Root Mean Squared Error -- train: 0.40991225838661194, -- test: 0.751987099647522 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.039002895355225, -- test: -20.169416427612305 \n",
      "Root Mean Squared Error -- train: 0.41257521510124207, -- test: 0.7622265815734863 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.021895885467529, -- test: -19.970745086669922 \n",
      "Root Mean Squared Error -- train: 0.412011981010437, -- test: 0.7586801648139954 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -17.721776962280273\n",
      "Test Root MSE of all sampled models: 0.7593382000923157\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 33 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.993461608886719 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 34 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.871915817260742, -- test: -19.89227294921875 \n",
      "Root Mean Squared Error -- train: 0.40873005986213684, -- test: 0.7606178522109985 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.906104564666748, -- test: -20.588394165039062 \n",
      "Root Mean Squared Error -- train: 0.40987417101860046, -- test: 0.7730520963668823 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.97585391998291, -- test: -20.10199737548828 \n",
      "Root Mean Squared Error -- train: 0.4121984839439392, -- test: 0.7643853425979614 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.909382343292236, -- test: -20.955516815185547 \n",
      "Root Mean Squared Error -- train: 0.40998369455337524, -- test: 0.7795299291610718 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.881064414978027, -- test: -20.692302703857422 \n",
      "Root Mean Squared Error -- train: 0.4090365171432495, -- test: 0.7748910188674927 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.941227436065674, -- test: -20.237834930419922 \n",
      "Root Mean Squared Error -- train: 0.41104623675346375, -- test: 0.7668156027793884 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.952328681945801, -- test: -18.607402801513672 \n",
      "Root Mean Squared Error -- train: 0.41141602396965027, -- test: 0.7371165752410889 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.895203113555908, -- test: -20.008525848388672 \n",
      "Root Mean Squared Error -- train: 0.40950971841812134, -- test: 0.7627084851264954 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.9461541175842285, -- test: -19.643543243408203 \n",
      "Root Mean Squared Error -- train: 0.41121041774749756, -- test: 0.7561253905296326 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.991462707519531, -- test: -19.193340301513672 \n",
      "Root Mean Squared Error -- train: 0.4127168655395508, -- test: 0.7479254603385925 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -16.352088928222656\n",
      "Test Root MSE of all sampled models: 0.7540977597236633\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 34 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.988056182861328 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 35 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.882905960083008, -- test: -19.151235580444336 \n",
      "Root Mean Squared Error -- train: 0.4431605339050293, -- test: 0.7504384517669678 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.006115436553955, -- test: -20.374588012695312 \n",
      "Root Mean Squared Error -- train: 0.41491538286209106, -- test: 0.7726410627365112 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.444344997406006, -- test: -18.796764373779297 \n",
      "Root Mean Squared Error -- train: 0.42926496267318726, -- test: 0.7438814043998718 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.808568954467773, -- test: -20.209205627441406 \n",
      "Root Mean Squared Error -- train: 0.40828192234039307, -- test: 0.769676923751831 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.811606407165527, -- test: -20.177806854248047 \n",
      "Root Mean Squared Error -- train: 0.408384770154953, -- test: 0.7691129446029663 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.8585100173950195, -- test: -18.306262969970703 \n",
      "Root Mean Squared Error -- train: 0.4099690616130829, -- test: 0.7347114682197571 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.867035388946533, -- test: -18.31103515625 \n",
      "Root Mean Squared Error -- train: 0.4102563261985779, -- test: 0.7348012328147888 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.858729362487793, -- test: -20.860872268676758 \n",
      "Root Mean Squared Error -- train: 0.40997645258903503, -- test: 0.7812912464141846 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.837908744812012, -- test: -16.599597930908203 \n",
      "Root Mean Squared Error -- train: 0.40927398204803467, -- test: 0.7018724083900452 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.868607997894287, -- test: -18.61868667602539 \n",
      "Root Mean Squared Error -- train: 0.4103093445301056, -- test: 0.7405653595924377 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -16.05406379699707\n",
      "Test Root MSE of all sampled models: 0.7492272257804871\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 35 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.933876037597656 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 36 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.988275527954102, -- test: -17.44600486755371 \n",
      "Root Mean Squared Error -- train: 0.4160313904285431, -- test: 0.7214860916137695 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.852659702301025, -- test: -18.433774948120117 \n",
      "Root Mean Squared Error -- train: 0.41146036982536316, -- test: 0.7403324842453003 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.8096137046813965, -- test: -20.07513427734375 \n",
      "Root Mean Squared Error -- train: 0.4099988043308258, -- test: 0.7706306576728821 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.937463760375977, -- test: -18.502784729003906 \n",
      "Root Mean Squared Error -- train: 0.41432464122772217, -- test: 0.741631269454956 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.777811050415039, -- test: -19.742263793945312 \n",
      "Root Mean Squared Error -- train: 0.4089156687259674, -- test: 0.764583170413971 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.830551624298096, -- test: -20.130800247192383 \n",
      "Root Mean Squared Error -- train: 0.4107103645801544, -- test: 0.7716373801231384 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.819085121154785, -- test: -20.17837905883789 \n",
      "Root Mean Squared Error -- train: 0.41032084822654724, -- test: 0.77249675989151 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.90917444229126, -- test: -20.528745651245117 \n",
      "Root Mean Squared Error -- train: 0.41337135434150696, -- test: 0.7787960171699524 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.833218097686768, -- test: -20.502290725708008 \n",
      "Root Mean Squared Error -- train: 0.41080090403556824, -- test: 0.778322160243988 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.8387250900268555, -- test: -19.192859649658203 \n",
      "Root Mean Squared Error -- train: 0.41098782420158386, -- test: 0.7544958591461182 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -17.309635162353516\n",
      "Test Root MSE of all sampled models: 0.7732328176498413\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 36 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.612987995147705 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 37 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.909699440002441, -- test: -21.336929321289062 \n",
      "Root Mean Squared Error -- train: 0.4150814414024353, -- test: 0.7965934872627258 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.912708759307861, -- test: -17.799556732177734 \n",
      "Root Mean Squared Error -- train: 0.4477919936180115, -- test: 0.7314493656158447 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.7087602615356445, -- test: -19.237207412719727 \n",
      "Root Mean Squared Error -- train: 0.4082132577896118, -- test: 0.7586001753807068 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.168560981750488, -- test: -20.362289428710938 \n",
      "Root Mean Squared Error -- train: 0.4237653315067291, -- test: 0.779188334941864 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.147299766540527, -- test: -20.830341339111328 \n",
      "Root Mean Squared Error -- train: 0.42305880784988403, -- test: 0.7875948548316956 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.7721662521362305, -- test: -19.027366638183594 \n",
      "Root Mean Squared Error -- train: 0.4103929400444031, -- test: 0.7546980977058411 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.7274065017700195, -- test: -20.16261863708496 \n",
      "Root Mean Squared Error -- train: 0.40885546803474426, -- test: 0.7755744457244873 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.724510192871094, -- test: -19.258193969726562 \n",
      "Root Mean Squared Error -- train: 0.4087558090686798, -- test: 0.7589892745018005 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.777939319610596, -- test: -19.499181747436523 \n",
      "Root Mean Squared Error -- train: 0.4105908274650574, -- test: 0.763443648815155 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.7383294105529785, -- test: -20.64636993408203 \n",
      "Root Mean Squared Error -- train: 0.4092312157154083, -- test: 0.7843014001846313 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -15.746565818786621\n",
      "Test Root MSE of all sampled models: 0.7685867547988892\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 37 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.639057636260986 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 38 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.726340293884277, -- test: -19.30077362060547 \n",
      "Root Mean Squared Error -- train: 0.410500168800354, -- test: 0.7631076574325562 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.721585750579834, -- test: -19.839250564575195 \n",
      "Root Mean Squared Error -- train: 0.4103356897830963, -- test: 0.7730606198310852 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.687417030334473, -- test: -20.342517852783203 \n",
      "Root Mean Squared Error -- train: 0.4091517925262451, -- test: 0.782248318195343 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.306814670562744, -- test: -20.46283721923828 \n",
      "Root Mean Squared Error -- train: 0.46193718910217285, -- test: 0.7844288945198059 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.710510730743408, -- test: -20.385251998901367 \n",
      "Root Mean Squared Error -- train: 0.4099523723125458, -- test: 0.7830234169960022 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.766547203063965, -- test: -17.877317428588867 \n",
      "Root Mean Squared Error -- train: 0.41188833117485046, -- test: 0.7361494898796082 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.779929161071777, -- test: -21.547151565551758 \n",
      "Root Mean Squared Error -- train: 0.4123493432998657, -- test: 0.8038136959075928 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.720478057861328, -- test: -19.359189987182617 \n",
      "Root Mean Squared Error -- train: 0.4102973937988281, -- test: 0.7641937136650085 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.7151618003845215, -- test: -19.218961715698242 \n",
      "Root Mean Squared Error -- train: 0.4101133644580841, -- test: 0.7615841031074524 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.7423858642578125, -- test: -20.46698570251465 \n",
      "Root Mean Squared Error -- train: 0.41105470061302185, -- test: 0.7845039367675781 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -16.407634735107422\n",
      "Test Root MSE of all sampled models: 0.7752750515937805\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 38 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.8275513648986816 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 39 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.738788604736328, -- test: -20.210678100585938 \n",
      "Root Mean Squared Error -- train: 0.4125899076461792, -- test: 0.7832105159759521 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.860909461975098, -- test: -19.196666717529297 \n",
      "Root Mean Squared Error -- train: 0.4168075621128082, -- test: 0.7644426822662354 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.238245487213135, -- test: -20.252948760986328 \n",
      "Root Mean Squared Error -- train: 0.42957794666290283, -- test: 0.7839831113815308 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.806704521179199, -- test: -19.001495361328125 \n",
      "Root Mean Squared Error -- train: 0.41494080424308777, -- test: 0.7607771754264832 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.6145782470703125, -- test: -20.076684951782227 \n",
      "Root Mean Squared Error -- train: 0.408255398273468, -- test: 0.7807562947273254 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.716292858123779, -- test: -20.416574478149414 \n",
      "Root Mean Squared Error -- train: 0.4118082523345947, -- test: 0.7869666814804077 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.703652381896973, -- test: -16.696748733520508 \n",
      "Root Mean Squared Error -- train: 0.41136839985847473, -- test: 0.7160747647285461 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.794408798217773, -- test: -18.60851287841797 \n",
      "Root Mean Squared Error -- train: 0.4145161807537079, -- test: 0.7533425688743591 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.686448574066162, -- test: -19.924152374267578 \n",
      "Root Mean Squared Error -- train: 0.4107690155506134, -- test: 0.7779532074928284 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.686749458312988, -- test: -18.677753448486328 \n",
      "Root Mean Squared Error -- train: 0.4107794761657715, -- test: 0.7546578645706177 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -15.963172912597656\n",
      "Test Root MSE of all sampled models: 0.7618003487586975\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 39 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.526808261871338 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 40 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.682908058166504, -- test: -19.325897216796875 \n",
      "Root Mean Squared Error -- train: 0.41229182481765747, -- test: 0.7701385617256165 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.722455024719238, -- test: -20.500253677368164 \n",
      "Root Mean Squared Error -- train: 0.41367536783218384, -- test: 0.7918636202812195 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.81458854675293, -- test: -18.794801712036133 \n",
      "Root Mean Squared Error -- train: 0.41688087582588196, -- test: 0.7601097226142883 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.025447845458984, -- test: -18.083343505859375 \n",
      "Root Mean Squared Error -- train: 0.4569234848022461, -- test: 0.7464637756347656 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.777688980102539, -- test: -19.11443519592285 \n",
      "Root Mean Squared Error -- train: 0.4156000316143036, -- test: 0.7661611437797546 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.62418794631958, -- test: -18.598957061767578 \n",
      "Root Mean Squared Error -- train: 0.4102289378643036, -- test: 0.7563778162002563 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.607564926147461, -- test: -19.280515670776367 \n",
      "Root Mean Squared Error -- train: 0.4096430540084839, -- test: 0.7692867517471313 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.618863582611084, -- test: -19.215808868408203 \n",
      "Root Mean Squared Error -- train: 0.41004136204719543, -- test: 0.7680703997612 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.649196624755859, -- test: -18.11602020263672 \n",
      "Root Mean Squared Error -- train: 0.4111087918281555, -- test: 0.7470960021018982 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.617300033569336, -- test: -18.30935287475586 \n",
      "Root Mean Squared Error -- train: 0.4099862575531006, -- test: 0.7508255243301392 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -14.747330665588379\n",
      "Test Root MSE of all sampled models: 0.75963294506073\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 40 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.596900939941406 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 41 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.813496112823486, -- test: -19.64113998413086 \n",
      "Root Mean Squared Error -- train: 0.41850990056991577, -- test: 0.7793341875076294 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.821597099304199, -- test: -18.509366989135742 \n",
      "Root Mean Squared Error -- train: 0.4187919497489929, -- test: 0.7578731179237366 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.674736022949219, -- test: -17.78329086303711 \n",
      "Root Mean Squared Error -- train: 0.41364943981170654, -- test: 0.7437790036201477 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.548945426940918, -- test: -18.65668487548828 \n",
      "Root Mean Squared Error -- train: 0.4091933071613312, -- test: 0.7607009410858154 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.835074424743652, -- test: -17.640043258666992 \n",
      "Root Mean Squared Error -- train: 0.419260710477829, -- test: 0.7409667372703552 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.589506149291992, -- test: -17.187847137451172 \n",
      "Root Mean Squared Error -- train: 0.41063544154167175, -- test: 0.732018232345581 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.602067470550537, -- test: -17.74201774597168 \n",
      "Root Mean Squared Error -- train: 0.4110810458660126, -- test: 0.7429698705673218 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.571793556213379, -- test: -16.633304595947266 \n",
      "Root Mean Squared Error -- train: 0.4100063145160675, -- test: 0.7208927273750305 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.6900434494018555, -- test: -16.899307250976562 \n",
      "Root Mean Squared Error -- train: 0.414188414812088, -- test: 0.7262506484985352 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.661655426025391, -- test: -15.769698143005371 \n",
      "Root Mean Squared Error -- train: 0.41318824887275696, -- test: 0.7032162547111511 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -14.645580291748047\n",
      "Test Root MSE of all sampled models: 0.7350941300392151\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 41 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.419764995574951 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 42 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.510303497314453, -- test: -15.608013153076172 \n",
      "Root Mean Squared Error -- train: 0.40942686796188354, -- test: 0.7027999758720398 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.586816310882568, -- test: -16.533885955810547 \n",
      "Root Mean Squared Error -- train: 0.4121650457382202, -- test: 0.7219075560569763 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.691014766693115, -- test: -16.845129013061523 \n",
      "Root Mean Squared Error -- train: 0.4158649742603302, -- test: 0.7282181978225708 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.522056579589844, -- test: -18.633424758911133 \n",
      "Root Mean Squared Error -- train: 0.409848690032959, -- test: 0.7634668946266174 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.771053791046143, -- test: -17.278051376342773 \n",
      "Root Mean Squared Error -- train: 0.41868487000465393, -- test: 0.736906111240387 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.543849945068359, -- test: -17.652034759521484 \n",
      "Root Mean Squared Error -- train: 0.41062965989112854, -- test: 0.7443296313285828 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.610416412353516, -- test: -18.523527145385742 \n",
      "Root Mean Squared Error -- train: 0.4130059480667114, -- test: 0.7613478302955627 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.5306501388549805, -- test: -18.894168853759766 \n",
      "Root Mean Squared Error -- train: 0.41015681624412537, -- test: 0.7684713006019592 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.515750885009766, -- test: -20.01289176940918 \n",
      "Root Mean Squared Error -- train: 0.4096224308013916, -- test: 0.7895827889442444 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.5511474609375, -- test: -18.820045471191406 \n",
      "Root Mean Squared Error -- train: 0.4108908176422119, -- test: 0.7670519351959229 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -16.28803062438965\n",
      "Test Root MSE of all sampled models: 0.7591091990470886\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 42 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.898431301116943 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 43 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.871386528015137, -- test: -17.261795043945312 \n",
      "Root Mean Squared Error -- train: 0.42387405037879944, -- test: 0.7396919131278992 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.1853742599487305, -- test: -19.352027893066406 \n",
      "Root Mean Squared Error -- train: 0.434719979763031, -- test: 0.7804718017578125 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.827470302581787, -- test: -18.118629455566406 \n",
      "Root Mean Squared Error -- train: 0.4223348796367645, -- test: 0.7566743493080139 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.5099687576293945, -- test: -17.28154945373535 \n",
      "Root Mean Squared Error -- train: 0.4110356271266937, -- test: 0.7400877475738525 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.458482265472412, -- test: -18.165029525756836 \n",
      "Root Mean Squared Error -- train: 0.4091739058494568, -- test: 0.7575831413269043 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.46744441986084, -- test: -18.604042053222656 \n",
      "Root Mean Squared Error -- train: 0.4094986021518707, -- test: 0.7661281824111938 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.450710773468018, -- test: -19.609363555908203 \n",
      "Root Mean Squared Error -- train: 0.4088921546936035, -- test: 0.7853459715843201 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.461317539215088, -- test: -19.0272216796875 \n",
      "Root Mean Squared Error -- train: 0.40927666425704956, -- test: 0.7742759585380554 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.45831823348999, -- test: -18.29512596130371 \n",
      "Root Mean Squared Error -- train: 0.40916797518730164, -- test: 0.7601253986358643 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.547142028808594, -- test: -20.177139282226562 \n",
      "Root Mean Squared Error -- train: 0.4123745560646057, -- test: 0.7959945797920227 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -16.190431594848633\n",
      "Test Root MSE of all sampled models: 0.7707456350326538\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 43 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.01542329788208 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 44 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.428426742553711, -- test: -19.762434005737305 \n",
      "Root Mean Squared Error -- train: 0.4096771776676178, -- test: 0.7915306687355042 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.721116542816162, -- test: -18.777971267700195 \n",
      "Root Mean Squared Error -- train: 0.4202268719673157, -- test: 0.7727047204971313 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.710435390472412, -- test: -17.935754776000977 \n",
      "Root Mean Squared Error -- train: 0.4198465347290039, -- test: 0.7562270760536194 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.32871150970459, -- test: -17.814241409301758 \n",
      "Root Mean Squared Error -- train: 0.44132253527641296, -- test: 0.7538199424743652 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.412446022033691, -- test: -19.135282516479492 \n",
      "Root Mean Squared Error -- train: 0.40909335017204285, -- test: 0.7795901894569397 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.4643235206604, -- test: -17.766016006469727 \n",
      "Root Mean Squared Error -- train: 0.4109856188297272, -- test: 0.7528625726699829 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.437107086181641, -- test: -17.744115829467773 \n",
      "Root Mean Squared Error -- train: 0.409993976354599, -- test: 0.7524273991584778 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.44789981842041, -- test: -17.401586532592773 \n",
      "Root Mean Squared Error -- train: 0.41038748621940613, -- test: 0.7455875873565674 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.440199851989746, -- test: -18.53122901916504 \n",
      "Root Mean Squared Error -- train: 0.4101067781448364, -- test: 0.7679138779640198 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.527998447418213, -- test: -18.55741310119629 \n",
      "Root Mean Squared Error -- train: 0.41329634189605713, -- test: 0.7684237360954285 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -15.039722442626953\n",
      "Test Root MSE of all sampled models: 0.7578411102294922\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 44 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.2257080078125 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 45 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.371360778808594, -- test: -18.731637954711914 \n",
      "Root Mean Squared Error -- train: 0.4091913104057312, -- test: 0.7750596404075623 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.389162540435791, -- test: -17.10767364501953 \n",
      "Root Mean Squared Error -- train: 0.40984711050987244, -- test: 0.742777943611145 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.704439163208008, -- test: -19.121559143066406 \n",
      "Root Mean Squared Error -- train: 0.42129233479499817, -- test: 0.7826123833656311 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.503011703491211, -- test: -17.30158805847168 \n",
      "Root Mean Squared Error -- train: 0.4489786624908447, -- test: 0.746705949306488 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.3686723709106445, -- test: -17.920574188232422 \n",
      "Root Mean Squared Error -- train: 0.4090921878814697, -- test: 0.7591087222099304 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.417241096496582, -- test: -18.915433883666992 \n",
      "Root Mean Squared Error -- train: 0.41087934374809265, -- test: 0.7786288857460022 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.62519645690918, -- test: -17.58449363708496 \n",
      "Root Mean Squared Error -- train: 0.4184451103210449, -- test: 0.7523999214172363 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.375638484954834, -- test: -18.541580200195312 \n",
      "Root Mean Squared Error -- train: 0.4093489944934845, -- test: 0.7713513374328613 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.3464484214782715, -- test: -18.529027938842773 \n",
      "Root Mean Squared Error -- train: 0.40827181935310364, -- test: 0.7711058259010315 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.382346153259277, -- test: -18.751571655273438 \n",
      "Root Mean Squared Error -- train: 0.40959614515304565, -- test: 0.7754475474357605 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -15.908594131469727\n",
      "Test Root MSE of all sampled models: 0.7709178924560547\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 45 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.981109142303467 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 46 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.3115973472595215, -- test: -16.168062210083008 \n",
      "Root Mean Squared Error -- train: 0.4085860848426819, -- test: 0.7264896035194397 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.111308574676514, -- test: -17.343120574951172 \n",
      "Root Mean Squared Error -- train: 0.43735721707344055, -- test: 0.7506991624832153 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.368305683135986, -- test: -17.77672576904297 \n",
      "Root Mean Squared Error -- train: 0.4106926918029785, -- test: 0.7594379186630249 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.4022345542907715, -- test: -18.05059051513672 \n",
      "Root Mean Squared Error -- train: 0.41194793581962585, -- test: 0.7649056911468506 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.375855922698975, -- test: -18.789159774780273 \n",
      "Root Mean Squared Error -- train: 0.41097235679626465, -- test: 0.7794604897499084 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.338235378265381, -- test: -17.21848487854004 \n",
      "Root Mean Squared Error -- train: 0.409576952457428, -- test: 0.7481685280799866 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.375331878662109, -- test: -16.410625457763672 \n",
      "Root Mean Squared Error -- train: 0.41095295548439026, -- test: 0.7315527200698853 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.337789535522461, -- test: -18.62187957763672 \n",
      "Root Mean Squared Error -- train: 0.4095603823661804, -- test: 0.7761878371238708 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.321976184844971, -- test: -18.43767738342285 \n",
      "Root Mean Squared Error -- train: 0.40897244215011597, -- test: 0.7725681662559509 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.3204216957092285, -- test: -17.547630310058594 \n",
      "Root Mean Squared Error -- train: 0.40891459584236145, -- test: 0.754833459854126 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -15.769609451293945\n",
      "Test Root MSE of all sampled models: 0.7582907676696777\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 46 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.8530478477478027 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 47 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.490893363952637, -- test: -18.636329650878906 \n",
      "Root Mean Squared Error -- train: 0.4168284833431244, -- test: 0.7797075510025024 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.293463706970215, -- test: -17.438213348388672 \n",
      "Root Mean Squared Error -- train: 0.4094946086406708, -- test: 0.7557561993598938 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.2848005294799805, -- test: -16.85492706298828 \n",
      "Root Mean Squared Error -- train: 0.4091697931289673, -- test: 0.7438167929649353 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.305825233459473, -- test: -16.910507202148438 \n",
      "Root Mean Squared Error -- train: 0.4099576473236084, -- test: 0.7449626922607422 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.309699535369873, -- test: -15.965144157409668 \n",
      "Root Mean Squared Error -- train: 0.4101026654243469, -- test: 0.7252248525619507 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.294917106628418, -- test: -18.51865577697754 \n",
      "Root Mean Squared Error -- train: 0.4095490872859955, -- test: 0.7773878574371338 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.350858211517334, -- test: -15.40792465209961 \n",
      "Root Mean Squared Error -- train: 0.41164010763168335, -- test: 0.7133352160453796 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.350583553314209, -- test: -17.958091735839844 \n",
      "Root Mean Squared Error -- train: 0.411629855632782, -- test: 0.7662409543991089 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.462732315063477, -- test: -19.50701904296875 \n",
      "Root Mean Squared Error -- train: 0.415790319442749, -- test: 0.7966617345809937 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.408847332000732, -- test: -23.19521713256836 \n",
      "Root Mean Squared Error -- train: 0.4137965440750122, -- test: 0.8648006319999695 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -14.433965682983398\n",
      "Test Root MSE of all sampled models: 0.7755775451660156\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 47 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.062819957733154 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 48 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.539339065551758, -- test: -21.38260269165039 \n",
      "Root Mean Squared Error -- train: 0.4202762544155121, -- test: 0.8355636596679688 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.3647541999816895, -- test: -19.12283706665039 \n",
      "Root Mean Squared Error -- train: 0.41379499435424805, -- test: 0.7925876379013062 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.30587911605835, -- test: -17.697940826416016 \n",
      "Root Mean Squared Error -- train: 0.41158631443977356, -- test: 0.7642478942871094 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.493782043457031, -- test: -17.195493698120117 \n",
      "Root Mean Squared Error -- train: 0.4185946583747864, -- test: 0.7540006637573242 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.466699600219727, -- test: -16.286949157714844 \n",
      "Root Mean Squared Error -- train: 0.41759181022644043, -- test: 0.7351087331771851 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.278134822845459, -- test: -17.290929794311523 \n",
      "Root Mean Squared Error -- train: 0.4105413556098938, -- test: 0.7559577226638794 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.234170913696289, -- test: -19.360076904296875 \n",
      "Root Mean Squared Error -- train: 0.4088800847530365, -- test: 0.797208309173584 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.321656703948975, -- test: -19.638294219970703 \n",
      "Root Mean Squared Error -- train: 0.4121793806552887, -- test: 0.8025932312011719 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.265447616577148, -- test: -18.232254028320312 \n",
      "Root Mean Squared Error -- train: 0.41006264090538025, -- test: 0.774996280670166 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.355530261993408, -- test: -17.927024841308594 \n",
      "Root Mean Squared Error -- train: 0.4134497344493866, -- test: 0.7688745856285095 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -15.731061935424805\n",
      "Test Root MSE of all sampled models: 0.7738980650901794\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 48 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.7295496463775635 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 49 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.769545078277588, -- test: -17.545042037963867 \n",
      "Root Mean Squared Error -- train: 0.43033087253570557, -- test: 0.7642739415168762 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.616389751434326, -- test: -16.680095672607422 \n",
      "Root Mean Squared Error -- train: 0.4247378408908844, -- test: 0.7463951110839844 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.257407188415527, -- test: -15.950823783874512 \n",
      "Root Mean Squared Error -- train: 0.4113302528858185, -- test: 0.7309810519218445 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.176348686218262, -- test: -17.212444305419922 \n",
      "Root Mean Squared Error -- train: 0.408241868019104, -- test: 0.7574489116668701 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.288365840911865, -- test: -17.6402530670166 \n",
      "Root Mean Squared Error -- train: 0.4125036597251892, -- test: 0.766216516494751 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.241660118103027, -- test: -14.9285306930542 \n",
      "Root Mean Squared Error -- train: 0.41073209047317505, -- test: 0.7088096141815186 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.233997821807861, -- test: -16.47325325012207 \n",
      "Root Mean Squared Error -- train: 0.41044071316719055, -- test: 0.7420557737350464 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.282530784606934, -- test: -16.868337631225586 \n",
      "Root Mean Squared Error -- train: 0.4122827649116516, -- test: 0.7503224015235901 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.323521614074707, -- test: -19.40459442138672 \n",
      "Root Mean Squared Error -- train: 0.4138321578502655, -- test: 0.8013622164726257 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.220803737640381, -- test: -16.84490203857422 \n",
      "Root Mean Squared Error -- train: 0.4099385142326355, -- test: 0.7498346567153931 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -14.254494667053223\n",
      "Test Root MSE of all sampled models: 0.7454846501350403\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 49 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.3195271492004395 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 50 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.166504859924316, -- test: -16.86272430419922 \n",
      "Root Mean Squared Error -- train: 0.4093680679798126, -- test: 0.7531720995903015 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.2734880447387695, -- test: -16.618568420410156 \n",
      "Root Mean Squared Error -- train: 0.4134611487388611, -- test: 0.748052179813385 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.225021839141846, -- test: -16.95021629333496 \n",
      "Root Mean Squared Error -- train: 0.4116119146347046, -- test: 0.7549983859062195 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.482242107391357, -- test: -17.67633819580078 \n",
      "Root Mean Squared Error -- train: 0.4213334321975708, -- test: 0.769987940788269 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.213851451873779, -- test: -18.194303512573242 \n",
      "Root Mean Squared Error -- train: 0.41118451952934265, -- test: 0.7805045247077942 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.290766716003418, -- test: -17.25847053527832 \n",
      "Root Mean Squared Error -- train: 0.4141184389591217, -- test: 0.7613977789878845 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.1899518966674805, -- test: -15.809831619262695 \n",
      "Root Mean Squared Error -- train: 0.4102686047554016, -- test: 0.730836808681488 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.207008361816406, -- test: -16.909198760986328 \n",
      "Root Mean Squared Error -- train: 0.41092249751091003, -- test: 0.7541428208351135 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.273026943206787, -- test: -16.405555725097656 \n",
      "Root Mean Squared Error -- train: 0.41344359517097473, -- test: 0.7435564994812012 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.168516635894775, -- test: -17.15340805053711 \n",
      "Root Mean Squared Error -- train: 0.4094454348087311, -- test: 0.7592227458953857 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -14.172133445739746\n",
      "Test Root MSE of all sampled models: 0.757453441619873\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 50 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.050002574920654 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 51 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.2212443351745605, -- test: -17.347307205200195 \n",
      "Root Mean Squared Error -- train: 0.4130288362503052, -- test: 0.7663394808769226 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.133683681488037, -- test: -17.146894454956055 \n",
      "Root Mean Squared Error -- train: 0.40965011715888977, -- test: 0.7621772289276123 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.145745277404785, -- test: -17.49042510986328 \n",
      "Root Mean Squared Error -- train: 0.4101172089576721, -- test: 0.7692980170249939 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.231159210205078, -- test: -17.050983428955078 \n",
      "Root Mean Squared Error -- train: 0.41340968012809753, -- test: 0.7601772546768188 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.135476112365723, -- test: -17.913753509521484 \n",
      "Root Mean Squared Error -- train: 0.4097195565700531, -- test: 0.7779832482337952 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.242208957672119, -- test: -18.068492889404297 \n",
      "Root Mean Squared Error -- train: 0.41383373737335205, -- test: 0.7811338305473328 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.122243881225586, -- test: -16.831897735595703 \n",
      "Root Mean Squared Error -- train: 0.4092066287994385, -- test: 0.7555888891220093 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.174683094024658, -- test: -17.651172637939453 \n",
      "Root Mean Squared Error -- train: 0.41123563051223755, -- test: 0.7726074457168579 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.185775279998779, -- test: -15.152992248535156 \n",
      "Root Mean Squared Error -- train: 0.4116635322570801, -- test: 0.7194569110870361 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.16729211807251, -- test: -14.967292785644531 \n",
      "Root Mean Squared Error -- train: 0.41095027327537537, -- test: 0.7153483629226685 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -13.426582336425781\n",
      "Test Root MSE of all sampled models: 0.7502993941307068\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 51 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3286570310592651 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 52 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.402138710021973, -- test: -16.517724990844727 \n",
      "Root Mean Squared Error -- train: 0.4214344024658203, -- test: 0.7518392205238342 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.075857639312744, -- test: -17.986370086669922 \n",
      "Root Mean Squared Error -- train: 0.4088607728481293, -- test: 0.7824662923812866 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.153611660003662, -- test: -16.998170852661133 \n",
      "Root Mean Squared Error -- train: 0.41189196705818176, -- test: 0.761993944644928 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.087096691131592, -- test: -16.53523063659668 \n",
      "Root Mean Squared Error -- train: 0.409300297498703, -- test: 0.7522116899490356 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.297688007354736, -- test: -16.953327178955078 \n",
      "Root Mean Squared Error -- train: 0.4174504578113556, -- test: 0.7610518336296082 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.1716485023498535, -- test: -16.04850196838379 \n",
      "Root Mean Squared Error -- train: 0.4125919044017792, -- test: 0.7417875528335571 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.130860805511475, -- test: -16.611684799194336 \n",
      "Root Mean Squared Error -- train: 0.4110073447227478, -- test: 0.753835916519165 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.310902118682861, -- test: -17.645795822143555 \n",
      "Root Mean Squared Error -- train: 0.4179565906524658, -- test: 0.7754718065261841 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.146418571472168, -- test: -18.0169734954834 \n",
      "Root Mean Squared Error -- train: 0.41161248087882996, -- test: 0.7830918431282043 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.1132073402404785, -- test: -16.471364974975586 \n",
      "Root Mean Squared Error -- train: 0.41031965613365173, -- test: 0.750852108001709 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -14.117972373962402\n",
      "Test Root MSE of all sampled models: 0.7584696412086487\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 52 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.767556190490723 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 53 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.0849127769470215, -- test: -17.311452865600586 \n",
      "Root Mean Squared Error -- train: 0.41074493527412415, -- test: 0.7716346979141235 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.608768939971924, -- test: -17.411149978637695 \n",
      "Root Mean Squared Error -- train: 0.43082690238952637, -- test: 0.7737160921096802 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.418281555175781, -- test: -17.03968048095703 \n",
      "Root Mean Squared Error -- train: 0.42363476753234863, -- test: 0.7659324407577515 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.324408054351807, -- test: -17.44879913330078 \n",
      "Root Mean Squared Error -- train: 0.42004507780075073, -- test: 0.7745005488395691 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.153131484985352, -- test: -18.11644744873047 \n",
      "Root Mean Squared Error -- train: 0.4134153425693512, -- test: 0.7882832884788513 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.030010223388672, -- test: -18.269813537597656 \n",
      "Root Mean Squared Error -- train: 0.4085831046104431, -- test: 0.7914154529571533 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.037776947021484, -- test: -17.51763343811035 \n",
      "Root Mean Squared Error -- train: 0.40888962149620056, -- test: 0.7759329080581665 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.095124244689941, -- test: -16.660768508911133 \n",
      "Root Mean Squared Error -- train: 0.41114577651023865, -- test: 0.7579103112220764 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.094666004180908, -- test: -18.280725479125977 \n",
      "Root Mean Squared Error -- train: 0.41112780570983887, -- test: 0.7916378378868103 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.158421993255615, -- test: -18.875940322875977 \n",
      "Root Mean Squared Error -- train: 0.413621723651886, -- test: 0.8036746978759766 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -15.103545188903809\n",
      "Test Root MSE of all sampled models: 0.7842961549758911\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 53 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.350454807281494 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 54 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.295938014984131, -- test: -17.39247703552246 \n",
      "Root Mean Squared Error -- train: 0.4205217659473419, -- test: 0.776435136795044 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.9983065128326416, -- test: -16.06633758544922 \n",
      "Root Mean Squared Error -- train: 0.408848375082016, -- test: 0.7481403350830078 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.30573844909668, -- test: -16.488107681274414 \n",
      "Root Mean Squared Error -- train: 0.4209006428718567, -- test: 0.7572540044784546 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.056393146514893, -- test: -15.536911964416504 \n",
      "Root Mean Squared Error -- train: 0.4111526310443878, -- test: 0.7365408539772034 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.977600336074829, -- test: -16.736183166503906 \n",
      "Root Mean Squared Error -- train: 0.4080238342285156, -- test: 0.7625635266304016 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.04291296005249, -- test: -16.594738006591797 \n",
      "Root Mean Squared Error -- train: 0.41061899065971375, -- test: 0.7595407962799072 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.021088123321533, -- test: -19.110136032104492 \n",
      "Root Mean Squared Error -- train: 0.40975362062454224, -- test: 0.8116185665130615 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.013939380645752, -- test: -19.474580764770508 \n",
      "Root Mean Squared Error -- train: 0.4094697833061218, -- test: 0.8188892602920532 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.113187789916992, -- test: -17.778034210205078 \n",
      "Root Mean Squared Error -- train: 0.41339316964149475, -- test: 0.7844700217247009 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.095229148864746, -- test: -15.399187088012695 \n",
      "Root Mean Squared Error -- train: 0.41268599033355713, -- test: 0.7334933876991272 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -14.712767601013184\n",
      "Test Root MSE of all sampled models: 0.7794590592384338\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 54 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.73673677444458 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 55 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.049689292907715, -- test: -17.454448699951172 \n",
      "Root Mean Squared Error -- train: 0.41240382194519043, -- test: 0.7808238863945007 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.9395225048065186, -- test: -17.069120407104492 \n",
      "Root Mean Squared Error -- train: 0.40799999237060547, -- test: 0.7726894617080688 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.9424986839294434, -- test: -17.428085327148438 \n",
      "Root Mean Squared Error -- train: 0.4081196188926697, -- test: 0.7802700400352478 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.178458213806152, -- test: -17.202533721923828 \n",
      "Root Mean Squared Error -- train: 0.4174923896789551, -- test: 0.7755155563354492 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.3280792236328125, -- test: -17.21725845336914 \n",
      "Root Mean Squared Error -- train: 0.42332813143730164, -- test: 0.7758268117904663 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.007851600646973, -- test: -14.140153884887695 \n",
      "Root Mean Squared Error -- train: 0.41073697805404663, -- test: 0.7078089714050293 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.02616548538208, -- test: -17.59748077392578 \n",
      "Root Mean Squared Error -- train: 0.41146746277809143, -- test: 0.7838217616081238 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.08729362487793, -- test: -18.302181243896484 \n",
      "Root Mean Squared Error -- train: 0.4138962924480438, -- test: 0.7984279990196228 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.048831462860107, -- test: -17.74707794189453 \n",
      "Root Mean Squared Error -- train: 0.4123696982860565, -- test: 0.7869451642036438 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.013859748840332, -- test: -17.160755157470703 \n",
      "Root Mean Squared Error -- train: 0.41097673773765564, -- test: 0.7746316194534302 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -13.92614459991455\n",
      "Test Root MSE of all sampled models: 0.7730549573898315\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 55 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.811645984649658 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 56 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.497213840484619, -- test: -17.85784339904785 \n",
      "Root Mean Squared Error -- train: 0.4314155876636505, -- test: 0.7923619747161865 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.083348751068115, -- test: -16.818683624267578 \n",
      "Root Mean Squared Error -- train: 0.4152548015117645, -- test: 0.7703775763511658 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.043076038360596, -- test: -17.551069259643555 \n",
      "Root Mean Squared Error -- train: 0.4136485159397125, -- test: 0.7859358787536621 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.107234954833984, -- test: -17.49579429626465 \n",
      "Root Mean Squared Error -- train: 0.416204571723938, -- test: 0.7847724556922913 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.9625332355499268, -- test: -17.718259811401367 \n",
      "Root Mean Squared Error -- train: 0.4104171693325043, -- test: 0.7894445657730103 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.9613537788391113, -- test: -16.432004928588867 \n",
      "Root Mean Squared Error -- train: 0.4103696346282959, -- test: 0.7620351910591125 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.983919620513916, -- test: -15.908655166625977 \n",
      "Root Mean Squared Error -- train: 0.4112776517868042, -- test: 0.7505964040756226 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.9860475063323975, -- test: -13.435198783874512 \n",
      "Root Mean Squared Error -- train: 0.4113631844520569, -- test: 0.6939882040023804 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.006508827209473, -- test: -17.64904022216797 \n",
      "Root Mean Squared Error -- train: 0.41218459606170654, -- test: 0.7879937887191772 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.1103949546813965, -- test: -16.66559600830078 \n",
      "Root Mean Squared Error -- train: 0.41633009910583496, -- test: 0.7670856714248657 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -13.461190223693848\n",
      "Test Root MSE of all sampled models: 0.7596799731254578\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 56 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.801612377166748 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 57 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.879690647125244, -- test: -16.739770889282227 \n",
      "Root Mean Squared Error -- train: 0.4085390269756317, -- test: 0.7716848254203796 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.935678720474243, -- test: -16.3731746673584 \n",
      "Root Mean Squared Error -- train: 0.41081634163856506, -- test: 0.7637275457382202 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.878349781036377, -- test: -15.987292289733887 \n",
      "Root Mean Squared Error -- train: 0.4084843397140503, -- test: 0.7552610039710999 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.069389343261719, -- test: -16.656360626220703 \n",
      "Root Mean Squared Error -- train: 0.41620469093322754, -- test: 0.769881546497345 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.9215049743652344, -- test: -18.12571144104004 \n",
      "Root Mean Squared Error -- train: 0.410241037607193, -- test: 0.8010538816452026 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.9908435344696045, -- test: -20.352754592895508 \n",
      "Root Mean Squared Error -- train: 0.4130479097366333, -- test: 0.8461139798164368 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.050215244293213, -- test: -18.88506317138672 \n",
      "Root Mean Squared Error -- train: 0.4154362678527832, -- test: 0.8166972398757935 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.020934581756592, -- test: -21.217069625854492 \n",
      "Root Mean Squared Error -- train: 0.4142601191997528, -- test: 0.8629682660102844 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.9946088790893555, -- test: -16.99898338317871 \n",
      "Root Mean Squared Error -- train: 0.4131998121738434, -- test: 0.7772620320320129 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.010325908660889, -- test: -16.999326705932617 \n",
      "Root Mean Squared Error -- train: 0.4138331711292267, -- test: 0.7772694230079651 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -14.5406494140625\n",
      "Test Root MSE of all sampled models: 0.8096284866333008\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 57 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.528514385223389 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 58 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.88562273979187, -- test: -16.33673095703125 \n",
      "Root Mean Squared Error -- train: 0.41026848554611206, -- test: 0.7659280896186829 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.848371744155884, -- test: -16.092330932617188 \n",
      "Root Mean Squared Error -- train: 0.40874040126800537, -- test: 0.7605488300323486 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.846721887588501, -- test: -16.758159637451172 \n",
      "Root Mean Squared Error -- train: 0.40867260098457336, -- test: 0.775115966796875 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.845123052597046, -- test: -16.79431915283203 \n",
      "Root Mean Squared Error -- train: 0.4086068272590637, -- test: 0.7758992314338684 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.8907620906829834, -- test: -16.413043975830078 \n",
      "Root Mean Squared Error -- train: 0.4104789197444916, -- test: 0.7675999999046326 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.852510452270508, -- test: -15.668315887451172 \n",
      "Root Mean Squared Error -- train: 0.40891045331954956, -- test: 0.7511249780654907 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.890164613723755, -- test: -16.854005813598633 \n",
      "Root Mean Squared Error -- train: 0.4104544222354889, -- test: 0.7771903872489929 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.9079744815826416, -- test: -16.58881378173828 \n",
      "Root Mean Squared Error -- train: 0.4111826717853546, -- test: 0.7714371085166931 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.882946252822876, -- test: -15.638740539550781 \n",
      "Root Mean Squared Error -- train: 0.4101589024066925, -- test: 0.7504633069038391 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.891690254211426, -- test: -14.091462135314941 \n",
      "Root Mean Squared Error -- train: 0.4105168581008911, -- test: 0.7149898409843445 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -13.435726165771484\n",
      "Test Root MSE of all sampled models: 0.7590628266334534\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 58 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.2496094703674316 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 59 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.8475446701049805, -- test: -15.804145812988281 \n",
      "Root Mean Squared Error -- train: 0.41016635298728943, -- test: 0.7570639252662659 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.811033248901367, -- test: -15.198382377624512 \n",
      "Root Mean Squared Error -- train: 0.4086562991142273, -- test: 0.7433920502662659 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.838369131088257, -- test: -17.060657501220703 \n",
      "Root Mean Squared Error -- train: 0.4097874164581299, -- test: 0.7846639752388 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.8836376667022705, -- test: -16.01862144470215 \n",
      "Root Mean Squared Error -- train: 0.41165366768836975, -- test: 0.7618458271026611 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.342660903930664, -- test: -17.08828353881836 \n",
      "Root Mean Squared Error -- train: 0.4301203489303589, -- test: 0.7852599024772644 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.9721627235412598, -- test: -15.030838966369629 \n",
      "Root Mean Squared Error -- train: 0.41527897119522095, -- test: 0.739565908908844 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.8891522884368896, -- test: -17.588525772094727 \n",
      "Root Mean Squared Error -- train: 0.4118804633617401, -- test: 0.7959734201431274 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.888195276260376, -- test: -17.300403594970703 \n",
      "Root Mean Squared Error -- train: 0.41184109449386597, -- test: 0.7898204922676086 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.815502405166626, -- test: -15.415316581726074 \n",
      "Root Mean Squared Error -- train: 0.40884149074554443, -- test: 0.7483168840408325 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.8349244594573975, -- test: -16.803516387939453 \n",
      "Root Mean Squared Error -- train: 0.40964505076408386, -- test: 0.7790952920913696 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -13.398344993591309\n",
      "Test Root MSE of all sampled models: 0.7660573124885559\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 59 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.125531196594238 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 60 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.833706855773926, -- test: -15.793743133544922 \n",
      "Root Mean Squared Error -- train: 0.4110580384731293, -- test: 0.7597503662109375 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.916496753692627, -- test: -16.211620330810547 \n",
      "Root Mean Squared Error -- train: 0.4144812822341919, -- test: 0.7690803408622742 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.013688564300537, -- test: -15.922815322875977 \n",
      "Root Mean Squared Error -- train: 0.4184642434120178, -- test: 0.762644350528717 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.786086082458496, -- test: -15.358855247497559 \n",
      "Root Mean Squared Error -- train: 0.4090760350227356, -- test: 0.749917209148407 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.865938901901245, -- test: -17.000625610351562 \n",
      "Root Mean Squared Error -- train: 0.4123941957950592, -- test: 0.7863949537277222 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.812628984451294, -- test: -16.658357620239258 \n",
      "Root Mean Squared Error -- train: 0.4101819396018982, -- test: 0.7789312601089478 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.8291196823120117, -- test: -17.331579208374023 \n",
      "Root Mean Squared Error -- train: 0.4108675718307495, -- test: 0.7935453057289124 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.850010395050049, -- test: -15.548051834106445 \n",
      "Root Mean Squared Error -- train: 0.411734402179718, -- test: 0.7542108297348022 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.894771099090576, -- test: -15.714308738708496 \n",
      "Root Mean Squared Error -- train: 0.41358572244644165, -- test: 0.7579638361930847 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.864668846130371, -- test: -15.6406831741333 \n",
      "Root Mean Squared Error -- train: 0.4123416244983673, -- test: 0.7563040852546692 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -13.62822151184082\n",
      "Test Root MSE of all sampled models: 0.7685045003890991\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 60 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.490570068359375 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 61 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.8926637172698975, -- test: -15.929268836975098 \n",
      "Root Mean Squared Error -- train: 0.4149613082408905, -- test: 0.7656985521316528 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.8642468452453613, -- test: -16.243436813354492 \n",
      "Root Mean Squared Error -- train: 0.41378164291381836, -- test: 0.7727242708206177 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.7726640701293945, -- test: -15.787095069885254 \n",
      "Root Mean Squared Error -- train: 0.4099566638469696, -- test: 0.7624978423118591 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.817359447479248, -- test: -16.472414016723633 \n",
      "Root Mean Squared Error -- train: 0.41182780265808105, -- test: 0.7778047919273376 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.8030431270599365, -- test: -15.496718406677246 \n",
      "Root Mean Squared Error -- train: 0.4112294018268585, -- test: 0.7559186816215515 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.8839845657348633, -- test: -15.917596817016602 \n",
      "Root Mean Squared Error -- train: 0.4146013557910919, -- test: 0.7654362916946411 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.7827818393707275, -- test: -15.185895919799805 \n",
      "Root Mean Squared Error -- train: 0.4103809893131256, -- test: 0.748812198638916 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.830547332763672, -- test: -17.811094284057617 \n",
      "Root Mean Squared Error -- train: 0.41237831115722656, -- test: 0.806867778301239 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.754592180252075, -- test: -17.630542755126953 \n",
      "Root Mean Squared Error -- train: 0.40919768810272217, -- test: 0.8030093908309937 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.831024169921875, -- test: -17.734285354614258 \n",
      "Root Mean Squared Error -- train: 0.41239815950393677, -- test: 0.8052286505699158 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -14.177806854248047\n",
      "Test Root MSE of all sampled models: 0.7844802141189575\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 61 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.51527738571167 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 62 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.07578182220459, -- test: -16.643051147460938 \n",
      "Root Mean Squared Error -- train: 0.4239697754383087, -- test: 0.7845259308815002 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.2668609619140625, -- test: -16.385639190673828 \n",
      "Root Mean Squared Error -- train: 0.43171218037605286, -- test: 0.7788170576095581 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.7845280170440674, -- test: -16.566648483276367 \n",
      "Root Mean Squared Error -- train: 0.4118884205818176, -- test: 0.7828357219696045 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.700838088989258, -- test: -16.589454650878906 \n",
      "Root Mean Squared Error -- train: 0.40835079550743103, -- test: 0.7833406925201416 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.851515769958496, -- test: -15.985565185546875 \n",
      "Root Mean Squared Error -- train: 0.4146982431411743, -- test: 0.7698601484298706 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.699131727218628, -- test: -16.904932022094727 \n",
      "Root Mean Squared Error -- train: 0.40827831625938416, -- test: 0.7902915477752686 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.826542615890503, -- test: -18.84624481201172 \n",
      "Root Mean Squared Error -- train: 0.4136529564857483, -- test: 0.831787109375 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.7964255809783936, -- test: -15.626482009887695 \n",
      "Root Mean Squared Error -- train: 0.4123888313770294, -- test: 0.7617313861846924 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.8269214630126953, -- test: -17.70920753479004 \n",
      "Root Mean Squared Error -- train: 0.4136688709259033, -- test: 0.8077415823936462 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.827007532119751, -- test: -16.946125030517578 \n",
      "Root Mean Squared Error -- train: 0.41367247700691223, -- test: 0.7911946773529053 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.208748817443848\n",
      "Test Root MSE of all sampled models: 0.7891809940338135\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 62 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.686919689178467 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 63 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.7611711025238037, -- test: -17.422412872314453 \n",
      "Root Mean Squared Error -- train: 0.4123590886592865, -- test: 0.8046408891677856 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.821226119995117, -- test: -17.91362953186035 \n",
      "Root Mean Squared Error -- train: 0.4148959815502167, -- test: 0.8152380585670471 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.017361164093018, -- test: -16.55017852783203 \n",
      "Root Mean Squared Error -- train: 0.42307543754577637, -- test: 0.7854716777801514 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.683284044265747, -- test: -15.39447021484375 \n",
      "Root Mean Squared Error -- train: 0.40904542803764343, -- test: 0.7593276500701904 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.8616943359375, -- test: -16.159217834472656 \n",
      "Root Mean Squared Error -- train: 0.4165968596935272, -- test: 0.7767259478569031 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.7543110847473145, -- test: -14.826543807983398 \n",
      "Root Mean Squared Error -- train: 0.41206830739974976, -- test: 0.7461444735527039 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.7497856616973877, -- test: -14.493979454040527 \n",
      "Root Mean Squared Error -- train: 0.4118763506412506, -- test: 0.7383154630661011 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.7496886253356934, -- test: -16.007694244384766 \n",
      "Root Mean Squared Error -- train: 0.4118722379207611, -- test: 0.7733098864555359 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.7287421226501465, -- test: -14.211130142211914 \n",
      "Root Mean Squared Error -- train: 0.4109826683998108, -- test: 0.7315908670425415 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.7408804893493652, -- test: -15.423518180847168 \n",
      "Root Mean Squared Error -- train: 0.41149839758872986, -- test: 0.759995698928833 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -13.703449249267578\n",
      "Test Root MSE of all sampled models: 0.7571310997009277\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 63 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.5638222694396973 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 64 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.649827718734741, -- test: -14.745256423950195 \n",
      "Root Mean Squared Error -- train: 0.4090404808521271, -- test: 0.7470582723617554 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.9469234943389893, -- test: -16.876819610595703 \n",
      "Root Mean Squared Error -- train: 0.42163708806037903, -- test: 0.7957196235656738 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.6404247283935547, -- test: -16.097877502441406 \n",
      "Root Mean Squared Error -- train: 0.4086354672908783, -- test: 0.7782900333404541 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.6848602294921875, -- test: -14.846663475036621 \n",
      "Root Mean Squared Error -- train: 0.4105459451675415, -- test: 0.7494449019432068 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.088884353637695, -- test: -16.1646785736084 \n",
      "Root Mean Squared Error -- train: 0.4275251030921936, -- test: 0.7798000574111938 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.721829652786255, -- test: -16.099855422973633 \n",
      "Root Mean Squared Error -- train: 0.4121286869049072, -- test: 0.7783347964286804 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.690500020980835, -- test: -16.23926544189453 \n",
      "Root Mean Squared Error -- train: 0.41078779101371765, -- test: 0.7814826965332031 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.7422420978546143, -- test: -17.212039947509766 \n",
      "Root Mean Squared Error -- train: 0.4129999577999115, -- test: 0.8031042218208313 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.7703192234039307, -- test: -14.807413101196289 \n",
      "Root Mean Squared Error -- train: 0.4141954481601715, -- test: 0.7485219836235046 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.74627423286438, -- test: -21.197673797607422 \n",
      "Root Mean Squared Error -- train: 0.41317182779312134, -- test: 0.8862000107765198 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -13.842608451843262\n",
      "Test Root MSE of all sampled models: 0.7982513904571533\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 64 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.11027193069458 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 65 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.6350648403167725, -- test: -15.551053047180176 \n",
      "Root Mean Squared Error -- train: 0.4098372161388397, -- test: 0.7687315940856934 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.6279146671295166, -- test: -14.5267333984375 \n",
      "Root Mean Squared Error -- train: 0.409527450799942, -- test: 0.7447066307067871 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.893430233001709, -- test: -15.23257827758789 \n",
      "Root Mean Squared Error -- train: 0.4208773374557495, -- test: 0.7613430619239807 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.6195931434631348, -- test: -14.678157806396484 \n",
      "Root Mean Squared Error -- train: 0.4091666638851166, -- test: 0.7483068704605103 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.6979780197143555, -- test: -14.583786964416504 \n",
      "Root Mean Squared Error -- train: 0.41255274415016174, -- test: 0.7460651397705078 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.622861862182617, -- test: -14.508008003234863 \n",
      "Root Mean Squared Error -- train: 0.40930840373039246, -- test: 0.7442601919174194 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.6444618701934814, -- test: -14.137822151184082 \n",
      "Root Mean Squared Error -- train: 0.4102439880371094, -- test: 0.7353793382644653 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.6176657676696777, -- test: -15.175724029541016 \n",
      "Root Mean Squared Error -- train: 0.4090830385684967, -- test: 0.7600166201591492 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.680781841278076, -- test: -13.369590759277344 \n",
      "Root Mean Squared Error -- train: 0.41181227564811707, -- test: 0.7165980935096741 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.6751742362976074, -- test: -13.989590644836426 \n",
      "Root Mean Squared Error -- train: 0.41157054901123047, -- test: 0.7317930459976196 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.874817848205566\n",
      "Test Root MSE of all sampled models: 0.7481201887130737\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 65 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.066132068634033 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 66 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.5803489685058594, -- test: -14.450239181518555 \n",
      "Root Mean Squared Error -- train: 0.4088907837867737, -- test: 0.7457072138786316 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.6532199382781982, -- test: -14.2216157913208 \n",
      "Root Mean Squared Error -- train: 0.4120664894580841, -- test: 0.7402026057243347 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.7689058780670166, -- test: -14.7173490524292 \n",
      "Root Mean Squared Error -- train: 0.4170582890510559, -- test: 0.752087414264679 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.220505237579346, -- test: -14.397490501403809 \n",
      "Root Mean Squared Error -- train: 0.43599802255630493, -- test: 0.7444407939910889 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.6966941356658936, -- test: -14.703228950500488 \n",
      "Root Mean Squared Error -- train: 0.4139494299888611, -- test: 0.7517515420913696 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.602562427520752, -- test: -16.4333553314209 \n",
      "Root Mean Squared Error -- train: 0.40986141562461853, -- test: 0.7918512225151062 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.5964715480804443, -- test: -16.264368057250977 \n",
      "Root Mean Squared Error -- train: 0.4095955193042755, -- test: 0.7880244255065918 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.638179063796997, -- test: -15.159250259399414 \n",
      "Root Mean Squared Error -- train: 0.4114129841327667, -- test: 0.7625255584716797 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.6398165225982666, -- test: -16.80752944946289 \n",
      "Root Mean Squared Error -- train: 0.4114841818809509, -- test: 0.8002594113349915 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.664454936981201, -- test: -15.260729789733887 \n",
      "Root Mean Squared Error -- train: 0.41255390644073486, -- test: 0.7649025321006775 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -13.120655059814453\n",
      "Test Root MSE of all sampled models: 0.780413031578064\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 66 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.6617093086242676 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 67 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.834068775177002, -- test: -12.833283424377441 \n",
      "Root Mean Squared Error -- train: 0.4213174283504486, -- test: 0.7085126638412476 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.645068645477295, -- test: -13.661754608154297 \n",
      "Root Mean Squared Error -- train: 0.4131508469581604, -- test: 0.7292887568473816 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.6059441566467285, -- test: -14.363122940063477 \n",
      "Root Mean Squared Error -- train: 0.41144007444381714, -- test: 0.7464255690574646 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.5912017822265625, -- test: -14.547179222106934 \n",
      "Root Mean Squared Error -- train: 0.41079357266426086, -- test: 0.750857949256897 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.8426835536956787, -- test: -13.88255500793457 \n",
      "Root Mean Squared Error -- train: 0.4216858446598053, -- test: 0.7347268462181091 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.5955111980438232, -- test: -13.89002799987793 \n",
      "Root Mean Squared Error -- train: 0.4109826683998108, -- test: 0.7349101305007935 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.670839309692383, -- test: -13.88796615600586 \n",
      "Root Mean Squared Error -- train: 0.41427385807037354, -- test: 0.7348595261573792 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.598867177963257, -- test: -15.394643783569336 \n",
      "Root Mean Squared Error -- train: 0.4111298620700836, -- test: 0.7709373235702515 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.606318712234497, -- test: -16.548606872558594 \n",
      "Root Mean Squared Error -- train: 0.41145649552345276, -- test: 0.7974663376808167 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.6415646076202393, -- test: -16.800647735595703 \n",
      "Root Mean Squared Error -- train: 0.41299793124198914, -- test: 0.8031439781188965 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -11.459556579589844\n",
      "Test Root MSE of all sampled models: 0.7673459649085999\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 67 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.5150599479675293 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 68 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.56398344039917, -- test: -16.551864624023438 \n",
      "Root Mean Squared Error -- train: 0.4110136330127716, -- test: 0.8005427122116089 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.5136497020721436, -- test: -14.710061073303223 \n",
      "Root Mean Squared Error -- train: 0.4087826609611511, -- test: 0.757590651512146 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.056225776672363, -- test: -13.31448745727539 \n",
      "Root Mean Squared Error -- train: 0.4322252571582794, -- test: 0.7233486175537109 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.591557264328003, -- test: -14.45718002319336 \n",
      "Root Mean Squared Error -- train: 0.4122307002544403, -- test: 0.7515016794204712 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.504566192626953, -- test: -14.054360389709473 \n",
      "Root Mean Squared Error -- train: 0.4083787202835083, -- test: 0.7416991591453552 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.543785572052002, -- test: -15.745051383972168 \n",
      "Root Mean Squared Error -- train: 0.41011983156204224, -- test: 0.782017707824707 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.5160837173461914, -- test: -15.680614471435547 \n",
      "Root Mean Squared Error -- train: 0.40889081358909607, -- test: 0.7805192470550537 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.5878283977508545, -- test: -15.080945014953613 \n",
      "Root Mean Squared Error -- train: 0.41206634044647217, -- test: 0.7664334774017334 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.5416715145111084, -- test: -15.050655364990234 \n",
      "Root Mean Squared Error -- train: 0.4100261628627777, -- test: 0.7657151222229004 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.565768241882324, -- test: -13.86623764038086 \n",
      "Root Mean Squared Error -- train: 0.4110925495624542, -- test: 0.7370765805244446 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.705059051513672\n",
      "Test Root MSE of all sampled models: 0.7680560350418091\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 68 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.716963291168213 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 69 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.4671149253845215, -- test: -15.699280738830566 \n",
      "Root Mean Squared Error -- train: 0.4081072211265564, -- test: 0.7838801741600037 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.462855815887451, -- test: -15.2517671585083 \n",
      "Root Mean Squared Error -- train: 0.4079160988330841, -- test: 0.773357093334198 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.481642007827759, -- test: -14.973437309265137 \n",
      "Root Mean Squared Error -- train: 0.4087584316730499, -- test: 0.7667393684387207 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.761253833770752, -- test: -16.438505172729492 \n",
      "Root Mean Squared Error -- train: 0.42109647393226624, -- test: 0.8009600639343262 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.6226794719696045, -- test: -14.481714248657227 \n",
      "Root Mean Squared Error -- train: 0.4150276482105255, -- test: 0.754906177520752 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.490602493286133, -- test: -15.760881423950195 \n",
      "Root Mean Squared Error -- train: 0.4091595709323883, -- test: 0.7853176593780518 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.555103302001953, -- test: -15.111200332641602 \n",
      "Root Mean Squared Error -- train: 0.41203573346138, -- test: 0.7700219750404358 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.6315431594848633, -- test: -14.987143516540527 \n",
      "Root Mean Squared Error -- train: 0.41541847586631775, -- test: 0.7670666575431824 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.6008517742156982, -- test: -13.997208595275879 \n",
      "Root Mean Squared Error -- train: 0.41406360268592834, -- test: 0.743062436580658 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.5269360542297363, -- test: -14.386792182922363 \n",
      "Root Mean Squared Error -- train: 0.41078218817710876, -- test: 0.7526004910469055 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.472389221191406\n",
      "Test Root MSE of all sampled models: 0.7647739052772522\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 69 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.0927958488464355 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 70 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.628298282623291, -- test: -13.596234321594238 \n",
      "Root Mean Squared Error -- train: 0.4167157709598541, -- test: 0.7358641624450684 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.4448869228363037, -- test: -14.110556602478027 \n",
      "Root Mean Squared Error -- train: 0.4085139334201813, -- test: 0.748649537563324 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.6255502700805664, -- test: -15.0004301071167 \n",
      "Root Mean Squared Error -- train: 0.41659411787986755, -- test: 0.7702693343162537 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.4444122314453125, -- test: -14.65573501586914 \n",
      "Root Mean Squared Error -- train: 0.4084925353527069, -- test: 0.761967658996582 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.4904227256774902, -- test: -14.609622955322266 \n",
      "Root Mean Squared Error -- train: 0.4105655252933502, -- test: 0.760850191116333 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.4877896308898926, -- test: -15.10552978515625 \n",
      "Root Mean Squared Error -- train: 0.41044721007347107, -- test: 0.7727828621864319 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.465104341506958, -- test: -14.506429672241211 \n",
      "Root Mean Squared Error -- train: 0.40942612290382385, -- test: 0.758343517780304 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.5615038871765137, -- test: -13.442214012145996 \n",
      "Root Mean Squared Error -- train: 0.4137476980686188, -- test: 0.7319921255111694 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.4991841316223145, -- test: -13.48759651184082 \n",
      "Root Mean Squared Error -- train: 0.4109590947628021, -- test: 0.7331352233886719 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.45574951171875, -- test: -14.551273345947266 \n",
      "Root Mean Squared Error -- train: 0.4090043008327484, -- test: 0.7594338655471802 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -11.571228981018066\n",
      "Test Root MSE of all sampled models: 0.7461174130439758\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 70 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.1358323097229004 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 71 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.539273500442505, -- test: -14.842214584350586 \n",
      "Root Mean Squared Error -- train: 0.41416218876838684, -- test: 0.7693087458610535 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.429323673248291, -- test: -14.865686416625977 \n",
      "Root Mean Squared Error -- train: 0.40919649600982666, -- test: 0.7698758244514465 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.44177508354187, -- test: -13.580070495605469 \n",
      "Root Mean Squared Error -- train: 0.40976187586784363, -- test: 0.7381751537322998 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.5717215538024902, -- test: -15.319714546203613 \n",
      "Root Mean Squared Error -- train: 0.41561630368232727, -- test: 0.7807637453079224 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.5884623527526855, -- test: -14.361069679260254 \n",
      "Root Mean Squared Error -- train: 0.41636452078819275, -- test: 0.7575911283493042 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.444638729095459, -- test: -14.298829078674316 \n",
      "Root Mean Squared Error -- train: 0.4098917841911316, -- test: 0.7560620903968811 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.455413579940796, -- test: -15.798670768737793 \n",
      "Root Mean Squared Error -- train: 0.4103802442550659, -- test: 0.7920873165130615 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.49515962600708, -- test: -14.502572059631348 \n",
      "Root Mean Squared Error -- train: 0.41217705607414246, -- test: 0.7610559463500977 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.4376256465911865, -- test: -14.86168098449707 \n",
      "Root Mean Squared Error -- train: 0.4095735251903534, -- test: 0.7697790861129761 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.5610878467559814, -- test: -14.052023887634277 \n",
      "Root Mean Squared Error -- train: 0.4151403307914734, -- test: 0.7499682903289795 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.389832496643066\n",
      "Test Root MSE of all sampled models: 0.7655590176582336\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 71 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.309227466583252 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 72 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.4829468727111816, -- test: -13.975732803344727 \n",
      "Root Mean Squared Error -- train: 0.41304177045822144, -- test: 0.7508694529533386 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.543306827545166, -- test: -14.461748123168945 \n",
      "Root Mean Squared Error -- train: 0.41577085852622986, -- test: 0.7629008293151855 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.403150796890259, -- test: -14.9682035446167 \n",
      "Root Mean Squared Error -- train: 0.40940597653388977, -- test: 0.7752395272254944 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.6097521781921387, -- test: -14.760272979736328 \n",
      "Root Mean Squared Error -- train: 0.418754518032074, -- test: 0.7701976895332336 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.634594202041626, -- test: -14.556536674499512 \n",
      "Root Mean Squared Error -- train: 0.41986456513404846, -- test: 0.765225350856781 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.4072659015655518, -- test: -13.589137077331543 \n",
      "Root Mean Squared Error -- train: 0.40959426760673523, -- test: 0.7411598563194275 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.488395929336548, -- test: -13.845900535583496 \n",
      "Root Mean Squared Error -- train: 0.4132888615131378, -- test: 0.7476227879524231 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.459634304046631, -- test: -13.425583839416504 \n",
      "Root Mean Squared Error -- train: 0.4119828939437866, -- test: 0.737013578414917 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.4597249031066895, -- test: -14.945296287536621 \n",
      "Root Mean Squared Error -- train: 0.4119870066642761, -- test: 0.7746857404708862 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.538295030593872, -- test: -12.384079933166504 \n",
      "Root Mean Squared Error -- train: 0.41554492712020874, -- test: 0.7100423574447632 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.018196105957031\n",
      "Test Root MSE of all sampled models: 0.748696506023407\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 72 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.5080435276031494 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 73 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.552368402481079, -- test: -13.546896934509277 \n",
      "Root Mean Squared Error -- train: 0.41757407784461975, -- test: 0.7427783608436584 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.354884147644043, -- test: -14.564802169799805 \n",
      "Root Mean Squared Error -- train: 0.4085485339164734, -- test: 0.768213152885437 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.6916353702545166, -- test: -14.556861877441406 \n",
      "Root Mean Squared Error -- train: 0.42382338643074036, -- test: 0.7680180668830872 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.3861746788024902, -- test: -14.445898056030273 \n",
      "Root Mean Squared Error -- train: 0.4099918603897095, -- test: 0.7652856707572937 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.4474992752075195, -- test: -14.707928657531738 \n",
      "Root Mean Squared Error -- train: 0.4128058850765228, -- test: 0.7717223167419434 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.3783628940582275, -- test: -14.37548828125 \n",
      "Root Mean Squared Error -- train: 0.40963199734687805, -- test: 0.7635468244552612 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.4307589530944824, -- test: -15.168291091918945 \n",
      "Root Mean Squared Error -- train: 0.4120396077632904, -- test: 0.782902717590332 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.37898588180542, -- test: -13.697183609008789 \n",
      "Root Mean Squared Error -- train: 0.4096606969833374, -- test: 0.7465881109237671 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.4160208702087402, -- test: -13.590725898742676 \n",
      "Root Mean Squared Error -- train: 0.411363810300827, -- test: 0.7438914179801941 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.394641637802124, -- test: -13.432913780212402 \n",
      "Root Mean Squared Error -- train: 0.4103815257549286, -- test: 0.7398757338523865 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.687261581420898\n",
      "Test Root MSE of all sampled models: 0.7596157193183899\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 73 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.79242205619812 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 74 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.456401824951172, -- test: -13.291297912597656 \n",
      "Root Mean Squared Error -- train: 0.4145973324775696, -- test: 0.7389311194419861 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.4799437522888184, -- test: -14.247821807861328 \n",
      "Root Mean Squared Error -- train: 0.4156759977340698, -- test: 0.763155460357666 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.327155828475952, -- test: -14.103937149047852 \n",
      "Root Mean Squared Error -- train: 0.40862491726875305, -- test: 0.7595608830451965 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.6489875316619873, -- test: -13.334107398986816 \n",
      "Root Mean Squared Error -- train: 0.42334040999412537, -- test: 0.7400321960449219 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.4020867347717285, -- test: -13.601231575012207 \n",
      "Root Mean Squared Error -- train: 0.4120980203151703, -- test: 0.7468664050102234 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.3937838077545166, -- test: -11.732072830200195 \n",
      "Root Mean Squared Error -- train: 0.4117146134376526, -- test: 0.6976423263549805 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.37040638923645, -- test: -13.006813049316406 \n",
      "Root Mean Squared Error -- train: 0.4106331765651703, -- test: 0.7315716743469238 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.376081705093384, -- test: -13.445813179016113 \n",
      "Root Mean Squared Error -- train: 0.410895973443985, -- test: 0.7428978085517883 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.407582998275757, -- test: -11.52298355102539 \n",
      "Root Mean Squared Error -- train: 0.4123516082763672, -- test: 0.6919183135032654 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.417304515838623, -- test: -14.053075790405273 \n",
      "Root Mean Squared Error -- train: 0.41279977560043335, -- test: 0.75828617811203 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.953455924987793\n",
      "Test Root MSE of all sampled models: 0.7227658629417419\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 74 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.1951162815093994 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 75 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.3652255535125732, -- test: -14.45783805847168 \n",
      "Root Mean Squared Error -- train: 0.41175034642219543, -- test: 0.7711447477340698 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.3286521434783936, -- test: -14.10388469696045 \n",
      "Root Mean Squared Error -- train: 0.41004469990730286, -- test: 0.7622984051704407 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.250139236450195, -- test: -13.304378509521484 \n",
      "Root Mean Squared Error -- train: 0.45105740427970886, -- test: 0.7419283390045166 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.3903896808624268, -- test: -13.991828918457031 \n",
      "Root Mean Squared Error -- train: 0.4129197895526886, -- test: 0.7594763040542603 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.3391120433807373, -- test: -13.746830940246582 \n",
      "Root Mean Squared Error -- train: 0.41053321957588196, -- test: 0.753269374370575 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.3384437561035156, -- test: -15.508996963500977 \n",
      "Root Mean Squared Error -- train: 0.41050204634666443, -- test: 0.7968375086784363 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.39398455619812, -- test: -14.712315559387207 \n",
      "Root Mean Squared Error -- train: 0.41308659315109253, -- test: 0.7774426937103271 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.4181933403015137, -- test: -15.194169044494629 \n",
      "Root Mean Squared Error -- train: 0.4142080545425415, -- test: 0.7892301678657532 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.433243989944458, -- test: -15.2053804397583 \n",
      "Root Mean Squared Error -- train: 0.41490378975868225, -- test: 0.7895023226737976 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.3992114067077637, -- test: -15.253151893615723 \n",
      "Root Mean Squared Error -- train: 0.41332897543907166, -- test: 0.7906609177589417 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.711470603942871\n",
      "Test Root MSE of all sampled models: 0.7959377765655518\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 75 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.3938469886779785 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 76 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.31205153465271, -- test: -15.005677223205566 \n",
      "Root Mean Squared Error -- train: 0.4106125831604004, -- test: 0.7874605655670166 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.2936158180236816, -- test: -13.387226104736328 \n",
      "Root Mean Squared Error -- train: 0.40974488854408264, -- test: 0.7467300295829773 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.279218912124634, -- test: -13.777984619140625 \n",
      "Root Mean Squared Error -- train: 0.40906602144241333, -- test: 0.7567647099494934 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.275846481323242, -- test: -13.938040733337402 \n",
      "Root Mean Squared Error -- train: 0.40890684723854065, -- test: 0.7608367800712585 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.273561477661133, -- test: -13.635083198547363 \n",
      "Root Mean Squared Error -- train: 0.4087989330291748, -- test: 0.7531105279922485 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.3304569721221924, -- test: -14.925239562988281 \n",
      "Root Mean Squared Error -- train: 0.4114769995212555, -- test: 0.785486102104187 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.322704553604126, -- test: -15.494346618652344 \n",
      "Root Mean Squared Error -- train: 0.4111131429672241, -- test: 0.7993507981300354 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.3938233852386475, -- test: -15.209637641906738 \n",
      "Root Mean Squared Error -- train: 0.41443926095962524, -- test: 0.7924449443817139 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.3805692195892334, -- test: -15.750785827636719 \n",
      "Root Mean Squared Error -- train: 0.41382139921188354, -- test: 0.805520236492157 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.368197202682495, -- test: -14.49610710144043 \n",
      "Root Mean Squared Error -- train: 0.4132438004016876, -- test: 0.7748675346374512 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.525089263916016\n",
      "Test Root MSE of all sampled models: 0.7948710918426514\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 76 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.344646453857422 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 77 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.2678844928741455, -- test: -14.343783378601074 \n",
      "Root Mean Squared Error -- train: 0.40986356139183044, -- test: 0.773815929889679 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.2450344562530518, -- test: -14.396025657653809 \n",
      "Root Mean Squared Error -- train: 0.4087778925895691, -- test: 0.7751277089118958 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.520479202270508, -- test: -13.884721755981445 \n",
      "Root Mean Squared Error -- train: 0.42167869210243225, -- test: 0.7621912956237793 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.319899559020996, -- test: -14.485115051269531 \n",
      "Root Mean Squared Error -- train: 0.4123242497444153, -- test: 0.7773597240447998 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.3886523246765137, -- test: -13.904864311218262 \n",
      "Root Mean Squared Error -- train: 0.41555437445640564, -- test: 0.7627050876617432 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.273935556411743, -- test: -14.368172645568848 \n",
      "Root Mean Squared Error -- train: 0.41015055775642395, -- test: 0.7744286060333252 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.286684513092041, -- test: -13.949073791503906 \n",
      "Root Mean Squared Error -- train: 0.41075462102890015, -- test: 0.7638314962387085 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.308332681655884, -- test: -13.568066596984863 \n",
      "Root Mean Squared Error -- train: 0.4117783010005951, -- test: 0.7540683746337891 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.253636121749878, -- test: -13.96563720703125 \n",
      "Root Mean Squared Error -- train: 0.4091868996620178, -- test: 0.7642530798912048 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.2858405113220215, -- test: -14.318317413330078 \n",
      "Root Mean Squared Error -- train: 0.41071465611457825, -- test: 0.7731755971908569 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.502098083496094\n",
      "Test Root MSE of all sampled models: 0.7714136242866516\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 77 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.0666749477386475 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 78 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.351571559906006, -- test: -13.423844337463379 \n",
      "Root Mean Squared Error -- train: 0.4151539206504822, -- test: 0.752983570098877 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.4822609424591064, -- test: -14.18593978881836 \n",
      "Root Mean Squared Error -- train: 0.42127567529678345, -- test: 0.7725561261177063 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.3021669387817383, -- test: -13.590140342712402 \n",
      "Root Mean Squared Error -- train: 0.41281604766845703, -- test: 0.7572976350784302 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.5926332473754883, -- test: -14.49901008605957 \n",
      "Root Mean Squared Error -- train: 0.42637723684310913, -- test: 0.7804543972015381 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.233191728591919, -- test: -14.52579116821289 \n",
      "Root Mean Squared Error -- train: 0.40952980518341064, -- test: 0.7811263203620911 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.2984914779663086, -- test: -14.318035125732422 \n",
      "Root Mean Squared Error -- train: 0.41264161467552185, -- test: 0.7758985161781311 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.2866947650909424, -- test: -14.072896957397461 \n",
      "Root Mean Squared Error -- train: 0.41208121180534363, -- test: 0.769684374332428 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.2884879112243652, -- test: -13.38134765625 \n",
      "Root Mean Squared Error -- train: 0.41216641664505005, -- test: 0.7518771290779114 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.2899088859558105, -- test: -14.369549751281738 \n",
      "Root Mean Squared Error -- train: 0.41223394870758057, -- test: 0.777198076248169 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.2863380908966064, -- test: -13.462238311767578 \n",
      "Root Mean Squared Error -- train: 0.41206422448158264, -- test: 0.7539817690849304 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.917313575744629\n",
      "Test Root MSE of all sampled models: 0.7633661031723022\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 78 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.6904454231262207 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 79 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.2255492210388184, -- test: -13.871415138244629 \n",
      "Root Mean Squared Error -- train: 0.41048792004585266, -- test: 0.7672472596168518 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.294219970703125, -- test: -14.157103538513184 \n",
      "Root Mean Squared Error -- train: 0.4137760400772095, -- test: 0.7745603919029236 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.220870018005371, -- test: -13.924612045288086 \n",
      "Root Mean Squared Error -- train: 0.41026291251182556, -- test: 0.7686142921447754 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.463845729827881, -- test: -13.308353424072266 \n",
      "Root Mean Squared Error -- train: 0.4217883050441742, -- test: 0.7526257634162903 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.434088945388794, -- test: -14.184443473815918 \n",
      "Root Mean Squared Error -- train: 0.42039376497268677, -- test: 0.7752566337585449 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.2923810482025146, -- test: -13.621150016784668 \n",
      "Root Mean Squared Error -- train: 0.4136883318424225, -- test: 0.7607830762863159 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.1967246532440186, -- test: -14.258784294128418 \n",
      "Root Mean Squared Error -- train: 0.40909987688064575, -- test: 0.7771466374397278 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.206521511077881, -- test: -13.674996376037598 \n",
      "Root Mean Squared Error -- train: 0.40957215428352356, -- test: 0.7621785402297974 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.282991409301758, -- test: -13.347567558288574 \n",
      "Root Mean Squared Error -- train: 0.4132401645183563, -- test: 0.7536532878875732 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.2326977252960205, -- test: -14.065570831298828 \n",
      "Root Mean Squared Error -- train: 0.41083142161369324, -- test: 0.7722248435020447 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -11.645445823669434\n",
      "Test Root MSE of all sampled models: 0.7678137421607971\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 79 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.4842889308929443 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 80 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.347111701965332, -- test: -13.83877182006836 \n",
      "Root Mean Squared Error -- train: 0.417611300945282, -- test: 0.7690588235855103 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.25533127784729, -- test: -13.709088325500488 \n",
      "Root Mean Squared Error -- train: 0.413220077753067, -- test: 0.7656999230384827 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.1569836139678955, -- test: -13.343610763549805 \n",
      "Root Mean Squared Error -- train: 0.4084623157978058, -- test: 0.7561537027359009 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.2590692043304443, -- test: -13.433391571044922 \n",
      "Root Mean Squared Error -- train: 0.413399875164032, -- test: 0.7585098743438721 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.216231107711792, -- test: -14.008352279663086 \n",
      "Root Mean Squared Error -- train: 0.41133514046669006, -- test: 0.7734289765357971 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.2120108604431152, -- test: -13.960622787475586 \n",
      "Root Mean Squared Error -- train: 0.4111311733722687, -- test: 0.7722014784812927 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.2073168754577637, -- test: -15.079628944396973 \n",
      "Root Mean Squared Error -- train: 0.410904198884964, -- test: 0.8004851937294006 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.203389883041382, -- test: -14.908211708068848 \n",
      "Root Mean Squared Error -- train: 0.41071417927742004, -- test: 0.7962176203727722 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.2902321815490723, -- test: -13.558335304260254 \n",
      "Root Mean Squared Error -- train: 0.4148954153060913, -- test: 0.7617768049240112 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.209636926651001, -- test: -14.220776557922363 \n",
      "Root Mean Squared Error -- train: 0.4110163450241089, -- test: 0.7788687348365784 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.366598129272461\n",
      "Test Root MSE of all sampled models: 0.783057689666748\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 80 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.059416770935059 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 81 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.1553235054016113, -- test: -13.331742286682129 \n",
      "Root Mean Squared Error -- train: 0.4096885323524475, -- test: 0.7584930062294006 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.4220409393310547, -- test: -13.595786094665527 \n",
      "Root Mean Squared Error -- train: 0.42252117395401, -- test: 0.7654305696487427 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.3797049522399902, -- test: -13.577537536621094 \n",
      "Root Mean Squared Error -- train: 0.4205103814601898, -- test: 0.7649531960487366 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.4154136180877686, -- test: -14.281865119934082 \n",
      "Root Mean Squared Error -- train: 0.4222070276737213, -- test: 0.7831698060035706 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.1322197914123535, -- test: -14.001326560974121 \n",
      "Root Mean Squared Error -- train: 0.4085579514503479, -- test: 0.7759652137756348 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.2282721996307373, -- test: -11.804797172546387 \n",
      "Root Mean Squared Error -- train: 0.41323792934417725, -- test: 0.7170581221580505 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.2871792316436768, -- test: -14.007696151733398 \n",
      "Root Mean Squared Error -- train: 0.4160819947719574, -- test: 0.7761295437812805 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.2076175212860107, -- test: -12.585982322692871 \n",
      "Root Mean Squared Error -- train: 0.4122360348701477, -- test: 0.7385466694831848 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.169198751449585, -- test: -12.844243049621582 \n",
      "Root Mean Squared Error -- train: 0.410366028547287, -- test: 0.7455145716667175 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.200120687484741, -- test: -13.591526985168457 \n",
      "Root Mean Squared Error -- train: 0.4118718206882477, -- test: 0.7653192281723022 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -11.397414207458496\n",
      "Test Root MSE of all sampled models: 0.7532661557197571\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 81 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.8285415172576904 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 82 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.521491765975952, -- test: -13.201602935791016 \n",
      "Root Mean Squared Error -- train: 0.4285695254802704, -- test: 0.7576597332954407 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.394064426422119, -- test: -13.06237506866455 \n",
      "Root Mean Squared Error -- train: 0.4225316643714905, -- test: 0.7539453506469727 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.181759834289551, -- test: -13.320507049560547 \n",
      "Root Mean Squared Error -- train: 0.41227567195892334, -- test: 0.7608175873756409 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.2750861644744873, -- test: -13.203307151794434 \n",
      "Root Mean Squared Error -- train: 0.4168151915073395, -- test: 0.7577051520347595 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.1312472820281982, -- test: -13.35020637512207 \n",
      "Root Mean Squared Error -- train: 0.409797728061676, -- test: 0.7616043090820312 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.161106824874878, -- test: -12.120945930480957 \n",
      "Root Mean Squared Error -- train: 0.4112643301486969, -- test: 0.7283322811126709 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.2170727252960205, -- test: -12.160553932189941 \n",
      "Root Mean Squared Error -- train: 0.4139992296695709, -- test: 0.7294279336929321 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.1174771785736084, -- test: -14.525764465332031 \n",
      "Root Mean Squared Error -- train: 0.4091196060180664, -- test: 0.7921165823936462 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.1499075889587402, -- test: -12.706153869628906 \n",
      "Root Mean Squared Error -- train: 0.41071486473083496, -- test: 0.7443574070930481 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.1548256874084473, -- test: -13.477019309997559 \n",
      "Root Mean Squared Error -- train: 0.4109562933444977, -- test: 0.7649543881416321 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.396625518798828\n",
      "Test Root MSE of all sampled models: 0.7563819289207458\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 82 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.424553394317627 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 83 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.110090494155884, -- test: -13.696556091308594 \n",
      "Root Mean Squared Error -- train: 0.4100436866283417, -- test: 0.7733888030052185 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.248197555541992, -- test: -13.202073097229004 \n",
      "Root Mean Squared Error -- train: 0.4168277382850647, -- test: 0.7602931261062622 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.117799758911133, -- test: -13.618732452392578 \n",
      "Root Mean Squared Error -- train: 0.4104253351688385, -- test: 0.7713425159454346 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.1122004985809326, -- test: -13.216858863830566 \n",
      "Root Mean Squared Error -- train: 0.41014817357063293, -- test: 0.7606879472732544 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.0932061672210693, -- test: -13.084907531738281 \n",
      "Root Mean Squared Error -- train: 0.4092065989971161, -- test: 0.7571569681167603 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.130718469619751, -- test: -13.781140327453613 \n",
      "Root Mean Squared Error -- train: 0.411064088344574, -- test: 0.7756067514419556 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.1280224323272705, -- test: -13.364930152893066 \n",
      "Root Mean Squared Error -- train: 0.410930871963501, -- test: 0.764630913734436 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.1443769931793213, -- test: -13.08673095703125 \n",
      "Root Mean Squared Error -- train: 0.4117383360862732, -- test: 0.7572058439254761 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.1050102710723877, -- test: -13.166601181030273 \n",
      "Root Mean Squared Error -- train: 0.4097920060157776, -- test: 0.7593450546264648 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.1400198936462402, -- test: -13.826044082641602 \n",
      "Root Mean Squared Error -- train: 0.41152337193489075, -- test: 0.7767816185951233 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -12.159984588623047\n",
      "Test Root MSE of all sampled models: 0.7700211405754089\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 83 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.9851174354553223 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 84 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.1009440422058105, -- test: -13.129101753234863 \n",
      "Root Mean Squared Error -- train: 0.4108988642692566, -- test: 0.7610008120536804 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.163419723510742, -- test: -13.024627685546875 \n",
      "Root Mean Squared Error -- train: 0.4139975309371948, -- test: 0.7581872940063477 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.2340781688690186, -- test: -12.259695053100586 \n",
      "Root Mean Squared Error -- train: 0.41747432947158813, -- test: 0.7372598052024841 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.0579006671905518, -- test: -12.297750473022461 \n",
      "Root Mean Squared Error -- train: 0.4087503254413605, -- test: 0.7383149266242981 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.054797887802124, -- test: -13.111961364746094 \n",
      "Root Mean Squared Error -- train: 0.4085950255393982, -- test: 0.7605398893356323 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.076545238494873, -- test: -12.37846565246582 \n",
      "Root Mean Squared Error -- train: 0.40968233346939087, -- test: 0.7405478954315186 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.124490261077881, -- test: -11.659809112548828 \n",
      "Root Mean Squared Error -- train: 0.4120694696903229, -- test: 0.7204226851463318 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.1426587104797363, -- test: -11.583059310913086 \n",
      "Root Mean Squared Error -- train: 0.4129704236984253, -- test: 0.718239963054657 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.208104133605957, -- test: -11.917776107788086 \n",
      "Root Mean Squared Error -- train: 0.41619962453842163, -- test: 0.7277107834815979 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.104085683822632, -- test: -14.236477851867676 \n",
      "Root Mean Squared Error -- train: 0.41105523705482483, -- test: 0.7902079820632935 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.437787055969238\n",
      "Test Root MSE of all sampled models: 0.73469078540802\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 84 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.4090845584869385 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 85 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.1036019325256348, -- test: -12.087695121765137 \n",
      "Root Mean Squared Error -- train: 0.412312775850296, -- test: 0.7349717617034912 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.0927162170410156, -- test: -12.733321189880371 \n",
      "Root Mean Squared Error -- train: 0.41176849603652954, -- test: 0.7528518438339233 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.9182019233703613, -- test: -12.114192008972168 \n",
      "Root Mean Squared Error -- train: 0.45118364691734314, -- test: 0.7357140779495239 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.028982400894165, -- test: -12.596159934997559 \n",
      "Root Mean Squared Error -- train: 0.4085672199726105, -- test: 0.7490890026092529 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.081256628036499, -- test: -12.744121551513672 \n",
      "Root Mean Squared Error -- train: 0.41119474172592163, -- test: 0.753147304058075 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.149799346923828, -- test: -12.329610824584961 \n",
      "Root Mean Squared Error -- train: 0.4146147072315216, -- test: 0.7417218685150146 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.0748536586761475, -- test: -13.458227157592773 \n",
      "Root Mean Squared Error -- train: 0.41087380051612854, -- test: 0.7724344730377197 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.07257080078125, -- test: -13.735379219055176 \n",
      "Root Mean Squared Error -- train: 0.410759299993515, -- test: 0.7797915935516357 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.0534508228302, -- test: -13.866079330444336 \n",
      "Root Mean Squared Error -- train: 0.409799188375473, -- test: 0.7832369804382324 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.162058115005493, -- test: -13.918252944946289 \n",
      "Root Mean Squared Error -- train: 0.4152233898639679, -- test: 0.7846081256866455 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.6910400390625\n",
      "Test Root MSE of all sampled models: 0.7652052044868469\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 85 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.999526262283325 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 86 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.199547290802002, -- test: -13.294106483459473 \n",
      "Root Mean Squared Error -- train: 0.4183736741542816, -- test: 0.7706544399261475 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.056135892868042, -- test: -13.404315948486328 \n",
      "Root Mean Squared Error -- train: 0.41120028495788574, -- test: 0.773615837097168 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.1944313049316406, -- test: -12.635032653808594 \n",
      "Root Mean Squared Error -- train: 0.418119877576828, -- test: 0.7527018785476685 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.0443713665008545, -- test: -13.202888488769531 \n",
      "Root Mean Squared Error -- train: 0.4106062650680542, -- test: 0.7681947350502014 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.205672264099121, -- test: -12.661052703857422 \n",
      "Root Mean Squared Error -- train: 0.41867730021476746, -- test: 0.7534187436103821 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.084669351577759, -- test: -13.223361015319824 \n",
      "Root Mean Squared Error -- train: 0.41263747215270996, -- test: 0.7687474489212036 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.0707435607910156, -- test: -13.893477439880371 \n",
      "Root Mean Squared Error -- train: 0.4119367003440857, -- test: 0.7866250872612 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.06738018989563, -- test: -13.755969047546387 \n",
      "Root Mean Squared Error -- train: 0.41176727414131165, -- test: 0.7829898595809937 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.122734546661377, -- test: -12.95147705078125 \n",
      "Root Mean Squared Error -- train: 0.4145469665527344, -- test: 0.761374294757843 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.1282553672790527, -- test: -14.2516508102417 \n",
      "Root Mean Squared Error -- train: 0.41482317447662354, -- test: 0.7960159182548523 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -11.430519104003906\n",
      "Test Root MSE of all sampled models: 0.7706422209739685\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 86 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.2086100578308105 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 87 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.9858040809631348, -- test: -13.085487365722656 \n",
      "Root Mean Squared Error -- train: 0.4088897705078125, -- test: 0.7676109075546265 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.9935901165008545, -- test: -12.792973518371582 \n",
      "Root Mean Squared Error -- train: 0.4092874228954315, -- test: 0.7596073150634766 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.998706817626953, -- test: -13.359667778015137 \n",
      "Root Mean Squared Error -- train: 0.4095485508441925, -- test: 0.7750377655029297 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.975142478942871, -- test: -13.136260986328125 \n",
      "Root Mean Squared Error -- train: 0.4083446264266968, -- test: 0.7689916491508484 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.024418592453003, -- test: -13.270552635192871 \n",
      "Root Mean Squared Error -- train: 0.410858154296875, -- test: 0.7726317644119263 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.063976287841797, -- test: -12.724518775939941 \n",
      "Root Mean Squared Error -- train: 0.41286492347717285, -- test: 0.757722020149231 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.0374443531036377, -- test: -11.1508207321167 \n",
      "Root Mean Squared Error -- train: 0.4115200340747833, -- test: 0.7130094766616821 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.0555763244628906, -- test: -12.80935287475586 \n",
      "Root Mean Squared Error -- train: 0.41243958473205566, -- test: 0.7600576281547546 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.0305256843566895, -- test: -11.501206398010254 \n",
      "Root Mean Squared Error -- train: 0.4111686050891876, -- test: 0.7232040762901306 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.017019510269165, -- test: -11.294642448425293 \n",
      "Root Mean Squared Error -- train: 0.410481721162796, -- test: 0.7172115445137024 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.572736740112305\n",
      "Test Root MSE of all sampled models: 0.7375832796096802\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 87 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.5161895751953125 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 88 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.0091097354888916, -- test: -12.857651710510254 \n",
      "Root Mean Squared Error -- train: 0.41131770610809326, -- test: 0.7639164328575134 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.157407283782959, -- test: -12.610812187194824 \n",
      "Root Mean Squared Error -- train: 0.4188341200351715, -- test: 0.7570880055427551 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.0121772289276123, -- test: -12.662062644958496 \n",
      "Root Mean Squared Error -- train: 0.4114745557308197, -- test: 0.7585108876228333 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.9782559871673584, -- test: -12.442381858825684 \n",
      "Root Mean Squared Error -- train: 0.4097365438938141, -- test: 0.7523931264877319 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.955068349838257, -- test: -13.190123558044434 \n",
      "Root Mean Squared Error -- train: 0.40854427218437195, -- test: 0.7730183005332947 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.0267646312713623, -- test: -12.666242599487305 \n",
      "Root Mean Squared Error -- train: 0.41221973299980164, -- test: 0.7586267590522766 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.0053703784942627, -- test: -12.2099609375 \n",
      "Root Mean Squared Error -- train: 0.41112640500068665, -- test: 0.7458660006523132 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.011115550994873, -- test: -12.767075538635254 \n",
      "Root Mean Squared Error -- train: 0.4114202857017517, -- test: 0.7614178657531738 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.984611988067627, -- test: -11.524421691894531 \n",
      "Root Mean Squared Error -- train: 0.4100627899169922, -- test: 0.7262722253799438 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.0082883834838867, -- test: -13.658465385437012 \n",
      "Root Mean Squared Error -- train: 0.4112756848335266, -- test: 0.7856609225273132 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.594338417053223\n",
      "Test Root MSE of all sampled models: 0.7617347240447998\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 88 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.2991433143615723 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 89 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.098670482635498, -- test: -12.801640510559082 \n",
      "Root Mean Squared Error -- train: 0.41713690757751465, -- test: 0.7649146914482117 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.999601364135742, -- test: -13.059167861938477 \n",
      "Root Mean Squared Error -- train: 0.41207513213157654, -- test: 0.7720137238502502 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.0203046798706055, -- test: -12.207523345947266 \n",
      "Root Mean Squared Error -- train: 0.4131380617618561, -- test: 0.7482801675796509 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.950678825378418, -- test: -13.110050201416016 \n",
      "Root Mean Squared Error -- train: 0.40955236554145813, -- test: 0.7734086513519287 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.0794339179992676, -- test: -13.251867294311523 \n",
      "Root Mean Squared Error -- train: 0.41615888476371765, -- test: 0.7772833108901978 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.0280275344848633, -- test: -12.283291816711426 \n",
      "Root Mean Squared Error -- train: 0.4135338366031647, -- test: 0.7504220008850098 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.980617046356201, -- test: -11.43826675415039 \n",
      "Root Mean Squared Error -- train: 0.41109803318977356, -- test: 0.7261760234832764 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.9820663928985596, -- test: -12.2523193359375 \n",
      "Root Mean Squared Error -- train: 0.41117268800735474, -- test: 0.7495471835136414 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.967479705810547, -- test: -11.774272918701172 \n",
      "Root Mean Squared Error -- train: 0.4104205071926117, -- test: 0.735912561416626 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.0581979751586914, -- test: -12.539446830749512 \n",
      "Root Mean Squared Error -- train: 0.41507649421691895, -- test: 0.7576185464859009 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.842891693115234\n",
      "Test Root MSE of all sampled models: 0.7482365965843201\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 89 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.062536716461182 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 90 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.0995633602142334, -- test: -12.399560928344727 \n",
      "Root Mean Squared Error -- train: 0.4184771776199341, -- test: 0.7562618255615234 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.907684564590454, -- test: -12.753722190856934 \n",
      "Root Mean Squared Error -- train: 0.40857818722724915, -- test: 0.7661874890327454 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.9804110527038574, -- test: -13.339844703674316 \n",
      "Root Mean Squared Error -- train: 0.4123580753803253, -- test: 0.7823373079299927 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.9105277061462402, -- test: -12.505417823791504 \n",
      "Root Mean Squared Error -- train: 0.40872660279273987, -- test: 0.7592421174049377 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.004411458969116, -- test: -13.220233917236328 \n",
      "Root Mean Squared Error -- train: 0.4135979413986206, -- test: 0.7790688276290894 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.961669921875, -- test: -13.609885215759277 \n",
      "Root Mean Squared Error -- train: 0.4113873541355133, -- test: 0.7896668314933777 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.9614834785461426, -- test: -12.522994041442871 \n",
      "Root Mean Squared Error -- train: 0.4113777279853821, -- test: 0.7597358822822571 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.9321982860565186, -- test: -12.311075210571289 \n",
      "Root Mean Squared Error -- train: 0.4098561406135559, -- test: 0.7537616491317749 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.9151370525360107, -- test: -12.900348663330078 \n",
      "Root Mean Squared Error -- train: 0.40896710753440857, -- test: 0.7702593803405762 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.985682725906372, -- test: -13.46535873413086 \n",
      "Root Mean Squared Error -- train: 0.41263070702552795, -- test: 0.785752534866333 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.332845687866211\n",
      "Test Root MSE of all sampled models: 0.770698606967926\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 90 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.134216070175171 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 91 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.914059638977051, -- test: -13.189440727233887 \n",
      "Root Mean Squared Error -- train: 0.410136342048645, -- test: 0.7808048129081726 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.9228827953338623, -- test: -12.206640243530273 \n",
      "Root Mean Squared Error -- train: 0.41059818863868713, -- test: 0.7532819509506226 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.014078378677368, -- test: -12.078100204467773 \n",
      "Root Mean Squared Error -- train: 0.41534170508384705, -- test: 0.749607503414154 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.986546277999878, -- test: -12.99081039428711 \n",
      "Root Mean Squared Error -- train: 0.41391539573669434, -- test: 0.7753210663795471 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.9327609539031982, -- test: -12.655012130737305 \n",
      "Root Mean Squared Error -- train: 0.4111146628856659, -- test: 0.7659609913825989 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.9798173904418945, -- test: -14.546719551086426 \n",
      "Root Mean Squared Error -- train: 0.41356605291366577, -- test: 0.8172922730445862 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.917015314102173, -- test: -12.759421348571777 \n",
      "Root Mean Squared Error -- train: 0.4102911055088043, -- test: 0.7688835859298706 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.0639989376068115, -- test: -12.891512870788574 \n",
      "Root Mean Squared Error -- train: 0.41791558265686035, -- test: 0.7725650668144226 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.0007057189941406, -- test: -13.365135192871094 \n",
      "Root Mean Squared Error -- train: 0.4146495759487152, -- test: 0.7856234312057495 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.0351743698120117, -- test: -12.459498405456543 \n",
      "Root Mean Squared Error -- train: 0.41643136739730835, -- test: 0.7604582905769348 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -9.729937553405762\n",
      "Test Root MSE of all sampled models: 0.7696133852005005\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 91 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.232027530670166 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 92 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.296119213104248, -- test: -12.50273323059082 \n",
      "Root Mean Squared Error -- train: 0.43098801374435425, -- test: 0.764204204082489 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.9839906692504883, -- test: -13.350153923034668 \n",
      "Root Mean Squared Error -- train: 0.41502851247787476, -- test: 0.7878233194351196 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.966830015182495, -- test: -12.85822868347168 \n",
      "Root Mean Squared Error -- train: 0.4141332805156708, -- test: 0.7742002010345459 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.936983108520508, -- test: -12.902966499328613 \n",
      "Root Mean Squared Error -- train: 0.4125714898109436, -- test: 0.7754490971565247 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.134202003479004, -- test: -13.435452461242676 \n",
      "Root Mean Squared Error -- train: 0.4227842092514038, -- test: 0.790161669254303 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.9664573669433594, -- test: -13.39350700378418 \n",
      "Root Mean Squared Error -- train: 0.4141137897968292, -- test: 0.789012610912323 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.9971253871917725, -- test: -13.260781288146973 \n",
      "Root Mean Squared Error -- train: 0.41571247577667236, -- test: 0.7853658199310303 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.996906280517578, -- test: -12.502904891967773 \n",
      "Root Mean Squared Error -- train: 0.4157010614871979, -- test: 0.7642090916633606 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.926234483718872, -- test: -12.75961685180664 \n",
      "Root Mean Squared Error -- train: 0.4120076298713684, -- test: 0.7714403867721558 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.996572971343994, -- test: -12.01713752746582 \n",
      "Root Mean Squared Error -- train: 0.41568371653556824, -- test: 0.7503347396850586 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.775315284729004\n",
      "Test Root MSE of all sampled models: 0.7751892805099487\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 92 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.8639976978302 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 93 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.948961019515991, -- test: -12.44137954711914 \n",
      "Root Mean Squared Error -- train: 0.41443225741386414, -- test: 0.7649751901626587 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.899808883666992, -- test: -12.350080490112305 \n",
      "Root Mean Squared Error -- train: 0.41184139251708984, -- test: 0.7623717188835144 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.905383586883545, -- test: -13.341584205627441 \n",
      "Root Mean Squared Error -- train: 0.412136048078537, -- test: 0.7901864051818848 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.9115588665008545, -- test: -13.36724853515625 \n",
      "Root Mean Squared Error -- train: 0.4124622046947479, -- test: 0.7908933758735657 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.980663537979126, -- test: -12.995306015014648 \n",
      "Root Mean Squared Error -- train: 0.4160947799682617, -- test: 0.7805848717689514 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.9558911323547363, -- test: -14.673938751220703 \n",
      "Root Mean Squared Error -- train: 0.41479623317718506, -- test: 0.8260895609855652 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.9149134159088135, -- test: -14.597979545593262 \n",
      "Root Mean Squared Error -- train: 0.4126392602920532, -- test: 0.8240847587585449 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.9089605808258057, -- test: -14.063759803771973 \n",
      "Root Mean Squared Error -- train: 0.412324994802475, -- test: 0.8098446130752563 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.9003002643585205, -- test: -12.274822235107422 \n",
      "Root Mean Squared Error -- train: 0.4118673503398895, -- test: 0.7602189779281616 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.9071433544158936, -- test: -12.025920867919922 \n",
      "Root Mean Squared Error -- train: 0.4122290015220642, -- test: 0.753055214881897 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -11.750282287597656\n",
      "Test Root MSE of all sampled models: 0.8022828102111816\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 93 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.8544883728027344 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 94 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.945333242416382, -- test: -12.629053115844727 \n",
      "Root Mean Squared Error -- train: 0.4154694378376007, -- test: 0.7728189826011658 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.828361749649048, -- test: -11.541608810424805 \n",
      "Root Mean Squared Error -- train: 0.40925008058547974, -- test: 0.7413261532783508 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.9808642864227295, -- test: -12.257550239562988 \n",
      "Root Mean Squared Error -- train: 0.4173402786254883, -- test: 0.7622064352035522 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.8555192947387695, -- test: -12.092233657836914 \n",
      "Root Mean Squared Error -- train: 0.4107024371623993, -- test: 0.7574360966682434 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.8186230659484863, -- test: -11.575569152832031 \n",
      "Root Mean Squared Error -- train: 0.4087279736995697, -- test: 0.7423298954963684 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.886111259460449, -- test: -11.397292137145996 \n",
      "Root Mean Squared Error -- train: 0.41233232617378235, -- test: 0.7370455265045166 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.866166830062866, -- test: -13.367523193359375 \n",
      "Root Mean Squared Error -- train: 0.4112704396247864, -- test: 0.7934931516647339 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.8832359313964844, -- test: -11.129424095153809 \n",
      "Root Mean Squared Error -- train: 0.41217944025993347, -- test: 0.7290335893630981 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.890789031982422, -- test: -10.717121124267578 \n",
      "Root Mean Squared Error -- train: 0.4125809967517853, -- test: 0.7165266275405884 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.9471845626831055, -- test: -11.802045822143555 \n",
      "Root Mean Squared Error -- train: 0.4155671298503876, -- test: 0.7489890456199646 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -9.438078880310059\n",
      "Test Root MSE of all sampled models: 0.7410100102424622\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 94 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.092449426651001 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 95 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.83790922164917, -- test: -10.731093406677246 \n",
      "Root Mean Squared Error -- train: 0.41097110509872437, -- test: 0.7192854285240173 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.935060977935791, -- test: -10.620287895202637 \n",
      "Root Mean Squared Error -- train: 0.4161566495895386, -- test: 0.7158768177032471 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.8690223693847656, -- test: -11.276656150817871 \n",
      "Root Mean Squared Error -- train: 0.41263890266418457, -- test: 0.7358378767967224 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.7991809844970703, -- test: -11.91098403930664 \n",
      "Root Mean Squared Error -- train: 0.4088855981826782, -- test: 0.7546271681785583 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.8286941051483154, -- test: -11.727596282958984 \n",
      "Root Mean Squared Error -- train: 0.41047582030296326, -- test: 0.7492435574531555 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.8712098598480225, -- test: -11.081804275512695 \n",
      "Root Mean Squared Error -- train: 0.41275590658187866, -- test: 0.7299691438674927 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.8470897674560547, -- test: -10.866228103637695 \n",
      "Root Mean Squared Error -- train: 0.4114639163017273, -- test: 0.7234207391738892 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.8349549770355225, -- test: -10.437103271484375 \n",
      "Root Mean Squared Error -- train: 0.4108124077320099, -- test: 0.7102057933807373 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.836751699447632, -- test: -10.466811180114746 \n",
      "Root Mean Squared Error -- train: 0.41090890765190125, -- test: 0.7111285924911499 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.7987661361694336, -- test: -13.177484512329102 \n",
      "Root Mean Squared Error -- train: 0.40886321663856506, -- test: 0.7908076047897339 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -9.91874885559082\n",
      "Test Root MSE of all sampled models: 0.7344473004341125\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 95 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7985833883285522 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 96 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.779244899749756, -- test: -12.465995788574219 \n",
      "Root Mean Squared Error -- train: 0.40896883606910706, -- test: 0.7731277346611023 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.8088982105255127, -- test: -11.759272575378418 \n",
      "Root Mean Squared Error -- train: 0.410576730966568, -- test: 0.7525424957275391 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.772770881652832, -- test: -11.955617904663086 \n",
      "Root Mean Squared Error -- train: 0.40861693024635315, -- test: 0.7583177089691162 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.807964324951172, -- test: -11.655906677246094 \n",
      "Root Mean Squared Error -- train: 0.41052618622779846, -- test: 0.7494843602180481 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.146268129348755, -- test: -13.068733215332031 \n",
      "Root Mean Squared Error -- train: 0.4284456968307495, -- test: 0.7902604937553406 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.9096717834472656, -- test: -10.564090728759766 \n",
      "Root Mean Squared Error -- train: 0.41599464416503906, -- test: 0.7163849472999573 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.865748643875122, -- test: -10.999980926513672 \n",
      "Root Mean Squared Error -- train: 0.41364195942878723, -- test: 0.7297794222831726 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.895378589630127, -- test: -9.318180084228516 \n",
      "Root Mean Squared Error -- train: 0.41523051261901855, -- test: 0.6766389012336731 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.950853109359741, -- test: -9.170702934265137 \n",
      "Root Mean Squared Error -- train: 0.4181884825229645, -- test: 0.6717785596847534 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.9259865283966064, -- test: -9.601670265197754 \n",
      "Root Mean Squared Error -- train: 0.41686517000198364, -- test: 0.6858850121498108 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -8.800286293029785\n",
      "Test Root MSE of all sampled models: 0.7042217254638672\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 96 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.5286755561828613 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 97 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.3561835289001465, -- test: -10.14938735961914 \n",
      "Root Mean Squared Error -- train: 0.44049304723739624, -- test: 0.7056455016136169 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.7820792198181152, -- test: -10.776653289794922 \n",
      "Root Mean Squared Error -- train: 0.4103058874607086, -- test: 0.7252565026283264 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.7469236850738525, -- test: -11.806143760681152 \n",
      "Root Mean Squared Error -- train: 0.40838488936424255, -- test: 0.7563413977622986 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.906813859939575, -- test: -11.743319511413574 \n",
      "Root Mean Squared Error -- train: 0.4170505106449127, -- test: 0.7544812560081482 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.7998218536376953, -- test: -12.165882110595703 \n",
      "Root Mean Squared Error -- train: 0.4112720489501953, -- test: 0.7669066190719604 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.8229026794433594, -- test: -12.084609031677246 \n",
      "Root Mean Squared Error -- train: 0.4125254452228546, -- test: 0.7645325064659119 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.7732043266296387, -- test: -12.04135513305664 \n",
      "Root Mean Squared Error -- train: 0.40982183814048767, -- test: 0.76326584815979 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.8113954067230225, -- test: -13.402543067932129 \n",
      "Root Mean Squared Error -- train: 0.4119010269641876, -- test: 0.8021652698516846 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.767368793487549, -- test: -11.402626991271973 \n",
      "Root Mean Squared Error -- train: 0.40950319170951843, -- test: 0.7443121671676636 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.7623660564422607, -- test: -13.605134010314941 \n",
      "Root Mean Squared Error -- train: 0.4092298448085785, -- test: 0.8077946305274963 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.913980484008789\n",
      "Test Root MSE of all sampled models: 0.780205488204956\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 97 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.6933743953704834 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 98 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.809213161468506, -- test: -11.526025772094727 \n",
      "Root Mean Squared Error -- train: 0.41296496987342834, -- test: 0.7503873109817505 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.7185778617858887, -- test: -11.7706880569458 \n",
      "Root Mean Squared Error -- train: 0.40799325704574585, -- test: 0.7576931118965149 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.724656820297241, -- test: -11.78675651550293 \n",
      "Root Mean Squared Error -- train: 0.4083286225795746, -- test: 0.7581705451011658 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.7227110862731934, -- test: -11.967212677001953 \n",
      "Root Mean Squared Error -- train: 0.4082213044166565, -- test: 0.7635109424591064 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.261234760284424, -- test: -11.476977348327637 \n",
      "Root Mean Squared Error -- train: 0.43691620230674744, -- test: 0.7489141225814819 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.801128387451172, -- test: -11.428157806396484 \n",
      "Root Mean Squared Error -- train: 0.41252389550209045, -- test: 0.7474449276924133 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.759413480758667, -- test: -12.403463363647461 \n",
      "Root Mean Squared Error -- train: 0.41024070978164673, -- test: 0.7762696146965027 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.8028509616851807, -- test: -13.115033149719238 \n",
      "Root Mean Squared Error -- train: 0.41261792182922363, -- test: 0.7966418862342834 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.7706549167633057, -- test: -11.620572090148926 \n",
      "Root Mean Squared Error -- train: 0.410857230424881, -- test: 0.753218948841095 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.7845945358276367, -- test: -11.2786283493042 \n",
      "Root Mean Squared Error -- train: 0.41162049770355225, -- test: 0.7429267764091492 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -9.898055076599121\n",
      "Test Root MSE of all sampled models: 0.7612817883491516\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 98 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.895268201828003 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 99 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.712146759033203, -- test: -11.62463092803955 \n",
      "Root Mean Squared Error -- train: 0.4088020324707031, -- test: 0.7557300329208374 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.7335751056671143, -- test: -11.687037467956543 \n",
      "Root Mean Squared Error -- train: 0.4099883735179901, -- test: 0.757599413394928 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.7063941955566406, -- test: -12.130573272705078 \n",
      "Root Mean Squared Error -- train: 0.40848296880722046, -- test: 0.7707546353340149 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.9225122928619385, -- test: -11.458852767944336 \n",
      "Root Mean Squared Error -- train: 0.4203035831451416, -- test: 0.7507416605949402 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.706613063812256, -- test: -11.786262512207031 \n",
      "Root Mean Squared Error -- train: 0.40849512815475464, -- test: 0.7605621814727783 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.8022162914276123, -- test: -10.902597427368164 \n",
      "Root Mean Squared Error -- train: 0.41376566886901855, -- test: 0.733755886554718 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.7591195106506348, -- test: -10.119867324829102 \n",
      "Root Mean Squared Error -- train: 0.41139811277389526, -- test: 0.7091656923294067 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.7481935024261475, -- test: -10.850607872009277 \n",
      "Root Mean Squared Error -- train: 0.41079574823379517, -- test: 0.7321482300758362 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.858515977859497, -- test: -9.950169563293457 \n",
      "Root Mean Squared Error -- train: 0.41683825850486755, -- test: 0.7037212252616882 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.8323874473571777, -- test: -10.336742401123047 \n",
      "Root Mean Squared Error -- train: 0.41541510820388794, -- test: 0.7160636186599731 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -9.045479774475098\n",
      "Test Root MSE of all sampled models: 0.7249219417572021\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 99 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.6933627128601074 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 100 of total 100 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.209841251373291, -- test: -11.363365173339844 \n",
      "Root Mean Squared Error -- train: 0.43678051233291626, -- test: 0.7502075433731079 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.8084988594055176, -- test: -11.400665283203125 \n",
      "Root Mean Squared Error -- train: 0.4152884781360626, -- test: 0.7513410449028015 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.9830880165100098, -- test: -11.934170722961426 \n",
      "Root Mean Squared Error -- train: 0.4247714579105377, -- test: 0.7673698663711548 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.686250925064087, -- test: -11.429577827453613 \n",
      "Root Mean Squared Error -- train: 0.408517450094223, -- test: 0.7522183656692505 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.845590829849243, -- test: -11.431330680847168 \n",
      "Root Mean Squared Error -- train: 0.41732117533683777, -- test: 0.7522715330123901 \n",
      "\n",
      "#################### Sample No.1 at Epoch 549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.766488552093506, -- test: -10.977031707763672 \n",
      "Root Mean Squared Error -- train: 0.41297417879104614, -- test: 0.7383654117584229 \n",
      "\n",
      "#################### Sample No.3 at Epoch 649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.7507128715515137, -- test: -11.154764175415039 \n",
      "Root Mean Squared Error -- train: 0.41210174560546875, -- test: 0.7438368201255798 \n",
      "\n",
      "#################### Sample No.5 at Epoch 749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.7023274898529053, -- test: -11.730798721313477 \n",
      "Root Mean Squared Error -- train: 0.40941429138183594, -- test: 0.7612994313240051 \n",
      "\n",
      "#################### Sample No.7 at Epoch 849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.7682619094848633, -- test: -13.007737159729004 \n",
      "Root Mean Squared Error -- train: 0.4130721092224121, -- test: 0.7986499667167664 \n",
      "\n",
      "#################### Sample No.9 at Epoch 949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.8378918170928955, -- test: -13.427044868469238 \n",
      "Root Mean Squared Error -- train: 0.416900098323822, -- test: 0.8105394244194031 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 10 \n",
      "Test Log Likelihood of all sampled models: -10.059699058532715\n",
      "Test Root MSE of all sampled models: 0.7650744915008545\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 100 of total 100 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.180774450302124 averaged by 10 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### After 100 EM steps, fixing hyperparams and sample from posterior. ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.7111270427703857, -- test: -11.15835952758789 \n",
      "Root Mean Squared Error -- train: 0.41107499599456787, -- test: 0.7463046312332153 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.6894965171813965, -- test: -11.678946495056152 \n",
      "Root Mean Squared Error -- train: 0.40986478328704834, -- test: 0.7621558904647827 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.7321927547454834, -- test: -11.801158905029297 \n",
      "Root Mean Squared Error -- train: 0.4122501611709595, -- test: 0.7658295035362244 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.7351560592651367, -- test: -12.316388130187988 \n",
      "Root Mean Squared Error -- train: 0.41241520643234253, -- test: 0.7811271548271179 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.9093756675720215, -- test: -11.539703369140625 \n",
      "Root Mean Squared Error -- train: 0.42200517654418945, -- test: 0.7579485774040222 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.7617805004119873, -- test: -11.557016372680664 \n",
      "Root Mean Squared Error -- train: 0.4138951599597931, -- test: 0.7584729194641113 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.955930233001709, -- test: -11.337594032287598 \n",
      "Root Mean Squared Error -- train: 0.42453110218048096, -- test: 0.7517997622489929 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.806314706802368, -- test: -11.964607238769531 \n",
      "Root Mean Squared Error -- train: 0.4163588583469391, -- test: 0.7707153558731079 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.6995232105255127, -- test: -11.880742073059082 \n",
      "Root Mean Squared Error -- train: 0.41042622923851013, -- test: 0.7682123780250549 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.734553575515747, -- test: -12.056188583374023 \n",
      "Root Mean Squared Error -- train: 0.412381649017334, -- test: 0.7734394669532776 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 1099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1099\n",
      "Mean Log Likelihood -- train: -2.739096164703369, -- test: -10.553189277648926 \n",
      "Root Mean Squared Error -- train: 0.41263461112976074, -- test: 0.7274439334869385 \n",
      "\n",
      "#################### Sample No.3 at Epoch 1149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 1199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1199\n",
      "Mean Log Likelihood -- train: -2.8432726860046387, -- test: -12.453290939331055 \n",
      "Root Mean Squared Error -- train: 0.4183923900127411, -- test: 0.7851419448852539 \n",
      "\n",
      "#################### Sample No.5 at Epoch 1249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 1299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1299\n",
      "Mean Log Likelihood -- train: -2.6826326847076416, -- test: -11.521540641784668 \n",
      "Root Mean Squared Error -- train: 0.4094800055027008, -- test: 0.7573980689048767 \n",
      "\n",
      "#################### Sample No.7 at Epoch 1349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 1399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1399\n",
      "Mean Log Likelihood -- train: -2.8155744075775146, -- test: -13.415761947631836 \n",
      "Root Mean Squared Error -- train: 0.41686931252479553, -- test: 0.8128067255020142 \n",
      "\n",
      "#################### Sample No.9 at Epoch 1449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 1499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1499\n",
      "Mean Log Likelihood -- train: -2.724332094192505, -- test: -10.992384910583496 \n",
      "Root Mean Squared Error -- train: 0.41181203722953796, -- test: 0.7411796450614929 \n",
      "\n",
      "#################### Sample No.11 at Epoch 1549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.12 at Epoch 1599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1599\n",
      "Mean Log Likelihood -- train: -2.7563278675079346, -- test: -12.35101318359375 \n",
      "Root Mean Squared Error -- train: 0.41359251737594604, -- test: 0.7821446061134338 \n",
      "\n",
      "#################### Sample No.13 at Epoch 1649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.14 at Epoch 1699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1699\n",
      "Mean Log Likelihood -- train: -2.7551612854003906, -- test: -12.293107032775879 \n",
      "Root Mean Squared Error -- train: 0.4135277271270752, -- test: 0.780442476272583 \n",
      "\n",
      "#################### Sample No.15 at Epoch 1749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.16 at Epoch 1799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1799\n",
      "Mean Log Likelihood -- train: -2.7784836292266846, -- test: -13.20981216430664 \n",
      "Root Mean Squared Error -- train: 0.41482090950012207, -- test: 0.8069668412208557 \n",
      "\n",
      "#################### Sample No.17 at Epoch 1849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.18 at Epoch 1899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1899\n",
      "Mean Log Likelihood -- train: -2.806138277053833, -- test: -11.522791862487793 \n",
      "Root Mean Squared Error -- train: 0.4163491129875183, -- test: 0.7574359774589539 \n",
      "\n",
      "#################### Sample No.19 at Epoch 1949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.20 at Epoch 1999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1999\n",
      "Mean Log Likelihood -- train: -2.753955602645874, -- test: -12.441702842712402 \n",
      "Root Mean Squared Error -- train: 0.41346079111099243, -- test: 0.7848028540611267 \n",
      "\n",
      "#################### Sample No.21 at Epoch 2049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.22 at Epoch 2099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2099\n",
      "Mean Log Likelihood -- train: -2.7799012660980225, -- test: -13.063651084899902 \n",
      "Root Mean Squared Error -- train: 0.41489937901496887, -- test: 0.802796483039856 \n",
      "\n",
      "#################### Sample No.23 at Epoch 2149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.24 at Epoch 2199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2199\n",
      "Mean Log Likelihood -- train: -2.745009660720825, -- test: -12.895013809204102 \n",
      "Root Mean Squared Error -- train: 0.4129635691642761, -- test: 0.797957718372345 \n",
      "\n",
      "#################### Sample No.25 at Epoch 2249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.26 at Epoch 2299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2299\n",
      "Mean Log Likelihood -- train: -2.8204185962677, -- test: -12.516524314880371 \n",
      "Root Mean Squared Error -- train: 0.4171360731124878, -- test: 0.7869893312454224 \n",
      "\n",
      "#################### Sample No.27 at Epoch 2349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.28 at Epoch 2399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2399\n",
      "Mean Log Likelihood -- train: -2.7708370685577393, -- test: -12.359633445739746 \n",
      "Root Mean Squared Error -- train: 0.41439738869667053, -- test: 0.7823975682258606 \n",
      "\n",
      "#################### Sample No.29 at Epoch 2449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.30 at Epoch 2499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2499\n",
      "Mean Log Likelihood -- train: -2.768543004989624, -- test: -14.821937561035156 \n",
      "Root Mean Squared Error -- train: 0.41427022218704224, -- test: 0.8516111969947815 \n",
      "\n",
      "#################### Sample No.31 at Epoch 2549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.32 at Epoch 2599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2599\n",
      "Mean Log Likelihood -- train: -2.766277313232422, -- test: -13.11143684387207 \n",
      "Root Mean Squared Error -- train: 0.4141446053981781, -- test: 0.804162323474884 \n",
      "\n",
      "#################### Sample No.33 at Epoch 2649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.34 at Epoch 2699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2699\n",
      "Mean Log Likelihood -- train: -2.7930681705474854, -- test: -18.49602508544922 \n",
      "Root Mean Squared Error -- train: 0.4156275689601898, -- test: 0.9455132484436035 \n",
      "\n",
      "#################### Sample No.35 at Epoch 2749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.36 at Epoch 2799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2799\n",
      "Mean Log Likelihood -- train: -2.8491504192352295, -- test: -17.80144500732422 \n",
      "Root Mean Squared Error -- train: 0.41871488094329834, -- test: 0.9284895062446594 \n",
      "\n",
      "#################### Sample No.37 at Epoch 2849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.38 at Epoch 2899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2899\n",
      "Mean Log Likelihood -- train: -2.797027349472046, -- test: -15.626635551452637 \n",
      "Root Mean Squared Error -- train: 0.4158462584018707, -- test: 0.8730418086051941 \n",
      "\n",
      "#################### Sample No.39 at Epoch 2949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.40 at Epoch 2999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2999\n",
      "Mean Log Likelihood -- train: -2.810098171234131, -- test: -15.409302711486816 \n",
      "Root Mean Squared Error -- train: 0.41656750440597534, -- test: 0.8673060536384583 \n",
      "\n",
      "#################### Sample No.41 at Epoch 3049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.42 at Epoch 3099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3099\n",
      "Mean Log Likelihood -- train: -2.784310817718506, -- test: -18.45793914794922 \n",
      "Root Mean Squared Error -- train: 0.4151434004306793, -- test: 0.9445877075195312 \n",
      "\n",
      "#################### Sample No.43 at Epoch 3149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.44 at Epoch 3199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3199\n",
      "Mean Log Likelihood -- train: -2.798337936401367, -- test: -13.0278959274292 \n",
      "Root Mean Squared Error -- train: 0.41591864824295044, -- test: 0.801772952079773 \n",
      "\n",
      "#################### Sample No.45 at Epoch 3249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.46 at Epoch 3299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3299\n",
      "Mean Log Likelihood -- train: -2.760695219039917, -- test: -14.407336235046387 \n",
      "Root Mean Squared Error -- train: 0.41383495926856995, -- test: 0.8403562903404236 \n",
      "\n",
      "#################### Sample No.47 at Epoch 3349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.48 at Epoch 3399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3399\n",
      "Mean Log Likelihood -- train: -2.8059842586517334, -- test: -13.37993049621582 \n",
      "Root Mean Squared Error -- train: 0.4163406193256378, -- test: 0.8117938041687012 \n",
      "\n",
      "#################### Sample No.49 at Epoch 3449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.50 at Epoch 3499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3499\n",
      "Mean Log Likelihood -- train: -2.885099411010742, -- test: -18.682870864868164 \n",
      "Root Mean Squared Error -- train: 0.42068198323249817, -- test: 0.9500406384468079 \n",
      "\n",
      "#################### Sample No.51 at Epoch 3549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.52 at Epoch 3599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3599\n",
      "Mean Log Likelihood -- train: -2.769747734069824, -- test: -13.536537170410156 \n",
      "Root Mean Squared Error -- train: 0.4143369793891907, -- test: 0.8162120580673218 \n",
      "\n",
      "#################### Sample No.53 at Epoch 3649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.54 at Epoch 3699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3699\n",
      "Mean Log Likelihood -- train: -2.764632225036621, -- test: -13.463741302490234 \n",
      "Root Mean Squared Error -- train: 0.414053350687027, -- test: 0.8141613006591797 \n",
      "\n",
      "#################### Sample No.55 at Epoch 3749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.56 at Epoch 3799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3799\n",
      "Mean Log Likelihood -- train: -2.758758544921875, -- test: -12.522186279296875 \n",
      "Root Mean Squared Error -- train: 0.41372743248939514, -- test: 0.7871545553207397 \n",
      "\n",
      "#################### Sample No.57 at Epoch 3849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.58 at Epoch 3899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3899\n",
      "Mean Log Likelihood -- train: -2.759364128112793, -- test: -15.932716369628906 \n",
      "Root Mean Squared Error -- train: 0.41376107931137085, -- test: 0.8810564875602722 \n",
      "\n",
      "#################### Sample No.59 at Epoch 3949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.60 at Epoch 3999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3999\n",
      "Mean Log Likelihood -- train: -2.809779644012451, -- test: -16.332773208618164 \n",
      "Root Mean Squared Error -- train: 0.4165499210357666, -- test: 0.8914233446121216 \n",
      "\n",
      "#################### Sample No.61 at Epoch 4049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.62 at Epoch 4099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4099\n",
      "Mean Log Likelihood -- train: -2.786979913711548, -- test: -14.012874603271484 \n",
      "Root Mean Squared Error -- train: 0.4152909815311432, -- test: 0.8295062780380249 \n",
      "\n",
      "#################### Sample No.63 at Epoch 4149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.64 at Epoch 4199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4199\n",
      "Mean Log Likelihood -- train: -2.7881622314453125, -- test: -13.341124534606934 \n",
      "Root Mean Squared Error -- train: 0.4153563976287842, -- test: 0.8106951117515564 \n",
      "\n",
      "#################### Sample No.65 at Epoch 4249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.66 at Epoch 4299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4299\n",
      "Mean Log Likelihood -- train: -2.7790536880493164, -- test: -13.845080375671387 \n",
      "Root Mean Squared Error -- train: 0.41485247015953064, -- test: 0.8248476982116699 \n",
      "\n",
      "#################### Sample No.67 at Epoch 4349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.68 at Epoch 4399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4399\n",
      "Mean Log Likelihood -- train: -2.7837705612182617, -- test: -16.196250915527344 \n",
      "Root Mean Squared Error -- train: 0.4151134788990021, -- test: 0.8878991007804871 \n",
      "\n",
      "#################### Sample No.69 at Epoch 4449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.70 at Epoch 4499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4499\n",
      "Mean Log Likelihood -- train: -2.814091682434082, -- test: -14.107887268066406 \n",
      "Root Mean Squared Error -- train: 0.41678759455680847, -- test: 0.8321326375007629 \n",
      "\n",
      "#################### Sample No.71 at Epoch 4549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.72 at Epoch 4599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4599\n",
      "Mean Log Likelihood -- train: -2.8198792934417725, -- test: -14.727006912231445 \n",
      "Root Mean Squared Error -- train: 0.41710636019706726, -- test: 0.8490473031997681 \n",
      "\n",
      "#################### Sample No.73 at Epoch 4649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.74 at Epoch 4699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4699\n",
      "Mean Log Likelihood -- train: -2.7980949878692627, -- test: -13.907745361328125 \n",
      "Root Mean Squared Error -- train: 0.415905237197876, -- test: 0.8265905976295471 \n",
      "\n",
      "#################### Sample No.75 at Epoch 4749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.76 at Epoch 4799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4799\n",
      "Mean Log Likelihood -- train: -2.7652626037597656, -- test: -16.093860626220703 \n",
      "Root Mean Squared Error -- train: 0.4140883684158325, -- test: 0.8852468729019165 \n",
      "\n",
      "#################### Sample No.77 at Epoch 4849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.78 at Epoch 4899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4899\n",
      "Mean Log Likelihood -- train: -2.767350196838379, -- test: -16.580089569091797 \n",
      "Root Mean Squared Error -- train: 0.41420406103134155, -- test: 0.8977721333503723 \n",
      "\n",
      "#################### Sample No.79 at Epoch 4949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.80 at Epoch 4999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4999\n",
      "Mean Log Likelihood -- train: -2.794840097427368, -- test: -13.81506633758545 \n",
      "Root Mean Squared Error -- train: 0.4157254695892334, -- test: 0.8240116834640503 \n",
      "\n",
      "#################### Sample No.81 at Epoch 5049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.82 at Epoch 5099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5099\n",
      "Mean Log Likelihood -- train: -2.78507399559021, -- test: -14.271424293518066 \n",
      "Root Mean Squared Error -- train: 0.4151856005191803, -- test: 0.8366338014602661 \n",
      "\n",
      "#################### Sample No.83 at Epoch 5149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.84 at Epoch 5199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5199\n",
      "Mean Log Likelihood -- train: -2.7959342002868652, -- test: -14.111741065979004 \n",
      "Root Mean Squared Error -- train: 0.41578587889671326, -- test: 0.832239031791687 \n",
      "\n",
      "#################### Sample No.85 at Epoch 5249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.86 at Epoch 5299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5299\n",
      "Mean Log Likelihood -- train: -2.8093056678771973, -- test: -17.19434356689453 \n",
      "Root Mean Squared Error -- train: 0.4165237843990326, -- test: 0.9133499264717102 \n",
      "\n",
      "#################### Sample No.87 at Epoch 5349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.88 at Epoch 5399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5399\n",
      "Mean Log Likelihood -- train: -2.885070562362671, -- test: -14.012725830078125 \n",
      "Root Mean Squared Error -- train: 0.4206804037094116, -- test: 0.8295021653175354 \n",
      "\n",
      "#################### Sample No.89 at Epoch 5449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.90 at Epoch 5499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5499\n",
      "Mean Log Likelihood -- train: -2.8027544021606445, -- test: -14.742626190185547 \n",
      "Root Mean Squared Error -- train: 0.4161624312400818, -- test: 0.8494697213172913 \n",
      "\n",
      "#################### Sample No.91 at Epoch 5549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.92 at Epoch 5599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5599\n",
      "Mean Log Likelihood -- train: -2.7697436809539795, -- test: -16.048728942871094 \n",
      "Root Mean Squared Error -- train: 0.41433677077293396, -- test: 0.8840752840042114 \n",
      "\n",
      "#################### Sample No.93 at Epoch 5649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.94 at Epoch 5699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5699\n",
      "Mean Log Likelihood -- train: -2.8201329708099365, -- test: -14.68139934539795 \n",
      "Root Mean Squared Error -- train: 0.4171203374862671, -- test: 0.847812831401825 \n",
      "\n",
      "#################### Sample No.95 at Epoch 5749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.96 at Epoch 5799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5799\n",
      "Mean Log Likelihood -- train: -2.780285358428955, -- test: -14.214268684387207 \n",
      "Root Mean Squared Error -- train: 0.4149206578731537, -- test: 0.8350633382797241 \n",
      "\n",
      "#################### Sample No.97 at Epoch 5849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.98 at Epoch 5899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5899\n",
      "Mean Log Likelihood -- train: -2.781590223312378, -- test: -11.796791076660156 \n",
      "Root Mean Squared Error -- train: 0.4149928689002991, -- test: 0.7656985521316528 \n",
      "\n",
      "#################### Sample No.99 at Epoch 5949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.100 at Epoch 5999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5999\n",
      "Mean Log Likelihood -- train: -2.8589179515838623, -- test: -11.306468963623047 \n",
      "Root Mean Squared Error -- train: 0.4192502498626709, -- test: 0.7508484125137329 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 100 \n",
      "Test Log Likelihood of all sampled models: -8.722248077392578\n",
      "Test Root MSE of all sampled models: 0.828028678894043\n",
      "********************************************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MCEM settings and training\n",
    "total_EM_steps = 100\n",
    "_, _, lines, W = MCEM_demo(sampler_EM, maximizer, sampler_fixing_hyper, total_EM_steps, ds_train, \n",
    "                      num_samples_EM=10, num_samples_fixing_hyper=100,\n",
    "                      print_epoch_cycle_EM=100, print_epoch_cycle_fixing=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.051458575>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.06790732], dtype=float32)>,\n",
       " <tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.01360142>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.05142293], dtype=float32)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Omega_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4c14599c40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print sampled lines\n",
    "fig, ax = plt.subplots(1, model.n_hidden_layers+1, figsize=((model.n_hidden_layers+1)*5, 5))\n",
    "ax = ax.flatten()\n",
    "for i in range(model.n_hidden_layers):\n",
    "    for model_line in lines[:]: # hidden outputs of each sampled model\n",
    "        line = model_line[i]\n",
    "        ax[i].plot(X_test[:,0], line.numpy()[:,0])\n",
    "    # for model_line in lines[690:701]: # hidden outputs of each sampled model\n",
    "    #     line = model_line[i]\n",
    "    #     ax[i].plot(X_test.numpy()[:,0], line.numpy()[:,0], 'b')\n",
    "for x, y in ds_train:\n",
    "    ax[-2].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "# for x, y in ds_test:\n",
    "    # ax[-1].plot(x[:,0], y[:,0], '*', label='ground truth')\n",
    "ax[-2].legend()\n",
    "\n",
    "# compute the mean of the sampled lines\n",
    "line_output = []\n",
    "for model_line in lines[:]:\n",
    "    line_output.append(model_line[-1]) #the final layer\n",
    "line_mean = tf.reduce_mean(tf.concat(line_output, axis=-1), axis=-1)\n",
    "ax[-1].plot(X_test[:,0], line_mean.numpy(), label='mean')\n",
    "for x, y in ds_train:\n",
    "    ax[-1].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "ax[-1].legend()\n",
    "# fig.savefig('2layer-sin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_index = (25,0)\n",
    "fig, ax = plt.subplots(1, model.n_hidden_layers, figsize=(model.n_hidden_layers*5,5))\n",
    "ax = ax.flatten()\n",
    "for i in range(model.n_hidden_layers):\n",
    "    W_print = []\n",
    "    for W_model in W['W_'+str(i)][:]:\n",
    "        W_print.append(W_model[print_index])\n",
    "    ax[i].hist(W_print, bins=60, density=True, label='W_'+str(i))\n",
    "    ax[i].legend()\n",
    "# fig.savefig('2w-sin-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try to show the correlation of two weights\n",
    "print_index_1 = (0,0)\n",
    "print_index_2 = (25,0)\n",
    "W_print_1 = []\n",
    "W_print_2 = []\n",
    "for W_model in W['W_'+ str(1)][10:]:\n",
    "    W_print_1.append(W_model[print_index_1])\n",
    "    W_print_2.append(W_model[print_index_2])\n",
    "plt.hist2d(W_print_1, W_print_2, bins=60, density=True)\n",
    "plt.xlabel(f'W_1{print_index_1}')\n",
    "plt.ylabel(f'W_1{print_index_2}')\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('probability')\n",
    "plt.savefig('correlation-sin-2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-layer DGPs (MCEM with Moving Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "d_in = 1\n",
    "d_out = 1\n",
    "model = DemoRegressionDGP(d_in, d_out, n_hidden_layers=2, n_rf=100, n_gp=1,\n",
    "                          likelihood=Gaussian(variance=0.01, trainable=True),\n",
    "                          kernel_type_list=['RBF' for i in range(2)], kernel_trainable=True,\n",
    "                          random_fixed=True, input_cat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 09:07:09.149112: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Omega_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM sampler settings\n",
    "batch_size = 47\n",
    "lr_mcmc_0 = 0.01\n",
    "sampler_EM = MCEM_sampler_demo(model, ds_train, ds_test, num_training, batch_size, X_test,\n",
    "                               lr_0=lr_mcmc_0, momentum_decay=0.95, resample_in_cycle_head=False,\n",
    "                               start_sampling_epoch=1000, epochs_per_cycle=50)\n",
    "\n",
    "# Maximizer setttings\n",
    "lr_maximizer = 0.01\n",
    "optimizer = optimizers.Adam(learning_rate=lr_maximizer)\n",
    "maximizer = MCEM_Q_maximizer_demo(model, num_training, optimizer)\n",
    "\n",
    "# sampler settings after fixing hyper-params\n",
    "lr_fixing_hyper_0 = 0.01\n",
    "sampler_fixing_hyper = MCEM_sampler_demo(model, ds_train, ds_test, num_training, batch_size, X_test,\n",
    "                                         lr_0=lr_fixing_hyper_0, momentum_decay=0.95, resample_in_cycle_head=False,\n",
    "                                         start_sampling_epoch=1000, epochs_per_cycle=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### EM step 1 of total 300 steps. E Step:  ###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 09:07:12.154415: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-25 09:07:12.730517: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-08-25 09:07:12.730567: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -8.184826850891113, -- test: -30.45105743408203 \n",
      "Root Mean Squared Error -- train: 0.43745797872543335, -- test: 0.7979311347007751 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -8.934456825256348, -- test: -26.9631290435791 \n",
      "Root Mean Squared Error -- train: 0.4542709290981293, -- test: 0.7529512047767639 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.135907173156738, -- test: -28.468067169189453 \n",
      "Root Mean Squared Error -- train: 0.41278451681137085, -- test: 0.7726799845695496 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.04610013961792, -- test: -34.507301330566406 \n",
      "Root Mean Squared Error -- train: 0.4106031060218811, -- test: 0.847241997718811 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -7.787141799926758, -- test: -31.67310333251953 \n",
      "Root Mean Squared Error -- train: 0.4282706677913666, -- test: 0.8131020665168762 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.943991661071777, -- test: -30.035768508911133 \n",
      "Root Mean Squared Error -- train: 0.40810877084732056, -- test: 0.792709469795227 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -7.089760780334473, -- test: -30.89984130859375 \n",
      "Root Mean Squared Error -- train: 0.4116651117801666, -- test: 0.8035357594490051 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.985724925994873, -- test: -31.964550018310547 \n",
      "Root Mean Squared Error -- train: 0.4091300964355469, -- test: 0.8166785836219788 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -8.230548858642578, -- test: -32.01272201538086 \n",
      "Root Mean Squared Error -- train: 0.43850189447402954, -- test: 0.8172682523727417 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -7.8945722579956055, -- test: -32.5641975402832 \n",
      "Root Mean Squared Error -- train: 0.4307718276977539, -- test: 0.8239883780479431 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -38.23020935058594\n",
      "Test Root MSE of all sampled models: 0.8900994658470154\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 1 \n",
      "Test Log Likelihood of all models in window: -38.23020935058594\n",
      "Test Root MSE of all models in window: 0.8900994658470154\n",
      "\n",
      "############### EM step 1 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.441811561584473 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 2 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.8593621253967285, -- test: -37.82748794555664 \n",
      "Root Mean Squared Error -- train: 0.4079412519931793, -- test: 0.8899457454681396 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.6925368309021, -- test: -38.565860748291016 \n",
      "Root Mean Squared Error -- train: 0.40378957986831665, -- test: 0.8982868790626526 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.857431411743164, -- test: -42.0788688659668 \n",
      "Root Mean Squared Error -- train: 0.43194684386253357, -- test: 0.936955451965332 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.420173168182373, -- test: -39.08348083496094 \n",
      "Root Mean Squared Error -- train: 0.4215981662273407, -- test: 0.9040883183479309 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.913887977600098, -- test: -41.49736022949219 \n",
      "Root Mean Squared Error -- train: 0.40928906202316284, -- test: 0.9306656122207642 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.98892068862915, -- test: -40.73283767700195 \n",
      "Root Mean Squared Error -- train: 0.41113656759262085, -- test: 0.9223309755325317 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.872961044311523, -- test: -32.381988525390625 \n",
      "Root Mean Squared Error -- train: 0.40827780961990356, -- test: 0.825832188129425 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -7.047223091125488, -- test: -35.56883239746094 \n",
      "Root Mean Squared Error -- train: 0.4125664234161377, -- test: 0.8639307022094727 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -7.446352481842041, -- test: -36.879241943359375 \n",
      "Root Mean Squared Error -- train: 0.42222490906715393, -- test: 0.8791176676750183 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.898494720458984, -- test: -36.638179779052734 \n",
      "Root Mean Squared Error -- train: 0.40890902280807495, -- test: 0.8763436079025269 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -37.11545181274414\n",
      "Test Root MSE of all sampled models: 0.8818273544311523\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 2 \n",
      "Test Log Likelihood of all models in window: -36.28276824951172\n",
      "Test Root MSE of all models in window: 0.8859730958938599\n",
      "\n",
      "############### EM step 2 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -9.145564079284668 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 3 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -7.913277626037598, -- test: -31.85358428955078 \n",
      "Root Mean Squared Error -- train: 0.4352465271949768, -- test: 0.8232733011245728 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -7.500861167907715, -- test: -28.634471893310547 \n",
      "Root Mean Squared Error -- train: 0.4254726469516754, -- test: 0.7823776006698608 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.688107013702393, -- test: -28.959976196289062 \n",
      "Root Mean Squared Error -- train: 0.4055221974849701, -- test: 0.7866094708442688 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.057513236999512, -- test: -30.712657928466797 \n",
      "Root Mean Squared Error -- train: 0.4147088825702667, -- test: 0.8090155720710754 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -7.222174644470215, -- test: -28.05682945251465 \n",
      "Root Mean Squared Error -- train: 0.41873884201049805, -- test: 0.7748108506202698 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.811031341552734, -- test: -28.756263732910156 \n",
      "Root Mean Squared Error -- train: 0.4086020886898041, -- test: 0.7839637398719788 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.7931694984436035, -- test: -28.589006423950195 \n",
      "Root Mean Squared Error -- train: 0.40815600752830505, -- test: 0.7817847728729248 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -7.062929630279541, -- test: -29.378385543823242 \n",
      "Root Mean Squared Error -- train: 0.41484206914901733, -- test: 0.7920159697532654 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -7.398881435394287, -- test: -25.461074829101562 \n",
      "Root Mean Squared Error -- train: 0.42302101850509644, -- test: 0.7398535013198853 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.628195285797119, -- test: -25.089561462402344 \n",
      "Root Mean Squared Error -- train: 0.4040125608444214, -- test: 0.734714150428772 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -28.276386260986328\n",
      "Test Root MSE of all sampled models: 0.7776956558227539\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 3 \n",
      "Test Log Likelihood of all models in window: -24.945161819458008\n",
      "Test Root MSE of all models in window: 0.8514119386672974\n",
      "\n",
      "############### EM step 3 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.0367512702941895 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 4 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -8.908889770507812, -- test: -25.578500747680664 \n",
      "Root Mean Squared Error -- train: 0.4600416123867035, -- test: 0.7449092864990234 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -7.163404941558838, -- test: -22.265178680419922 \n",
      "Root Mean Squared Error -- train: 0.419161319732666, -- test: 0.6976129412651062 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.709666728973389, -- test: -22.637678146362305 \n",
      "Root Mean Squared Error -- train: 0.4078640639781952, -- test: 0.7030889391899109 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.747425556182861, -- test: -22.79409408569336 \n",
      "Root Mean Squared Error -- train: 0.4088160991668701, -- test: 0.7053757309913635 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.563469886779785, -- test: -22.16283416748047 \n",
      "Root Mean Squared Error -- train: 0.40415674448013306, -- test: 0.6961008906364441 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.949069499969482, -- test: -22.608938217163086 \n",
      "Root Mean Squared Error -- train: 0.4138632118701935, -- test: 0.7026680111885071 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.777806758880615, -- test: -20.12987518310547 \n",
      "Root Mean Squared Error -- train: 0.4095804989337921, -- test: 0.6653531193733215 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.986635684967041, -- test: -22.385326385498047 \n",
      "Root Mean Squared Error -- train: 0.4147966504096985, -- test: 0.6993838548660278 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.6777472496032715, -- test: -21.543968200683594 \n",
      "Root Mean Squared Error -- train: 0.4070574939250946, -- test: 0.6868864893913269 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -7.031261920928955, -- test: -20.335268020629883 \n",
      "Root Mean Squared Error -- train: 0.41590285301208496, -- test: 0.6685237884521484 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -21.322895050048828\n",
      "Test Root MSE of all sampled models: 0.6835648417472839\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 4 \n",
      "Test Log Likelihood of all models in window: -19.43158531188965\n",
      "Test Root MSE of all models in window: 0.8127065300941467\n",
      "\n",
      "############### EM step 4 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -9.411840438842773 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 5 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.510078430175781, -- test: -20.94890594482422 \n",
      "Root Mean Squared Error -- train: 0.404619425535202, -- test: 0.6811150908470154 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.535799026489258, -- test: -20.946409225463867 \n",
      "Root Mean Squared Error -- train: 0.4052796959877014, -- test: 0.6810769438743591 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.004284858703613, -- test: -20.89203643798828 \n",
      "Root Mean Squared Error -- train: 0.4171235263347626, -- test: 0.6802465319633484 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.540823459625244, -- test: -20.247146606445312 \n",
      "Root Mean Squared Error -- train: 0.4054085612297058, -- test: 0.6703187823295593 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.626913070678711, -- test: -21.372228622436523 \n",
      "Root Mean Squared Error -- train: 0.40761011838912964, -- test: 0.6875457763671875 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -7.187483310699463, -- test: -21.099376678466797 \n",
      "Root Mean Squared Error -- train: 0.4216645061969757, -- test: 0.6834078431129456 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.527160167694092, -- test: -21.634645462036133 \n",
      "Root Mean Squared Error -- train: 0.4050580561161041, -- test: 0.6915020942687988 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.817381381988525, -- test: -21.907987594604492 \n",
      "Root Mean Squared Error -- train: 0.41243916749954224, -- test: 0.6955992579460144 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.665180683135986, -- test: -19.75625991821289 \n",
      "Root Mean Squared Error -- train: 0.4085848927497864, -- test: 0.6626622080802917 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.747453212738037, -- test: -22.215717315673828 \n",
      "Root Mean Squared Error -- train: 0.4106728732585907, -- test: 0.700183093547821 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -20.783971786499023\n",
      "Test Root MSE of all sampled models: 0.678593099117279\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 5 \n",
      "Test Log Likelihood of all models in window: -18.792997360229492\n",
      "Test Root MSE of all models in window: 0.7877126932144165\n",
      "\n",
      "############### EM step 5 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.490139007568359 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 6 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.620020389556885, -- test: -20.025428771972656 \n",
      "Root Mean Squared Error -- train: 0.40927058458328247, -- test: 0.6700031161308289 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -7.914863109588623, -- test: -19.137290954589844 \n",
      "Root Mean Squared Error -- train: 0.44122928380966187, -- test: 0.6559425592422485 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.091791152954102, -- test: -20.626184463500977 \n",
      "Root Mean Squared Error -- train: 0.42119547724723816, -- test: 0.6793490052223206 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.706662654876709, -- test: -21.278329849243164 \n",
      "Root Mean Squared Error -- train: 0.4362485706806183, -- test: 0.689350962638855 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -7.457688331604004, -- test: -20.62900161743164 \n",
      "Root Mean Squared Error -- train: 0.4302167296409607, -- test: 0.6793925762176514 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.458550453186035, -- test: -20.88530731201172 \n",
      "Root Mean Squared Error -- train: 0.4051084518432617, -- test: 0.6833407282829285 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.490891933441162, -- test: -20.270545959472656 \n",
      "Root Mean Squared Error -- train: 0.4059455096721649, -- test: 0.6738319993019104 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.515707015991211, -- test: -20.138280868530273 \n",
      "Root Mean Squared Error -- train: 0.40658658742904663, -- test: 0.6717687249183655 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.657812118530273, -- test: -20.765607833862305 \n",
      "Root Mean Squared Error -- train: 0.4102385938167572, -- test: 0.681499719619751 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.632471561431885, -- test: -20.575546264648438 \n",
      "Root Mean Squared Error -- train: 0.4095897376537323, -- test: 0.6785662770271301 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -20.712913513183594\n",
      "Test Root MSE of all sampled models: 0.680687665939331\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 6 \n",
      "Test Log Likelihood of all models in window: -18.33359146118164\n",
      "Test Root MSE of all models in window: 0.7709077000617981\n",
      "\n",
      "############### EM step 6 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -7.876805305480957 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 7 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.368989944458008, -- test: -20.322620391845703 \n",
      "Root Mean Squared Error -- train: 0.40461933612823486, -- test: 0.6778585910797119 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.402938365936279, -- test: -20.4321346282959 \n",
      "Root Mean Squared Error -- train: 0.40550756454467773, -- test: 0.6795687079429626 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.710906982421875, -- test: -18.958051681518555 \n",
      "Root Mean Squared Error -- train: 0.41347843408584595, -- test: 0.6561763882637024 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.425021648406982, -- test: -22.288911819458008 \n",
      "Root Mean Squared Error -- train: 0.4060843288898468, -- test: 0.7079348564147949 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.551692008972168, -- test: -21.498979568481445 \n",
      "Root Mean Squared Error -- train: 0.40937700867652893, -- test: 0.6960083842277527 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.755573749542236, -- test: -20.266923904418945 \n",
      "Root Mean Squared Error -- train: 0.4146217703819275, -- test: 0.6769872307777405 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.382728099822998, -- test: -21.601205825805664 \n",
      "Root Mean Squared Error -- train: 0.40497902035713196, -- test: 0.6975632905960083 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.369853496551514, -- test: -20.809858322143555 \n",
      "Root Mean Squared Error -- train: 0.40464192628860474, -- test: 0.6854344010353088 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -7.007498264312744, -- test: -20.6965274810791 \n",
      "Root Mean Squared Error -- train: 0.4210122227668762, -- test: 0.6836797595024109 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -7.682676315307617, -- test: -19.416297912597656 \n",
      "Root Mean Squared Error -- train: 0.4376791715621948, -- test: 0.6635366678237915 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -20.52397918701172\n",
      "Test Root MSE of all sampled models: 0.6809996366500854\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 7 \n",
      "Test Log Likelihood of all models in window: -17.999526977539062\n",
      "Test Root MSE of all models in window: 0.7587162852287292\n",
      "\n",
      "############### EM step 7 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -7.804022789001465 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 8 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -7.433167934417725, -- test: -20.117080688476562 \n",
      "Root Mean Squared Error -- train: 0.43359994888305664, -- test: 0.6778833866119385 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.7638654708862305, -- test: -19.410167694091797 \n",
      "Root Mean Squared Error -- train: 0.4167511761188507, -- test: 0.666628360748291 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.553166389465332, -- test: -20.94139862060547 \n",
      "Root Mean Squared Error -- train: 0.4113043248653412, -- test: 0.6907760500907898 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.361244201660156, -- test: -20.653974533081055 \n",
      "Root Mean Squared Error -- train: 0.4062793254852295, -- test: 0.6863081455230713 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -7.4961042404174805, -- test: -19.245519638061523 \n",
      "Root Mean Squared Error -- train: 0.43515071272850037, -- test: 0.6639795899391174 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.852726936340332, -- test: -20.868810653686523 \n",
      "Root Mean Squared Error -- train: 0.4190271496772766, -- test: 0.6896504163742065 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.52154541015625, -- test: -20.47998809814453 \n",
      "Root Mean Squared Error -- train: 0.4104806184768677, -- test: 0.6835893988609314 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.333808898925781, -- test: -21.155969619750977 \n",
      "Root Mean Squared Error -- train: 0.4055559039115906, -- test: 0.6940927505493164 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.313689708709717, -- test: -20.735761642456055 \n",
      "Root Mean Squared Error -- train: 0.40502458810806274, -- test: 0.6875824332237244 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.311794757843018, -- test: -21.040027618408203 \n",
      "Root Mean Squared Error -- train: 0.40497449040412903, -- test: 0.6923025250434875 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -20.440492630004883\n",
      "Test Root MSE of all sampled models: 0.6829707026481628\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 8 \n",
      "Test Log Likelihood of all models in window: -17.88762855529785\n",
      "Test Root MSE of all models in window: 0.7496667504310608\n",
      "\n",
      "############### EM step 8 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.743050575256348 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 9 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.638289928436279, -- test: -20.29707908630371 \n",
      "Root Mean Squared Error -- train: 0.41538676619529724, -- test: 0.6839334964752197 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.297133445739746, -- test: -20.13661766052246 \n",
      "Root Mean Squared Error -- train: 0.4064141809940338, -- test: 0.6813933253288269 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.272421836853027, -- test: -20.16501808166504 \n",
      "Root Mean Squared Error -- train: 0.40575656294822693, -- test: 0.6818435788154602 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.50528621673584, -- test: -20.08970069885254 \n",
      "Root Mean Squared Error -- train: 0.43736177682876587, -- test: 0.6806487441062927 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.2948126792907715, -- test: -20.392719268798828 \n",
      "Root Mean Squared Error -- train: 0.4063524603843689, -- test: 0.6854430437088013 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.738349437713623, -- test: -19.094860076904297 \n",
      "Root Mean Squared Error -- train: 0.417981892824173, -- test: 0.664665699005127 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -7.605699062347412, -- test: -20.208749771118164 \n",
      "Root Mean Squared Error -- train: 0.43983587622642517, -- test: 0.6825364232063293 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -8.368555068969727, -- test: -19.846166610717773 \n",
      "Root Mean Squared Error -- train: 0.4581962823867798, -- test: 0.6767710447311401 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.428455829620361, -- test: -19.768491744995117 \n",
      "Root Mean Squared Error -- train: 0.409891277551651, -- test: 0.6755295991897583 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.503606796264648, -- test: -19.415552139282227 \n",
      "Root Mean Squared Error -- train: 0.4118679463863373, -- test: 0.6698595881462097 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -20.666902542114258\n",
      "Test Root MSE of all sampled models: 0.6897523403167725\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 9 \n",
      "Test Log Likelihood of all models in window: -17.671354293823242\n",
      "Test Root MSE of all models in window: 0.7432481050491333\n",
      "\n",
      "############### EM step 9 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.911972522735596 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 10 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.356888771057129, -- test: -20.620920181274414 \n",
      "Root Mean Squared Error -- train: 0.4098394215106964, -- test: 0.6922783255577087 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.28628396987915, -- test: -20.240734100341797 \n",
      "Root Mean Squared Error -- train: 0.4079553186893463, -- test: 0.6862598061561584 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -8.063841819763184, -- test: -20.073772430419922 \n",
      "Root Mean Squared Error -- train: 0.45301082730293274, -- test: 0.6836000680923462 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.173719882965088, -- test: -19.937814712524414 \n",
      "Root Mean Squared Error -- train: 0.4049334228038788, -- test: 0.681426465511322 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.7956061363220215, -- test: -20.47942352294922 \n",
      "Root Mean Squared Error -- train: 0.42135775089263916, -- test: 0.6900445222854614 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.158626556396484, -- test: -20.4898681640625 \n",
      "Root Mean Squared Error -- train: 0.4045265316963196, -- test: 0.690209686756134 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.214666366577148, -- test: -20.659988403320312 \n",
      "Root Mean Squared Error -- train: 0.40603527426719666, -- test: 0.6928938031196594 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.563196182250977, -- test: -21.213520050048828 \n",
      "Root Mean Squared Error -- train: 0.41529572010040283, -- test: 0.7015564441680908 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.472837924957275, -- test: -20.720468521118164 \n",
      "Root Mean Squared Error -- train: 0.41291487216949463, -- test: 0.6938455700874329 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.198838233947754, -- test: -19.838659286499023 \n",
      "Root Mean Squared Error -- train: 0.40560972690582275, -- test: 0.6798368096351624 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -19.295909881591797\n",
      "Test Root MSE of all sampled models: 0.6710691452026367\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 10 \n",
      "Test Log Likelihood of all models in window: -17.588172912597656\n",
      "Test Root MSE of all models in window: 0.7363486289978027\n",
      "\n",
      "############### EM step 10 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.418318748474121 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 11 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.113651275634766, -- test: -19.948759078979492 \n",
      "Root Mean Squared Error -- train: 0.40513092279434204, -- test: 0.6848204731941223 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -7.898252964019775, -- test: -19.01078987121582 \n",
      "Root Mean Squared Error -- train: 0.45105838775634766, -- test: 0.6695607900619507 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.8113226890563965, -- test: -19.294782638549805 \n",
      "Root Mean Squared Error -- train: 0.4236789345741272, -- test: 0.6742174625396729 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.135307788848877, -- test: -20.62993621826172 \n",
      "Root Mean Squared Error -- train: 0.40571942925453186, -- test: 0.6956928372383118 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -7.011826038360596, -- test: -19.139244079589844 \n",
      "Root Mean Squared Error -- train: 0.4288610517978668, -- test: 0.6716709733009338 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.969839572906494, -- test: -21.17163848876953 \n",
      "Root Mean Squared Error -- train: 0.4277810752391815, -- test: 0.7042191028594971 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.313232898712158, -- test: -20.229246139526367 \n",
      "Root Mean Squared Error -- train: 0.4105225205421448, -- test: 0.6893181800842285 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.353227138519287, -- test: -19.682605743408203 \n",
      "Root Mean Squared Error -- train: 0.411594420671463, -- test: 0.6805252432823181 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -7.454405307769775, -- test: -19.232830047607422 \n",
      "Root Mean Squared Error -- train: 0.4400838017463684, -- test: 0.6732043027877808 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -7.295699596405029, -- test: -18.376113891601562 \n",
      "Root Mean Squared Error -- train: 0.4360926151275635, -- test: 0.659034788608551 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -19.495826721191406\n",
      "Test Root MSE of all sampled models: 0.6774947643280029\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 11 \n",
      "Test Log Likelihood of all models in window: -17.324565887451172\n",
      "Test Root MSE of all models in window: 0.7311941385269165\n",
      "\n",
      "############### EM step 11 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.665580749511719 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 12 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.814424991607666, -- test: -19.313812255859375 \n",
      "Root Mean Squared Error -- train: 0.4256914258003235, -- test: 0.6777254343032837 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.7859930992126465, -- test: -20.75058364868164 \n",
      "Root Mean Squared Error -- train: 0.4249477982521057, -- test: 0.700912594795227 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.161583423614502, -- test: -19.4763240814209 \n",
      "Root Mean Squared Error -- train: 0.43466898798942566, -- test: 0.6803876757621765 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.996305465698242, -- test: -19.888866424560547 \n",
      "Root Mean Squared Error -- train: 0.4037460684776306, -- test: 0.6870996952056885 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.150655746459961, -- test: -19.789199829101562 \n",
      "Root Mean Squared Error -- train: 0.4079767167568207, -- test: 0.6854842305183411 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.286905288696289, -- test: -20.592636108398438 \n",
      "Root Mean Squared Error -- train: 0.4116751551628113, -- test: 0.6984012126922607 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -7.341663837432861, -- test: -18.10338592529297 \n",
      "Root Mean Squared Error -- train: 0.4392535984516144, -- test: 0.6575567722320557 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.085056304931641, -- test: -19.72027015686035 \n",
      "Root Mean Squared Error -- train: 0.40618404746055603, -- test: 0.6843646168708801 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.12839937210083, -- test: -19.77161407470703 \n",
      "Root Mean Squared Error -- train: 0.4073694050312042, -- test: 0.6851987242698669 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.020941734313965, -- test: -19.608346939086914 \n",
      "Root Mean Squared Error -- train: 0.4044242799282074, -- test: 0.6825428605079651 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -19.151103973388672\n",
      "Test Root MSE of all sampled models: 0.675049364566803\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 12 \n",
      "Test Log Likelihood of all models in window: -17.09268569946289\n",
      "Test Root MSE of all models in window: 0.7266810536384583\n",
      "\n",
      "############### EM step 12 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.4783453941345215 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 13 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.117038726806641, -- test: -18.873443603515625 \n",
      "Root Mean Squared Error -- train: 0.4088903069496155, -- test: 0.6736117005348206 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.952669143676758, -- test: -19.423213958740234 \n",
      "Root Mean Squared Error -- train: 0.4043499231338501, -- test: 0.6827171444892883 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.136877059936523, -- test: -20.046566009521484 \n",
      "Root Mean Squared Error -- train: 0.4094349145889282, -- test: 0.6928967237472534 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.996483325958252, -- test: -19.27639389038086 \n",
      "Root Mean Squared Error -- train: 0.40556517243385315, -- test: 0.6802974343299866 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.258772373199463, -- test: -19.111135482788086 \n",
      "Root Mean Squared Error -- train: 0.4127653241157532, -- test: 0.6775634288787842 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.990835666656494, -- test: -19.23479652404785 \n",
      "Root Mean Squared Error -- train: 0.40540874004364014, -- test: 0.6796103119850159 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.974640369415283, -- test: -18.744264602661133 \n",
      "Root Mean Squared Error -- train: 0.4049597978591919, -- test: 0.6714542508125305 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.976608753204346, -- test: -19.2587833404541 \n",
      "Root Mean Squared Error -- train: 0.40501439571380615, -- test: 0.6800066232681274 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.467588424682617, -- test: -19.58214569091797 \n",
      "Root Mean Squared Error -- train: 0.41840896010398865, -- test: 0.6853269934654236 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.02117919921875, -- test: -18.636337280273438 \n",
      "Root Mean Squared Error -- train: 0.406248539686203, -- test: 0.6696463823318481 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -19.495664596557617\n",
      "Test Root MSE of all sampled models: 0.6839081048965454\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 13 \n",
      "Test Log Likelihood of all models in window: -17.0290584564209\n",
      "Test Root MSE of all models in window: 0.7234806418418884\n",
      "\n",
      "############### EM step 13 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.557291030883789 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 14 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.374993324279785, -- test: -20.441694259643555 \n",
      "Root Mean Squared Error -- train: 0.4177993834018707, -- test: 0.7025817632675171 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.897755146026611, -- test: -19.0594425201416 \n",
      "Root Mean Squared Error -- train: 0.4046374559402466, -- test: 0.6799033284187317 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.897486686706543, -- test: -19.084749221801758 \n",
      "Root Mean Squared Error -- train: 0.4046299457550049, -- test: 0.6803252696990967 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.758699417114258, -- test: -19.17359161376953 \n",
      "Root Mean Squared Error -- train: 0.42808833718299866, -- test: 0.6818047165870667 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.584480285644531, -- test: -18.654937744140625 \n",
      "Root Mean Squared Error -- train: 0.42344769835472107, -- test: 0.6731221079826355 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.90140438079834, -- test: -19.31819725036621 \n",
      "Root Mean Squared Error -- train: 0.40473973751068115, -- test: 0.6842058897018433 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.194000720977783, -- test: -19.287843704223633 \n",
      "Root Mean Squared Error -- train: 0.4128571152687073, -- test: 0.6837025284767151 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.5589599609375, -- test: -19.831954956054688 \n",
      "Root Mean Squared Error -- train: 0.4227636754512787, -- test: 0.6926693916320801 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.329291343688965, -- test: -19.362957000732422 \n",
      "Root Mean Squared Error -- train: 0.4165569543838501, -- test: 0.6849473714828491 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.081418991088867, -- test: -19.543338775634766 \n",
      "Root Mean Squared Error -- train: 0.40975281596183777, -- test: 0.6879276037216187 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -19.871183395385742\n",
      "Test Root MSE of all sampled models: 0.693311333656311\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 14 \n",
      "Test Log Likelihood of all models in window: -17.029010772705078\n",
      "Test Root MSE of all models in window: 0.7213674783706665\n",
      "\n",
      "############### EM step 14 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.23516321182251 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 15 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.99022912979126, -- test: -19.41057586669922 \n",
      "Root Mean Squared Error -- train: 0.409042090177536, -- test: 0.6889480948448181 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.929773330688477, -- test: -19.156892776489258 \n",
      "Root Mean Squared Error -- train: 0.407346248626709, -- test: 0.6847188472747803 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.841396808624268, -- test: -18.685827255249023 \n",
      "Root Mean Squared Error -- train: 0.4048544466495514, -- test: 0.6767955422401428 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.010519981384277, -- test: -20.21359634399414 \n",
      "Root Mean Squared Error -- train: 0.4366700053215027, -- test: 0.7021673917770386 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.868133068084717, -- test: -19.33456802368164 \n",
      "Root Mean Squared Error -- train: 0.4056098759174347, -- test: 0.6876835823059082 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -8.06208324432373, -- test: -19.99827766418457 \n",
      "Root Mean Squared Error -- train: 0.46342435479164124, -- test: 0.6986473798751831 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.019454479217529, -- test: -19.483299255371094 \n",
      "Root Mean Squared Error -- train: 0.40985938906669617, -- test: 0.6901556253433228 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.821631908416748, -- test: -19.172222137451172 \n",
      "Root Mean Squared Error -- train: 0.4042949974536896, -- test: 0.6849750876426697 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.095599174499512, -- test: -17.72075653076172 \n",
      "Root Mean Squared Error -- train: 0.4119811952114105, -- test: 0.6602662801742554 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.399394512176514, -- test: -18.074214935302734 \n",
      "Root Mean Squared Error -- train: 0.42033982276916504, -- test: 0.6663677096366882 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -19.519996643066406\n",
      "Test Root MSE of all sampled models: 0.6907642483711243\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 15 \n",
      "Test Log Likelihood of all models in window: -16.468578338623047\n",
      "Test Root MSE of all models in window: 0.7193678021430969\n",
      "\n",
      "############### EM step 15 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.20987606048584 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 16 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.846626281738281, -- test: -19.44869613647461 \n",
      "Root Mean Squared Error -- train: 0.4067968428134918, -- test: 0.6927874684333801 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.8287458419799805, -- test: -19.101001739501953 \n",
      "Root Mean Squared Error -- train: 0.40628841519355774, -- test: 0.6869614124298096 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.810672760009766, -- test: -18.7631893157959 \n",
      "Root Mean Squared Error -- train: 0.4057738780975342, -- test: 0.6812532544136047 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.787405014038086, -- test: -19.68893814086914 \n",
      "Root Mean Squared Error -- train: 0.4051104784011841, -- test: 0.696784496307373 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.0165886878967285, -- test: -19.37885856628418 \n",
      "Root Mean Squared Error -- train: 0.41159820556640625, -- test: 0.6916211843490601 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.786883354187012, -- test: -18.4217472076416 \n",
      "Root Mean Squared Error -- train: 0.4050956070423126, -- test: 0.6754347681999207 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.7637619972229, -- test: -19.286340713500977 \n",
      "Root Mean Squared Error -- train: 0.40443530678749084, -- test: 0.6900731325149536 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.88293981552124, -- test: -18.920005798339844 \n",
      "Root Mean Squared Error -- train: 0.4078274369239807, -- test: 0.6839089393615723 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.898314952850342, -- test: -18.729276657104492 \n",
      "Root Mean Squared Error -- train: 0.4082629978656769, -- test: 0.6806776523590088 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.79901123046875, -- test: -19.089515686035156 \n",
      "Root Mean Squared Error -- train: 0.405441552400589, -- test: 0.6867681741714478 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -19.425003051757812\n",
      "Test Root MSE of all sampled models: 0.6923920512199402\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 16 \n",
      "Test Log Likelihood of all models in window: -16.437015533447266\n",
      "Test Root MSE of all models in window: 0.7177115678787231\n",
      "\n",
      "############### EM step 16 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.517025470733643 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 17 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.876540184020996, -- test: -19.029869079589844 \n",
      "Root Mean Squared Error -- train: 0.4094645082950592, -- test: 0.6889708042144775 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.717672348022461, -- test: -19.393861770629883 \n",
      "Root Mean Squared Error -- train: 0.40491101145744324, -- test: 0.6951093673706055 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.836862564086914, -- test: -18.809953689575195 \n",
      "Root Mean Squared Error -- train: 0.4083319902420044, -- test: 0.6852355003356934 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.749879837036133, -- test: -19.120996475219727 \n",
      "Root Mean Squared Error -- train: 0.4058382511138916, -- test: 0.6905127167701721 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.792311191558838, -- test: -18.658384323120117 \n",
      "Root Mean Squared Error -- train: 0.40705665946006775, -- test: 0.6826491355895996 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.723198890686035, -- test: -18.096071243286133 \n",
      "Root Mean Squared Error -- train: 0.4050702750682831, -- test: 0.6729668974876404 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.886308193206787, -- test: -18.881919860839844 \n",
      "Root Mean Squared Error -- train: 0.4097428023815155, -- test: 0.686460018157959 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.6582536697387695, -- test: -18.387123107910156 \n",
      "Root Mean Squared Error -- train: 0.4311700463294983, -- test: 0.6779956817626953 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.734266757965088, -- test: -18.515958786010742 \n",
      "Root Mean Squared Error -- train: 0.4053890109062195, -- test: 0.680209755897522 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -6.350898742675781, -- test: -19.34398651123047 \n",
      "Root Mean Squared Error -- train: 0.422768771648407, -- test: 0.694271445274353 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.616561889648438\n",
      "Test Root MSE of all sampled models: 0.6645990610122681\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 17 \n",
      "Test Log Likelihood of all models in window: -15.75727653503418\n",
      "Test Root MSE of all models in window: 0.7146965265274048\n",
      "\n",
      "############### EM step 17 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.650042533874512 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 18 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.25406551361084, -- test: -19.126075744628906 \n",
      "Root Mean Squared Error -- train: 0.4219628572463989, -- test: 0.6938201785087585 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.733180046081543, -- test: -17.61734962463379 \n",
      "Root Mean Squared Error -- train: 0.4351358115673065, -- test: 0.667707085609436 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.63663387298584, -- test: -18.379579544067383 \n",
      "Root Mean Squared Error -- train: 0.40435460209846497, -- test: 0.681024968624115 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.719825267791748, -- test: -18.212244033813477 \n",
      "Root Mean Squared Error -- train: 0.40677157044410706, -- test: 0.6781235933303833 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.704154014587402, -- test: -19.798486709594727 \n",
      "Root Mean Squared Error -- train: 0.4063173532485962, -- test: 0.705146849155426 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.6890668869018555, -- test: -18.609413146972656 \n",
      "Root Mean Squared Error -- train: 0.40587958693504333, -- test: 0.6849898099899292 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.447964191436768, -- test: -19.07426643371582 \n",
      "Root Mean Squared Error -- train: 0.42734289169311523, -- test: 0.692939817905426 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.831876754760742, -- test: -18.92436981201172 \n",
      "Root Mean Squared Error -- train: 0.4100044369697571, -- test: 0.690386176109314 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.760253429412842, -- test: -19.69318199157715 \n",
      "Root Mean Squared Error -- train: 0.40794092416763306, -- test: 0.7033849954605103 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.843266487121582, -- test: -17.872314453125 \n",
      "Root Mean Squared Error -- train: 0.4103316068649292, -- test: 0.6721912622451782 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -19.743614196777344\n",
      "Test Root MSE of all sampled models: 0.7042293548583984\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 18 \n",
      "Test Log Likelihood of all models in window: -15.775439262390137\n",
      "Test Root MSE of all models in window: 0.714119017124176\n",
      "\n",
      "############### EM step 18 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.902019023895264 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 19 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.261713027954102, -- test: -18.453285217285156 \n",
      "Root Mean Squared Error -- train: 0.42406192421913147, -- test: 0.6854798197746277 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.458649158477783, -- test: -18.39531898498535 \n",
      "Root Mean Squared Error -- train: 0.42955079674720764, -- test: 0.6844731569290161 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.669273853302002, -- test: -18.416534423828125 \n",
      "Root Mean Squared Error -- train: 0.40710389614105225, -- test: 0.6848416924476624 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.653250217437744, -- test: -18.343103408813477 \n",
      "Root Mean Squared Error -- train: 0.40663543343544006, -- test: 0.683565080165863 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.607511520385742, -- test: -18.7487735748291 \n",
      "Root Mean Squared Error -- train: 0.405295193195343, -- test: 0.6905885934829712 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.133339881896973, -- test: -17.902835845947266 \n",
      "Root Mean Squared Error -- train: 0.42044541239738464, -- test: 0.6758598685264587 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.146638870239258, -- test: -17.731719970703125 \n",
      "Root Mean Squared Error -- train: 0.42082151770591736, -- test: 0.6728413701057434 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.5974602699279785, -- test: -17.967145919799805 \n",
      "Root Mean Squared Error -- train: 0.40500009059906006, -- test: 0.6769908666610718 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.223898410797119, -- test: -18.595916748046875 \n",
      "Root Mean Squared Error -- train: 0.42299985885620117, -- test: 0.6879505515098572 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.855014801025391, -- test: -18.233253479003906 \n",
      "Root Mean Squared Error -- train: 0.41249558329582214, -- test: 0.6816508173942566 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.498952865600586\n",
      "Test Root MSE of all sampled models: 0.6687135100364685\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 19 \n",
      "Test Log Likelihood of all models in window: -15.58071517944336\n",
      "Test Root MSE of all models in window: 0.7118014693260193\n",
      "\n",
      "############### EM step 19 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.761944770812988 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 20 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.579417705535889, -- test: -18.496030807495117 \n",
      "Root Mean Squared Error -- train: 0.40626147389411926, -- test: 0.6894170045852661 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.78623628616333, -- test: -18.6927547454834 \n",
      "Root Mean Squared Error -- train: 0.4123299717903137, -- test: 0.6928354501724243 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.4178571701049805, -- test: -18.56852912902832 \n",
      "Root Mean Squared Error -- train: 0.43033367395401, -- test: 0.6906787753105164 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.779494285583496, -- test: -18.797943115234375 \n",
      "Root Mean Squared Error -- train: 0.4121335446834564, -- test: 0.6946563720703125 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.530788898468018, -- test: -18.648014068603516 \n",
      "Root Mean Squared Error -- train: 0.40482139587402344, -- test: 0.6920594573020935 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.656181335449219, -- test: -17.76557159423828 \n",
      "Root Mean Squared Error -- train: 0.40852436423301697, -- test: 0.6765727996826172 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.659780979156494, -- test: -18.026718139648438 \n",
      "Root Mean Squared Error -- train: 0.4086301922798157, -- test: 0.6811925172805786 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.429744720458984, -- test: -17.725767135620117 \n",
      "Root Mean Squared Error -- train: 0.4306653141975403, -- test: 0.6758658289909363 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.58945369720459, -- test: -18.070695877075195 \n",
      "Root Mean Squared Error -- train: 0.4065580368041992, -- test: 0.6819674372673035 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.622348785400391, -- test: -18.453105926513672 \n",
      "Root Mean Squared Error -- train: 0.4075286090373993, -- test: 0.6886687874794006 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.903383255004883\n",
      "Test Root MSE of all sampled models: 0.6610912084579468\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 20 \n",
      "Test Log Likelihood of all models in window: -15.472691535949707\n",
      "Test Root MSE of all models in window: 0.7093520760536194\n",
      "\n",
      "############### EM step 20 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.564089298248291 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 21 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.454222202301025, -- test: -17.748960494995117 \n",
      "Root Mean Squared Error -- train: 0.40431880950927734, -- test: 0.6794149875640869 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.4879255294799805, -- test: -18.321596145629883 \n",
      "Root Mean Squared Error -- train: 0.4053281843662262, -- test: 0.6895580887794495 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.801092147827148, -- test: -18.75524139404297 \n",
      "Root Mean Squared Error -- train: 0.41458994150161743, -- test: 0.6971410512924194 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.477578163146973, -- test: -17.807392120361328 \n",
      "Root Mean Squared Error -- train: 0.40501856803894043, -- test: 0.6804568767547607 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.52935791015625, -- test: -18.18117904663086 \n",
      "Root Mean Squared Error -- train: 0.40656566619873047, -- test: 0.6870846748352051 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.740347385406494, -- test: -17.99040985107422 \n",
      "Root Mean Squared Error -- train: 0.41280969977378845, -- test: 0.6837101578712463 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.560706615447998, -- test: -17.991836547851562 \n",
      "Root Mean Squared Error -- train: 0.40749940276145935, -- test: 0.6837354302406311 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.790789604187012, -- test: -18.818994522094727 \n",
      "Root Mean Squared Error -- train: 0.41428855061531067, -- test: 0.6982489228248596 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.486751556396484, -- test: -18.234907150268555 \n",
      "Root Mean Squared Error -- train: 0.4052930772304535, -- test: 0.6880321502685547 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.5539751052856445, -- test: -18.16488265991211 \n",
      "Root Mean Squared Error -- train: 0.40729913115501404, -- test: 0.6867970824241638 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.852672576904297\n",
      "Test Root MSE of all sampled models: 0.681263267993927\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 21 \n",
      "Test Log Likelihood of all models in window: -15.375277519226074\n",
      "Test Root MSE of all models in window: 0.7080397605895996\n",
      "\n",
      "############### EM step 21 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.757552146911621 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 22 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.552496910095215, -- test: -18.819995880126953 \n",
      "Root Mean Squared Error -- train: 0.4090525209903717, -- test: 0.7015089392662048 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.460782527923584, -- test: -17.891761779785156 \n",
      "Root Mean Squared Error -- train: 0.40629884600639343, -- test: 0.6851214170455933 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.429018020629883, -- test: -17.858190536499023 \n",
      "Root Mean Squared Error -- train: 0.4053407907485962, -- test: 0.6845214366912842 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.901986598968506, -- test: -18.238079071044922 \n",
      "Root Mean Squared Error -- train: 0.41937994956970215, -- test: 0.6912809014320374 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.597742557525635, -- test: -18.083520889282227 \n",
      "Root Mean Squared Error -- train: 0.41040414571762085, -- test: 0.6885387897491455 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.5183820724487305, -- test: -17.977354049682617 \n",
      "Root Mean Squared Error -- train: 0.43699997663497925, -- test: 0.6866489052772522 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.463071346282959, -- test: -18.363178253173828 \n",
      "Root Mean Squared Error -- train: 0.40636777877807617, -- test: 0.6934923529624939 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.712093353271484, -- test: -17.82238006591797 \n",
      "Root Mean Squared Error -- train: 0.41380056738853455, -- test: 0.6838807463645935 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.8105597496032715, -- test: -16.18726921081543 \n",
      "Root Mean Squared Error -- train: 0.4451085031032562, -- test: 0.6539610624313354 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.610991954803467, -- test: -18.257007598876953 \n",
      "Root Mean Squared Error -- train: 0.410799115896225, -- test: 0.6916159987449646 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -18.412261962890625\n",
      "Test Root MSE of all sampled models: 0.694358229637146\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 22 \n",
      "Test Log Likelihood of all models in window: -15.393820762634277\n",
      "Test Root MSE of all models in window: 0.7074236273765564\n",
      "\n",
      "############### EM step 22 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.348593235015869 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 23 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.39940071105957, -- test: -16.335336685180664 \n",
      "Root Mean Squared Error -- train: 0.40621891617774963, -- test: 0.6597512364387512 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.387207508087158, -- test: -17.198501586914062 \n",
      "Root Mean Squared Error -- train: 0.40584784746170044, -- test: 0.6757240295410156 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.346558094024658, -- test: -18.082809448242188 \n",
      "Root Mean Squared Error -- train: 0.4046083390712738, -- test: 0.6917056441307068 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.36234188079834, -- test: -17.327611923217773 \n",
      "Root Mean Squared Error -- train: 0.4050900638103485, -- test: 0.6780808568000793 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.8280348777771, -- test: -18.578086853027344 \n",
      "Root Mean Squared Error -- train: 0.4190543591976166, -- test: 0.7004972696304321 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.442054748535156, -- test: -17.87672233581543 \n",
      "Root Mean Squared Error -- train: 0.4075142741203308, -- test: 0.6880143284797668 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -7.029393196105957, -- test: -17.40769386291504 \n",
      "Root Mean Squared Error -- train: 0.4530954658985138, -- test: 0.6795386075973511 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.539013862609863, -- test: -17.814224243164062 \n",
      "Root Mean Squared Error -- train: 0.4104437232017517, -- test: 0.6868910193443298 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.707314491271973, -- test: -18.078125 \n",
      "Root Mean Squared Error -- train: 0.4442251920700073, -- test: 0.6916219592094421 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.431174278259277, -- test: -16.94126319885254 \n",
      "Root Mean Squared Error -- train: 0.4071842432022095, -- test: 0.6710036396980286 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -18.039213180541992\n",
      "Test Root MSE of all sampled models: 0.6909263730049133\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 23 \n",
      "Test Log Likelihood of all models in window: -15.328177452087402\n",
      "Test Root MSE of all models in window: 0.706714391708374\n",
      "\n",
      "############### EM step 23 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.62523889541626 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 24 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.298651695251465, -- test: -17.066082000732422 \n",
      "Root Mean Squared Error -- train: 0.4048864543437958, -- test: 0.6763647794723511 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.524606227874756, -- test: -16.759414672851562 \n",
      "Root Mean Squared Error -- train: 0.44103771448135376, -- test: 0.670685887336731 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.367924690246582, -- test: -17.63359832763672 \n",
      "Root Mean Squared Error -- train: 0.4070148169994354, -- test: 0.6867502331733704 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.338698863983154, -- test: -18.585935592651367 \n",
      "Root Mean Squared Error -- train: 0.406118243932724, -- test: 0.7038336992263794 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.042816638946533, -- test: -16.969900131225586 \n",
      "Root Mean Squared Error -- train: 0.42719563841819763, -- test: 0.6745887994766235 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.463122844696045, -- test: -17.194873809814453 \n",
      "Root Mean Squared Error -- train: 0.40992167592048645, -- test: 0.678735613822937 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.3540849685668945, -- test: -17.285999298095703 \n",
      "Root Mean Squared Error -- train: 0.4065904915332794, -- test: 0.6804081201553345 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.332192420959473, -- test: -17.37078094482422 \n",
      "Root Mean Squared Error -- train: 0.4059183597564697, -- test: 0.68196040391922 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.807458877563477, -- test: -17.843639373779297 \n",
      "Root Mean Squared Error -- train: 0.4202679395675659, -- test: 0.6905543804168701 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.330708026885986, -- test: -17.69672966003418 \n",
      "Root Mean Squared Error -- train: 0.40587276220321655, -- test: 0.6878958344459534 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.598011016845703\n",
      "Test Root MSE of all sampled models: 0.6861035823822021\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 24 \n",
      "Test Log Likelihood of all models in window: -15.285282135009766\n",
      "Test Root MSE of all models in window: 0.7058676481246948\n",
      "\n",
      "############### EM step 24 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.027679443359375 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 25 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.487829208374023, -- test: -16.754915237426758 \n",
      "Root Mean Squared Error -- train: 0.41246238350868225, -- test: 0.6736708879470825 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.541238784790039, -- test: -17.416271209716797 \n",
      "Root Mean Squared Error -- train: 0.41408947110176086, -- test: 0.6859195232391357 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.776425838470459, -- test: -16.894283294677734 \n",
      "Root Mean Squared Error -- train: 0.42117947340011597, -- test: 0.6762705445289612 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.2637505531311035, -- test: -17.288854598999023 \n",
      "Root Mean Squared Error -- train: 0.40556490421295166, -- test: 0.683576762676239 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.2475905418396, -- test: -17.01251220703125 \n",
      "Root Mean Squared Error -- train: 0.4050629138946533, -- test: 0.6784680485725403 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.542165756225586, -- test: -16.714981079101562 \n",
      "Root Mean Squared Error -- train: 0.4434790015220642, -- test: 0.6729242205619812 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.270810127258301, -- test: -17.269777297973633 \n",
      "Root Mean Squared Error -- train: 0.4057839810848236, -- test: 0.6832253336906433 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.231720447540283, -- test: -18.03458023071289 \n",
      "Root Mean Squared Error -- train: 0.4045693576335907, -- test: 0.6971762776374817 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.224215507507324, -- test: -16.874488830566406 \n",
      "Root Mean Squared Error -- train: 0.40433573722839355, -- test: 0.6759019494056702 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.62526798248291, -- test: -16.839500427246094 \n",
      "Root Mean Squared Error -- train: 0.41663646697998047, -- test: 0.6752498745918274 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.88084602355957\n",
      "Test Root MSE of all sampled models: 0.6943944692611694\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 25 \n",
      "Test Log Likelihood of all models in window: -15.261792182922363\n",
      "Test Root MSE of all models in window: 0.7054122686386108\n",
      "\n",
      "############### EM step 25 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.154842376708984 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 26 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.201857566833496, -- test: -17.745468139648438 \n",
      "Root Mean Squared Error -- train: 0.40540218353271484, -- test: 0.6951256394386292 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.33624267578125, -- test: -16.407703399658203 \n",
      "Root Mean Squared Error -- train: 0.4095935821533203, -- test: 0.6702199578285217 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.236231327056885, -- test: -17.506790161132812 \n",
      "Root Mean Squared Error -- train: 0.4064784049987793, -- test: 0.6907479166984558 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.518757343292236, -- test: -18.160276412963867 \n",
      "Root Mean Squared Error -- train: 0.41521838307380676, -- test: 0.7026690244674683 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.237085342407227, -- test: -16.905088424682617 \n",
      "Root Mean Squared Error -- train: 0.40650510787963867, -- test: 0.6795865893363953 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.322565078735352, -- test: -17.372419357299805 \n",
      "Root Mean Squared Error -- train: 0.40916895866394043, -- test: 0.6882711052894592 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.191465377807617, -- test: -17.315025329589844 \n",
      "Root Mean Squared Error -- train: 0.405076265335083, -- test: 0.6872104406356812 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.2876386642456055, -- test: -17.2099609375 \n",
      "Root Mean Squared Error -- train: 0.40808260440826416, -- test: 0.6852646470069885 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.843886375427246, -- test: -18.22460174560547 \n",
      "Root Mean Squared Error -- train: 0.4250538647174835, -- test: 0.7038315534591675 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.4982404708862305, -- test: -17.39739227294922 \n",
      "Root Mean Squared Error -- train: 0.41458985209465027, -- test: 0.6887320280075073 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.50310516357422\n",
      "Test Root MSE of all sampled models: 0.6906800866127014\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 26 \n",
      "Test Log Likelihood of all models in window: -15.277531623840332\n",
      "Test Root MSE of all models in window: 0.7048513293266296\n",
      "\n",
      "############### EM step 26 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.209583282470703 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 27 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.310197353363037, -- test: -17.118572235107422 \n",
      "Root Mean Squared Error -- train: 0.4105420410633087, -- test: 0.6866621375083923 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.335461616516113, -- test: -16.765335083007812 \n",
      "Root Mean Squared Error -- train: 0.4113307297229767, -- test: 0.680030882358551 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.199918270111084, -- test: -16.638463973999023 \n",
      "Root Mean Squared Error -- train: 0.4070815443992615, -- test: 0.6776334047317505 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.237922668457031, -- test: -16.909046173095703 \n",
      "Root Mean Squared Error -- train: 0.4082774221897125, -- test: 0.6827365159988403 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.232853889465332, -- test: -16.358478546142578 \n",
      "Root Mean Squared Error -- train: 0.4081181287765503, -- test: 0.6723120212554932 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.280965805053711, -- test: -16.82044792175293 \n",
      "Root Mean Squared Error -- train: 0.40962761640548706, -- test: 0.6810697317123413 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.008054733276367, -- test: -17.363983154296875 \n",
      "Root Mean Squared Error -- train: 0.43179771304130554, -- test: 0.6912316679954529 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.467902183532715, -- test: -16.43219757080078 \n",
      "Root Mean Squared Error -- train: 0.4154405891895294, -- test: 0.6737172603607178 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.31404972076416, -- test: -16.77172088623047 \n",
      "Root Mean Squared Error -- train: 0.4106624126434326, -- test: 0.6801513433456421 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.183376312255859, -- test: -16.8201847076416 \n",
      "Root Mean Squared Error -- train: 0.4065599739551544, -- test: 0.6810648441314697 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.726655960083008\n",
      "Test Root MSE of all sampled models: 0.6793007850646973\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 27 \n",
      "Test Log Likelihood of all models in window: -15.060672760009766\n",
      "Test Root MSE of all models in window: 0.7039215564727783\n",
      "\n",
      "############### EM step 27 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.754425048828125 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 28 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.120389461517334, -- test: -16.666563034057617 \n",
      "Root Mean Squared Error -- train: 0.40632739663124084, -- test: 0.6812769174575806 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.122627258300781, -- test: -16.597745895385742 \n",
      "Root Mean Squared Error -- train: 0.4063987135887146, -- test: 0.6799675822257996 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.476418972015381, -- test: -17.005661010742188 \n",
      "Root Mean Squared Error -- train: 0.44746169447898865, -- test: 0.6876922249794006 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.2340779304504395, -- test: -16.877174377441406 \n",
      "Root Mean Squared Error -- train: 0.4099345803260803, -- test: 0.6852684617042542 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.223865985870361, -- test: -16.556758880615234 \n",
      "Root Mean Squared Error -- train: 0.40961188077926636, -- test: 0.6791866421699524 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.149438381195068, -- test: -16.85678482055664 \n",
      "Root Mean Squared Error -- train: 0.40725210309028625, -- test: 0.6848831176757812 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.230008602142334, -- test: -17.226160049438477 \n",
      "Root Mean Squared Error -- train: 0.4098060429096222, -- test: 0.6918318867683411 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.358400821685791, -- test: -17.103565216064453 \n",
      "Root Mean Squared Error -- train: 0.4138432443141937, -- test: 0.6895333528518677 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.381504058837891, -- test: -17.645151138305664 \n",
      "Root Mean Squared Error -- train: 0.4145655333995819, -- test: 0.6996304988861084 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.100779056549072, -- test: -16.700984954833984 \n",
      "Root Mean Squared Error -- train: 0.4057019352912903, -- test: 0.6819308996200562 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -18.04187774658203\n",
      "Test Root MSE of all sampled models: 0.706935465335846\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 28 \n",
      "Test Log Likelihood of all models in window: -14.908220291137695\n",
      "Test Root MSE of all models in window: 0.7040294408798218\n",
      "\n",
      "############### EM step 28 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.910324811935425 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 29 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.392127990722656, -- test: -16.428930282592773 \n",
      "Root Mean Squared Error -- train: 0.41667065024375916, -- test: 0.6797848343849182 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.200407981872559, -- test: -17.100811004638672 \n",
      "Root Mean Squared Error -- train: 0.41061297059059143, -- test: 0.6925820112228394 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.101887226104736, -- test: -16.755475997924805 \n",
      "Root Mean Squared Error -- train: 0.40746501088142395, -- test: 0.6860342621803284 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.097506523132324, -- test: -16.156810760498047 \n",
      "Root Mean Squared Error -- train: 0.40732449293136597, -- test: 0.6745327115058899 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.204881191253662, -- test: -16.970962524414062 \n",
      "Root Mean Squared Error -- train: 0.41075533628463745, -- test: 0.6901273131370544 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.057473182678223, -- test: -17.00694465637207 \n",
      "Root Mean Squared Error -- train: 0.40603795647621155, -- test: 0.6908084154129028 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.230506896972656, -- test: -17.27548599243164 \n",
      "Root Mean Squared Error -- train: 0.41156989336013794, -- test: 0.6958704590797424 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.06079626083374, -- test: -16.651687622070312 \n",
      "Root Mean Squared Error -- train: 0.4061448872089386, -- test: 0.6840541362762451 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.165462493896484, -- test: -16.30643081665039 \n",
      "Root Mean Squared Error -- train: 0.4094991683959961, -- test: 0.6774255633354187 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.049157619476318, -- test: -16.738750457763672 \n",
      "Root Mean Squared Error -- train: 0.4057701826095581, -- test: 0.6857155561447144 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.20673370361328\n",
      "Test Root MSE of all sampled models: 0.6945779919624329\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 29 \n",
      "Test Log Likelihood of all models in window: -14.714298248291016\n",
      "Test Root MSE of all models in window: 0.7037056088447571\n",
      "\n",
      "############### EM step 29 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.8495774269104 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 30 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.651160717010498, -- test: -15.871495246887207 \n",
      "Root Mean Squared Error -- train: 0.4265265464782715, -- test: 0.6719636917114258 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.372361183166504, -- test: -15.744996070861816 \n",
      "Root Mean Squared Error -- train: 0.44827452301979065, -- test: 0.6694760322570801 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.9673357009887695, -- test: -16.5931339263916 \n",
      "Root Mean Squared Error -- train: 0.4048280715942383, -- test: 0.685982346534729 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.059539318084717, -- test: -16.417142868041992 \n",
      "Root Mean Squared Error -- train: 0.40782108902931213, -- test: 0.6825900673866272 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.251871109008789, -- test: -16.956785202026367 \n",
      "Root Mean Squared Error -- train: 0.4139948785305023, -- test: 0.6929393410682678 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.991868019104004, -- test: -16.532489776611328 \n",
      "Root Mean Squared Error -- train: 0.4056265354156494, -- test: 0.6848152875900269 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.04210901260376, -- test: -16.423669815063477 \n",
      "Root Mean Squared Error -- train: 0.40725699067115784, -- test: 0.6827161908149719 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.990711688995361, -- test: -17.22665786743164 \n",
      "Root Mean Squared Error -- train: 0.40558892488479614, -- test: 0.6980573534965515 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.969276428222656, -- test: -16.385560989379883 \n",
      "Root Mean Squared Error -- train: 0.4048912823200226, -- test: 0.6819794774055481 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.625687122344971, -- test: -16.937946319580078 \n",
      "Root Mean Squared Error -- train: 0.42573803663253784, -- test: 0.6925806403160095 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.95514488220215\n",
      "Test Root MSE of all sampled models: 0.6929080486297607\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 30 \n",
      "Test Log Likelihood of all models in window: -14.568924903869629\n",
      "Test Root MSE of all models in window: 0.7033483386039734\n",
      "\n",
      "############### EM step 30 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.304076194763184 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 31 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.930377006530762, -- test: -16.361236572265625 \n",
      "Root Mean Squared Error -- train: 0.40532490611076355, -- test: 0.6845490336418152 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.928408145904541, -- test: -16.017845153808594 \n",
      "Root Mean Squared Error -- train: 0.40526023507118225, -- test: 0.6778386831283569 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.414475440979004, -- test: -16.50345802307129 \n",
      "Root Mean Squared Error -- train: 0.4209230840206146, -- test: 0.6873089671134949 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.063621997833252, -- test: -16.341644287109375 \n",
      "Root Mean Squared Error -- train: 0.4096774458885193, -- test: 0.6841679811477661 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.2954511642456055, -- test: -16.437610626220703 \n",
      "Root Mean Squared Error -- train: 0.41714203357696533, -- test: 0.6860324740409851 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.819047451019287, -- test: -17.575525283813477 \n",
      "Root Mean Squared Error -- train: 0.43352851271629333, -- test: 0.7077675461769104 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.898345470428467, -- test: -17.206096649169922 \n",
      "Root Mean Squared Error -- train: 0.43595650792121887, -- test: 0.7007851004600525 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.978286266326904, -- test: -16.272478103637695 \n",
      "Root Mean Squared Error -- train: 0.406895250082016, -- test: 0.6828209161758423 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -6.394773960113525, -- test: -15.883357048034668 \n",
      "Root Mean Squared Error -- train: 0.45085951685905457, -- test: 0.6751925349235535 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.920835494995117, -- test: -16.0953311920166 \n",
      "Root Mean Squared Error -- train: 0.40501144528388977, -- test: 0.6793587803840637 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.9427547454834\n",
      "Test Root MSE of all sampled models: 0.69576495885849\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 31 \n",
      "Test Log Likelihood of all models in window: -14.552392959594727\n",
      "Test Root MSE of all models in window: 0.7031050324440002\n",
      "\n",
      "############### EM step 31 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.031607151031494 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 32 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.886603355407715, -- test: -16.655420303344727 \n",
      "Root Mean Squared Error -- train: 0.40560248494148254, -- test: 0.6933534741401672 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.051863193511963, -- test: -16.302209854125977 \n",
      "Root Mean Squared Error -- train: 0.4110400080680847, -- test: 0.6864753365516663 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.72072696685791, -- test: -15.904123306274414 \n",
      "Root Mean Squared Error -- train: 0.4323495328426361, -- test: 0.6786397695541382 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.149310111999512, -- test: -15.858504295349121 \n",
      "Root Mean Squared Error -- train: 0.41421282291412354, -- test: 0.6777360439300537 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.270909786224365, -- test: -16.887348175048828 \n",
      "Root Mean Squared Error -- train: 0.4181382656097412, -- test: 0.6978330016136169 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.6788225173950195, -- test: -15.425790786743164 \n",
      "Root Mean Squared Error -- train: 0.43104541301727295, -- test: 0.6691033244132996 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.274482727050781, -- test: -16.676036834716797 \n",
      "Root Mean Squared Error -- train: 0.4182530343532562, -- test: 0.6937527656555176 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.967238426208496, -- test: -15.691570281982422 \n",
      "Root Mean Squared Error -- train: 0.4082646667957306, -- test: 0.6744186878204346 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.147853851318359, -- test: -16.178281784057617 \n",
      "Root Mean Squared Error -- train: 0.41416558623313904, -- test: 0.6840456128120422 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.037245273590088, -- test: -16.20025634765625 \n",
      "Root Mean Squared Error -- train: 0.4105619490146637, -- test: 0.6844770908355713 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.815743446350098\n",
      "Test Root MSE of all sampled models: 0.6768878102302551\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 32 \n",
      "Test Log Likelihood of all models in window: -14.471668243408203\n",
      "Test Root MSE of all models in window: 0.7023005485534668\n",
      "\n",
      "############### EM step 32 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.867927312850952 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 33 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.813197135925293, -- test: -15.586004257202148 \n",
      "Root Mean Squared Error -- train: 0.4048430025577545, -- test: 0.6752749681472778 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.807772636413574, -- test: -15.917409896850586 \n",
      "Root Mean Squared Error -- train: 0.4046613276004791, -- test: 0.6818959712982178 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.884274959564209, -- test: -16.060392379760742 \n",
      "Root Mean Squared Error -- train: 0.43924880027770996, -- test: 0.6847327947616577 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.345766544342041, -- test: -16.30082130432129 \n",
      "Root Mean Squared Error -- train: 0.4223010838031769, -- test: 0.6894766688346863 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.66415548324585, -- test: -15.4569673538208 \n",
      "Root Mean Squared Error -- train: 0.43240153789520264, -- test: 0.6726793050765991 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.411118984222412, -- test: -16.942718505859375 \n",
      "Root Mean Squared Error -- train: 0.4243938624858856, -- test: 0.7019848823547363 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.8115668296813965, -- test: -16.53948211669922 \n",
      "Root Mean Squared Error -- train: 0.40478840470314026, -- test: 0.6941536068916321 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.062458515167236, -- test: -16.048677444458008 \n",
      "Root Mean Squared Error -- train: 0.413105845451355, -- test: 0.6845007538795471 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.8262834548950195, -- test: -16.531734466552734 \n",
      "Root Mean Squared Error -- train: 0.40528103709220886, -- test: 0.6940022706985474 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.819267272949219, -- test: -16.227622985839844 \n",
      "Root Mean Squared Error -- train: 0.4050462543964386, -- test: 0.6880358457565308 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.813193321228027\n",
      "Test Root MSE of all sampled models: 0.6595770716667175\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 33 \n",
      "Test Log Likelihood of all models in window: -14.089112281799316\n",
      "Test Root MSE of all models in window: 0.7010441422462463\n",
      "\n",
      "############### EM step 33 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.822561025619507 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 34 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.786369323730469, -- test: -16.517127990722656 \n",
      "Root Mean Squared Error -- train: 0.40557050704956055, -- test: 0.6966786980628967 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.896073818206787, -- test: -15.983787536621094 \n",
      "Root Mean Squared Error -- train: 0.40925323963165283, -- test: 0.6861286759376526 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.796494483947754, -- test: -16.11333656311035 \n",
      "Root Mean Squared Error -- train: 0.4059118330478668, -- test: 0.68870609998703 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.311795234680176, -- test: -16.350828170776367 \n",
      "Root Mean Squared Error -- train: 0.422917902469635, -- test: 0.6934062838554382 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.9431376457214355, -- test: -15.559743881225586 \n",
      "Root Mean Squared Error -- train: 0.4108230471611023, -- test: 0.6776235103607178 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.785452842712402, -- test: -15.616593360900879 \n",
      "Root Mean Squared Error -- train: 0.4055396318435669, -- test: 0.6787698864936829 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.799792766571045, -- test: -15.714142799377441 \n",
      "Root Mean Squared Error -- train: 0.40602293610572815, -- test: 0.6807326078414917 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.2661261558532715, -- test: -14.906607627868652 \n",
      "Root Mean Squared Error -- train: 0.42143842577934265, -- test: 0.6643102765083313 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.783019065856934, -- test: -15.602985382080078 \n",
      "Root Mean Squared Error -- train: 0.4054575562477112, -- test: 0.6784956455230713 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.827861309051514, -- test: -16.756237030029297 \n",
      "Root Mean Squared Error -- train: 0.40696731209754944, -- test: 0.7013568878173828 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.891368865966797\n",
      "Test Root MSE of all sampled models: 0.684283971786499\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 34 \n",
      "Test Log Likelihood of all models in window: -14.034843444824219\n",
      "Test Root MSE of all models in window: 0.7005569338798523\n",
      "\n",
      "############### EM step 34 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -7.143610954284668 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 35 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.732005596160889, -- test: -15.751341819763184 \n",
      "Root Mean Squared Error -- train: 0.4054052531719208, -- test: 0.6844702959060669 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.899453639984131, -- test: -15.843457221984863 \n",
      "Root Mean Squared Error -- train: 0.4110659062862396, -- test: 0.6863250136375427 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.081557273864746, -- test: -15.96157455444336 \n",
      "Root Mean Squared Error -- train: 0.4171348214149475, -- test: 0.688696026802063 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.749415397644043, -- test: -16.00762367248535 \n",
      "Root Mean Squared Error -- train: 0.40599745512008667, -- test: 0.6896181702613831 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.929328441619873, -- test: -15.680480003356934 \n",
      "Root Mean Squared Error -- train: 0.4120676517486572, -- test: 0.6830399632453918 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.68218469619751, -- test: -15.283011436462402 \n",
      "Root Mean Squared Error -- train: 0.4670979976654053, -- test: 0.6749616265296936 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.79014253616333, -- test: -15.749115943908691 \n",
      "Root Mean Squared Error -- train: 0.40737947821617126, -- test: 0.684425413608551 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.094357967376709, -- test: -15.08302116394043 \n",
      "Root Mean Squared Error -- train: 0.41755804419517517, -- test: 0.6708599925041199 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.918531894683838, -- test: -15.82651138305664 \n",
      "Root Mean Squared Error -- train: 0.411705881357193, -- test: 0.6859841346740723 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.779441833496094, -- test: -15.764861106872559 \n",
      "Root Mean Squared Error -- train: 0.4070168435573578, -- test: 0.6847427487373352 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.984832763671875\n",
      "Test Root MSE of all sampled models: 0.6688370704650879\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 35 \n",
      "Test Log Likelihood of all models in window: -13.961247444152832\n",
      "Test Root MSE of all models in window: 0.6996706128120422\n",
      "\n",
      "############### EM step 35 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.76920747756958 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 36 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.674098014831543, -- test: -15.975790023803711 \n",
      "Root Mean Squared Error -- train: 0.4050901532173157, -- test: 0.6919905543327332 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.784055709838867, -- test: -15.255607604980469 \n",
      "Root Mean Squared Error -- train: 0.4088524580001831, -- test: 0.6773432493209839 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.747358798980713, -- test: -15.706125259399414 \n",
      "Root Mean Squared Error -- train: 0.40760067105293274, -- test: 0.6865425705909729 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.018501281738281, -- test: -15.320866584777832 \n",
      "Root Mean Squared Error -- train: 0.4167609214782715, -- test: 0.6786835193634033 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.717022895812988, -- test: -15.3766508102417 \n",
      "Root Mean Squared Error -- train: 0.4065629839897156, -- test: 0.6798270344734192 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.713659286499023, -- test: -15.820815086364746 \n",
      "Root Mean Squared Error -- train: 0.40644773840904236, -- test: 0.6888649463653564 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.657121658325195, -- test: -15.782266616821289 \n",
      "Root Mean Squared Error -- train: 0.4045061469078064, -- test: 0.6880851984024048 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.764194488525391, -- test: -15.570547103881836 \n",
      "Root Mean Squared Error -- train: 0.40817543864250183, -- test: 0.6837871670722961 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.858738899230957, -- test: -15.443315505981445 \n",
      "Root Mean Squared Error -- train: 0.41138824820518494, -- test: 0.6811912059783936 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.859971523284912, -- test: -15.644462585449219 \n",
      "Root Mean Squared Error -- train: 0.4114299714565277, -- test: 0.6852907538414001 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.432992935180664\n",
      "Test Root MSE of all sampled models: 0.7011305689811707\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 36 \n",
      "Test Log Likelihood of all models in window: -13.963993072509766\n",
      "Test Root MSE of all models in window: 0.6997112035751343\n",
      "\n",
      "############### EM step 36 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.477980613708496 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 37 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.6691412925720215, -- test: -15.63162612915039 \n",
      "Root Mean Squared Error -- train: 0.4065725803375244, -- test: 0.6879954934120178 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.747742176055908, -- test: -15.626063346862793 \n",
      "Root Mean Squared Error -- train: 0.4092797040939331, -- test: 0.6878818869590759 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.694638729095459, -- test: -15.208399772644043 \n",
      "Root Mean Squared Error -- train: 0.4074527323246002, -- test: 0.6792977452278137 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.77239990234375, -- test: -15.336511611938477 \n",
      "Root Mean Squared Error -- train: 0.4101252853870392, -- test: 0.681942343711853 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.994749546051025, -- test: -15.608758926391602 \n",
      "Root Mean Squared Error -- train: 0.4176728129386902, -- test: 0.6875283718109131 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.300544738769531, -- test: -16.305641174316406 \n",
      "Root Mean Squared Error -- train: 0.42783546447753906, -- test: 0.7016246318817139 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.856843948364258, -- test: -15.496072769165039 \n",
      "Root Mean Squared Error -- train: 0.4130079448223114, -- test: 0.685221791267395 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.6532182693481445, -- test: -15.403735160827637 \n",
      "Root Mean Squared Error -- train: 0.40602195262908936, -- test: 0.6833258867263794 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.633905410766602, -- test: -15.087594985961914 \n",
      "Root Mean Squared Error -- train: 0.4053531289100647, -- test: 0.6767946481704712 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.663779258728027, -- test: -15.600957870483398 \n",
      "Root Mean Squared Error -- train: 0.40638723969459534, -- test: 0.6873689889907837 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.810830116271973\n",
      "Test Root MSE of all sampled models: 0.6916453838348389\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 37 \n",
      "Test Log Likelihood of all models in window: -13.870262145996094\n",
      "Test Root MSE of all models in window: 0.6994944214820862\n",
      "\n",
      "############### EM step 37 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.8986570835113525 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 38 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.893567085266113, -- test: -15.6660737991333 \n",
      "Root Mean Squared Error -- train: 0.41590026021003723, -- test: 0.6915894150733948 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.659137725830078, -- test: -15.239582061767578 \n",
      "Root Mean Squared Error -- train: 0.40783408284187317, -- test: 0.6827942132949829 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.57611608505249, -- test: -15.472225189208984 \n",
      "Root Mean Squared Error -- train: 0.4049389958381653, -- test: 0.6876057982444763 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.617565631866455, -- test: -15.109588623046875 \n",
      "Root Mean Squared Error -- train: 0.43987858295440674, -- test: 0.6800908446311951 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.000416278839111, -- test: -15.284612655639648 \n",
      "Root Mean Squared Error -- train: 0.41952523589134216, -- test: 0.6837282180786133 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.646157264709473, -- test: -15.608778953552246 \n",
      "Root Mean Squared Error -- train: 0.4073827862739563, -- test: 0.6904143691062927 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.57614803314209, -- test: -15.194239616394043 \n",
      "Root Mean Squared Error -- train: 0.40494009852409363, -- test: 0.6818524599075317 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.600211143493652, -- test: -15.039453506469727 \n",
      "Root Mean Squared Error -- train: 0.4057813286781311, -- test: 0.6786278486251831 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.586551189422607, -- test: -14.911754608154297 \n",
      "Root Mean Squared Error -- train: 0.4053040146827698, -- test: 0.6759559512138367 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.637011528015137, -- test: -15.23741340637207 \n",
      "Root Mean Squared Error -- train: 0.4070645272731781, -- test: 0.6827492117881775 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.12881088256836\n",
      "Test Root MSE of all sampled models: 0.7010071873664856\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 38 \n",
      "Test Log Likelihood of all models in window: -13.880620002746582\n",
      "Test Root MSE of all models in window: 0.6995342969894409\n",
      "\n",
      "############### EM step 38 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -6.544341564178467 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 39 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.850545883178711, -- test: -15.728249549865723 \n",
      "Root Mean Squared Error -- train: 0.41611748933792114, -- test: 0.6958438754081726 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.006725788116455, -- test: -15.200528144836426 \n",
      "Root Mean Squared Error -- train: 0.4214495122432709, -- test: 0.6849150061607361 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.961753845214844, -- test: -15.314623832702637 \n",
      "Root Mean Squared Error -- train: 0.4199211001396179, -- test: 0.6872925758361816 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.62130880355835, -- test: -14.750072479248047 \n",
      "Root Mean Squared Error -- train: 0.4081651568412781, -- test: 0.6754463911056519 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.918699264526367, -- test: -15.208662033081055 \n",
      "Root Mean Squared Error -- train: 0.4184526205062866, -- test: 0.6850847005844116 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.593203067779541, -- test: -15.145626068115234 \n",
      "Root Mean Squared Error -- train: 0.40717950463294983, -- test: 0.6837679743766785 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.24741792678833, -- test: -15.357064247131348 \n",
      "Root Mean Squared Error -- train: 0.42953720688819885, -- test: 0.6881749033927917 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.932890892028809, -- test: -15.30709457397461 \n",
      "Root Mean Squared Error -- train: 0.4189372658729553, -- test: 0.6871359348297119 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.8024582862854, -- test: -14.95398235321045 \n",
      "Root Mean Squared Error -- train: 0.41446200013160706, -- test: 0.6797489523887634 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.790085315704346, -- test: -14.460992813110352 \n",
      "Root Mean Squared Error -- train: 0.4140349328517914, -- test: 0.6692994236946106 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.448785781860352\n",
      "Test Root MSE of all sampled models: 0.6900778412818909\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 39 \n",
      "Test Log Likelihood of all models in window: -13.677315711975098\n",
      "Test Root MSE of all models in window: 0.6992933750152588\n",
      "\n",
      "############### EM step 39 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.472445964813232 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 40 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.55975866317749, -- test: -15.103568077087402 \n",
      "Root Mean Squared Error -- train: 0.40765926241874695, -- test: 0.6858445405960083 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.568306922912598, -- test: -14.783382415771484 \n",
      "Root Mean Squared Error -- train: 0.4079616367816925, -- test: 0.679076611995697 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.4567670822143555, -- test: -14.101651191711426 \n",
      "Root Mean Squared Error -- train: 0.438252717256546, -- test: 0.6644371151924133 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.665639877319336, -- test: -14.854988098144531 \n",
      "Root Mean Squared Error -- train: 0.41138890385627747, -- test: 0.6805960536003113 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.822509288787842, -- test: -14.246679306030273 \n",
      "Root Mean Squared Error -- train: 0.41685327887535095, -- test: 0.6675783395767212 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -5.266396522521973, -- test: -14.883888244628906 \n",
      "Root Mean Squared Error -- train: 0.43194109201431274, -- test: 0.6812083125114441 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.542137145996094, -- test: -14.818146705627441 \n",
      "Root Mean Squared Error -- train: 0.407035231590271, -- test: 0.6798146367073059 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.060948371887207, -- test: -15.957503318786621 \n",
      "Root Mean Squared Error -- train: 0.4250244200229645, -- test: 0.7035760879516602 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.150550365447998, -- test: -14.58167839050293 \n",
      "Root Mean Squared Error -- train: 0.42805472016334534, -- test: 0.6747783422470093 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.670795917510986, -- test: -14.890877723693848 \n",
      "Root Mean Squared Error -- train: 0.41156965494155884, -- test: 0.6813563108444214 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.06173324584961\n",
      "Test Root MSE of all sampled models: 0.6849639415740967\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 40 \n",
      "Test Log Likelihood of all models in window: -13.670099258422852\n",
      "Test Root MSE of all models in window: 0.6989387273788452\n",
      "\n",
      "############### EM step 40 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.920116424560547 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 41 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.895758628845215, -- test: -15.895672798156738 \n",
      "Root Mean Squared Error -- train: 0.42107319831848145, -- test: 0.7053055167198181 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.6030168533325195, -- test: -14.961509704589844 \n",
      "Root Mean Squared Error -- train: 0.4108313322067261, -- test: 0.6857601404190063 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.561246395111084, -- test: -14.3052978515625 \n",
      "Root Mean Squared Error -- train: 0.4093490540981293, -- test: 0.6716902852058411 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.712963104248047, -- test: -15.611351013183594 \n",
      "Root Mean Squared Error -- train: 0.41470757126808167, -- test: 0.6994144916534424 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.513595104217529, -- test: -15.032912254333496 \n",
      "Root Mean Squared Error -- train: 0.40765151381492615, -- test: 0.6872736811637878 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.7993083000183105, -- test: -14.945178985595703 \n",
      "Root Mean Squared Error -- train: 0.4177265465259552, -- test: 0.6854134798049927 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.8039703369140625, -- test: -13.840559005737305 \n",
      "Root Mean Squared Error -- train: 0.41788890957832336, -- test: 0.6615448594093323 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.505373477935791, -- test: -14.742964744567871 \n",
      "Root Mean Squared Error -- train: 0.40735793113708496, -- test: 0.6811065673828125 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.503849029541016, -- test: -15.906466484069824 \n",
      "Root Mean Squared Error -- train: 0.40730348229408264, -- test: 0.7055281400680542 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.598958969116211, -- test: -14.812474250793457 \n",
      "Root Mean Squared Error -- train: 0.44471263885498047, -- test: 0.6825900673866272 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.506552696228027\n",
      "Test Root MSE of all sampled models: 0.6972305178642273\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 41 \n",
      "Test Log Likelihood of all models in window: -13.200611114501953\n",
      "Test Root MSE of all models in window: 0.698897123336792\n",
      "\n",
      "############### EM step 41 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.451197624206543 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 42 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.712032318115234, -- test: -14.040212631225586 \n",
      "Root Mean Squared Error -- train: 0.4163338840007782, -- test: 0.6687377095222473 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.804409980773926, -- test: -14.928985595703125 \n",
      "Root Mean Squared Error -- train: 0.41957855224609375, -- test: 0.6879713535308838 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.4494309425354, -- test: -14.611189842224121 \n",
      "Root Mean Squared Error -- train: 0.40696921944618225, -- test: 0.6811564564704895 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.820228099822998, -- test: -14.989136695861816 \n",
      "Root Mean Squared Error -- train: 0.4201316237449646, -- test: 0.6892536282539368 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.621580600738525, -- test: -14.757872581481934 \n",
      "Root Mean Squared Error -- train: 0.41313230991363525, -- test: 0.6843103766441345 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.451725959777832, -- test: -14.309914588928223 \n",
      "Root Mean Squared Error -- train: 0.40705201029777527, -- test: 0.67463219165802 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.517151355743408, -- test: -14.878702163696289 \n",
      "Root Mean Squared Error -- train: 0.4094047248363495, -- test: 0.6868975758552551 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.550888538360596, -- test: -14.225123405456543 \n",
      "Root Mean Squared Error -- train: 0.41061267256736755, -- test: 0.6727845668792725 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.493176460266113, -- test: -14.601092338562012 \n",
      "Root Mean Squared Error -- train: 0.40854412317276, -- test: 0.6809388399124146 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.620645046234131, -- test: -14.849212646484375 \n",
      "Root Mean Squared Error -- train: 0.4130990207195282, -- test: 0.686267077922821 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.278936386108398\n",
      "Test Root MSE of all sampled models: 0.6739577054977417\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 42 \n",
      "Test Log Likelihood of all models in window: -13.105635643005371\n",
      "Test Root MSE of all models in window: 0.6983137130737305\n",
      "\n",
      "############### EM step 42 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.246170997619629 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 43 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.981856822967529, -- test: -13.069930076599121 \n",
      "Root Mean Squared Error -- train: 0.42746278643608093, -- test: 0.6498346924781799 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.550473690032959, -- test: -14.704495429992676 \n",
      "Root Mean Squared Error -- train: 0.4122466444969177, -- test: 0.6860752701759338 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.752678871154785, -- test: -14.484149932861328 \n",
      "Root Mean Squared Error -- train: 0.41944774985313416, -- test: 0.6813023090362549 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.4627251625061035, -- test: -14.698081970214844 \n",
      "Root Mean Squared Error -- train: 0.40908223390579224, -- test: 0.6859368085861206 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -5.470137596130371, -- test: -16.32146453857422 \n",
      "Root Mean Squared Error -- train: 0.4440571963787079, -- test: 0.7201335430145264 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.67549467086792, -- test: -17.737537384033203 \n",
      "Root Mean Squared Error -- train: 0.416713684797287, -- test: 0.7486889362335205 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.635180950164795, -- test: -17.402990341186523 \n",
      "Root Mean Squared Error -- train: 0.41527849435806274, -- test: 0.742041826248169 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.39596700668335, -- test: -18.45730209350586 \n",
      "Root Mean Squared Error -- train: 0.40665826201438904, -- test: 0.7627933621406555 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.655238628387451, -- test: -19.411026000976562 \n",
      "Root Mean Squared Error -- train: 0.41599318385124207, -- test: 0.781090259552002 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.493242263793945, -- test: -19.36257553100586 \n",
      "Root Mean Squared Error -- train: 0.4101855158805847, -- test: 0.7801711559295654 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.96809196472168\n",
      "Test Root MSE of all sampled models: 0.7532355785369873\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 43 \n",
      "Test Log Likelihood of all models in window: -12.973710060119629\n",
      "Test Root MSE of all models in window: 0.6996399164199829\n",
      "\n",
      "############### EM step 43 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.786666393280029 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 44 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.437777996063232, -- test: -18.495267868041992 \n",
      "Root Mean Squared Error -- train: 0.4098359942436218, -- test: 0.7668480277061462 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.751181602478027, -- test: -18.084362030029297 \n",
      "Root Mean Squared Error -- train: 0.42110711336135864, -- test: 0.7587993741035461 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.618642807006836, -- test: -19.09929847717285 \n",
      "Root Mean Squared Error -- train: 0.4163777530193329, -- test: 0.7785284519195557 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.0290398597717285, -- test: -17.675390243530273 \n",
      "Root Mean Squared Error -- train: 0.43085339665412903, -- test: 0.7507029175758362 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.5312910079956055, -- test: -19.339431762695312 \n",
      "Root Mean Squared Error -- train: 0.41323122382164, -- test: 0.7831236720085144 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.671926498413086, -- test: -17.60289764404297 \n",
      "Root Mean Squared Error -- train: 0.4182855188846588, -- test: 0.7492586374282837 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.377277851104736, -- test: -18.009197235107422 \n",
      "Root Mean Squared Error -- train: 0.4076242744922638, -- test: 0.7573177814483643 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.732634544372559, -- test: -19.292173385620117 \n",
      "Root Mean Squared Error -- train: 0.42044851183891296, -- test: 0.7822214365005493 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.371016979217529, -- test: -17.95330810546875 \n",
      "Root Mean Squared Error -- train: 0.40739473700523376, -- test: 0.7562142610549927 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.498071670532227, -- test: -17.998977661132812 \n",
      "Root Mean Squared Error -- train: 0.41202834248542786, -- test: 0.7571160793304443 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -18.748136520385742\n",
      "Test Root MSE of all sampled models: 0.7717593908309937\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 44 \n",
      "Test Log Likelihood of all models in window: -12.929792404174805\n",
      "Test Root MSE of all models in window: 0.701361358165741\n",
      "\n",
      "############### EM step 44 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.874211072921753 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 45 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.413149356842041, -- test: -18.61115264892578 \n",
      "Root Mean Squared Error -- train: 0.4105455279350281, -- test: 0.772341251373291 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.5704779624938965, -- test: -17.6895694732666 \n",
      "Root Mean Squared Error -- train: 0.4162810444831848, -- test: 0.7541433572769165 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.9076104164123535, -- test: -17.26072883605957 \n",
      "Root Mean Squared Error -- train: 0.42831286787986755, -- test: 0.7455238699913025 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.936445713043213, -- test: -17.568662643432617 \n",
      "Root Mean Squared Error -- train: 0.4293263256549835, -- test: 0.7517231106758118 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.459752559661865, -- test: -18.95484733581543 \n",
      "Root Mean Squared Error -- train: 0.412252813577652, -- test: 0.7790191173553467 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.349630832672119, -- test: -18.92285919189453 \n",
      "Root Mean Squared Error -- train: 0.40820708870887756, -- test: 0.7784000039100647 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.514460563659668, -- test: -18.124156951904297 \n",
      "Root Mean Squared Error -- train: 0.4142480194568634, -- test: 0.7627789378166199 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.575742721557617, -- test: -17.521753311157227 \n",
      "Root Mean Squared Error -- train: 0.48346003890037537, -- test: 0.7507820725440979 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.35758638381958, -- test: -18.841760635375977 \n",
      "Root Mean Squared Error -- train: 0.40850070118904114, -- test: 0.7768281698226929 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.370186805725098, -- test: -18.905349731445312 \n",
      "Root Mean Squared Error -- train: 0.4089653193950653, -- test: 0.7780609130859375 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.134531021118164\n",
      "Test Root MSE of all sampled models: 0.7429683208465576\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 45 \n",
      "Test Log Likelihood of all models in window: -12.658019065856934\n",
      "Test Root MSE of all models in window: 0.7023127675056458\n",
      "\n",
      "############### EM step 45 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.896702766418457 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 46 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.462154865264893, -- test: -18.3126220703125 \n",
      "Root Mean Squared Error -- train: 0.41396859288215637, -- test: 0.769729495048523 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.543056964874268, -- test: -18.7962703704834 \n",
      "Root Mean Squared Error -- train: 0.45192262530326843, -- test: 0.7792229652404785 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.51727294921875, -- test: -18.310976028442383 \n",
      "Root Mean Squared Error -- train: 0.4159877598285675, -- test: 0.7696970105171204 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.366042613983154, -- test: -18.341218948364258 \n",
      "Root Mean Squared Error -- train: 0.4104238450527191, -- test: 0.7702940702438354 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.325464725494385, -- test: -18.27246856689453 \n",
      "Root Mean Squared Error -- train: 0.4089181125164032, -- test: 0.7689360976219177 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.456971645355225, -- test: -18.12051010131836 \n",
      "Root Mean Squared Error -- train: 0.413778156042099, -- test: 0.7659258842468262 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.279909610748291, -- test: -18.752758026123047 \n",
      "Root Mean Squared Error -- train: 0.4072209894657135, -- test: 0.778373658657074 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.499734878540039, -- test: -17.918167114257812 \n",
      "Root Mean Squared Error -- train: 0.41534632444381714, -- test: 0.7618991732597351 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.094257831573486, -- test: -19.12761688232422 \n",
      "Root Mean Squared Error -- train: 0.43656453490257263, -- test: 0.7856607437133789 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.48342752456665, -- test: -18.134611129760742 \n",
      "Root Mean Squared Error -- train: 0.41474902629852295, -- test: 0.7662057280540466 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.624631881713867\n",
      "Test Root MSE of all sampled models: 0.7356367111206055\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 46 \n",
      "Test Log Likelihood of all models in window: -12.589851379394531\n",
      "Test Root MSE of all models in window: 0.7030539512634277\n",
      "\n",
      "############### EM step 46 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.100142478942871 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 47 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.318358421325684, -- test: -17.899606704711914 \n",
      "Root Mean Squared Error -- train: 0.4102477729320526, -- test: 0.7647115588188171 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.4725341796875, -- test: -17.793825149536133 \n",
      "Root Mean Squared Error -- train: 0.41597017645835876, -- test: 0.7625876069068909 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.325972557067871, -- test: -17.774385452270508 \n",
      "Root Mean Squared Error -- train: 0.41053226590156555, -- test: 0.7621966004371643 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.623483657836914, -- test: -18.904315948486328 \n",
      "Root Mean Squared Error -- train: 0.42149752378463745, -- test: 0.7845979928970337 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.699857711791992, -- test: -18.172496795654297 \n",
      "Root Mean Squared Error -- train: 0.4242667257785797, -- test: 0.7701637148857117 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.4084272384643555, -- test: -19.473989486694336 \n",
      "Root Mean Squared Error -- train: 0.4136003851890564, -- test: 0.7956528663635254 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.585710525512695, -- test: -18.227794647216797 \n",
      "Root Mean Squared Error -- train: 0.4201212227344513, -- test: 0.771263837814331 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.7882280349731445, -- test: -18.957433700561523 \n",
      "Root Mean Squared Error -- train: 0.42744845151901245, -- test: 0.7856352925300598 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.568324089050293, -- test: -18.786640167236328 \n",
      "Root Mean Squared Error -- train: 0.4194861650466919, -- test: 0.7822949290275574 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.238632678985596, -- test: -17.782428741455078 \n",
      "Root Mean Squared Error -- train: 0.4072571396827698, -- test: 0.7623584270477295 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.842723846435547\n",
      "Test Root MSE of all sampled models: 0.7635701894760132\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 47 \n",
      "Test Log Likelihood of all models in window: -12.57615852355957\n",
      "Test Root MSE of all models in window: 0.7043957114219666\n",
      "\n",
      "############### EM step 47 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.43240213394165 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 48 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.448022842407227, -- test: -18.749248504638672 \n",
      "Root Mean Squared Error -- train: 0.4166831970214844, -- test: 0.7848216891288757 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.270288467407227, -- test: -18.034099578857422 \n",
      "Root Mean Squared Error -- train: 0.4100338816642761, -- test: 0.7706012725830078 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.244503021240234, -- test: -18.52188491821289 \n",
      "Root Mean Squared Error -- train: 0.4090602397918701, -- test: 0.7803287506103516 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.22291898727417, -- test: -17.953126907348633 \n",
      "Root Mean Squared Error -- train: 0.40824344754219055, -- test: 0.7689746022224426 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.692358493804932, -- test: -17.875829696655273 \n",
      "Root Mean Squared Error -- train: 0.42565470933914185, -- test: 0.7674185633659363 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.241398811340332, -- test: -20.013240814208984 \n",
      "Root Mean Squared Error -- train: 0.408942848443985, -- test: 0.8093447089195251 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.919550895690918, -- test: -19.627946853637695 \n",
      "Root Mean Squared Error -- train: 0.43383026123046875, -- test: 0.8019489645957947 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.708155155181885, -- test: -18.850662231445312 \n",
      "Root Mean Squared Error -- train: 0.42622819542884827, -- test: 0.7868174314498901 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.262290000915527, -- test: -18.02627944946289 \n",
      "Root Mean Squared Error -- train: 0.4097321033477783, -- test: 0.770444393157959 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.367216110229492, -- test: -18.903663635253906 \n",
      "Root Mean Squared Error -- train: 0.4136733412742615, -- test: 0.7878584861755371 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -19.390535354614258\n",
      "Test Root MSE of all sampled models: 0.7973576784133911\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 48 \n",
      "Test Log Likelihood of all models in window: -12.288860321044922\n",
      "Test Root MSE of all models in window: 0.7064571976661682\n",
      "\n",
      "############### EM step 48 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.990852117538452 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 49 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.561912536621094, -- test: -18.522857666015625 \n",
      "Root Mean Squared Error -- train: 0.4225160777568817, -- test: 0.7835702896118164 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.796717643737793, -- test: -17.169641494750977 \n",
      "Root Mean Squared Error -- train: 0.43109598755836487, -- test: 0.7561570405960083 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.163848400115967, -- test: -17.772008895874023 \n",
      "Root Mean Squared Error -- train: 0.4075581133365631, -- test: 0.7684804797172546 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.882455825805664, -- test: -17.31123161315918 \n",
      "Root Mean Squared Error -- train: 0.4341866672039032, -- test: 0.7590717673301697 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.38573694229126, -- test: -19.539752960205078 \n",
      "Root Mean Squared Error -- train: 0.4159623384475708, -- test: 0.8035551905632019 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.153357982635498, -- test: -17.634130477905273 \n",
      "Root Mean Squared Error -- train: 0.4071565270423889, -- test: 0.765677273273468 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.255478382110596, -- test: -17.60974884033203 \n",
      "Root Mean Squared Error -- train: 0.4110495150089264, -- test: 0.7651805281639099 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.201645374298096, -- test: -18.05168914794922 \n",
      "Root Mean Squared Error -- train: 0.4090019166469574, -- test: 0.7741356492042542 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.844997882843018, -- test: -18.07010269165039 \n",
      "Root Mean Squared Error -- train: 0.46748387813568115, -- test: 0.7745065093040466 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.209976673126221, -- test: -18.641817092895508 \n",
      "Root Mean Squared Error -- train: 0.4093194901943207, -- test: 0.7859343886375427 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.40526008605957\n",
      "Test Root MSE of all sampled models: 0.7402238249778748\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 49 \n",
      "Test Log Likelihood of all models in window: -12.226388931274414\n",
      "Test Root MSE of all models in window: 0.7071623802185059\n",
      "\n",
      "############### EM step 49 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.789170026779175 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 50 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.5141730308532715, -- test: -17.699871063232422 \n",
      "Root Mean Squared Error -- train: 0.4223560392856598, -- test: 0.7701406478881836 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.343042373657227, -- test: -18.523235321044922 \n",
      "Root Mean Squared Error -- train: 0.45216718316078186, -- test: 0.7867743968963623 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.279893398284912, -- test: -17.5526065826416 \n",
      "Root Mean Squared Error -- train: 0.4499655067920685, -- test: 0.7671275734901428 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.129796981811523, -- test: -17.15054702758789 \n",
      "Root Mean Squared Error -- train: 0.4077925384044647, -- test: 0.7588402628898621 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.190770149230957, -- test: -18.069948196411133 \n",
      "Root Mean Squared Error -- train: 0.41013723611831665, -- test: 0.7776609659194946 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.14194393157959, -- test: -17.223159790039062 \n",
      "Root Mean Squared Error -- train: 0.4082607328891754, -- test: 0.7603436708450317 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.339800834655762, -- test: -17.569679260253906 \n",
      "Root Mean Squared Error -- train: 0.41581252217292786, -- test: 0.7674774527549744 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.659121990203857, -- test: -18.826248168945312 \n",
      "Root Mean Squared Error -- train: 0.42771920561790466, -- test: 0.7928081154823303 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -8.976401329040527, -- test: -15.700691223144531 \n",
      "Root Mean Squared Error -- train: 0.5645669102668762, -- test: 0.7281731367111206 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.100569248199463, -- test: -17.685644149780273 \n",
      "Root Mean Squared Error -- train: 0.40666383504867554, -- test: 0.7698500752449036 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.121707916259766\n",
      "Test Root MSE of all sampled models: 0.7372097969055176\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 50 \n",
      "Test Log Likelihood of all models in window: -12.188244819641113\n",
      "Test Root MSE of all models in window: 0.707775890827179\n",
      "\n",
      "############### EM step 50 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.522202014923096 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 51 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.283814907073975, -- test: -17.77596092224121 \n",
      "Root Mean Squared Error -- train: 0.41526418924331665, -- test: 0.7748423218727112 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.071573257446289, -- test: -18.158769607543945 \n",
      "Root Mean Squared Error -- train: 0.4070781171321869, -- test: 0.7826380729675293 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.34329891204834, -- test: -17.063146591186523 \n",
      "Root Mean Squared Error -- train: 0.4175297021865845, -- test: 0.7601131200790405 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.124426364898682, -- test: -17.677330017089844 \n",
      "Root Mean Squared Error -- train: 0.4091319441795349, -- test: 0.7728210687637329 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.106537342071533, -- test: -17.782495498657227 \n",
      "Root Mean Squared Error -- train: 0.40843793749809265, -- test: 0.7749760746955872 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.784180641174316, -- test: -17.170944213867188 \n",
      "Root Mean Squared Error -- train: 0.4339523911476135, -- test: 0.7623588442802429 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.4713568687438965, -- test: -17.5798282623291 \n",
      "Root Mean Squared Error -- train: 0.42236560583114624, -- test: 0.7708176374435425 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.122807502746582, -- test: -18.568361282348633 \n",
      "Root Mean Squared Error -- train: 0.4090692102909088, -- test: 0.790894091129303 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.11908483505249, -- test: -17.813875198364258 \n",
      "Root Mean Squared Error -- train: 0.4089248776435852, -- test: 0.7756179571151733 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.096058368682861, -- test: -17.52957534790039 \n",
      "Root Mean Squared Error -- train: 0.4080308973789215, -- test: 0.7697830200195312 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.885866165161133\n",
      "Test Root MSE of all sampled models: 0.7564054131507874\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 51 \n",
      "Test Log Likelihood of all models in window: -12.103250503540039\n",
      "Test Root MSE of all models in window: 0.70876145362854\n",
      "\n",
      "############### EM step 51 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.323044776916504 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 52 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.154624938964844, -- test: -16.82124900817871 \n",
      "Root Mean Squared Error -- train: 0.4118812382221222, -- test: 0.7581714391708374 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.050479412078857, -- test: -16.839309692382812 \n",
      "Root Mean Squared Error -- train: 0.4078170657157898, -- test: 0.7585523128509521 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.341705322265625, -- test: -17.280454635620117 \n",
      "Root Mean Squared Error -- train: 0.4190828204154968, -- test: 0.7677973508834839 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.357278347015381, -- test: -17.476093292236328 \n",
      "Root Mean Squared Error -- train: 0.4196767807006836, -- test: 0.7718619704246521 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.0316386222839355, -- test: -17.799484252929688 \n",
      "Root Mean Squared Error -- train: 0.40707746148109436, -- test: 0.7785342335700989 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.154125690460205, -- test: -17.075223922729492 \n",
      "Root Mean Squared Error -- train: 0.4118618369102478, -- test: 0.7635102868080139 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.080000877380371, -- test: -17.875993728637695 \n",
      "Root Mean Squared Error -- train: 0.40897318720817566, -- test: 0.7801043391227722 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.421759128570557, -- test: -17.558013916015625 \n",
      "Root Mean Squared Error -- train: 0.42212697863578796, -- test: 0.7735576033592224 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.148550033569336, -- test: -17.994436264038086 \n",
      "Root Mean Squared Error -- train: 0.4116452634334564, -- test: 0.7825289368629456 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.0934648513793945, -- test: -16.942380905151367 \n",
      "Root Mean Squared Error -- train: 0.4094993770122528, -- test: 0.7607223987579346 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.549440383911133\n",
      "Test Root MSE of all sampled models: 0.7733802795410156\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 52 \n",
      "Test Log Likelihood of all models in window: -12.011175155639648\n",
      "Test Root MSE of all models in window: 0.7100595831871033\n",
      "\n",
      "############### EM step 52 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.409695863723755 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 53 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.090924263000488, -- test: -16.898557662963867 \n",
      "Root Mean Squared Error -- train: 0.410945862531662, -- test: 0.7628843784332275 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.011582851409912, -- test: -17.888174057006836 \n",
      "Root Mean Squared Error -- train: 0.4078201651573181, -- test: 0.7835261821746826 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.1407647132873535, -- test: -16.908998489379883 \n",
      "Root Mean Squared Error -- train: 0.4128972589969635, -- test: 0.7631051540374756 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -5.102846145629883, -- test: -16.712890625 \n",
      "Root Mean Squared Error -- train: 0.44890591502189636, -- test: 0.7589492797851562 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.652589321136475, -- test: -18.1202335357666 \n",
      "Root Mean Squared Error -- train: 0.43242722749710083, -- test: 0.7882882952690125 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.017581462860107, -- test: -16.830650329589844 \n",
      "Root Mean Squared Error -- train: 0.4080573320388794, -- test: 0.7614474892616272 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.107245922088623, -- test: -17.375286102294922 \n",
      "Root Mean Squared Error -- train: 0.4115859270095825, -- test: 0.7728970646858215 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.091677188873291, -- test: -17.098411560058594 \n",
      "Root Mean Squared Error -- train: 0.4109753966331482, -- test: 0.7670978307723999 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.040297031402588, -- test: -17.104164123535156 \n",
      "Root Mean Squared Error -- train: 0.4089541435241699, -- test: 0.7672187685966492 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.0988335609436035, -- test: -16.57406997680664 \n",
      "Root Mean Squared Error -- train: 0.4112561345100403, -- test: 0.7559935450553894 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.390146255493164\n",
      "Test Root MSE of all sampled models: 0.7732070684432983\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 53 \n",
      "Test Log Likelihood of all models in window: -12.011059761047363\n",
      "Test Root MSE of all models in window: 0.7113029360771179\n",
      "\n",
      "############### EM step 53 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.616853713989258 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 54 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.087924480438232, -- test: -17.151451110839844 \n",
      "Root Mean Squared Error -- train: 0.41238483786582947, -- test: 0.7713432908058167 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.993600368499756, -- test: -17.277603149414062 \n",
      "Root Mean Squared Error -- train: 0.4086480736732483, -- test: 0.773998498916626 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.849801540374756, -- test: -17.012605667114258 \n",
      "Root Mean Squared Error -- train: 0.44140949845314026, -- test: 0.7684102058410645 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.290187835693359, -- test: -18.107250213623047 \n",
      "Root Mean Squared Error -- train: 0.42028576135635376, -- test: 0.7912390232086182 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.281031131744385, -- test: -16.460895538330078 \n",
      "Root Mean Squared Error -- train: 0.4199313521385193, -- test: 0.7566433548927307 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.298588752746582, -- test: -17.28280258178711 \n",
      "Root Mean Squared Error -- train: 0.4206107556819916, -- test: 0.7741076946258545 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.016933917999268, -- test: -17.66646957397461 \n",
      "Root Mean Squared Error -- train: 0.4095756411552429, -- test: 0.7821266651153564 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.9897894859313965, -- test: -16.56378173828125 \n",
      "Root Mean Squared Error -- train: 0.4084964096546173, -- test: 0.7588515877723694 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.034690856933594, -- test: -17.88023567199707 \n",
      "Root Mean Squared Error -- train: 0.41028010845184326, -- test: 0.7865590453147888 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.097961902618408, -- test: -16.43378448486328 \n",
      "Root Mean Squared Error -- train: 0.4127805233001709, -- test: 0.7560604214668274 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.904151916503906\n",
      "Test Root MSE of all sampled models: 0.7870534062385559\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 54 \n",
      "Test Log Likelihood of all models in window: -12.008927345275879\n",
      "Test Root MSE of all models in window: 0.7127788662910461\n",
      "\n",
      "############### EM step 54 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.6174588203430176 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 55 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.345641613006592, -- test: -17.160490036010742 \n",
      "Root Mean Squared Error -- train: 0.4240131080150604, -- test: 0.7746362686157227 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -5.105660438537598, -- test: -17.71674346923828 \n",
      "Root Mean Squared Error -- train: 0.4524517357349396, -- test: 0.7863231897354126 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.9293394088745117, -- test: -18.08930015563965 \n",
      "Root Mean Squared Error -- train: 0.40759551525115967, -- test: 0.7940544486045837 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.059948444366455, -- test: -17.802501678466797 \n",
      "Root Mean Squared Error -- train: 0.41281658411026, -- test: 0.7881096005439758 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.952221155166626, -- test: -16.941740036010742 \n",
      "Root Mean Squared Error -- train: 0.4085150361061096, -- test: 0.7699916958808899 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.026546955108643, -- test: -16.680944442749023 \n",
      "Root Mean Squared Error -- train: 0.4114876687526703, -- test: 0.7644175291061401 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.176750183105469, -- test: -17.44818878173828 \n",
      "Root Mean Squared Error -- train: 0.41743040084838867, -- test: 0.7807027101516724 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.26865291595459, -- test: -17.609256744384766 \n",
      "Root Mean Squared Error -- train: 0.42102518677711487, -- test: 0.7840784192085266 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.935499906539917, -- test: -16.981821060180664 \n",
      "Root Mean Squared Error -- train: 0.4078432619571686, -- test: 0.7708447575569153 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.270384311676025, -- test: -16.905527114868164 \n",
      "Root Mean Squared Error -- train: 0.42109259963035583, -- test: 0.7692201137542725 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -18.02989387512207\n",
      "Test Root MSE of all sampled models: 0.7928267121315002\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 55 \n",
      "Test Log Likelihood of all models in window: -12.012733459472656\n",
      "Test Root MSE of all models in window: 0.714314341545105\n",
      "\n",
      "############### EM step 55 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.6231513023376465 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 56 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.9156441688537598, -- test: -17.392728805541992 \n",
      "Root Mean Squared Error -- train: 0.4085419476032257, -- test: 0.7826350331306458 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.164254188537598, -- test: -16.918466567993164 \n",
      "Root Mean Squared Error -- train: 0.41848137974739075, -- test: 0.772551953792572 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.723232746124268, -- test: -17.227149963378906 \n",
      "Root Mean Squared Error -- train: 0.440010130405426, -- test: 0.7791295647621155 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.0045270919799805, -- test: -16.673189163208008 \n",
      "Root Mean Squared Error -- train: 0.41212305426597595, -- test: 0.767285168170929 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.078087329864502, -- test: -16.749170303344727 \n",
      "Root Mean Squared Error -- train: 0.41506338119506836, -- test: 0.7689206004142761 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.019518852233887, -- test: -18.00678825378418 \n",
      "Root Mean Squared Error -- train: 0.41272398829460144, -- test: 0.7955005168914795 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.108083724975586, -- test: -16.952787399291992 \n",
      "Root Mean Squared Error -- train: 0.4162564277648926, -- test: 0.7732860445976257 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -5.445859432220459, -- test: -16.88066864013672 \n",
      "Root Mean Squared Error -- train: 0.46637117862701416, -- test: 0.7717426419258118 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.113739013671875, -- test: -17.97740936279297 \n",
      "Root Mean Squared Error -- train: 0.41648098826408386, -- test: 0.7948898077011108 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.272132873535156, -- test: -17.21601104736328 \n",
      "Root Mean Squared Error -- train: 0.42272165417671204, -- test: 0.7788931727409363 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.417505264282227\n",
      "Test Root MSE of all sampled models: 0.7617562413215637\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 56 \n",
      "Test Log Likelihood of all models in window: -11.90951919555664\n",
      "Test Root MSE of all models in window: 0.7151891589164734\n",
      "\n",
      "############### EM step 56 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.184587001800537 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 57 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.807148456573486, -- test: -16.224821090698242 \n",
      "Root Mean Squared Error -- train: 0.44480812549591064, -- test: 0.760565996170044 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.002030372619629, -- test: -15.842830657958984 \n",
      "Root Mean Squared Error -- train: 0.4135405719280243, -- test: 0.7521482110023499 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.9396839141845703, -- test: -16.28314781188965 \n",
      "Root Mean Squared Error -- train: 0.41102004051208496, -- test: 0.7618429660797119 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.8926806449890137, -- test: -16.890426635742188 \n",
      "Root Mean Squared Error -- train: 0.40910956263542175, -- test: 0.775015115737915 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.093631744384766, -- test: -16.78389549255371 \n",
      "Root Mean Squared Error -- train: 0.41721612215042114, -- test: 0.7727206349372864 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.599312782287598, -- test: -17.027189254760742 \n",
      "Root Mean Squared Error -- train: 0.4369508922100067, -- test: 0.7779507637023926 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.96651554107666, -- test: -16.45948028564453 \n",
      "Root Mean Squared Error -- train: 0.45074018836021423, -- test: 0.7656911015510559 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.908170700073242, -- test: -16.710725784301758 \n",
      "Root Mean Squared Error -- train: 0.409740149974823, -- test: 0.7711408138275146 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.196470737457275, -- test: -15.8336181640625 \n",
      "Root Mean Squared Error -- train: 0.4213044345378876, -- test: 0.7519440054893494 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.873478651046753, -- test: -16.854387283325195 \n",
      "Root Mean Squared Error -- train: 0.40832647681236267, -- test: 0.7742396593093872 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.790945053100586\n",
      "Test Root MSE of all sampled models: 0.7941454648971558\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 57 \n",
      "Test Log Likelihood of all models in window: -11.911334037780762\n",
      "Test Root MSE of all models in window: 0.7166493535041809\n",
      "\n",
      "############### EM step 57 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.232326984405518 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 58 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.9057157039642334, -- test: -16.631582260131836 \n",
      "Root Mean Squared Error -- train: 0.41114646196365356, -- test: 0.7724815607070923 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.121543884277344, -- test: -16.92700958251953 \n",
      "Root Mean Squared Error -- train: 0.4198748767375946, -- test: 0.7788814306259155 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -5.0360589027404785, -- test: -15.816215515136719 \n",
      "Root Mean Squared Error -- train: 0.45500504970550537, -- test: 0.7545364499092102 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.865811586380005, -- test: -16.519826889038086 \n",
      "Root Mean Squared Error -- train: 0.40951231122016907, -- test: 0.7700466513633728 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.970970630645752, -- test: -17.38313865661621 \n",
      "Root Mean Squared Error -- train: 0.41380491852760315, -- test: 0.7886607646942139 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.018892288208008, -- test: -16.42185401916504 \n",
      "Root Mean Squared Error -- train: 0.4157463610172272, -- test: 0.7679057717323303 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.8269295692443848, -- test: -16.41766357421875 \n",
      "Root Mean Squared Error -- train: 0.4079137146472931, -- test: 0.7678140997886658 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.103555202484131, -- test: -16.81098175048828 \n",
      "Root Mean Squared Error -- train: 0.4191543161869049, -- test: 0.7763741612434387 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.838942527770996, -- test: -16.129392623901367 \n",
      "Root Mean Squared Error -- train: 0.4084082841873169, -- test: 0.7614790201187134 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.838163375854492, -- test: -16.827333450317383 \n",
      "Root Mean Squared Error -- train: 0.4083762466907501, -- test: 0.7767279744148254 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.797365188598633\n",
      "Test Root MSE of all sampled models: 0.7760794162750244\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 58 \n",
      "Test Log Likelihood of all models in window: -11.794262886047363\n",
      "Test Root MSE of all models in window: 0.7177156805992126\n",
      "\n",
      "############### EM step 58 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.690136432647705 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 59 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.8507895469665527, -- test: -16.52093505859375 \n",
      "Root Mean Squared Error -- train: 0.410383015871048, -- test: 0.7730977535247803 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.8190579414367676, -- test: -17.015052795410156 \n",
      "Root Mean Squared Error -- train: 0.40907108783721924, -- test: 0.7838500142097473 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.9502482414245605, -- test: -16.815784454345703 \n",
      "Root Mean Squared Error -- train: 0.4144681990146637, -- test: 0.7795316576957703 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.058310508728027, -- test: -16.425003051757812 \n",
      "Root Mean Squared Error -- train: 0.41886159777641296, -- test: 0.7709927558898926 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.8398807048797607, -- test: -17.169071197509766 \n",
      "Root Mean Squared Error -- train: 0.4099324941635132, -- test: 0.7871715426445007 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -7.661397933959961, -- test: -15.047037124633789 \n",
      "Root Mean Squared Error -- train: 0.5454521775245667, -- test: 0.7400974631309509 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.840378761291504, -- test: -16.702220916748047 \n",
      "Root Mean Squared Error -- train: 0.4099530279636383, -- test: 0.7770599126815796 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.053409576416016, -- test: -15.765883445739746 \n",
      "Root Mean Squared Error -- train: 0.41866335272789, -- test: 0.7563722133636475 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.933558464050293, -- test: -15.886591911315918 \n",
      "Root Mean Squared Error -- train: 0.45287808775901794, -- test: 0.7590708136558533 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.7926485538482666, -- test: -16.03225326538086 \n",
      "Root Mean Squared Error -- train: 0.407975971698761, -- test: 0.7623145580291748 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.04314613342285\n",
      "Test Root MSE of all sampled models: 0.7844569087028503\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 59 \n",
      "Test Log Likelihood of all models in window: -11.797204971313477\n",
      "Test Root MSE of all models in window: 0.7188984751701355\n",
      "\n",
      "############### EM step 59 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7804300785064697 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 60 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.808094024658203, -- test: -16.311710357666016 \n",
      "Root Mean Squared Error -- train: 0.4100358486175537, -- test: 0.7713850140571594 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.8480100631713867, -- test: -16.338268280029297 \n",
      "Root Mean Squared Error -- train: 0.41169434785842896, -- test: 0.7719725370407104 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.77432107925415, -- test: -16.36571502685547 \n",
      "Root Mean Squared Error -- train: 0.44846275448799133, -- test: 0.7725793123245239 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.151378154754639, -- test: -16.16781997680664 \n",
      "Root Mean Squared Error -- train: 0.4240872263908386, -- test: 0.7681940793991089 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.924880266189575, -- test: -17.154254913330078 \n",
      "Root Mean Squared Error -- train: 0.4148695766925812, -- test: 0.7898110151290894 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.7398412227630615, -- test: -16.5202693939209 \n",
      "Root Mean Squared Error -- train: 0.40718430280685425, -- test: 0.775986909866333 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.786217212677002, -- test: -17.023874282836914 \n",
      "Root Mean Squared Error -- train: 0.4091239869594574, -- test: 0.7869879603385925 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.862832546234131, -- test: -15.030865669250488 \n",
      "Root Mean Squared Error -- train: 0.4123085141181946, -- test: 0.7424982190132141 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.7683117389678955, -- test: -17.218284606933594 \n",
      "Root Mean Squared Error -- train: 0.40837618708610535, -- test: 0.7911937236785889 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.9198529720306396, -- test: -15.729537010192871 \n",
      "Root Mean Squared Error -- train: 0.4146626591682434, -- test: 0.7583917379379272 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -17.4220027923584\n",
      "Test Root MSE of all sampled models: 0.7955772876739502\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 60 \n",
      "Test Log Likelihood of all models in window: -11.790679931640625\n",
      "Test Root MSE of all models in window: 0.7202433943748474\n",
      "\n",
      "############### EM step 60 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -5.884214878082275 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 61 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.8558428287506104, -- test: -16.32748794555664 \n",
      "Root Mean Squared Error -- train: 0.4135054051876068, -- test: 0.7747414112091064 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.729329824447632, -- test: -15.344682693481445 \n",
      "Root Mean Squared Error -- train: 0.4082064628601074, -- test: 0.7525947690010071 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.107795238494873, -- test: -16.828081130981445 \n",
      "Root Mean Squared Error -- train: 0.4238610565662384, -- test: 0.7857818603515625 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.82281231880188, -- test: -15.77356243133545 \n",
      "Root Mean Squared Error -- train: 0.4121285080909729, -- test: 0.7623383402824402 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.911895751953125, -- test: -14.714363098144531 \n",
      "Root Mean Squared Error -- train: 0.415831595659256, -- test: 0.7380414605140686 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.089634895324707, -- test: -16.558204650878906 \n",
      "Root Mean Squared Error -- train: 0.4231230914592743, -- test: 0.7798492312431335 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.9351117610931396, -- test: -16.376293182373047 \n",
      "Root Mean Squared Error -- train: 0.41679123044013977, -- test: 0.7758246660232544 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.075826644897461, -- test: -16.319316864013672 \n",
      "Root Mean Squared Error -- train: 0.4225611686706543, -- test: 0.7745598554611206 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.740692377090454, -- test: -16.276409149169922 \n",
      "Root Mean Squared Error -- train: 0.40868520736694336, -- test: 0.7736059427261353 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.244174480438232, -- test: -16.25838851928711 \n",
      "Root Mean Squared Error -- train: 0.4293622672557831, -- test: 0.7732051014900208 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.977195739746094\n",
      "Test Root MSE of all sampled models: 0.7669212222099304\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 61 \n",
      "Test Log Likelihood of all models in window: -11.688799858093262\n",
      "Test Root MSE of all models in window: 0.721032977104187\n",
      "\n",
      "############### EM step 61 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.307595729827881 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 62 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.8820855617523193, -- test: -15.9509916305542 \n",
      "Root Mean Squared Error -- train: 0.4160989224910736, -- test: 0.7693299651145935 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.7371981143951416, -- test: -16.287141799926758 \n",
      "Root Mean Squared Error -- train: 0.41001394391059875, -- test: 0.7768726348876953 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.7170491218566895, -- test: -16.40127944946289 \n",
      "Root Mean Squared Error -- train: 0.4091605842113495, -- test: 0.7794172167778015 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.364789962768555, -- test: -15.567826271057129 \n",
      "Root Mean Squared Error -- train: 0.4357587695121765, -- test: 0.7606409192085266 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.0686354637146, -- test: -15.638233184814453 \n",
      "Root Mean Squared Error -- train: 0.4238049387931824, -- test: 0.7622449994087219 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.756486654281616, -- test: -14.897930145263672 \n",
      "Root Mean Squared Error -- train: 0.41082924604415894, -- test: 0.745206356048584 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.06664514541626, -- test: -17.05599021911621 \n",
      "Root Mean Squared Error -- train: 0.4628569483757019, -- test: 0.7938554286956787 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.409776210784912, -- test: -15.476335525512695 \n",
      "Root Mean Squared Error -- train: 0.4375460147857666, -- test: 0.7585514187812805 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.2431440353393555, -- test: -17.05645179748535 \n",
      "Root Mean Squared Error -- train: 0.4308888614177704, -- test: 0.793865442276001 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.693025588989258, -- test: -16.6184024810791 \n",
      "Root Mean Squared Error -- train: 0.40814074873924255, -- test: 0.7842348217964172 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.439102172851562\n",
      "Test Root MSE of all sampled models: 0.7802586555480957\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 62 \n",
      "Test Log Likelihood of all models in window: -11.671634674072266\n",
      "Test Root MSE of all models in window: 0.7220267653465271\n",
      "\n",
      "############### EM step 62 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.521932363510132 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 63 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.773637056350708, -- test: -15.827219009399414 \n",
      "Root Mean Squared Error -- train: 0.41302475333213806, -- test: 0.7694987058639526 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -4.087539196014404, -- test: -15.9969482421875 \n",
      "Root Mean Squared Error -- train: 0.4261070787906647, -- test: 0.7733460664749146 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.7961485385894775, -- test: -15.894030570983887 \n",
      "Root Mean Squared Error -- train: 0.41397666931152344, -- test: 0.771015465259552 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.7676749229431152, -- test: -16.10218048095703 \n",
      "Root Mean Squared Error -- train: 0.4127722382545471, -- test: 0.7757217884063721 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.6982831954956055, -- test: -16.45233726501465 \n",
      "Root Mean Squared Error -- train: 0.40982210636138916, -- test: 0.7835750579833984 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.801384449005127, -- test: -17.099462509155273 \n",
      "Root Mean Squared Error -- train: 0.41419777274131775, -- test: 0.797885537147522 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.070211410522461, -- test: -15.87182331085205 \n",
      "Root Mean Squared Error -- train: 0.4253954291343689, -- test: 0.7705116271972656 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.6761202812194824, -- test: -15.733429908752441 \n",
      "Root Mean Squared Error -- train: 0.40887534618377686, -- test: 0.7673645615577698 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.6970765590667725, -- test: -16.31317710876465 \n",
      "Root Mean Squared Error -- train: 0.4097706079483032, -- test: 0.7804633975028992 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.7404584884643555, -- test: -15.876921653747559 \n",
      "Root Mean Squared Error -- train: 0.4116176664829254, -- test: 0.7706273794174194 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.898378372192383\n",
      "Test Root MSE of all sampled models: 0.7934664487838745\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 63 \n",
      "Test Log Likelihood of all models in window: -11.669045448303223\n",
      "Test Root MSE of all models in window: 0.7232158184051514\n",
      "\n",
      "############### EM step 63 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.622187852859497 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 64 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.6547579765319824, -- test: -15.626202583312988 \n",
      "Root Mean Squared Error -- train: 0.40937626361846924, -- test: 0.7677947282791138 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.6163597106933594, -- test: -15.675187110900879 \n",
      "Root Mean Squared Error -- train: 0.40772002935409546, -- test: 0.7689181566238403 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.6885764598846436, -- test: -15.601424217224121 \n",
      "Root Mean Squared Error -- train: 0.41082942485809326, -- test: 0.7672257423400879 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.60042142868042, -- test: -16.527246475219727 \n",
      "Root Mean Squared Error -- train: 0.44823846220970154, -- test: 0.7882037162780762 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.85989236831665, -- test: -14.946247100830078 \n",
      "Root Mean Squared Error -- train: 0.45832574367523193, -- test: 0.7520269155502319 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.642181158065796, -- test: -16.664865493774414 \n",
      "Root Mean Squared Error -- train: 0.4088345170021057, -- test: 0.7912744283676147 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.6859235763549805, -- test: -15.582693099975586 \n",
      "Root Mean Squared Error -- train: 0.41071560978889465, -- test: 0.7667953968048096 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.7137389183044434, -- test: -16.182079315185547 \n",
      "Root Mean Squared Error -- train: 0.4119073450565338, -- test: 0.7804485559463501 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.6844635009765625, -- test: -14.992048263549805 \n",
      "Root Mean Squared Error -- train: 0.4106529653072357, -- test: 0.7530993223190308 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.6588990688323975, -- test: -15.411219596862793 \n",
      "Root Mean Squared Error -- train: 0.40955445170402527, -- test: 0.7628446221351624 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.312341690063477\n",
      "Test Root MSE of all sampled models: 0.7833843231201172\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 64 \n",
      "Test Log Likelihood of all models in window: -11.547764778137207\n",
      "Test Root MSE of all models in window: 0.7241944074630737\n",
      "\n",
      "############### EM step 64 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.617636680603027 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 65 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.5910634994506836, -- test: -16.50675392150879 \n",
      "Root Mean Squared Error -- train: 0.4080542027950287, -- test: 0.7907565832138062 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.8396193981170654, -- test: -16.066787719726562 \n",
      "Root Mean Squared Error -- train: 0.41873306035995483, -- test: 0.78081214427948 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.630037784576416, -- test: -16.186439514160156 \n",
      "Root Mean Squared Error -- train: 0.40974709391593933, -- test: 0.7835291028022766 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.066176891326904, -- test: -15.736393928527832 \n",
      "Root Mean Squared Error -- train: 0.42823487520217896, -- test: 0.773260235786438 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -4.003342628479004, -- test: -15.461905479431152 \n",
      "Root Mean Squared Error -- train: 0.4256208539009094, -- test: 0.7669296264648438 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.606224775314331, -- test: -15.773597717285156 \n",
      "Root Mean Squared Error -- train: 0.40871360898017883, -- test: 0.7741143107414246 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.8791451454162598, -- test: -15.8101224899292 \n",
      "Root Mean Squared Error -- train: 0.4204062521457672, -- test: 0.7749518752098083 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.6357622146606445, -- test: -15.801644325256348 \n",
      "Root Mean Squared Error -- train: 0.4099951684474945, -- test: 0.7747575640678406 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.78075909614563, -- test: -16.218482971191406 \n",
      "Root Mean Squared Error -- train: 0.4162289798259735, -- test: 0.7842550873756409 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.5919201374053955, -- test: -16.728137969970703 \n",
      "Root Mean Squared Error -- train: 0.4080915153026581, -- test: 0.7957134246826172 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.941472053527832\n",
      "Test Root MSE of all sampled models: 0.7779564261436462\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 65 \n",
      "Test Log Likelihood of all models in window: -11.463972091674805\n",
      "Test Root MSE of all models in window: 0.7250517010688782\n",
      "\n",
      "############### EM step 65 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.63818359375 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 66 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.7350687980651855, -- test: -16.11113166809082 \n",
      "Root Mean Squared Error -- train: 0.41572707891464233, -- test: 0.7847891449928284 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.586660623550415, -- test: -14.940730094909668 \n",
      "Root Mean Squared Error -- train: 0.40928715467453003, -- test: 0.757623553276062 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.002045154571533, -- test: -15.472553253173828 \n",
      "Root Mean Squared Error -- train: 0.538318932056427, -- test: 0.7700862288475037 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.6840715408325195, -- test: -14.473560333251953 \n",
      "Root Mean Squared Error -- train: 0.454756498336792, -- test: 0.7465043067932129 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.572115421295166, -- test: -14.997103691101074 \n",
      "Root Mean Squared Error -- train: 0.40865054726600647, -- test: 0.7589542865753174 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.9358315467834473, -- test: -15.496908187866211 \n",
      "Root Mean Squared Error -- train: 0.42428332567214966, -- test: 0.7706521153450012 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.582479953765869, -- test: -15.933858871459961 \n",
      "Root Mean Squared Error -- train: 0.40910428762435913, -- test: 0.7807352542877197 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -4.033770561218262, -- test: -14.737112998962402 \n",
      "Root Mean Squared Error -- train: 0.4283953607082367, -- test: 0.7527974247932434 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.129594326019287, -- test: -16.13597869873047 \n",
      "Root Mean Squared Error -- train: 0.432380735874176, -- test: 0.7853556871414185 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.73789381980896, -- test: -16.08932113647461 \n",
      "Root Mean Squared Error -- train: 0.4158487319946289, -- test: 0.7842915058135986 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.876290321350098\n",
      "Test Root MSE of all sampled models: 0.7560995221138\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 66 \n",
      "Test Log Likelihood of all models in window: -11.364648818969727\n",
      "Test Root MSE of all models in window: 0.725532054901123\n",
      "\n",
      "############### EM step 66 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.751617193222046 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 67 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.014515399932861, -- test: -14.363696098327637 \n",
      "Root Mean Squared Error -- train: 0.429094135761261, -- test: 0.7466724514961243 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.5575640201568604, -- test: -14.919061660766602 \n",
      "Root Mean Squared Error -- train: 0.4094325304031372, -- test: 0.7599719762802124 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.5406970977783203, -- test: -16.25123405456543 \n",
      "Root Mean Squared Error -- train: 0.4086886942386627, -- test: 0.790962815284729 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.812666654586792, -- test: -15.84875202178955 \n",
      "Root Mean Squared Error -- train: 0.42052242159843445, -- test: 0.7817291617393494 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.5387041568756104, -- test: -14.840744972229004 \n",
      "Root Mean Squared Error -- train: 0.40860068798065186, -- test: 0.7581106424331665 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.6585371494293213, -- test: -15.869294166564941 \n",
      "Root Mean Squared Error -- train: 0.4138576090335846, -- test: 0.7822031378746033 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.570986270904541, -- test: -16.00389289855957 \n",
      "Root Mean Squared Error -- train: 0.4100234806537628, -- test: 0.7853012681007385 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.732283592224121, -- test: -15.589001655578613 \n",
      "Root Mean Squared Error -- train: 0.4170597791671753, -- test: 0.7757118940353394 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.281175136566162, -- test: -15.860448837280273 \n",
      "Root Mean Squared Error -- train: 0.4401623010635376, -- test: 0.7819991111755371 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.5783963203430176, -- test: -15.669587135314941 \n",
      "Root Mean Squared Error -- train: 0.41034939885139465, -- test: 0.777583658695221 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.38637924194336\n",
      "Test Root MSE of all sampled models: 0.7709852457046509\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 67 \n",
      "Test Log Likelihood of all models in window: -11.340117454528809\n",
      "Test Root MSE of all models in window: 0.7262313365936279\n",
      "\n",
      "############### EM step 67 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.203907489776611 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 68 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.5763821601867676, -- test: -15.718535423278809 \n",
      "Root Mean Squared Error -- train: 0.41169849038124084, -- test: 0.781684398651123 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.910261869430542, -- test: -15.923844337463379 \n",
      "Root Mean Squared Error -- train: 0.4261886477470398, -- test: 0.7864453792572021 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.5832877159118652, -- test: -15.878365516662598 \n",
      "Root Mean Squared Error -- train: 0.4120033383369446, -- test: 0.7853932976722717 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.487190008163452, -- test: -15.09844970703125 \n",
      "Root Mean Squared Error -- train: 0.40774041414260864, -- test: 0.7671257257461548 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.5292491912841797, -- test: -15.265270233154297 \n",
      "Root Mean Squared Error -- train: 0.40961161255836487, -- test: 0.7710694074630737 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.7848851680755615, -- test: -14.979369163513184 \n",
      "Root Mean Squared Error -- train: 0.42080584168434143, -- test: 0.764298141002655 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.5597851276397705, -- test: -15.506340026855469 \n",
      "Root Mean Squared Error -- train: 0.41096484661102295, -- test: 0.7767331004142761 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.702035427093506, -- test: -16.702529907226562 \n",
      "Root Mean Squared Error -- train: 0.41721078753471375, -- test: 0.8042463660240173 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.552528142929077, -- test: -15.678780555725098 \n",
      "Root Mean Squared Error -- train: 0.41064363718032837, -- test: 0.7807591557502747 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.040500164031982, -- test: -14.53442096710205 \n",
      "Root Mean Squared Error -- train: 0.43170905113220215, -- test: 0.7536389827728271 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -13.848176002502441\n",
      "Test Root MSE of all sampled models: 0.7368969917297363\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 68 \n",
      "Test Log Likelihood of all models in window: -11.165419578552246\n",
      "Test Root MSE of all models in window: 0.7263893485069275\n",
      "\n",
      "############### EM step 68 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.6761350631713867 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 69 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.541126251220703, -- test: -15.882004737854004 \n",
      "Root Mean Squared Error -- train: 0.4115390181541443, -- test: 0.7883967161178589 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.7177512645721436, -- test: -14.712725639343262 \n",
      "Root Mean Squared Error -- train: 0.419328510761261, -- test: 0.7607387900352478 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.886728525161743, -- test: -16.08932876586914 \n",
      "Root Mean Squared Error -- train: 0.4266476035118103, -- test: 0.7932000160217285 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.507110595703125, -- test: -15.438333511352539 \n",
      "Root Mean Squared Error -- train: 0.4100218415260315, -- test: 0.7780179977416992 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.7237255573272705, -- test: -14.8383207321167 \n",
      "Root Mean Squared Error -- train: 0.41958945989608765, -- test: 0.7637576460838318 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -4.185910701751709, -- test: -15.103411674499512 \n",
      "Root Mean Squared Error -- train: 0.43930745124816895, -- test: 0.7700905203819275 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.567274808883667, -- test: -15.095471382141113 \n",
      "Root Mean Squared Error -- train: 0.41270142793655396, -- test: 0.7699015736579895 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.4597175121307373, -- test: -15.355382919311523 \n",
      "Root Mean Squared Error -- train: 0.40789860486984253, -- test: 0.7760620713233948 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.841888427734375, -- test: -15.531498908996582 \n",
      "Root Mean Squared Error -- train: 0.4247176945209503, -- test: 0.7802087664604187 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.409646511077881, -- test: -15.302498817443848 \n",
      "Root Mean Squared Error -- train: 0.44854143261909485, -- test: 0.7748125791549683 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.603545188903809\n",
      "Test Root MSE of all sampled models: 0.7818987369537354\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 69 \n",
      "Test Log Likelihood of all models in window: -11.152374267578125\n",
      "Test Root MSE of all models in window: 0.7272240519523621\n",
      "\n",
      "############### EM step 69 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.5249574184417725 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 70 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.4675517082214355, -- test: -15.237829208374023 \n",
      "Root Mean Squared Error -- train: 0.4096347689628601, -- test: 0.7761383056640625 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.996568441390991, -- test: -14.670759201049805 \n",
      "Root Mean Squared Error -- train: 0.432820200920105, -- test: 0.7625305652618408 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.456843376159668, -- test: -15.647396087646484 \n",
      "Root Mean Squared Error -- train: 0.45202651619911194, -- test: 0.785819947719574 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.458744764328003, -- test: -15.411303520202637 \n",
      "Root Mean Squared Error -- train: 0.40923765301704407, -- test: 0.7802536487579346 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.4574673175811768, -- test: -15.597618103027344 \n",
      "Root Mean Squared Error -- train: 0.40918001532554626, -- test: 0.7846496105194092 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.7041327953338623, -- test: -15.548356056213379 \n",
      "Root Mean Squared Error -- train: 0.4201616942882538, -- test: 0.7834897041320801 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.444650888442993, -- test: -15.16697883605957 \n",
      "Root Mean Squared Error -- train: 0.4086013734340668, -- test: 0.7744511365890503 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.4372713565826416, -- test: -15.229493141174316 \n",
      "Root Mean Squared Error -- train: 0.4082678258419037, -- test: 0.77593994140625 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.245894432067871, -- test: -15.172136306762695 \n",
      "Root Mean Squared Error -- train: 0.48317885398864746, -- test: 0.7745741009712219 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.34978723526001, -- test: -14.866083145141602 \n",
      "Root Mean Squared Error -- train: 0.4476327896118164, -- test: 0.7672449350357056 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.903406143188477\n",
      "Test Root MSE of all sampled models: 0.7681425213813782\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 70 \n",
      "Test Log Likelihood of all models in window: -11.141632080078125\n",
      "Test Root MSE of all models in window: 0.727824866771698\n",
      "\n",
      "############### EM step 70 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.3651740550994873 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 71 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.7290825843811035, -- test: -14.762063026428223 \n",
      "Root Mean Squared Error -- train: 0.46461158990859985, -- test: 0.7675387263298035 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.4395439624786377, -- test: -14.762981414794922 \n",
      "Root Mean Squared Error -- train: 0.4097437262535095, -- test: 0.7675609588623047 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.147463321685791, -- test: -13.706534385681152 \n",
      "Root Mean Squared Error -- train: 0.440711110830307, -- test: 0.7415169477462769 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.431688070297241, -- test: -14.77403450012207 \n",
      "Root Mean Squared Error -- train: 0.40938690304756165, -- test: 0.7678287625312805 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.5664761066436768, -- test: -14.049554824829102 \n",
      "Root Mean Squared Error -- train: 0.4154660999774933, -- test: 0.7500723600387573 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.431007146835327, -- test: -15.64079475402832 \n",
      "Root Mean Squared Error -- train: 0.4093559682369232, -- test: 0.788547158241272 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.7161028385162354, -- test: -15.515149116516113 \n",
      "Root Mean Squared Error -- train: 0.42211201786994934, -- test: 0.7855777740478516 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.5645790100097656, -- test: -14.869855880737305 \n",
      "Root Mean Squared Error -- train: 0.41538116335868835, -- test: 0.7701466083526611 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.4458961486816406, -- test: -14.327322006225586 \n",
      "Root Mean Squared Error -- train: 0.4100319743156433, -- test: 0.7569293975830078 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.3873441219329834, -- test: -15.640033721923828 \n",
      "Root Mean Squared Error -- train: 0.407367080450058, -- test: 0.7885292172431946 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -15.29833698272705\n",
      "Test Root MSE of all sampled models: 0.7804270386695862\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 71 \n",
      "Test Log Likelihood of all models in window: -11.103933334350586\n",
      "Test Root MSE of all models in window: 0.7285920977592468\n",
      "\n",
      "############### EM step 71 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.4325873851776123 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 72 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.383427143096924, -- test: -14.514457702636719 \n",
      "Root Mean Squared Error -- train: 0.40854787826538086, -- test: 0.7642872333526611 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.4550065994262695, -- test: -15.2551908493042 \n",
      "Root Mean Squared Error -- train: 0.41181841492652893, -- test: 0.7822402715682983 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.5016913414001465, -- test: -14.33751106262207 \n",
      "Root Mean Squared Error -- train: 0.413937509059906, -- test: 0.7599358558654785 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.4423630237579346, -- test: -15.026942253112793 \n",
      "Root Mean Squared Error -- train: 0.4112425744533539, -- test: 0.7767524719238281 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.4473376274108887, -- test: -15.04310417175293 \n",
      "Root Mean Squared Error -- train: 0.4114692211151123, -- test: 0.777142345905304 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.521132469177246, -- test: -15.01081657409668 \n",
      "Root Mean Squared Error -- train: 0.41481679677963257, -- test: 0.7763632535934448 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.404218912124634, -- test: -14.638008117675781 \n",
      "Root Mean Squared Error -- train: 0.4095005691051483, -- test: 0.7673109173774719 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.621819019317627, -- test: -15.219922065734863 \n",
      "Root Mean Squared Error -- train: 0.41934114694595337, -- test: 0.7813947796821594 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.3747875690460205, -- test: -15.01700210571289 \n",
      "Root Mean Squared Error -- train: 0.4081513583660126, -- test: 0.7765125632286072 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.393157958984375, -- test: -14.435338973999023 \n",
      "Root Mean Squared Error -- train: 0.40899401903152466, -- test: 0.7623446583747864 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.961433410644531\n",
      "Test Root MSE of all sampled models: 0.7751702666282654\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 72 \n",
      "Test Log Likelihood of all models in window: -11.034045219421387\n",
      "Test Root MSE of all models in window: 0.7292593717575073\n",
      "\n",
      "############### EM step 72 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.4904024600982666 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 73 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.429166316986084, -- test: -14.479243278503418 \n",
      "Root Mean Squared Error -- train: 0.41200900077819824, -- test: 0.7661934494972229 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.33868145942688, -- test: -15.342601776123047 \n",
      "Root Mean Squared Error -- train: 0.4078409671783447, -- test: 0.7871828675270081 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.438349962234497, -- test: -15.346056938171387 \n",
      "Root Mean Squared Error -- train: 0.4124296307563782, -- test: 0.7872657775878906 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.4589784145355225, -- test: -15.195384979248047 \n",
      "Root Mean Squared Error -- train: 0.4133729636669159, -- test: 0.7836436033248901 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.826052665710449, -- test: -14.746048927307129 \n",
      "Root Mean Squared Error -- train: 0.4298134744167328, -- test: 0.7727407217025757 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.38201642036438, -- test: -15.498638153076172 \n",
      "Root Mean Squared Error -- train: 0.4098424017429352, -- test: 0.7909168601036072 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.576003313064575, -- test: -14.278040885925293 \n",
      "Root Mean Squared Error -- train: 0.4186843931674957, -- test: 0.7612189054489136 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.3753416538238525, -- test: -14.65127182006836 \n",
      "Root Mean Squared Error -- train: 0.409534752368927, -- test: 0.7704214453697205 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.3564939498901367, -- test: -14.469768524169922 \n",
      "Root Mean Squared Error -- train: 0.40866485238075256, -- test: 0.7659599184989929 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.523347854614258, -- test: -14.7645845413208 \n",
      "Root Mean Squared Error -- train: 0.416302889585495, -- test: 0.7731935977935791 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.02340316772461\n",
      "Test Root MSE of all sampled models: 0.7548760771751404\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 73 \n",
      "Test Log Likelihood of all models in window: -10.829285621643066\n",
      "Test Root MSE of all models in window: 0.7296163439750671\n",
      "\n",
      "############### EM step 73 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.7623910903930664 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 74 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.857357978820801, -- test: -14.977507591247559 \n",
      "Root Mean Squared Error -- train: 0.4326118230819702, -- test: 0.7811509370803833 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.358442544937134, -- test: -14.116485595703125 \n",
      "Root Mean Squared Error -- train: 0.4100887179374695, -- test: 0.759895384311676 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.3710761070251465, -- test: -14.9155912399292 \n",
      "Root Mean Squared Error -- train: 0.4106743037700653, -- test: 0.7796418070793152 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.368340253829956, -- test: -14.176623344421387 \n",
      "Root Mean Squared Error -- train: 0.41054755449295044, -- test: 0.7613992691040039 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.8258440494537354, -- test: -13.944245338439941 \n",
      "Root Mean Squared Error -- train: 0.43122395873069763, -- test: 0.7555716037750244 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.35558819770813, -- test: -14.302972793579102 \n",
      "Root Mean Squared Error -- train: 0.40995627641677856, -- test: 0.7645492553710938 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.3257179260253906, -- test: -14.405661582946777 \n",
      "Root Mean Squared Error -- train: 0.40856799483299255, -- test: 0.7670997977256775 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.3163607120513916, -- test: -14.810197830200195 \n",
      "Root Mean Squared Error -- train: 0.4081321358680725, -- test: 0.777066171169281 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.4317054748535156, -- test: -14.191658020019531 \n",
      "Root Mean Squared Error -- train: 0.413472980260849, -- test: 0.7617747783660889 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.4016411304473877, -- test: -15.532727241516113 \n",
      "Root Mean Squared Error -- train: 0.4120875895023346, -- test: 0.7945559024810791 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -13.46557903289795\n",
      "Test Root MSE of all sampled models: 0.7434235215187073\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 74 \n",
      "Test Log Likelihood of all models in window: -10.675127983093262\n",
      "Test Root MSE of all models in window: 0.7298046946525574\n",
      "\n",
      "############### EM step 74 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.6997647285461426 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 75 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.9049065113067627, -- test: -13.73482894897461 \n",
      "Root Mean Squared Error -- train: 0.4361412823200226, -- test: 0.7529587745666504 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.427154541015625, -- test: -14.12802505493164 \n",
      "Root Mean Squared Error -- train: 0.4146197736263275, -- test: 0.7628996968269348 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.42961049079895, -- test: -14.407169342041016 \n",
      "Root Mean Squared Error -- train: 0.41473326086997986, -- test: 0.7698792815208435 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.2992286682128906, -- test: -15.218510627746582 \n",
      "Root Mean Squared Error -- train: 0.408664733171463, -- test: 0.7898154258728027 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.2931623458862305, -- test: -14.377087593078613 \n",
      "Root Mean Squared Error -- train: 0.4083801805973053, -- test: 0.7691301107406616 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.337078332901001, -- test: -14.801897048950195 \n",
      "Root Mean Squared Error -- train: 0.41043567657470703, -- test: 0.7796421051025391 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.327043294906616, -- test: -14.147063255310059 \n",
      "Root Mean Squared Error -- train: 0.4099668860435486, -- test: 0.7633777856826782 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.3298392295837402, -- test: -15.483325004577637 \n",
      "Root Mean Squared Error -- train: 0.41009753942489624, -- test: 0.7962142825126648 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.012784957885742, -- test: -12.474506378173828 \n",
      "Root Mean Squared Error -- train: 0.4408555328845978, -- test: 0.7201705574989319 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.3755123615264893, -- test: -14.458122253417969 \n",
      "Root Mean Squared Error -- train: 0.4122261703014374, -- test: 0.7711464166641235 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -16.664535522460938\n",
      "Test Root MSE of all sampled models: 0.8241521120071411\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 75 \n",
      "Test Log Likelihood of all models in window: -10.674430847167969\n",
      "Test Root MSE of all models in window: 0.7311427593231201\n",
      "\n",
      "############### EM step 75 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.4737536907196045 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 76 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.2785706520080566, -- test: -14.980125427246094 \n",
      "Root Mean Squared Error -- train: 0.4089955687522888, -- test: 0.7867498993873596 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.262359619140625, -- test: -15.032203674316406 \n",
      "Root Mean Squared Error -- train: 0.4082298278808594, -- test: 0.7880265116691589 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.296989679336548, -- test: -14.02893352508545 \n",
      "Root Mean Squared Error -- train: 0.4098638594150543, -- test: 0.7630583643913269 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.7346036434173584, -- test: -14.370624542236328 \n",
      "Root Mean Squared Error -- train: 0.4299778640270233, -- test: 0.7716526985168457 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.303528070449829, -- test: -14.432251930236816 \n",
      "Root Mean Squared Error -- train: 0.41017165780067444, -- test: 0.7731925845146179 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.34979510307312, -- test: -15.682093620300293 \n",
      "Root Mean Squared Error -- train: 0.41234299540519714, -- test: 0.8037863373756409 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.2552237510681152, -- test: -14.62413215637207 \n",
      "Root Mean Squared Error -- train: 0.4078923165798187, -- test: 0.7779675722122192 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.817342519760132, -- test: -13.348004341125488 \n",
      "Root Mean Squared Error -- train: 0.43367594480514526, -- test: 0.7456360459327698 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.278947114944458, -- test: -14.928918838500977 \n",
      "Root Mean Squared Error -- train: 0.4090133607387543, -- test: 0.7854927778244019 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -4.633363246917725, -- test: -13.85600471496582 \n",
      "Root Mean Squared Error -- train: 0.468587726354599, -- test: 0.7586717009544373 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.98340129852295\n",
      "Test Root MSE of all sampled models: 0.7361378073692322\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 76 \n",
      "Test Log Likelihood of all models in window: -10.545044898986816\n",
      "Test Root MSE of all models in window: 0.7312086820602417\n",
      "\n",
      "############### EM step 76 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.598177433013916 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 77 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.2447426319122314, -- test: -15.29076862335205 \n",
      "Root Mean Squared Error -- train: 0.408728688955307, -- test: 0.7971851229667664 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.397847890853882, -- test: -14.483498573303223 \n",
      "Root Mean Squared Error -- train: 0.41594839096069336, -- test: 0.7772457599639893 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -4.1629109382629395, -- test: -13.503225326538086 \n",
      "Root Mean Squared Error -- train: 0.4502941370010376, -- test: 0.7523231506347656 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.2376492023468018, -- test: -15.064692497253418 \n",
      "Root Mean Squared Error -- train: 0.4083910882472992, -- test: 0.791651725769043 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.301394462585449, -- test: -14.9971923828125 \n",
      "Root Mean Squared Error -- train: 0.4114149212837219, -- test: 0.7899920344352722 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.308668851852417, -- test: -13.991268157958984 \n",
      "Root Mean Squared Error -- train: 0.41175854206085205, -- test: 0.7648327946662903 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.75358510017395, -- test: -14.21385383605957 \n",
      "Root Mean Squared Error -- train: 0.4322579801082611, -- test: 0.7704706788063049 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.9048566818237305, -- test: -13.625657081604004 \n",
      "Root Mean Squared Error -- train: 0.43900975584983826, -- test: 0.7554808855056763 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.2416532039642334, -- test: -13.916197776794434 \n",
      "Root Mean Squared Error -- train: 0.4085816740989685, -- test: 0.762921929359436 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.2726356983184814, -- test: -13.966214179992676 \n",
      "Root Mean Squared Error -- train: 0.41005346179008484, -- test: 0.7641955614089966 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -13.622968673706055\n",
      "Test Root MSE of all sampled models: 0.755411684513092\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 77 \n",
      "Test Log Likelihood of all models in window: -10.530813217163086\n",
      "Test Root MSE of all models in window: 0.7315281629562378\n",
      "\n",
      "############### EM step 77 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.8070569038391113 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 78 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.416999340057373, -- test: -14.970483779907227 \n",
      "Root Mean Squared Error -- train: 0.41819098591804504, -- test: 0.7921200394630432 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.354862689971924, -- test: -15.202614784240723 \n",
      "Root Mean Squared Error -- train: 0.4152706563472748, -- test: 0.7978390455245972 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.2316484451293945, -- test: -13.878213882446289 \n",
      "Root Mean Squared Error -- train: 0.40941813588142395, -- test: 0.7646359205245972 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.5602433681488037, -- test: -13.943368911743164 \n",
      "Root Mean Squared Error -- train: 0.4248468279838562, -- test: 0.7663029432296753 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.49920392036438, -- test: -13.829572677612305 \n",
      "Root Mean Squared Error -- train: 0.4220234751701355, -- test: 0.7633889317512512 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.87850022315979, -- test: -13.450455665588379 \n",
      "Root Mean Squared Error -- train: 0.439273864030838, -- test: 0.7535992860794067 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.628443956375122, -- test: -13.866063117980957 \n",
      "Root Mean Squared Error -- train: 0.42797937989234924, -- test: 0.7643245458602905 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.3448421955108643, -- test: -13.223613739013672 \n",
      "Root Mean Squared Error -- train: 0.41479772329330444, -- test: 0.7476804852485657 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.169143199920654, -- test: -14.882129669189453 \n",
      "Root Mean Squared Error -- train: 0.45204704999923706, -- test: 0.7899324297904968 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.2197022438049316, -- test: -13.616186141967773 \n",
      "Root Mean Squared Error -- train: 0.4088462293148041, -- test: 0.7578943967819214 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.089411735534668\n",
      "Test Root MSE of all sampled models: 0.7700266242027283\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 78 \n",
      "Test Log Likelihood of all models in window: -10.526357650756836\n",
      "Test Root MSE of all models in window: 0.7320345044136047\n",
      "\n",
      "############### EM step 78 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.6375792026519775 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 79 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.7185540199279785, -- test: -13.897207260131836 \n",
      "Root Mean Squared Error -- train: 0.4334981441497803, -- test: 0.7678276896476746 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.1815550327301025, -- test: -14.376625061035156 \n",
      "Root Mean Squared Error -- train: 0.4083273708820343, -- test: 0.780049204826355 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.3519105911254883, -- test: -14.20378303527832 \n",
      "Root Mean Squared Error -- train: 0.416477233171463, -- test: 0.775665283203125 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.1865034103393555, -- test: -14.241929054260254 \n",
      "Root Mean Squared Error -- train: 0.4085663855075836, -- test: 0.7766348719596863 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.2344048023223877, -- test: -13.666570663452148 \n",
      "Root Mean Squared Error -- train: 0.41087302565574646, -- test: 0.761878490447998 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.1848456859588623, -- test: -13.738011360168457 \n",
      "Root Mean Squared Error -- train: 0.40848633646965027, -- test: 0.7637262344360352 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.3181312084198, -- test: -14.344865798950195 \n",
      "Root Mean Squared Error -- train: 0.4148739278316498, -- test: 0.7792454957962036 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.2635252475738525, -- test: -13.8991117477417 \n",
      "Root Mean Squared Error -- train: 0.4122689366340637, -- test: 0.7678766250610352 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.3231751918792725, -- test: -14.506855010986328 \n",
      "Root Mean Squared Error -- train: 0.4151137173175812, -- test: 0.7833361029624939 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.574305534362793, -- test: -14.208998680114746 \n",
      "Root Mean Squared Error -- train: 0.4268825948238373, -- test: 0.7757979035377502 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.007232666015625\n",
      "Test Root MSE of all sampled models: 0.7706496119499207\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 79 \n",
      "Test Log Likelihood of all models in window: -10.516763687133789\n",
      "Test Root MSE of all models in window: 0.7325360178947449\n",
      "\n",
      "############### EM step 79 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.6152369976043701 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 80 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.158182382583618, -- test: -13.793496131896973 \n",
      "Root Mean Squared Error -- train: 0.4084528684616089, -- test: 0.7677480578422546 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.983366012573242, -- test: -13.818286895751953 \n",
      "Root Mean Squared Error -- train: 0.44679200649261475, -- test: 0.7683893442153931 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.2149176597595215, -- test: -14.336992263793945 \n",
      "Root Mean Squared Error -- train: 0.4112032949924469, -- test: 0.7816862463951111 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -4.112051010131836, -- test: -14.010363578796387 \n",
      "Root Mean Squared Error -- train: 0.45247817039489746, -- test: 0.7733398675918579 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.3580029010772705, -- test: -13.083089828491211 \n",
      "Root Mean Squared Error -- train: 0.4180595278739929, -- test: 0.7491385340690613 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.1598761081695557, -- test: -13.543902397155762 \n",
      "Root Mean Squared Error -- train: 0.4085352420806885, -- test: 0.7612616419792175 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.9634222984313965, -- test: -13.95041275024414 \n",
      "Root Mean Squared Error -- train: 0.44590431451797485, -- test: 0.7717981338500977 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.173091173171997, -- test: -13.794946670532227 \n",
      "Root Mean Squared Error -- train: 0.40917739272117615, -- test: 0.7677856087684631 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.322692632675171, -- test: -14.918662071228027 \n",
      "Root Mean Squared Error -- train: 0.41637805104255676, -- test: 0.7963331937789917 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.3671605587005615, -- test: -14.364704132080078 \n",
      "Root Mean Squared Error -- train: 0.4184945225715637, -- test: 0.782390296459198 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -13.107585906982422\n",
      "Test Root MSE of all sampled models: 0.7497879266738892\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 80 \n",
      "Test Log Likelihood of all models in window: -10.411993026733398\n",
      "Test Root MSE of all models in window: 0.7327542304992676\n",
      "\n",
      "############### EM step 80 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -4.841666221618652 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 81 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.3705716133117676, -- test: -13.603655815124512 \n",
      "Root Mean Squared Error -- train: 0.42000478506088257, -- test: 0.7654963731765747 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.126835346221924, -- test: -13.950727462768555 \n",
      "Root Mean Squared Error -- train: 0.40822598338127136, -- test: 0.774516761302948 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.151456117630005, -- test: -13.891268730163574 \n",
      "Root Mean Squared Error -- train: 0.40943118929862976, -- test: 0.7729789614677429 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.2462615966796875, -- test: -13.950600624084473 \n",
      "Root Mean Squared Error -- train: 0.4140392541885376, -- test: 0.7745136022567749 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.91001296043396, -- test: -13.568016052246094 \n",
      "Root Mean Squared Error -- train: 0.444966584444046, -- test: 0.764564037322998 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.2286980152130127, -- test: -13.538178443908691 \n",
      "Root Mean Squared Error -- train: 0.41318947076797485, -- test: 0.7637826800346375 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.1922197341918945, -- test: -13.020415306091309 \n",
      "Root Mean Squared Error -- train: 0.4114188551902771, -- test: 0.7500935792922974 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.1912946701049805, -- test: -13.628423690795898 \n",
      "Root Mean Squared Error -- train: 0.4113738536834717, -- test: 0.7661436200141907 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.1375956535339355, -- test: -14.546475410461426 \n",
      "Root Mean Squared Error -- train: 0.4087531566619873, -- test: 0.7897602319717407 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.134859561920166, -- test: -14.086520195007324 \n",
      "Root Mean Squared Error -- train: 0.4086191654205322, -- test: 0.7780176401138306 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.266453742980957\n",
      "Test Root MSE of all sampled models: 0.7826322913169861\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 81 \n",
      "Test Log Likelihood of all models in window: -10.402946472167969\n",
      "Test Root MSE of all models in window: 0.7333906888961792\n",
      "\n",
      "############### EM step 81 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.5602118968963623 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 82 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -4.0492048263549805, -- test: -14.634629249572754 \n",
      "Root Mean Squared Error -- train: 0.45266610383987427, -- test: 0.794785737991333 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.4581053256988525, -- test: -13.474444389343262 \n",
      "Root Mean Squared Error -- train: 0.42552903294563293, -- test: 0.7647932767868042 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.5792462825775146, -- test: -14.421503067016602 \n",
      "Root Mean Squared Error -- train: 0.43122971057891846, -- test: 0.7893615365028381 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.1065733432769775, -- test: -13.890105247497559 \n",
      "Root Mean Squared Error -- train: 0.40853649377822876, -- test: 0.7756720185279846 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.1551108360290527, -- test: -13.603654861450195 \n",
      "Root Mean Squared Error -- train: 0.4109245240688324, -- test: 0.7681914567947388 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.1241066455841064, -- test: -13.802425384521484 \n",
      "Root Mean Squared Error -- train: 0.4094007611274719, -- test: 0.7733900547027588 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.80273699760437, -- test: -13.39453125 \n",
      "Root Mean Squared Error -- train: 0.44155365228652954, -- test: 0.7626839280128479 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.298539161682129, -- test: -14.825601577758789 \n",
      "Root Mean Squared Error -- train: 0.41790148615837097, -- test: 0.7996149063110352 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.1102073192596436, -- test: -13.883829116821289 \n",
      "Root Mean Squared Error -- train: 0.40871578454971313, -- test: 0.7755089402198792 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.175679922103882, -- test: -13.729708671569824 \n",
      "Root Mean Squared Error -- train: 0.4119323790073395, -- test: 0.7714922428131104 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.112634658813477\n",
      "Test Root MSE of all sampled models: 0.7814338803291321\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 82 \n",
      "Test Log Likelihood of all models in window: -10.250587463378906\n",
      "Test Root MSE of all models in window: 0.7339954972267151\n",
      "\n",
      "############### EM step 82 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.5041353702545166 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 83 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -5.284393787384033, -- test: -12.538496017456055 \n",
      "Root Mean Squared Error -- train: 0.5063422322273254, -- test: 0.7422536015510559 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.101938486099243, -- test: -14.1996488571167 \n",
      "Root Mean Squared Error -- train: 0.4095880091190338, -- test: 0.7863794565200806 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.222041130065918, -- test: -13.371006965637207 \n",
      "Root Mean Squared Error -- train: 0.4154987037181854, -- test: 0.7646862864494324 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.075462818145752, -- test: -13.944232940673828 \n",
      "Root Mean Squared Error -- train: 0.40827351808547974, -- test: 0.7797572612762451 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.079193115234375, -- test: -13.109099388122559 \n",
      "Root Mean Squared Error -- train: 0.40845897793769836, -- test: 0.757700502872467 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.0857186317443848, -- test: -13.637626647949219 \n",
      "Root Mean Squared Error -- train: 0.4087832272052765, -- test: 0.7717326879501343 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.195852041244507, -- test: -13.038335800170898 \n",
      "Root Mean Squared Error -- train: 0.414217084646225, -- test: 0.7558020949363708 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.360062599182129, -- test: -13.883792877197266 \n",
      "Root Mean Squared Error -- train: 0.4221891164779663, -- test: 0.7781819701194763 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -4.1333909034729, -- test: -13.274428367614746 \n",
      "Root Mean Squared Error -- train: 0.4578702747821808, -- test: 0.7621178030967712 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.0808959007263184, -- test: -13.100008964538574 \n",
      "Root Mean Squared Error -- train: 0.4085436165332794, -- test: 0.7574569582939148 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -13.428815841674805\n",
      "Test Root MSE of all sampled models: 0.7662195563316345\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 83 \n",
      "Test Log Likelihood of all models in window: -10.229645729064941\n",
      "Test Root MSE of all models in window: 0.7343921065330505\n",
      "\n",
      "############### EM step 83 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.1118361949920654 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 84 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.1980109214782715, -- test: -13.792959213256836 \n",
      "Root Mean Squared Error -- train: 0.41561946272850037, -- test: 0.7784696221351624 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.072916269302368, -- test: -12.847421646118164 \n",
      "Root Mean Squared Error -- train: 0.40941891074180603, -- test: 0.7532248497009277 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.0876026153564453, -- test: -13.913573265075684 \n",
      "Root Mean Squared Error -- train: 0.41015172004699707, -- test: 0.7816312313079834 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.0884451866149902, -- test: -13.301600456237793 \n",
      "Root Mean Squared Error -- train: 0.41019371151924133, -- test: 0.7654548287391663 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.6385581493377686, -- test: -13.731200218200684 \n",
      "Root Mean Squared Error -- train: 0.4367556571960449, -- test: 0.7768458127975464 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.158132791519165, -- test: -13.227178573608398 \n",
      "Root Mean Squared Error -- train: 0.4136529266834259, -- test: 0.7634642124176025 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.1995790004730225, -- test: -13.679557800292969 \n",
      "Root Mean Squared Error -- train: 0.4156965911388397, -- test: 0.7754852771759033 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.1004891395568848, -- test: -12.852557182312012 \n",
      "Root Mean Squared Error -- train: 0.410793662071228, -- test: 0.7533642649650574 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.0666892528533936, -- test: -13.05029296875 \n",
      "Root Mean Squared Error -- train: 0.4091078042984009, -- test: 0.7587120532989502 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.175396203994751, -- test: -13.43597412109375 \n",
      "Root Mean Squared Error -- train: 0.41450539231300354, -- test: 0.7690358757972717 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -13.236852645874023\n",
      "Test Root MSE of all sampled models: 0.7637233138084412\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 84 \n",
      "Test Log Likelihood of all models in window: -10.181720733642578\n",
      "Test Root MSE of all models in window: 0.7347481846809387\n",
      "\n",
      "############### EM step 84 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.0250093936920166 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 85 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.314897298812866, -- test: -12.493871688842773 \n",
      "Root Mean Squared Error -- train: 0.4226453900337219, -- test: 0.7460910677909851 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.140331506729126, -- test: -13.388934135437012 \n",
      "Root Mean Squared Error -- train: 0.4140530228614807, -- test: 0.7703984379768372 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.274984836578369, -- test: -13.781402587890625 \n",
      "Root Mean Squared Error -- train: 0.42069631814956665, -- test: 0.7808181047439575 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.176723003387451, -- test: -13.213898658752441 \n",
      "Root Mean Squared Error -- train: 0.4158588945865631, -- test: 0.7657056450843811 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.325468063354492, -- test: -14.03781509399414 \n",
      "Root Mean Squared Error -- train: 0.4231601059436798, -- test: 0.7875512838363647 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.2906863689422607, -- test: -13.609502792358398 \n",
      "Root Mean Squared Error -- train: 0.4214641749858856, -- test: 0.7762715816497803 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.17569899559021, -- test: -13.146134376525879 \n",
      "Root Mean Squared Error -- train: 0.41580820083618164, -- test: 0.7638810873031616 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.172048807144165, -- test: -12.95505142211914 \n",
      "Root Mean Squared Error -- train: 0.4156273901462555, -- test: 0.758712649345398 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.2806689739227295, -- test: -13.284218788146973 \n",
      "Root Mean Squared Error -- train: 0.420974463224411, -- test: 0.7675943970680237 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.065258026123047, -- test: -13.723735809326172 \n",
      "Root Mean Squared Error -- train: 0.41030246019363403, -- test: 0.7792958617210388 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -13.482839584350586\n",
      "Test Root MSE of all sampled models: 0.7729042768478394\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 85 \n",
      "Test Log Likelihood of all models in window: -10.12545394897461\n",
      "Test Root MSE of all models in window: 0.7352085709571838\n",
      "\n",
      "############### EM step 85 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.895533800125122 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 86 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.042381763458252, -- test: -14.157210350036621 \n",
      "Root Mean Squared Error -- train: 0.41043761372566223, -- test: 0.793405294418335 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.1773414611816406, -- test: -13.122160911560059 \n",
      "Root Mean Squared Error -- train: 0.4172014594078064, -- test: 0.7658714652061462 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.9965126514434814, -- test: -13.039604187011719 \n",
      "Root Mean Squared Error -- train: 0.4081132411956787, -- test: 0.7636326551437378 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.4080700874328613, -- test: -13.6449556350708 \n",
      "Root Mean Squared Error -- train: 0.42851772904396057, -- test: 0.779900074005127 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.0563507080078125, -- test: -13.179991722106934 \n",
      "Root Mean Squared Error -- train: 0.41114285588264465, -- test: 0.7674359679222107 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.610804796218872, -- test: -13.408727645874023 \n",
      "Root Mean Squared Error -- train: 0.43821990489959717, -- test: 0.7735927104949951 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.2675528526306152, -- test: -13.515926361083984 \n",
      "Root Mean Squared Error -- train: 0.4216620922088623, -- test: 0.7764613032341003 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.0147974491119385, -- test: -13.921009063720703 \n",
      "Root Mean Squared Error -- train: 0.4090413749217987, -- test: 0.7872068881988525 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.218496561050415, -- test: -12.81052017211914 \n",
      "Root Mean Squared Error -- train: 0.41924232244491577, -- test: 0.7573853731155396 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.052020788192749, -- test: -13.7919340133667 \n",
      "Root Mean Squared Error -- train: 0.41092440485954285, -- test: 0.78379887342453 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.982958793640137\n",
      "Test Root MSE of all sampled models: 0.762092649936676\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 86 \n",
      "Test Log Likelihood of all models in window: -10.118436813354492\n",
      "Test Root MSE of all models in window: 0.7355268597602844\n",
      "\n",
      "############### EM step 86 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.372526168823242 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 87 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.983612298965454, -- test: -13.130005836486816 \n",
      "Root Mean Squared Error -- train: 0.40870487689971924, -- test: 0.7686706185340881 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.999088764190674, -- test: -12.311867713928223 \n",
      "Root Mean Squared Error -- train: 0.4094949960708618, -- test: 0.7461104989051819 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.9710891246795654, -- test: -13.165095329284668 \n",
      "Root Mean Squared Error -- train: 0.40806448459625244, -- test: 0.7696233987808228 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.9837918281555176, -- test: -13.788932800292969 \n",
      "Root Mean Squared Error -- train: 0.40871408581733704, -- test: 0.7863700985908508 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.3227357864379883, -- test: -13.996354103088379 \n",
      "Root Mean Squared Error -- train: 0.4256816506385803, -- test: 0.7918598055839539 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.4567818641662598, -- test: -13.989093780517578 \n",
      "Root Mean Squared Error -- train: 0.43220826983451843, -- test: 0.7916682362556458 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.6326229572296143, -- test: -13.619479179382324 \n",
      "Root Mean Squared Error -- train: 0.4406232535839081, -- test: 0.7818565964698792 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.056110143661499, -- test: -13.368851661682129 \n",
      "Root Mean Squared Error -- train: 0.4123929440975189, -- test: 0.775132954120636 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.9770348072052, -- test: -12.999756813049316 \n",
      "Root Mean Squared Error -- train: 0.40836867690086365, -- test: 0.7651235461235046 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.059769868850708, -- test: -13.570160865783691 \n",
      "Root Mean Squared Error -- train: 0.412578284740448, -- test: 0.7805380821228027 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.451274871826172\n",
      "Test Root MSE of all sampled models: 0.7500026226043701\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 87 \n",
      "Test Log Likelihood of all models in window: -10.082133293151855\n",
      "Test Root MSE of all models in window: 0.7356948852539062\n",
      "\n",
      "############### EM step 87 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.902034044265747 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 88 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.9742233753204346, -- test: -12.984362602233887 \n",
      "Root Mean Squared Error -- train: 0.4094955027103424, -- test: 0.7673279047012329 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.1025021076202393, -- test: -12.887524604797363 \n",
      "Root Mean Squared Error -- train: 0.41603243350982666, -- test: 0.7646687626838684 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.250361919403076, -- test: -12.570137977600098 \n",
      "Root Mean Squared Error -- train: 0.4234420359134674, -- test: 0.7558878660202026 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.4694364070892334, -- test: -13.740351676940918 \n",
      "Root Mean Squared Error -- train: 0.4341878890991211, -- test: 0.7877784967422485 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.014719247817993, -- test: -13.301060676574707 \n",
      "Root Mean Squared Error -- train: 0.41157037019729614, -- test: 0.7759606242179871 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.1549928188323975, -- test: -12.945220947265625 \n",
      "Root Mean Squared Error -- train: 0.4186778962612152, -- test: 0.766254186630249 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.948105812072754, -- test: -13.457043647766113 \n",
      "Root Mean Squared Error -- train: 0.408151775598526, -- test: 0.7801773548126221 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.9699831008911133, -- test: -13.125832557678223 \n",
      "Root Mean Squared Error -- train: 0.40927764773368835, -- test: 0.7711960673332214 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.0137205123901367, -- test: -13.01690673828125 \n",
      "Root Mean Squared Error -- train: 0.411519318819046, -- test: 0.7682194113731384 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.3073225021362305, -- test: -12.614397048950195 \n",
      "Root Mean Squared Error -- train: 0.4262620508670807, -- test: 0.7571184635162354 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.659693717956543\n",
      "Test Root MSE of all sampled models: 0.7583759427070618\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 88 \n",
      "Test Log Likelihood of all models in window: -9.991072654724121\n",
      "Test Root MSE of all models in window: 0.7359565496444702\n",
      "\n",
      "############### EM step 88 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.139299154281616 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 89 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.173860549926758, -- test: -12.327937126159668 \n",
      "Root Mean Squared Error -- train: 0.4209030866622925, -- test: 0.7516129612922668 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.0527758598327637, -- test: -13.91543197631836 \n",
      "Root Mean Squared Error -- train: 0.4147653579711914, -- test: 0.7950897216796875 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.9973556995391846, -- test: -13.84118938446045 \n",
      "Root Mean Squared Error -- train: 0.41192564368247986, -- test: 0.7931095361709595 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.923015832901001, -- test: -13.080451965332031 \n",
      "Root Mean Squared Error -- train: 0.4080854058265686, -- test: 0.7725272178649902 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.9918644428253174, -- test: -13.268649101257324 \n",
      "Root Mean Squared Error -- train: 0.41164320707321167, -- test: 0.7776697278022766 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.9976816177368164, -- test: -13.529631614685059 \n",
      "Root Mean Squared Error -- train: 0.41194239258766174, -- test: 0.7847453951835632 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.090123176574707, -- test: -13.088269233703613 \n",
      "Root Mean Squared Error -- train: 0.4166681170463562, -- test: 0.7727414965629578 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.4317007064819336, -- test: -12.066462516784668 \n",
      "Root Mean Squared Error -- train: 0.43368348479270935, -- test: 0.7442083358764648 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.049787759780884, -- test: -13.531288146972656 \n",
      "Root Mean Squared Error -- train: 0.41461271047592163, -- test: 0.7847900986671448 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.9381232261657715, -- test: -12.917205810546875 \n",
      "Root Mean Squared Error -- train: 0.4088687598705292, -- test: 0.7680385708808899 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.870705604553223\n",
      "Test Root MSE of all sampled models: 0.766755223274231\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 89 \n",
      "Test Log Likelihood of all models in window: -9.954292297363281\n",
      "Test Root MSE of all models in window: 0.7363097667694092\n",
      "\n",
      "############### EM step 89 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.4192609786987305 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 90 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.929516077041626, -- test: -11.99473762512207 \n",
      "Root Mean Squared Error -- train: 0.40963342785835266, -- test: 0.7445880770683289 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.893691301345825, -- test: -13.140213966369629 \n",
      "Root Mean Squared Error -- train: 0.4077642560005188, -- test: 0.7767003774642944 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.481437921524048, -- test: -12.864633560180664 \n",
      "Root Mean Squared Error -- train: 0.4374217689037323, -- test: 0.7690972685813904 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.9685208797454834, -- test: -13.466841697692871 \n",
      "Root Mean Squared Error -- train: 0.4116588234901428, -- test: 0.7856165170669556 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.206211805343628, -- test: -13.301340103149414 \n",
      "Root Mean Squared Error -- train: 0.42379239201545715, -- test: 0.781111478805542 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.279978036880493, -- test: -13.116462707519531 \n",
      "Root Mean Squared Error -- train: 0.4274879992008209, -- test: 0.776047945022583 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -4.328864574432373, -- test: -12.45266342163086 \n",
      "Root Mean Squared Error -- train: 0.47694724798202515, -- test: 0.7575888633728027 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.9147210121154785, -- test: -12.9533052444458 \n",
      "Root Mean Squared Error -- train: 0.40886250138282776, -- test: 0.7715518474578857 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.938947916030884, -- test: -13.237951278686523 \n",
      "Root Mean Squared Error -- train: 0.41012412309646606, -- test: 0.7793790698051453 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.1822710037231445, -- test: -12.907160758972168 \n",
      "Root Mean Squared Error -- train: 0.422586053609848, -- test: 0.7702754139900208 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -13.044852256774902\n",
      "Test Root MSE of all sampled models: 0.7740778923034668\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 90 \n",
      "Test Log Likelihood of all models in window: -9.916014671325684\n",
      "Test Root MSE of all models in window: 0.7367400527000427\n",
      "\n",
      "############### EM step 90 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.9026741981506348 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 91 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.895118236541748, -- test: -13.508915901184082 \n",
      "Root Mean Squared Error -- train: 0.4090718924999237, -- test: 0.7893927693367004 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.1594719886779785, -- test: -12.74190902709961 \n",
      "Root Mean Squared Error -- train: 0.4227201044559479, -- test: 0.7682462930679321 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.8787336349487305, -- test: -12.887685775756836 \n",
      "Root Mean Squared Error -- train: 0.40821096301078796, -- test: 0.7723098993301392 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.8795113563537598, -- test: -13.57323932647705 \n",
      "Root Mean Squared Error -- train: 0.40825188159942627, -- test: 0.7911404967308044 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.1983230113983154, -- test: -13.651561737060547 \n",
      "Root Mean Squared Error -- train: 0.4246889650821686, -- test: 0.79326331615448 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.9463400840759277, -- test: -13.336230278015137 \n",
      "Root Mean Squared Error -- train: 0.41175174713134766, -- test: 0.7846815586090088 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.9587743282318115, -- test: -13.239084243774414 \n",
      "Root Mean Squared Error -- train: 0.41239967942237854, -- test: 0.7820186614990234 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.9690427780151367, -- test: -13.473588943481445 \n",
      "Root Mean Squared Error -- train: 0.41293397545814514, -- test: 0.7884312272071838 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.338604211807251, -- test: -12.504817008972168 \n",
      "Root Mean Squared Error -- train: 0.4317232668399811, -- test: 0.7615908980369568 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.9004340171813965, -- test: -12.972553253173828 \n",
      "Root Mean Squared Error -- train: 0.40935084223747253, -- test: 0.774665892124176 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -13.06341552734375\n",
      "Test Root MSE of all sampled models: 0.7771803140640259\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 91 \n",
      "Test Log Likelihood of all models in window: -9.908090591430664\n",
      "Test Root MSE of all models in window: 0.7371965050697327\n",
      "\n",
      "############### EM step 91 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.213928461074829 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 92 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.8982462882995605, -- test: -13.150108337402344 \n",
      "Root Mean Squared Error -- train: 0.41044390201568604, -- test: 0.7821183204650879 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.9770078659057617, -- test: -12.47140884399414 \n",
      "Root Mean Squared Error -- train: 0.41457146406173706, -- test: 0.7631285786628723 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.945173978805542, -- test: -13.18925666809082 \n",
      "Root Mean Squared Error -- train: 0.412908136844635, -- test: 0.783199667930603 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.10436749458313, -- test: -13.091906547546387 \n",
      "Root Mean Squared Error -- train: 0.4211602807044983, -- test: 0.7805080413818359 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.064976215362549, -- test: -13.0787353515625 \n",
      "Root Mean Squared Error -- train: 0.4191334843635559, -- test: 0.780143141746521 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.379540205001831, -- test: -12.821908950805664 \n",
      "Root Mean Squared Error -- train: 0.4350554049015045, -- test: 0.7729936838150024 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.2832119464874268, -- test: -13.304587364196777 \n",
      "Root Mean Squared Error -- train: 0.43024224042892456, -- test: 0.7863765358924866 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.8610289096832275, -- test: -13.139161109924316 \n",
      "Root Mean Squared Error -- train: 0.45835644006729126, -- test: 0.781815767288208 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.9635491371154785, -- test: -12.728752136230469 \n",
      "Root Mean Squared Error -- train: 0.41386905312538147, -- test: 0.7703840136528015 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.5641496181488037, -- test: -12.575931549072266 \n",
      "Root Mean Squared Error -- train: 0.4441338777542114, -- test: 0.7660837173461914 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -13.696525573730469\n",
      "Test Root MSE of all sampled models: 0.7970782518386841\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 92 \n",
      "Test Log Likelihood of all models in window: -9.795467376708984\n",
      "Test Root MSE of all models in window: 0.7378734946250916\n",
      "\n",
      "############### EM step 92 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.3552396297454834 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 93 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.080641746520996, -- test: -12.109301567077637 \n",
      "Root Mean Squared Error -- train: 0.42119818925857544, -- test: 0.755272626876831 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.897031784057617, -- test: -12.695919036865234 \n",
      "Root Mean Squared Error -- train: 0.4116007089614868, -- test: 0.7719928026199341 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.8240537643432617, -- test: -13.078017234802246 \n",
      "Root Mean Squared Error -- train: 0.4077233374118805, -- test: 0.7826916575431824 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.893307685852051, -- test: -12.058877944946289 \n",
      "Root Mean Squared Error -- train: 0.41140374541282654, -- test: 0.753818154335022 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.830288887023926, -- test: -13.335236549377441 \n",
      "Root Mean Squared Error -- train: 0.40805602073669434, -- test: 0.7898121476173401 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.208116292953491, -- test: -12.668312072753906 \n",
      "Root Mean Squared Error -- train: 0.42773476243019104, -- test: 0.7712141275405884 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.295628309249878, -- test: -12.576329231262207 \n",
      "Root Mean Squared Error -- train: 0.4321649670600891, -- test: 0.7686136960983276 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.9242918491363525, -- test: -12.730327606201172 \n",
      "Root Mean Squared Error -- train: 0.4130397140979767, -- test: 0.7729623317718506 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.0000908374786377, -- test: -11.744400978088379 \n",
      "Root Mean Squared Error -- train: 0.41701486706733704, -- test: 0.7446826696395874 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.2483460903167725, -- test: -11.980036735534668 \n",
      "Root Mean Squared Error -- train: 0.429777055978775, -- test: 0.7515382170677185 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.318769454956055\n",
      "Test Root MSE of all sampled models: 0.7612851858139038\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 93 \n",
      "Test Log Likelihood of all models in window: -9.68176555633545\n",
      "Test Root MSE of all models in window: 0.738129198551178\n",
      "\n",
      "############### EM step 93 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.942849636077881 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 94 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.929189920425415, -- test: -12.651637077331543 \n",
      "Root Mean Squared Error -- train: 0.4145561158657074, -- test: 0.7733347415924072 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.136153221130371, -- test: -13.48925495147705 \n",
      "Root Mean Squared Error -- train: 0.4253576695919037, -- test: 0.7967208623886108 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.3823978900909424, -- test: -12.549386978149414 \n",
      "Root Mean Squared Error -- train: 0.437862366437912, -- test: 0.7704313397407532 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.147536516189575, -- test: -12.614043235778809 \n",
      "Root Mean Squared Error -- train: 0.4259438216686249, -- test: 0.772268533706665 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.92734956741333, -- test: -12.817033767700195 \n",
      "Root Mean Squared Error -- train: 0.4144588112831116, -- test: 0.778008222579956 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.852931499481201, -- test: -13.021241188049316 \n",
      "Root Mean Squared Error -- train: 0.4105044901371002, -- test: 0.7837401032447815 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.0154900550842285, -- test: -13.070629119873047 \n",
      "Root Mean Squared Error -- train: 0.4190939962863922, -- test: 0.7851200699806213 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.6326255798339844, -- test: -12.523344993591309 \n",
      "Root Mean Squared Error -- train: 0.4502136707305908, -- test: 0.7696900367736816 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.216205358505249, -- test: -12.054338455200195 \n",
      "Root Mean Squared Error -- train: 0.4294627606868744, -- test: 0.7562166452407837 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.1108219623565674, -- test: -12.555627822875977 \n",
      "Root Mean Squared Error -- train: 0.42405036091804504, -- test: 0.7706088423728943 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.462433815002441\n",
      "Test Root MSE of all sampled models: 0.767953634262085\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 94 \n",
      "Test Log Likelihood of all models in window: -9.651877403259277\n",
      "Test Root MSE of all models in window: 0.7384527921676636\n",
      "\n",
      "############### EM step 94 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.174278974533081 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 95 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.950897455215454, -- test: -12.086577415466309 \n",
      "Root Mean Squared Error -- train: 0.41693711280822754, -- test: 0.7596285939216614 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.9166386127471924, -- test: -13.096319198608398 \n",
      "Root Mean Squared Error -- train: 0.4151199460029602, -- test: 0.7884160876274109 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.822176694869995, -- test: -12.4451322555542 \n",
      "Root Mean Squared Error -- train: 0.41006773710250854, -- test: 0.7699741125106812 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.0146899223327637, -- test: -12.944371223449707 \n",
      "Root Mean Squared Error -- train: 0.4202999174594879, -- test: 0.7841516137123108 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.0262041091918945, -- test: -12.326074600219727 \n",
      "Root Mean Squared Error -- train: 0.4209040403366089, -- test: 0.7665543556213379 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.9687840938568115, -- test: -12.428162574768066 \n",
      "Root Mean Squared Error -- train: 0.4178827404975891, -- test: 0.7694876194000244 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.8103272914886475, -- test: -11.702479362487793 \n",
      "Root Mean Squared Error -- train: 0.4094295799732208, -- test: 0.7483872175216675 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.0391693115234375, -- test: -12.369795799255371 \n",
      "Root Mean Squared Error -- train: 0.42158323526382446, -- test: 0.7678119540214539 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.811267614364624, -- test: -12.737902641296387 \n",
      "Root Mean Squared Error -- train: 0.4602266848087311, -- test: 0.7783195972442627 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.7826600074768066, -- test: -12.903398513793945 \n",
      "Root Mean Squared Error -- train: 0.40793561935424805, -- test: 0.782997727394104 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.56527328491211\n",
      "Test Root MSE of all sampled models: 0.7734096050262451\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 95 \n",
      "Test Log Likelihood of all models in window: -9.586856842041016\n",
      "Test Root MSE of all models in window: 0.7388293743133545\n",
      "\n",
      "############### EM step 95 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.834765911102295 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 96 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.814763069152832, -- test: -12.381824493408203 \n",
      "Root Mean Squared Error -- train: 0.41087237000465393, -- test: 0.770659863948822 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.8670225143432617, -- test: -13.003715515136719 \n",
      "Root Mean Squared Error -- train: 0.4136885404586792, -- test: 0.7883841395378113 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.769514322280884, -- test: -12.594727516174316 \n",
      "Root Mean Squared Error -- train: 0.40841832756996155, -- test: 0.7767731547355652 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.7554192543029785, -- test: -12.698999404907227 \n",
      "Root Mean Squared Error -- train: 0.4076508581638336, -- test: 0.7797498106956482 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.9619956016540527, -- test: -11.85400676727295 \n",
      "Root Mean Squared Error -- train: 0.41875791549682617, -- test: 0.7552903294563293 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.790560483932495, -- test: -12.616337776184082 \n",
      "Root Mean Squared Error -- train: 0.4095615744590759, -- test: 0.7773910164833069 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.5261573791503906, -- test: -12.359643936157227 \n",
      "Root Mean Squared Error -- train: 0.44768965244293213, -- test: 0.7700201272964478 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.895029306411743, -- test: -12.707911491394043 \n",
      "Root Mean Squared Error -- train: 0.41518986225128174, -- test: 0.7800036668777466 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.3839845657348633, -- test: -11.970490455627441 \n",
      "Root Mean Squared Error -- train: 0.44057774543762207, -- test: 0.7587090730667114 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.798234224319458, -- test: -12.337255477905273 \n",
      "Root Mean Squared Error -- train: 0.40997761487960815, -- test: 0.7693739533424377 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -14.034061431884766\n",
      "Test Root MSE of all sampled models: 0.8169037103652954\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 96 \n",
      "Test Log Likelihood of all models in window: -9.538361549377441\n",
      "Test Root MSE of all models in window: 0.7396851181983948\n",
      "\n",
      "############### EM step 96 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.5111899375915527 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 97 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.1787307262420654, -- test: -12.116337776184082 \n",
      "Root Mean Squared Error -- train: 0.43136611580848694, -- test: 0.7654176950454712 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.791123628616333, -- test: -12.441210746765137 \n",
      "Root Mean Squared Error -- train: 0.4107781648635864, -- test: 0.7748523950576782 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.7730257511138916, -- test: -12.439791679382324 \n",
      "Root Mean Squared Error -- train: 0.40979161858558655, -- test: 0.7748114466667175 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.7561428546905518, -- test: -12.2725248336792 \n",
      "Root Mean Squared Error -- train: 0.4088691174983978, -- test: 0.7699680328369141 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.17541766166687, -- test: -13.318273544311523 \n",
      "Root Mean Squared Error -- train: 0.4311943054199219, -- test: 0.7997674942016602 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.7621829509735107, -- test: -11.993753433227539 \n",
      "Root Mean Squared Error -- train: 0.40919941663742065, -- test: 0.7618273496627808 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.846224546432495, -- test: -12.566025733947754 \n",
      "Root Mean Squared Error -- train: 0.41376733779907227, -- test: 0.7784466743469238 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.99769926071167, -- test: -12.315746307373047 \n",
      "Root Mean Squared Error -- train: 0.42187556624412537, -- test: 0.7712223529815674 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.756162643432617, -- test: -11.962668418884277 \n",
      "Root Mean Squared Error -- train: 0.4088701903820038, -- test: 0.7609142661094666 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.7942955493927, -- test: -13.098910331726074 \n",
      "Root Mean Squared Error -- train: 0.4109508693218231, -- test: 0.7936092615127563 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.036263465881348\n",
      "Test Root MSE of all sampled models: 0.7630743384361267\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 97 \n",
      "Test Log Likelihood of all models in window: -9.507976531982422\n",
      "Test Root MSE of all models in window: 0.7399300336837769\n",
      "\n",
      "############### EM step 97 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.3709876537323 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 98 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.259819507598877, -- test: -12.161172866821289 \n",
      "Root Mean Squared Error -- train: 0.43684667348861694, -- test: 0.7692162394523621 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.7755186557769775, -- test: -12.771310806274414 \n",
      "Root Mean Squared Error -- train: 0.4111268222332001, -- test: 0.7868736982345581 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.749133825302124, -- test: -11.922224998474121 \n",
      "Root Mean Squared Error -- train: 0.40967926383018494, -- test: 0.762189507484436 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.756267547607422, -- test: -13.054215431213379 \n",
      "Root Mean Squared Error -- train: 0.41007116436958313, -- test: 0.7949278950691223 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.1741485595703125, -- test: -12.0985746383667 \n",
      "Root Mean Squared Error -- train: 0.43240833282470703, -- test: 0.7673816084861755 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.7407872676849365, -- test: -11.860065460205078 \n",
      "Root Mean Squared Error -- train: 0.40922024846076965, -- test: 0.7603509426116943 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -5.025978088378906, -- test: -10.617684364318848 \n",
      "Root Mean Squared Error -- train: 0.5199723243713379, -- test: 0.7226237058639526 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.9957826137542725, -- test: -12.79854965209961 \n",
      "Root Mean Squared Error -- train: 0.42301836609840393, -- test: 0.7876527309417725 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.215175151824951, -- test: -11.418416976928711 \n",
      "Root Mean Squared Error -- train: 0.43453943729400635, -- test: 0.7471577525138855 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.724410057067871, -- test: -12.181221008300781 \n",
      "Root Mean Squared Error -- train: 0.4083181321620941, -- test: 0.7698027491569519 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -11.488410949707031\n",
      "Test Root MSE of all sampled models: 0.7492641806602478\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 98 \n",
      "Test Log Likelihood of all models in window: -9.409980773925781\n",
      "Test Root MSE of all models in window: 0.7400258779525757\n",
      "\n",
      "############### EM step 98 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.142176866531372 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 99 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.724282741546631, -- test: -11.803825378417969 \n",
      "Root Mean Squared Error -- train: 0.4094754755496979, -- test: 0.7610878348350525 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.6994431018829346, -- test: -12.261981964111328 \n",
      "Root Mean Squared Error -- train: 0.4080982208251953, -- test: 0.7746116518974304 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.776413917541504, -- test: -11.744524955749512 \n",
      "Root Mean Squared Error -- train: 0.41235095262527466, -- test: 0.7593196630477905 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.7408688068389893, -- test: -11.983604431152344 \n",
      "Root Mean Squared Error -- train: 0.41039255261421204, -- test: 0.7664229869842529 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.88531494140625, -- test: -12.54736042022705 \n",
      "Root Mean Squared Error -- train: 0.4182940423488617, -- test: 0.7829174995422363 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.723564624786377, -- test: -12.27450180053711 \n",
      "Root Mean Squared Error -- train: 0.4094357192516327, -- test: 0.77497798204422 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.989223003387451, -- test: -11.598393440246582 \n",
      "Root Mean Squared Error -- train: 0.4238869845867157, -- test: 0.7549451589584351 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.703792095184326, -- test: -11.967504501342773 \n",
      "Root Mean Squared Error -- train: 0.4083397090435028, -- test: 0.765946626663208 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.7664239406585693, -- test: -12.575797080993652 \n",
      "Root Mean Squared Error -- train: 0.4118015170097351, -- test: 0.783740222454071 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.7463386058807373, -- test: -12.299041748046875 \n",
      "Root Mean Squared Error -- train: 0.41069450974464417, -- test: 0.7756952047348022 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.616148948669434\n",
      "Test Root MSE of all sampled models: 0.7849063873291016\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.396010398864746\n",
      "Test Root MSE of all models in window: 0.7404928207397461\n",
      "\n",
      "############### EM step 99 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.9507429599761963 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 100 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.8306949138641357, -- test: -11.771767616271973 \n",
      "Root Mean Squared Error -- train: 0.41651487350463867, -- test: 0.7625439763069153 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.688460350036621, -- test: -12.330516815185547 \n",
      "Root Mean Squared Error -- train: 0.4086494445800781, -- test: 0.7790825366973877 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.7304348945617676, -- test: -11.995944023132324 \n",
      "Root Mean Squared Error -- train: 0.4109862148761749, -- test: 0.7692221403121948 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.060645818710327, -- test: -11.9786958694458 \n",
      "Root Mean Squared Error -- train: 0.4289259612560272, -- test: 0.7687104344367981 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.740807294845581, -- test: -12.547595024108887 \n",
      "Root Mean Squared Error -- train: 0.41156163811683655, -- test: 0.7854139804840088 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.7725210189819336, -- test: -12.151938438415527 \n",
      "Root Mean Squared Error -- train: 0.4133159816265106, -- test: 0.7738351821899414 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.130890130996704, -- test: -11.832840919494629 \n",
      "Root Mean Squared Error -- train: 0.432646244764328, -- test: 0.7643690705299377 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.8623385429382324, -- test: -11.771186828613281 \n",
      "Root Mean Squared Error -- train: 0.4182446002960205, -- test: 0.7625265717506409 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.838249921798706, -- test: -11.657357215881348 \n",
      "Root Mean Squared Error -- train: 0.4169284701347351, -- test: 0.7591131329536438 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.7114686965942383, -- test: -12.053156852722168 \n",
      "Root Mean Squared Error -- train: 0.4099319875240326, -- test: 0.7709172368049622 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.58890151977539\n",
      "Test Root MSE of all sampled models: 0.786612868309021\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.39028263092041\n",
      "Test Root MSE of all models in window: 0.7393084168434143\n",
      "\n",
      "############### EM step 100 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.6420466899871826 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 101 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.6969854831695557, -- test: -11.868830680847168 \n",
      "Root Mean Squared Error -- train: 0.41028329730033875, -- test: 0.7678543329238892 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.7052271366119385, -- test: -12.317259788513184 \n",
      "Root Mean Squared Error -- train: 0.4107443392276764, -- test: 0.7811509370803833 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.689011812210083, -- test: -12.236322402954102 \n",
      "Root Mean Squared Error -- train: 0.4098367393016815, -- test: 0.7787678837776184 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.6996119022369385, -- test: -11.721207618713379 \n",
      "Root Mean Squared Error -- train: 0.41043025255203247, -- test: 0.7634264230728149 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.701702117919922, -- test: -11.558808326721191 \n",
      "Root Mean Squared Error -- train: 0.4105471968650818, -- test: 0.7585253715515137 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.6802711486816406, -- test: -11.50696086883545 \n",
      "Root Mean Squared Error -- train: 0.40934666991233826, -- test: 0.7569539546966553 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.2417120933532715, -- test: -13.023502349853516 \n",
      "Root Mean Squared Error -- train: 0.4397180676460266, -- test: 0.8016452193260193 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.697862386703491, -- test: -12.267888069152832 \n",
      "Root Mean Squared Error -- train: 0.4103323817253113, -- test: 0.7796981930732727 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.965975522994995, -- test: -12.171539306640625 \n",
      "Root Mean Squared Error -- train: 0.42507320642471313, -- test: 0.7768550515174866 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.802272319793701, -- test: -12.288902282714844 \n",
      "Root Mean Squared Error -- train: 0.41613489389419556, -- test: 0.7803168296813965 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -11.726776123046875\n",
      "Test Root MSE of all sampled models: 0.7635939121246338\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.207318305969238\n",
      "Test Root MSE of all models in window: 0.7379782199859619\n",
      "\n",
      "############### EM step 101 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.209026575088501 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 102 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.138324737548828, -- test: -11.73876953125 \n",
      "Root Mean Squared Error -- train: 0.43551185727119446, -- test: 0.7663158774375916 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.644962787628174, -- test: -12.021454811096191 \n",
      "Root Mean Squared Error -- train: 0.40849006175994873, -- test: 0.7747952938079834 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.6343889236450195, -- test: -12.257226943969727 \n",
      "Root Mean Squared Error -- train: 0.40789130330085754, -- test: 0.7817969918251038 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.7934303283691406, -- test: -11.81142807006836 \n",
      "Root Mean Squared Error -- train: 0.41680604219436646, -- test: 0.76850426197052 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.6386613845825195, -- test: -12.103907585144043 \n",
      "Root Mean Squared Error -- train: 0.4081333577632904, -- test: 0.7772510051727295 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.9466819763183594, -- test: -11.958409309387207 \n",
      "Root Mean Squared Error -- train: 0.42521944642066956, -- test: 0.7729122042655945 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.6465392112731934, -- test: -11.935128211975098 \n",
      "Root Mean Squared Error -- train: 0.4085792601108551, -- test: 0.7722156643867493 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.7212414741516113, -- test: -13.127989768981934 \n",
      "Root Mean Squared Error -- train: 0.41278350353240967, -- test: 0.8071300983428955 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.6478335857391357, -- test: -12.529158592224121 \n",
      "Root Mean Squared Error -- train: 0.4086524546146393, -- test: 0.7897955775260925 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.790656805038452, -- test: -12.115034103393555 \n",
      "Root Mean Squared Error -- train: 0.41665220260620117, -- test: 0.7775818705558777 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -11.182860374450684\n",
      "Test Root MSE of all sampled models: 0.7493612766265869\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.431565284729004\n",
      "Test Root MSE of all models in window: 0.7376819849014282\n",
      "\n",
      "############### EM step 102 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.9767444133758545 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 103 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.6303865909576416, -- test: -12.319305419921875 \n",
      "Root Mean Squared Error -- train: 0.40879932045936584, -- test: 0.7860692739486694 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.7165448665618896, -- test: -11.929093360900879 \n",
      "Root Mean Squared Error -- train: 0.41367319226264954, -- test: 0.7744352221488953 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -3.006239652633667, -- test: -11.529536247253418 \n",
      "Root Mean Squared Error -- train: 0.429655522108078, -- test: 0.7623385190963745 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.6460890769958496, -- test: -11.81341552734375 \n",
      "Root Mean Squared Error -- train: 0.4096919000148773, -- test: 0.7709525227546692 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.655245780944824, -- test: -11.99119758605957 \n",
      "Root Mean Squared Error -- train: 0.4102115035057068, -- test: 0.7762985229492188 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.684729814529419, -- test: -11.802412033081055 \n",
      "Root Mean Squared Error -- train: 0.4118801951408386, -- test: 0.7706204056739807 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.6544790267944336, -- test: -11.647539138793945 \n",
      "Root Mean Squared Error -- train: 0.4101680517196655, -- test: 0.7659309506416321 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.7913734912872314, -- test: -11.517913818359375 \n",
      "Root Mean Squared Error -- train: 0.4178600013256073, -- test: 0.7619836926460266 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.7301790714263916, -- test: -12.125099182128906 \n",
      "Root Mean Squared Error -- train: 0.41443923115730286, -- test: 0.7803007364273071 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.6795387268066406, -- test: -11.288273811340332 \n",
      "Root Mean Squared Error -- train: 0.4115868806838989, -- test: 0.7549404501914978 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -11.9906587600708\n",
      "Test Root MSE of all sampled models: 0.7762823700904846\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.385871887207031\n",
      "Test Root MSE of all models in window: 0.7386081218719482\n",
      "\n",
      "############### EM step 103 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.4830374717712402 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 104 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.867492437362671, -- test: -11.670865058898926 \n",
      "Root Mean Squared Error -- train: 0.42328575253486633, -- test: 0.7690660357475281 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.6127676963806152, -- test: -11.404967308044434 \n",
      "Root Mean Squared Error -- train: 0.4089513421058655, -- test: 0.7609268426895142 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.6067700386047363, -- test: -12.116052627563477 \n",
      "Root Mean Squared Error -- train: 0.4086077809333801, -- test: 0.7825038433074951 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.6088645458221436, -- test: -11.026638984680176 \n",
      "Root Mean Squared Error -- train: 0.408727765083313, -- test: 0.7491938471794128 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.961691379547119, -- test: -11.778168678283691 \n",
      "Root Mean Squared Error -- train: 0.42846524715423584, -- test: 0.7723264098167419 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.607515811920166, -- test: -11.887194633483887 \n",
      "Root Mean Squared Error -- train: 0.4086504876613617, -- test: 0.7756249308586121 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.5948336124420166, -- test: -12.175047874450684 \n",
      "Root Mean Squared Error -- train: 0.4079231321811676, -- test: 0.7842673063278198 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.637019634246826, -- test: -11.01318359375 \n",
      "Root Mean Squared Error -- train: 0.4103376567363739, -- test: 0.7487730979919434 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.6023757457733154, -- test: -12.15696907043457 \n",
      "Root Mean Squared Error -- train: 0.40835583209991455, -- test: 0.7837272882461548 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.6009082794189453, -- test: -12.173584938049316 \n",
      "Root Mean Squared Error -- train: 0.4082717001438141, -- test: 0.7842236161231995 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.941669464111328\n",
      "Test Root MSE of all sampled models: 0.746533215045929\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.232091903686523\n",
      "Test Root MSE of all models in window: 0.7392699122428894\n",
      "\n",
      "############### EM step 104 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.420034170150757 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 105 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.423349142074585, -- test: -11.831358909606934 \n",
      "Root Mean Squared Error -- train: 0.454299658536911, -- test: 0.7763575315475464 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.5900847911834717, -- test: -11.828581809997559 \n",
      "Root Mean Squared Error -- train: 0.40878987312316895, -- test: 0.776273250579834 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.865605115890503, -- test: -11.310491561889648 \n",
      "Root Mean Squared Error -- train: 0.4243781864643097, -- test: 0.7603802680969238 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.59870982170105, -- test: -11.708046913146973 \n",
      "Root Mean Squared Error -- train: 0.40928685665130615, -- test: 0.7726048827171326 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.5966975688934326, -- test: -11.56157112121582 \n",
      "Root Mean Squared Error -- train: 0.4091709554195404, -- test: 0.7681235074996948 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.120978832244873, -- test: -11.6289701461792 \n",
      "Root Mean Squared Error -- train: 0.4383319020271301, -- test: 0.7701887488365173 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.754615068435669, -- test: -11.657062530517578 \n",
      "Root Mean Squared Error -- train: 0.4181685149669647, -- test: 0.7710480093955994 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.583601236343384, -- test: -11.224647521972656 \n",
      "Root Mean Squared Error -- train: 0.40841585397720337, -- test: 0.7577146291732788 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.608292579650879, -- test: -11.887913703918457 \n",
      "Root Mean Squared Error -- train: 0.40983831882476807, -- test: 0.7780726552009583 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.601081609725952, -- test: -11.943504333496094 \n",
      "Root Mean Squared Error -- train: 0.4094234108924866, -- test: 0.7797548174858093 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.890486717224121\n",
      "Test Root MSE of all sampled models: 0.80787193775177\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.229606628417969\n",
      "Test Root MSE of all models in window: 0.7405621409416199\n",
      "\n",
      "############### EM step 105 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.673832416534424 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 106 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.5632591247558594, -- test: -11.699398040771484 \n",
      "Root Mean Squared Error -- train: 0.4083721935749054, -- test: 0.7747451066970825 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.6740329265594482, -- test: -11.186921119689941 \n",
      "Root Mean Squared Error -- train: 0.4147571921348572, -- test: 0.7588910460472107 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.68696665763855, -- test: -11.55828857421875 \n",
      "Root Mean Squared Error -- train: 0.41549623012542725, -- test: 0.770412266254425 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.938730001449585, -- test: -11.43747329711914 \n",
      "Root Mean Squared Error -- train: 0.4296300709247589, -- test: 0.7666831612586975 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.598355293273926, -- test: -12.146257400512695 \n",
      "Root Mean Squared Error -- train: 0.4104059040546417, -- test: 0.7883089780807495 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.5552127361297607, -- test: -12.149467468261719 \n",
      "Root Mean Squared Error -- train: 0.4079045057296753, -- test: 0.7884056568145752 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.7622861862182617, -- test: -11.010384559631348 \n",
      "Root Mean Squared Error -- train: 0.41977453231811523, -- test: 0.7533524632453918 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.1478517055511475, -- test: -12.465344429016113 \n",
      "Root Mean Squared Error -- train: 0.4410257637500763, -- test: 0.7978534698486328 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.591104030609131, -- test: -11.799700736999512 \n",
      "Root Mean Squared Error -- train: 0.40998655557632446, -- test: 0.777810275554657 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.5506837368011475, -- test: -12.003327369689941 \n",
      "Root Mean Squared Error -- train: 0.40764105319976807, -- test: 0.7839961051940918 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -11.429469108581543\n",
      "Test Root MSE of all sampled models: 0.766435444355011\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.20726203918457\n",
      "Test Root MSE of all models in window: 0.7414050102233887\n",
      "\n",
      "############### EM step 106 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.493192195892334 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 107 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.9773194789886475, -- test: -11.513291358947754 \n",
      "Root Mean Squared Error -- train: 0.4329657256603241, -- test: 0.7713966965675354 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.150017499923706, -- test: -11.047794342041016 \n",
      "Root Mean Squared Error -- train: 0.44238635897636414, -- test: 0.7568522095680237 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.5488176345825195, -- test: -11.842323303222656 \n",
      "Root Mean Squared Error -- train: 0.4086543023586273, -- test: 0.781514048576355 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.6358022689819336, -- test: -11.072837829589844 \n",
      "Root Mean Squared Error -- train: 0.413705050945282, -- test: 0.7576418519020081 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.8308346271514893, -- test: -10.67896842956543 \n",
      "Root Mean Squared Error -- train: 0.42481133341789246, -- test: 0.7451267838478088 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.5526952743530273, -- test: -11.778643608093262 \n",
      "Root Mean Squared Error -- train: 0.4088807702064514, -- test: 0.7795661687850952 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.5738303661346436, -- test: -10.998678207397461 \n",
      "Root Mean Squared Error -- train: 0.41011303663253784, -- test: 0.7553012371063232 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -3.036703586578369, -- test: -11.411815643310547 \n",
      "Root Mean Squared Error -- train: 0.43622806668281555, -- test: 0.7682496309280396 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.582947015762329, -- test: -12.427556037902832 \n",
      "Root Mean Squared Error -- train: 0.41064342856407166, -- test: 0.7991928458213806 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.662501573562622, -- test: -12.051913261413574 \n",
      "Root Mean Squared Error -- train: 0.4152430295944214, -- test: 0.7878909111022949 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.153599739074707\n",
      "Test Root MSE of all sampled models: 0.790966272354126\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.18338680267334\n",
      "Test Root MSE of all models in window: 0.7424886226654053\n",
      "\n",
      "############### EM step 107 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.949458599090576 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 108 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.6415035724639893, -- test: -11.745540618896484 \n",
      "Root Mean Squared Error -- train: 0.4151846170425415, -- test: 0.7809672355651855 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.631789445877075, -- test: -11.349958419799805 \n",
      "Root Mean Squared Error -- train: 0.4146220088005066, -- test: 0.7686992287635803 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.5238842964172363, -- test: -11.517120361328125 \n",
      "Root Mean Squared Error -- train: 0.40832045674324036, -- test: 0.7739070057868958 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.6194374561309814, -- test: -11.727950096130371 \n",
      "Root Mean Squared Error -- train: 0.4139055609703064, -- test: 0.7804257869720459 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -3.3567914962768555, -- test: -10.637823104858398 \n",
      "Root Mean Squared Error -- train: 0.4547024667263031, -- test: 0.7461058497428894 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.6912503242492676, -- test: -11.817586898803711 \n",
      "Root Mean Squared Error -- train: 0.41805389523506165, -- test: 0.783180832862854 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.6921775341033936, -- test: -10.612722396850586 \n",
      "Root Mean Squared Error -- train: 0.41810721158981323, -- test: 0.7452969551086426 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.947474718093872, -- test: -10.829272270202637 \n",
      "Root Mean Squared Error -- train: 0.4325309097766876, -- test: 0.7522464394569397 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.7623660564422607, -- test: -11.105786323547363 \n",
      "Root Mean Squared Error -- train: 0.4221218228340149, -- test: 0.7610280513763428 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.5316145420074463, -- test: -11.23124885559082 \n",
      "Root Mean Squared Error -- train: 0.40877512097358704, -- test: 0.764979362487793 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.479728698730469\n",
      "Test Root MSE of all sampled models: 0.7409966588020325\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.040022850036621\n",
      "Test Root MSE of all models in window: 0.7429871559143066\n",
      "\n",
      "############### EM step 108 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.5221333503723145 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 109 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.6056931018829346, -- test: -11.373054504394531 \n",
      "Root Mean Squared Error -- train: 0.41424450278282166, -- test: 0.7717874050140381 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.774758815765381, -- test: -10.319430351257324 \n",
      "Root Mean Squared Error -- train: 0.4239998161792755, -- test: 0.738034188747406 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.5095326900482178, -- test: -11.61465835571289 \n",
      "Root Mean Squared Error -- train: 0.40859201550483704, -- test: 0.7793212532997131 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.803096294403076, -- test: -11.308341979980469 \n",
      "Root Mean Squared Error -- train: 0.42561304569244385, -- test: 0.7697569727897644 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.552593469619751, -- test: -10.580053329467773 \n",
      "Root Mean Squared Error -- train: 0.4111328125, -- test: 0.7465253472328186 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.5192344188690186, -- test: -10.87502670288086 \n",
      "Root Mean Squared Error -- train: 0.4091658592224121, -- test: 0.7560206651687622 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.0903680324554443, -- test: -11.771976470947266 \n",
      "Root Mean Squared Error -- train: 0.4416346251964569, -- test: 0.7841879725456238 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.6355714797973633, -- test: -11.303853988647461 \n",
      "Root Mean Squared Error -- train: 0.4159851372241974, -- test: 0.7696160078048706 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.7040703296661377, -- test: -11.824662208557129 \n",
      "Root Mean Squared Error -- train: 0.419948548078537, -- test: 0.7858110666275024 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.551612377166748, -- test: -11.346841812133789 \n",
      "Root Mean Squared Error -- train: 0.4110751152038574, -- test: 0.770965576171875 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -11.3728609085083\n",
      "Test Root MSE of all sampled models: 0.7717813849449158\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.123690605163574\n",
      "Test Root MSE of all models in window: 0.7439742684364319\n",
      "\n",
      "############### EM step 109 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.4549736976623535 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 110 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.5497257709503174, -- test: -10.852770805358887 \n",
      "Root Mean Squared Error -- train: 0.41208305954933167, -- test: 0.7576074004173279 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.4771552085876465, -- test: -11.54407024383545 \n",
      "Root Mean Squared Error -- train: 0.4077744483947754, -- test: 0.7794988751411438 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.6085431575775146, -- test: -11.383927345275879 \n",
      "Root Mean Squared Error -- train: 0.4155423045158386, -- test: 0.7744826674461365 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.476970672607422, -- test: -11.32687759399414 \n",
      "Root Mean Squared Error -- train: 0.40776345133781433, -- test: 0.7726877927780151 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.4817724227905273, -- test: -11.337101936340332 \n",
      "Root Mean Squared Error -- train: 0.40804994106292725, -- test: 0.7730098366737366 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.733042001724243, -- test: -11.435425758361816 \n",
      "Root Mean Squared Error -- train: 0.4227712154388428, -- test: 0.7760993838310242 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.7128665447235107, -- test: -11.022953987121582 \n",
      "Root Mean Squared Error -- train: 0.4216081500053406, -- test: 0.7630548477172852 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.746366500854492, -- test: -11.60815715789795 \n",
      "Root Mean Squared Error -- train: 0.42353755235671997, -- test: 0.7814972400665283 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.494174003601074, -- test: -11.437307357788086 \n",
      "Root Mean Squared Error -- train: 0.4087889492511749, -- test: 0.7761582732200623 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.492478370666504, -- test: -10.720088958740234 \n",
      "Root Mean Squared Error -- train: 0.4086879789829254, -- test: 0.7533330321311951 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.91897201538086\n",
      "Test Root MSE of all sampled models: 0.7597311735153198\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.093218803405762\n",
      "Test Root MSE of all models in window: 0.74477618932724\n",
      "\n",
      "############### EM step 110 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.4747812747955322 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 111 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.5027122497558594, -- test: -11.624957084655762 \n",
      "Root Mean Squared Error -- train: 0.4104008674621582, -- test: 0.7843903303146362 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.7948906421661377, -- test: -10.949631690979004 \n",
      "Root Mean Squared Error -- train: 0.4274819493293762, -- test: 0.763012707233429 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.4841275215148926, -- test: -11.640422821044922 \n",
      "Root Mean Squared Error -- train: 0.4092903137207031, -- test: 0.7848731279373169 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.4580745697021484, -- test: -11.17654800415039 \n",
      "Root Mean Squared Error -- train: 0.40772831439971924, -- test: 0.7702620029449463 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.5776426792144775, -- test: -11.872562408447266 \n",
      "Root Mean Squared Error -- train: 0.4148484766483307, -- test: 0.7920837998390198 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.4597489833831787, -- test: -11.246136665344238 \n",
      "Root Mean Squared Error -- train: 0.4078288674354553, -- test: 0.77247154712677 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -3.045944929122925, -- test: -11.545862197875977 \n",
      "Root Mean Squared Error -- train: 0.4416314363479614, -- test: 0.7819167971611023 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.4594287872314453, -- test: -11.214919090270996 \n",
      "Root Mean Squared Error -- train: 0.40780967473983765, -- test: 0.7714810967445374 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.4904065132141113, -- test: -11.1053466796875 \n",
      "Root Mean Squared Error -- train: 0.40966588258743286, -- test: 0.76799476146698 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.6115787029266357, -- test: -10.767075538635254 \n",
      "Root Mean Squared Error -- train: 0.4168471693992615, -- test: 0.7571302056312561 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.471785545349121\n",
      "Test Root MSE of all sampled models: 0.7475171685218811\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.075566291809082\n",
      "Test Root MSE of all models in window: 0.7454749345779419\n",
      "\n",
      "############### EM step 111 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.5518354177474976 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 112 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.784827709197998, -- test: -11.060468673706055 \n",
      "Root Mean Squared Error -- train: 0.42803117632865906, -- test: 0.7688013315200806 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.5455844402313232, -- test: -11.240342140197754 \n",
      "Root Mean Squared Error -- train: 0.41402918100357056, -- test: 0.7745451927185059 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.6139466762542725, -- test: -10.996795654296875 \n",
      "Root Mean Squared Error -- train: 0.4180780053138733, -- test: 0.7667578458786011 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.5684080123901367, -- test: -10.994545936584473 \n",
      "Root Mean Squared Error -- train: 0.41538530588150024, -- test: 0.7666855454444885 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.495885133743286, -- test: -11.664484024047852 \n",
      "Root Mean Squared Error -- train: 0.411060631275177, -- test: 0.7879232168197632 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.517890214920044, -- test: -10.99328327178955 \n",
      "Root Mean Squared Error -- train: 0.41237765550613403, -- test: 0.7666449546813965 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.4525301456451416, -- test: -11.416394233703613 \n",
      "Root Mean Squared Error -- train: 0.40845343470573425, -- test: 0.7801259160041809 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.554898262023926, -- test: -11.038402557373047 \n",
      "Root Mean Squared Error -- train: 0.41458314657211304, -- test: 0.7680937647819519 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.505842685699463, -- test: -11.70794677734375 \n",
      "Root Mean Squared Error -- train: 0.4116571247577667, -- test: 0.7892812490463257 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.445945978164673, -- test: -11.683917999267578 \n",
      "Root Mean Squared Error -- train: 0.40805599093437195, -- test: 0.788530707359314 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -12.02372932434082\n",
      "Test Root MSE of all sampled models: 0.799079179763794\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -9.065985679626465\n",
      "Test Root MSE of all models in window: 0.7466311454772949\n",
      "\n",
      "############### EM step 112 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.5286054611206055 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 113 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.6351630687713623, -- test: -12.066106796264648 \n",
      "Root Mean Squared Error -- train: 0.42045852541923523, -- test: 0.8028013706207275 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.580475091934204, -- test: -10.78030776977539 \n",
      "Root Mean Squared Error -- train: 0.4172208607196808, -- test: 0.7620524764060974 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.5406532287597656, -- test: -10.930768013000488 \n",
      "Root Mean Squared Error -- train: 0.41484740376472473, -- test: 0.7669326663017273 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.4708030223846436, -- test: -10.705704689025879 \n",
      "Root Mean Squared Error -- train: 0.4106510877609253, -- test: 0.7596211433410645 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.529910087585449, -- test: -11.125553131103516 \n",
      "Root Mean Squared Error -- train: 0.41420480608940125, -- test: 0.7732048034667969 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.5653223991394043, -- test: -10.398362159729004 \n",
      "Root Mean Squared Error -- train: 0.416319340467453, -- test: 0.7495213747024536 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.428135395050049, -- test: -11.381512641906738 \n",
      "Root Mean Squared Error -- train: 0.4080665707588196, -- test: 0.7813700437545776 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.5469300746917725, -- test: -10.731934547424316 \n",
      "Root Mean Squared Error -- train: 0.4152224361896515, -- test: 0.7604768872261047 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.5380682945251465, -- test: -11.127723693847656 \n",
      "Root Mean Squared Error -- train: 0.4146929085254669, -- test: 0.7732743620872498 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -3.722169876098633, -- test: -10.662528038024902 \n",
      "Root Mean Squared Error -- train: 0.48030489683151245, -- test: 0.7582103610038757 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.034327507019043\n",
      "Test Root MSE of all sampled models: 0.7373797297477722\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.877575874328613\n",
      "Test Root MSE of all models in window: 0.7470575571060181\n",
      "\n",
      "############### EM step 113 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.8719024658203125 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 114 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.406358480453491, -- test: -10.914677619934082 \n",
      "Root Mean Squared Error -- train: 0.4078337550163269, -- test: 0.7687323689460754 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.407508611679077, -- test: -11.121615409851074 \n",
      "Root Mean Squared Error -- train: 0.40790414810180664, -- test: 0.7754205465316772 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.636200189590454, -- test: -10.725525856018066 \n",
      "Root Mean Squared Error -- train: 0.42166218161582947, -- test: 0.7625677585601807 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.4493279457092285, -- test: -10.529494285583496 \n",
      "Root Mean Squared Error -- train: 0.4104544222354889, -- test: 0.7561258673667908 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.4133920669555664, -- test: -10.981019020080566 \n",
      "Root Mean Squared Error -- train: 0.4082638621330261, -- test: 0.7708828449249268 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.5035579204559326, -- test: -11.584587097167969 \n",
      "Root Mean Squared Error -- train: 0.4137381613254547, -- test: 0.7901787161827087 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.4254233837127686, -- test: -10.824355125427246 \n",
      "Root Mean Squared Error -- train: 0.40899860858917236, -- test: 0.7657948732376099 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.7028536796569824, -- test: -11.092394828796387 \n",
      "Root Mean Squared Error -- train: 0.42558833956718445, -- test: 0.7744796276092529 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.1251165866851807, -- test: -11.219827651977539 \n",
      "Root Mean Squared Error -- train: 0.4496655762195587, -- test: 0.7785746455192566 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.427753210067749, -- test: -10.783997535705566 \n",
      "Root Mean Squared Error -- train: 0.4091407060623169, -- test: 0.7644787430763245 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.10867691040039\n",
      "Test Root MSE of all sampled models: 0.7421082854270935\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.851749420166016\n",
      "Test Root MSE of all models in window: 0.7475547194480896\n",
      "\n",
      "############### EM step 114 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.9501980543136597 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 115 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.4582247734069824, -- test: -10.503417015075684 \n",
      "Root Mean Squared Error -- train: 0.41207751631736755, -- test: 0.7574973702430725 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.4376487731933594, -- test: -11.482230186462402 \n",
      "Root Mean Squared Error -- train: 0.4108218848705292, -- test: 0.7892743349075317 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.449279546737671, -- test: -10.858725547790527 \n",
      "Root Mean Squared Error -- train: 0.41153210401535034, -- test: 0.7691841721534729 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.5154106616973877, -- test: -10.550202369689941 \n",
      "Root Mean Squared Error -- train: 0.4155472218990326, -- test: 0.7590464949607849 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.3875975608825684, -- test: -10.924725532531738 \n",
      "Root Mean Squared Error -- train: 0.40775150060653687, -- test: 0.7713354825973511 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.4242069721221924, -- test: -11.310791969299316 \n",
      "Root Mean Squared Error -- train: 0.4099995493888855, -- test: 0.7838016748428345 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.8024675846099854, -- test: -10.70569133758545 \n",
      "Root Mean Squared Error -- train: 0.43254390358924866, -- test: 0.7641724944114685 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.4863243103027344, -- test: -10.523475646972656 \n",
      "Root Mean Squared Error -- train: 0.4137860834598541, -- test: 0.7581619024276733 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.3955187797546387, -- test: -11.103659629821777 \n",
      "Root Mean Squared Error -- train: 0.40823894739151, -- test: 0.7771381735801697 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.3962152004241943, -- test: -10.594618797302246 \n",
      "Root Mean Squared Error -- train: 0.40828177332878113, -- test: 0.7605142593383789 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -11.5430908203125\n",
      "Test Root MSE of all sampled models: 0.7912079691886902\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.846817970275879\n",
      "Test Root MSE of all models in window: 0.7485445141792297\n",
      "\n",
      "############### EM step 115 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.749281644821167 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 116 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.368102788925171, -- test: -10.823508262634277 \n",
      "Root Mean Squared Error -- train: 0.40762004256248474, -- test: 0.7703178524971008 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.4100260734558105, -- test: -10.038496017456055 \n",
      "Root Mean Squared Error -- train: 0.4102102220058441, -- test: 0.7441266775131226 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.759659767150879, -- test: -11.085546493530273 \n",
      "Root Mean Squared Error -- train: 0.4312061667442322, -- test: 0.7788645029067993 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.3667891025543213, -- test: -10.93458366394043 \n",
      "Root Mean Squared Error -- train: 0.40753862261772156, -- test: 0.7739522457122803 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.4245381355285645, -- test: -10.433444023132324 \n",
      "Root Mean Squared Error -- train: 0.4111030101776123, -- test: 0.7574169635772705 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.3886375427246094, -- test: -11.291897773742676 \n",
      "Root Mean Squared Error -- train: 0.4088907837867737, -- test: 0.7855294346809387 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.428241491317749, -- test: -10.536397933959961 \n",
      "Root Mean Squared Error -- train: 0.41133052110671997, -- test: 0.7608432173728943 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.4414689540863037, -- test: -10.830060958862305 \n",
      "Root Mean Squared Error -- train: 0.41214218735694885, -- test: 0.7705327868461609 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.814476490020752, -- test: -10.762728691101074 \n",
      "Root Mean Squared Error -- train: 0.43440595269203186, -- test: 0.7683218717575073 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.395554780960083, -- test: -10.28463363647461 \n",
      "Root Mean Squared Error -- train: 0.4093179702758789, -- test: 0.7524369359016418 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -11.288566589355469\n",
      "Test Root MSE of all sampled models: 0.7854223251342773\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.839666366577148\n",
      "Test Root MSE of all models in window: 0.7497256398200989\n",
      "\n",
      "############### EM step 116 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.113978147506714 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 117 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.66565203666687, -- test: -10.600677490234375 \n",
      "Root Mean Squared Error -- train: 0.48268139362335205, -- test: 0.7652072310447693 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.361480951309204, -- test: -11.0723876953125 \n",
      "Root Mean Squared Error -- train: 0.40826496481895447, -- test: 0.7807193398475647 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.6477017402648926, -- test: -10.428742408752441 \n",
      "Root Mean Squared Error -- train: 0.4257124364376068, -- test: 0.7594743371009827 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.801694393157959, -- test: -10.132818222045898 \n",
      "Root Mean Squared Error -- train: 0.43480998277664185, -- test: 0.7495046854019165 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.4647140502929688, -- test: -10.534195899963379 \n",
      "Root Mean Squared Error -- train: 0.4146425127983093, -- test: 0.7629956007003784 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.361600160598755, -- test: -11.166752815246582 \n",
      "Root Mean Squared Error -- train: 0.4082723557949066, -- test: 0.7837857007980347 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.6634366512298584, -- test: -11.035993576049805 \n",
      "Root Mean Squared Error -- train: 0.42665091156959534, -- test: 0.7795335650444031 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.376298666000366, -- test: -11.138812065124512 \n",
      "Root Mean Squared Error -- train: 0.409186452627182, -- test: 0.7828789949417114 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.578768730163574, -- test: -10.60977554321289 \n",
      "Root Mean Squared Error -- train: 0.42157644033432007, -- test: 0.7655093669891357 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.3808209896087646, -- test: -10.777368545532227 \n",
      "Root Mean Squared Error -- train: 0.40946730971336365, -- test: 0.7710541486740112 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -11.246865272521973\n",
      "Test Root MSE of all sampled models: 0.7863795161247253\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.818696022033691\n",
      "Test Root MSE of all models in window: 0.7505500912666321\n",
      "\n",
      "############### EM step 117 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.4424538612365723 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 118 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.482436418533325, -- test: -10.551370620727539 \n",
      "Root Mean Squared Error -- train: 0.4168081283569336, -- test: 0.7657935619354248 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.555433511734009, -- test: -10.667607307434082 \n",
      "Root Mean Squared Error -- train: 0.4212632477283478, -- test: 0.7696655988693237 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.42897629737854, -- test: -10.335559844970703 \n",
      "Root Mean Squared Error -- train: 0.41351497173309326, -- test: 0.7585523128509521 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -3.028536558151245, -- test: -10.275321006774902 \n",
      "Root Mean Squared Error -- train: 0.4490668475627899, -- test: 0.7565186023712158 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.5363805294036865, -- test: -10.520946502685547 \n",
      "Root Mean Squared Error -- train: 0.4201049208641052, -- test: 0.7647769451141357 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.4687721729278564, -- test: -10.283575057983398 \n",
      "Root Mean Squared Error -- train: 0.4159688949584961, -- test: 0.7567976713180542 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.55334734916687, -- test: -10.472142219543457 \n",
      "Root Mean Squared Error -- train: 0.4211365580558777, -- test: 0.7631431818008423 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.655637741088867, -- test: -10.728896141052246 \n",
      "Root Mean Squared Error -- train: 0.4273030757904053, -- test: 0.7716993689537048 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.7342581748962402, -- test: -10.78948974609375 \n",
      "Root Mean Squared Error -- train: 0.4319828748703003, -- test: 0.7737048864364624 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.349898099899292, -- test: -10.451635360717773 \n",
      "Root Mean Squared Error -- train: 0.4085950553417206, -- test: 0.7624556422233582 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.352678298950195\n",
      "Test Root MSE of all sampled models: 0.7591292262077332\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.831025123596191\n",
      "Test Root MSE of all models in window: 0.7514182925224304\n",
      "\n",
      "############### EM step 118 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.349867343902588 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 119 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.3329291343688965, -- test: -10.648477554321289 \n",
      "Root Mean Squared Error -- train: 0.4085761606693268, -- test: 0.7712593674659729 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -3.115706443786621, -- test: -9.699939727783203 \n",
      "Root Mean Squared Error -- train: 0.45520883798599243, -- test: 0.7389388084411621 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.3427488803863525, -- test: -9.959946632385254 \n",
      "Root Mean Squared Error -- train: 0.40919408202171326, -- test: 0.7479373216629028 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.326815366744995, -- test: -10.302414894104004 \n",
      "Root Mean Squared Error -- train: 0.4081909656524658, -- test: 0.7596270442008972 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.3499016761779785, -- test: -9.956350326538086 \n",
      "Root Mean Squared Error -- train: 0.4096435606479645, -- test: 0.7478136420249939 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.320857524871826, -- test: -10.750504493713379 \n",
      "Root Mean Squared Error -- train: 0.40781524777412415, -- test: 0.7746555805206299 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.318959951400757, -- test: -11.01675033569336 \n",
      "Root Mean Squared Error -- train: 0.4076955318450928, -- test: 0.7834487557411194 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.3872761726379395, -- test: -10.303170204162598 \n",
      "Root Mean Squared Error -- train: 0.4119843542575836, -- test: 0.7596525549888611 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.9032366275787354, -- test: -10.687967300415039 \n",
      "Root Mean Squared Error -- train: 0.44303691387176514, -- test: 0.7725756764411926 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.539695978164673, -- test: -9.756396293640137 \n",
      "Root Mean Squared Error -- train: 0.42139577865600586, -- test: 0.7409020066261292 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.651605606079102\n",
      "Test Root MSE of all sampled models: 0.7713637351989746\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.836688995361328\n",
      "Test Root MSE of all models in window: 0.7524793148040771\n",
      "\n",
      "############### EM step 119 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.188274621963501 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 120 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.7768404483795166, -- test: -10.100656509399414 \n",
      "Root Mean Squared Error -- train: 0.4367636442184448, -- test: 0.7549170255661011 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.3464722633361816, -- test: -10.423575401306152 \n",
      "Root Mean Squared Error -- train: 0.4104671776294708, -- test: 0.7659088969230652 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.3316590785980225, -- test: -10.531652450561523 \n",
      "Root Mean Squared Error -- train: 0.40953198075294495, -- test: 0.7695527672767639 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.375617742538452, -- test: -10.12362289428711 \n",
      "Root Mean Squared Error -- train: 0.4123009741306305, -- test: 0.7557040452957153 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.4577364921569824, -- test: -11.179235458374023 \n",
      "Root Mean Squared Error -- train: 0.4174244701862335, -- test: 0.7910343408584595 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.3600120544433594, -- test: -10.520776748657227 \n",
      "Root Mean Squared Error -- train: 0.4113200902938843, -- test: 0.769186794757843 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.4583840370178223, -- test: -10.655233383178711 \n",
      "Root Mean Squared Error -- train: 0.41746458411216736, -- test: 0.7736981511116028 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.418834686279297, -- test: -10.830888748168945 \n",
      "Root Mean Squared Error -- train: 0.4150052070617676, -- test: 0.7795525789260864 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.3319151401519775, -- test: -10.591552734375 \n",
      "Root Mean Squared Error -- train: 0.40954816341400146, -- test: 0.7715648412704468 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.452681541442871, -- test: -10.401196479797363 \n",
      "Root Mean Squared Error -- train: 0.4171108901500702, -- test: 0.7651522159576416 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.47775650024414\n",
      "Test Root MSE of all sampled models: 0.7677378058433533\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.812488555908203\n",
      "Test Root MSE of all models in window: 0.7533197999000549\n",
      "\n",
      "############### EM step 120 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.3287878036499023 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 121 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.374368190765381, -- test: -10.727965354919434 \n",
      "Root Mean Squared Error -- train: 0.4132651686668396, -- test: 0.7783443331718445 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.2912356853485107, -- test: -10.620862007141113 \n",
      "Root Mean Squared Error -- train: 0.4079935848712921, -- test: 0.7747530937194824 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.5453453063964844, -- test: -10.387163162231445 \n",
      "Root Mean Squared Error -- train: 0.4239010214805603, -- test: 0.7668585181236267 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.287287473678589, -- test: -10.41450309753418 \n",
      "Root Mean Squared Error -- train: 0.407741516828537, -- test: 0.7677863240242004 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.294874429702759, -- test: -10.319588661193848 \n",
      "Root Mean Squared Error -- train: 0.40822574496269226, -- test: 0.7645606398582458 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.431159496307373, -- test: -9.552715301513672 \n",
      "Root Mean Squared Error -- train: 0.4168280363082886, -- test: 0.7379812002182007 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.301243305206299, -- test: -10.6010103225708 \n",
      "Root Mean Squared Error -- train: 0.4086317718029022, -- test: 0.7740856409072876 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.524909019470215, -- test: -10.593676567077637 \n",
      "Root Mean Squared Error -- train: 0.42264384031295776, -- test: 0.7738388776779175 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.4249978065490723, -- test: -10.67786979675293 \n",
      "Root Mean Squared Error -- train: 0.41644296050071716, -- test: 0.7766667008399963 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.2981579303741455, -- test: -10.189878463745117 \n",
      "Root Mean Squared Error -- train: 0.4084351360797882, -- test: 0.7601302862167358 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.27429485321045\n",
      "Test Root MSE of all sampled models: 0.7630164623260498\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.787014961242676\n",
      "Test Root MSE of all models in window: 0.7539904117584229\n",
      "\n",
      "############### EM step 121 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.7636218070983887 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 122 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.278325319290161, -- test: -10.284533500671387 \n",
      "Root Mean Squared Error -- train: 0.4082033336162567, -- test: 0.7655644416809082 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.2805633544921875, -- test: -10.252593994140625 \n",
      "Root Mean Squared Error -- train: 0.40834692120552063, -- test: 0.7644708156585693 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.3003036975860596, -- test: -10.595510482788086 \n",
      "Root Mean Squared Error -- train: 0.409611314535141, -- test: 0.7761324048042297 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.5971930027008057, -- test: -10.658517837524414 \n",
      "Root Mean Squared Error -- train: 0.42817750573158264, -- test: 0.7782561182975769 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.2916955947875977, -- test: -10.474370002746582 \n",
      "Root Mean Squared Error -- train: 0.40906044840812683, -- test: 0.7720329165458679 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.7605578899383545, -- test: -10.048526763916016 \n",
      "Root Mean Squared Error -- train: 0.43805813789367676, -- test: 0.757445752620697 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.288559913635254, -- test: -9.911931991577148 \n",
      "Root Mean Squared Error -- train: 0.40885958075523376, -- test: 0.7527069449424744 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.2881274223327637, -- test: -10.033820152282715 \n",
      "Root Mean Squared Error -- train: 0.4088318645954132, -- test: 0.7569370269775391 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.290217638015747, -- test: -10.243948936462402 \n",
      "Root Mean Squared Error -- train: 0.4089657962322235, -- test: 0.7641745209693909 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.3579156398773193, -- test: -10.321880340576172 \n",
      "Root Mean Squared Error -- train: 0.41327935457229614, -- test: 0.7668412923812866 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.852588653564453\n",
      "Test Root MSE of all sampled models: 0.7506387829780579\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.756129264831543\n",
      "Test Root MSE of all models in window: 0.7545667886734009\n",
      "\n",
      "############### EM step 122 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.9578721523284912 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 123 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.3172080516815186, -- test: -10.193224906921387 \n",
      "Root Mean Squared Error -- train: 0.4117186665534973, -- test: 0.7645910382270813 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.5235698223114014, -- test: -10.603006362915039 \n",
      "Root Mean Squared Error -- train: 0.4247211515903473, -- test: 0.7785859107971191 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.4408440589904785, -- test: -10.046528816223145 \n",
      "Root Mean Squared Error -- train: 0.4195571541786194, -- test: 0.7595183253288269 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.2669661045074463, -- test: -10.592581748962402 \n",
      "Root Mean Squared Error -- train: 0.4084903299808502, -- test: 0.778232991695404 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.3438775539398193, -- test: -10.376864433288574 \n",
      "Root Mean Squared Error -- train: 0.4134220480918884, -- test: 0.7708940505981445 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.2834537029266357, -- test: -10.057238578796387 \n",
      "Root Mean Squared Error -- train: 0.40955254435539246, -- test: 0.7598899602890015 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.6940133571624756, -- test: -10.315888404846191 \n",
      "Root Mean Squared Error -- train: 0.4351676404476166, -- test: 0.7688069939613342 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.2583253383636475, -- test: -10.74856948852539 \n",
      "Root Mean Squared Error -- train: 0.4079325497150421, -- test: 0.7834970355033875 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.318629264831543, -- test: -10.10840129852295 \n",
      "Root Mean Squared Error -- train: 0.41180962324142456, -- test: 0.761661946773529 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.5864343643188477, -- test: -10.329989433288574 \n",
      "Root Mean Squared Error -- train: 0.42860379815101624, -- test: 0.7692901492118835 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -11.276859283447266\n",
      "Test Root MSE of all sampled models: 0.8010678887367249\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.736449241638184\n",
      "Test Root MSE of all models in window: 0.755710244178772\n",
      "\n",
      "############### EM step 123 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.1392910480499268 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 124 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.2462704181671143, -- test: -10.444705963134766 \n",
      "Root Mean Squared Error -- train: 0.4081577658653259, -- test: 0.7753787636756897 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.6657443046569824, -- test: -10.415696144104004 \n",
      "Root Mean Squared Error -- train: 0.4345459043979645, -- test: 0.774386465549469 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.409766912460327, -- test: -10.504585266113281 \n",
      "Root Mean Squared Error -- train: 0.4186408221721649, -- test: 0.7774230241775513 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.6460344791412354, -- test: -10.612970352172852 \n",
      "Root Mean Squared Error -- train: 0.43334195017814636, -- test: 0.7811096906661987 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.375133514404297, -- test: -10.152813911437988 \n",
      "Root Mean Squared Error -- train: 0.41644224524497986, -- test: 0.7653354406356812 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -3.0120246410369873, -- test: -10.514369010925293 \n",
      "Root Mean Squared Error -- train: 0.45517832040786743, -- test: 0.7777565121650696 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.4810492992401123, -- test: -10.108997344970703 \n",
      "Root Mean Squared Error -- train: 0.42313000559806824, -- test: 0.7638164758682251 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.2862401008605957, -- test: -10.058784484863281 \n",
      "Root Mean Squared Error -- train: 0.410745233297348, -- test: 0.7620718479156494 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.401111602783203, -- test: -10.279167175292969 \n",
      "Root Mean Squared Error -- train: 0.41809242963790894, -- test: 0.7696990370750427 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.431522846221924, -- test: -9.891779899597168 \n",
      "Root Mean Squared Error -- train: 0.4200160503387451, -- test: 0.7562409043312073 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.120110511779785\n",
      "Test Root MSE of all sampled models: 0.7642019391059875\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.64217472076416\n",
      "Test Root MSE of all models in window: 0.756390392780304\n",
      "\n",
      "############### EM step 124 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.3634696006774902 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 125 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.438797950744629, -- test: -10.312527656555176 \n",
      "Root Mean Squared Error -- train: 0.4215226471424103, -- test: 0.7730063796043396 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.227787494659424, -- test: -10.173274040222168 \n",
      "Root Mean Squared Error -- train: 0.40795767307281494, -- test: 0.7681882977485657 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.243720769882202, -- test: -10.08996295928955 \n",
      "Root Mean Squared Error -- train: 0.40899765491485596, -- test: 0.7652912735939026 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.3108391761779785, -- test: -9.883626937866211 \n",
      "Root Mean Squared Error -- train: 0.41334983706474304, -- test: 0.7580686807632446 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.2392079830169678, -- test: -9.636019706726074 \n",
      "Root Mean Squared Error -- train: 0.40870338678359985, -- test: 0.7493095397949219 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.3049416542053223, -- test: -10.459280014038086 \n",
      "Root Mean Squared Error -- train: 0.41296929121017456, -- test: 0.778051495552063 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.2252275943756104, -- test: -10.474199295043945 \n",
      "Root Mean Squared Error -- train: 0.40779033303260803, -- test: 0.7785625457763672 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.227665901184082, -- test: -10.227147102355957 \n",
      "Root Mean Squared Error -- train: 0.4079497456550598, -- test: 0.770055890083313 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.321995258331299, -- test: -10.019192695617676 \n",
      "Root Mean Squared Error -- train: 0.4140688478946686, -- test: 0.7628217935562134 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.269413471221924, -- test: -10.325800895690918 \n",
      "Root Mean Squared Error -- train: 0.41066911816596985, -- test: 0.773464024066925 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.922667503356934\n",
      "Test Root MSE of all sampled models: 0.7937718629837036\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.623595237731934\n",
      "Test Root MSE of all models in window: 0.757411539554596\n",
      "\n",
      "############### EM step 125 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.675791025161743 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 126 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.2869811058044434, -- test: -10.47435188293457 \n",
      "Root Mean Squared Error -- train: 0.41283556818962097, -- test: 0.7807719707489014 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.2607014179229736, -- test: -9.932356834411621 \n",
      "Root Mean Squared Error -- train: 0.4111247658729553, -- test: 0.7619265913963318 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.356679677963257, -- test: -10.115148544311523 \n",
      "Root Mean Squared Error -- train: 0.4173389971256256, -- test: 0.7683340311050415 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.227895975112915, -- test: -10.402044296264648 \n",
      "Root Mean Squared Error -- train: 0.40897905826568604, -- test: 0.7782841920852661 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.442164659500122, -- test: -10.139082908630371 \n",
      "Root Mean Squared Error -- train: 0.42279696464538574, -- test: 0.7691690325737 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.2446541786193848, -- test: -10.162252426147461 \n",
      "Root Mean Squared Error -- train: 0.4100765585899353, -- test: 0.7699765563011169 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.36523699760437, -- test: -10.068512916564941 \n",
      "Root Mean Squared Error -- train: 0.4178885817527771, -- test: 0.7667044401168823 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.2220513820648193, -- test: -10.314314842224121 \n",
      "Root Mean Squared Error -- train: 0.40859562158584595, -- test: 0.7752550840377808 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.2207047939300537, -- test: -10.693292617797852 \n",
      "Root Mean Squared Error -- train: 0.40850719809532166, -- test: 0.788256824016571 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.237185478210449, -- test: -10.10581111907959 \n",
      "Root Mean Squared Error -- train: 0.4095878005027771, -- test: 0.7680079936981201 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.82147216796875\n",
      "Test Root MSE of all sampled models: 0.7926061153411865\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.663982391357422\n",
      "Test Root MSE of all models in window: 0.7585228085517883\n",
      "\n",
      "############### EM step 126 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.912376880645752 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 127 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.5600476264953613, -- test: -9.951180458068848 \n",
      "Root Mean Squared Error -- train: 0.43128061294555664, -- test: 0.7647066712379456 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.297159433364868, -- test: -10.086779594421387 \n",
      "Root Mean Squared Error -- train: 0.4145110249519348, -- test: 0.7694753408432007 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.2254586219787598, -- test: -10.414453506469727 \n",
      "Root Mean Squared Error -- train: 0.4098181426525116, -- test: 0.780878484249115 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.2964301109313965, -- test: -10.487112045288086 \n",
      "Root Mean Squared Error -- train: 0.4144635498523712, -- test: 0.7833845019340515 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.2404487133026123, -- test: -9.381165504455566 \n",
      "Root Mean Squared Error -- train: 0.4108036756515503, -- test: 0.7443267703056335 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.3831682205200195, -- test: -10.345232963562012 \n",
      "Root Mean Squared Error -- train: 0.42007121443748474, -- test: 0.778483510017395 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.270613670349121, -- test: -9.748184204101562 \n",
      "Root Mean Squared Error -- train: 0.412779837846756, -- test: 0.7575117349624634 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.238344669342041, -- test: -10.340588569641113 \n",
      "Root Mean Squared Error -- train: 0.41066551208496094, -- test: 0.7783225774765015 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.2241220474243164, -- test: -9.961862564086914 \n",
      "Root Mean Squared Error -- train: 0.4097301661968231, -- test: 0.765083372592926 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.7831530570983887, -- test: -10.219380378723145 \n",
      "Root Mean Squared Error -- train: 0.4450170695781708, -- test: 0.7741101384162903 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.275045394897461\n",
      "Test Root MSE of all sampled models: 0.7760475277900696\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.572948455810547\n",
      "Test Root MSE of all models in window: 0.7592049241065979\n",
      "\n",
      "############### EM step 127 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.929903030395508 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 128 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.290250301361084, -- test: -9.852092742919922 \n",
      "Root Mean Squared Error -- train: 0.41509684920310974, -- test: 0.7633580565452576 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.1879241466522217, -- test: -10.00219440460205 \n",
      "Root Mean Squared Error -- train: 0.40835249423980713, -- test: 0.7686755657196045 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.2041361331939697, -- test: -9.730181694030762 \n",
      "Root Mean Squared Error -- train: 0.4094284474849701, -- test: 0.7590118646621704 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.3816821575164795, -- test: -10.341024398803711 \n",
      "Root Mean Squared Error -- train: 0.42103177309036255, -- test: 0.7805457711219788 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.2806057929992676, -- test: -9.727640151977539 \n",
      "Root Mean Squared Error -- train: 0.41446584463119507, -- test: 0.7589209675788879 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.1959691047668457, -- test: -10.258624076843262 \n",
      "Root Mean Squared Error -- train: 0.40888676047325134, -- test: 0.7776757478713989 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.2168221473693848, -- test: -10.003722190856934 \n",
      "Root Mean Squared Error -- train: 0.4102684259414673, -- test: 0.768729567527771 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.1811583042144775, -- test: -10.202339172363281 \n",
      "Root Mean Squared Error -- train: 0.40790262818336487, -- test: 0.7757091522216797 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.2624576091766357, -- test: -10.10168170928955 \n",
      "Root Mean Squared Error -- train: 0.41327589750289917, -- test: 0.7721798419952393 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.7855451107025146, -- test: -9.948287963867188 \n",
      "Root Mean Squared Error -- train: 0.4463036358356476, -- test: 0.7667701244354248 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.155289649963379\n",
      "Test Root MSE of all sampled models: 0.7740615010261536\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.538908958435059\n",
      "Test Root MSE of all models in window: 0.759981095790863\n",
      "\n",
      "############### EM step 128 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7765753269195557 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 129 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.2342491149902344, -- test: -9.972909927368164 \n",
      "Root Mean Squared Error -- train: 0.41242286562919617, -- test: 0.7697684168815613 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.2973146438598633, -- test: -10.123645782470703 \n",
      "Root Mean Squared Error -- train: 0.41657575964927673, -- test: 0.7750948667526245 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.2060892581939697, -- test: -9.731210708618164 \n",
      "Root Mean Squared Error -- train: 0.4105549454689026, -- test: 0.7611498832702637 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.182377815246582, -- test: -10.240876197814941 \n",
      "Root Mean Squared Error -- train: 0.4089755415916443, -- test: 0.779212236404419 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.61002254486084, -- test: -10.669890403747559 \n",
      "Root Mean Squared Error -- train: 0.4365844130516052, -- test: 0.7940978407859802 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.185004234313965, -- test: -9.34533977508545 \n",
      "Root Mean Squared Error -- train: 0.40915077924728394, -- test: 0.7471844553947449 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.219146966934204, -- test: -9.746438980102539 \n",
      "Root Mean Squared Error -- train: 0.4114221930503845, -- test: 0.7616958022117615 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.183627128601074, -- test: -9.720974922180176 \n",
      "Root Mean Squared Error -- train: 0.40905892848968506, -- test: 0.760782778263092 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.181105375289917, -- test: -9.83454418182373 \n",
      "Root Mean Squared Error -- train: 0.40889057517051697, -- test: 0.7648465037345886 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.787937879562378, -- test: -9.739880561828613 \n",
      "Root Mean Squared Error -- train: 0.447569340467453, -- test: 0.7614607214927673 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.7582426071167\n",
      "Test Root MSE of all sampled models: 0.7971289157867432\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.525856018066406\n",
      "Test Root MSE of all models in window: 0.7610123753547668\n",
      "\n",
      "############### EM step 129 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.3958590030670166 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 130 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.2178494930267334, -- test: -10.00445556640625 \n",
      "Root Mean Squared Error -- train: 0.4123400151729584, -- test: 0.7730271220207214 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.1845784187316895, -- test: -9.811385154724121 \n",
      "Root Mean Squared Error -- train: 0.41011878848075867, -- test: 0.7661395072937012 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.2303338050842285, -- test: -9.881702423095703 \n",
      "Root Mean Squared Error -- train: 0.41317039728164673, -- test: 0.7686551809310913 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.758652687072754, -- test: -9.267058372497559 \n",
      "Root Mean Squared Error -- train: 0.4468989670276642, -- test: 0.7463791370391846 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.1675045490264893, -- test: -10.119462966918945 \n",
      "Root Mean Squared Error -- train: 0.4089742600917816, -- test: 0.7771008014678955 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.4700663089752197, -- test: -10.045071601867676 \n",
      "Root Mean Squared Error -- train: 0.4288041293621063, -- test: 0.774468183517456 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.234534978866577, -- test: -10.079437255859375 \n",
      "Root Mean Squared Error -- train: 0.4134494662284851, -- test: 0.7756854295730591 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.2330610752105713, -- test: -9.699559211730957 \n",
      "Root Mean Squared Error -- train: 0.41335156559944153, -- test: 0.7621217966079712 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.224240303039551, -- test: -9.643863677978516 \n",
      "Root Mean Squared Error -- train: 0.4127652943134308, -- test: 0.7601127624511719 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.1517932415008545, -- test: -10.076496124267578 \n",
      "Root Mean Squared Error -- train: 0.40791821479797363, -- test: 0.7755813598632812 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -10.684518814086914\n",
      "Test Root MSE of all sampled models: 0.7968134880065918\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.513055801391602\n",
      "Test Root MSE of all models in window: 0.7620126605033875\n",
      "\n",
      "############### EM step 130 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.212348222732544 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 131 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.1455788612365723, -- test: -9.678400993347168 \n",
      "Root Mean Squared Error -- train: 0.40848508477211, -- test: 0.7634609341621399 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.2475686073303223, -- test: -9.715265274047852 \n",
      "Root Mean Squared Error -- train: 0.41532227396965027, -- test: 0.7647930979728699 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.1416656970977783, -- test: -10.091513633728027 \n",
      "Root Mean Squared Error -- train: 0.40822046995162964, -- test: 0.7782592177391052 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.2232017517089844, -- test: -10.003469467163086 \n",
      "Root Mean Squared Error -- train: 0.41369909048080444, -- test: 0.7751290798187256 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.3112525939941406, -- test: -9.865422248840332 \n",
      "Root Mean Squared Error -- train: 0.4195350706577301, -- test: 0.7701955437660217 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.182781219482422, -- test: -9.917501449584961 \n",
      "Root Mean Squared Error -- train: 0.41099226474761963, -- test: 0.7720604538917542 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.1436827182769775, -- test: -10.050848007202148 \n",
      "Root Mean Squared Error -- train: 0.4083568751811981, -- test: 0.7768149971961975 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.204693078994751, -- test: -10.22978401184082 \n",
      "Root Mean Squared Error -- train: 0.4124617874622345, -- test: 0.7831498384475708 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.1845407485961914, -- test: -9.461742401123047 \n",
      "Root Mean Squared Error -- train: 0.4111104905605316, -- test: 0.7555840611457825 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.149634599685669, -- test: -9.810874938964844 \n",
      "Root Mean Squared Error -- train: 0.40875914692878723, -- test: 0.7682374119758606 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.698175430297852\n",
      "Test Root MSE of all sampled models: 0.7641758322715759\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.500892639160156\n",
      "Test Root MSE of all models in window: 0.7628459334373474\n",
      "\n",
      "############### EM step 131 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.204133987426758 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 132 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.152554512023926, -- test: -9.622034072875977 \n",
      "Root Mean Squared Error -- train: 0.40997594594955444, -- test: 0.7635855078697205 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.1535143852233887, -- test: -9.681963920593262 \n",
      "Root Mean Squared Error -- train: 0.4100410044193268, -- test: 0.7657625675201416 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.2217719554901123, -- test: -10.128288269042969 \n",
      "Root Mean Squared Error -- train: 0.4146393835544586, -- test: 0.7817856669425964 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.1223044395446777, -- test: -9.603453636169434 \n",
      "Root Mean Squared Error -- train: 0.40792116522789, -- test: 0.7629092335700989 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.1788811683654785, -- test: -9.832674980163574 \n",
      "Root Mean Squared Error -- train: 0.41175591945648193, -- test: 0.7712103724479675 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.1246984004974365, -- test: -9.857492446899414 \n",
      "Root Mean Squared Error -- train: 0.4080841541290283, -- test: 0.7721037268638611 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.1501400470733643, -- test: -10.05199909210205 \n",
      "Root Mean Squared Error -- train: 0.409812331199646, -- test: 0.7790701985359192 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.190361738204956, -- test: -9.670997619628906 \n",
      "Root Mean Squared Error -- train: 0.41252970695495605, -- test: 0.7653646469116211 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -3.1767311096191406, -- test: -10.011836051940918 \n",
      "Root Mean Squared Error -- train: 0.4743211567401886, -- test: 0.7776368856430054 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.1410531997680664, -- test: -9.983996391296387 \n",
      "Root Mean Squared Error -- train: 0.4091959297657013, -- test: 0.7766417264938354 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.47541618347168\n",
      "Test Root MSE of all sampled models: 0.7582328915596008\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.504334449768066\n",
      "Test Root MSE of all models in window: 0.7637713551521301\n",
      "\n",
      "############### EM step 132 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2730282545089722 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 133 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.267637014389038, -- test: -9.761650085449219 \n",
      "Root Mean Squared Error -- train: 0.41870856285095215, -- test: 0.7707503437995911 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.3148348331451416, -- test: -9.800423622131348 \n",
      "Root Mean Squared Error -- train: 0.42184606194496155, -- test: 0.7721545100212097 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.1456642150878906, -- test: -9.808640480041504 \n",
      "Root Mean Squared Error -- train: 0.4104892909526825, -- test: 0.7724517583847046 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.220088005065918, -- test: -9.251636505126953 \n",
      "Root Mean Squared Error -- train: 0.4155237376689911, -- test: 0.7520360946655273 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.4828951358795166, -- test: -9.808085441589355 \n",
      "Root Mean Squared Error -- train: 0.43283337354660034, -- test: 0.7724316716194153 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.1152520179748535, -- test: -9.951936721801758 \n",
      "Root Mean Squared Error -- train: 0.40841415524482727, -- test: 0.7776172757148743 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.177666187286377, -- test: -9.538946151733398 \n",
      "Root Mean Squared Error -- train: 0.412661612033844, -- test: 0.7626349925994873 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.7850186824798584, -- test: -8.667403221130371 \n",
      "Root Mean Squared Error -- train: 0.45191407203674316, -- test: 0.7300091981887817 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.1453614234924316, -- test: -9.699660301208496 \n",
      "Root Mean Squared Error -- train: 0.4104686677455902, -- test: 0.768500030040741 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.107881784439087, -- test: -9.604166030883789 \n",
      "Root Mean Squared Error -- train: 0.40790966153144836, -- test: 0.7650206089019775 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.533085823059082\n",
      "Test Root MSE of all sampled models: 0.7624202966690063\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.494697570800781\n",
      "Test Root MSE of all models in window: 0.7645184993743896\n",
      "\n",
      "############### EM step 133 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3425312042236328 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 134 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.1122541427612305, -- test: -9.519436836242676 \n",
      "Root Mean Squared Error -- train: 0.4091508090496063, -- test: 0.7639307379722595 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.905647039413452, -- test: -9.722911834716797 \n",
      "Root Mean Squared Error -- train: 0.46041569113731384, -- test: 0.7713772654533386 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.3541581630706787, -- test: -9.20095443725586 \n",
      "Root Mean Squared Error -- train: 0.42543649673461914, -- test: 0.7521274089813232 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.2064080238342285, -- test: -10.006796836853027 \n",
      "Root Mean Squared Error -- train: 0.4155653715133667, -- test: 0.7816479206085205 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.235013246536255, -- test: -9.465110778808594 \n",
      "Root Mean Squared Error -- train: 0.4174947142601013, -- test: 0.7619302272796631 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.2332324981689453, -- test: -9.608890533447266 \n",
      "Root Mean Squared Error -- train: 0.4173748195171356, -- test: 0.7672133445739746 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.133254289627075, -- test: -9.5691499710083 \n",
      "Root Mean Squared Error -- train: 0.41059020161628723, -- test: 0.7657567858695984 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.206411600112915, -- test: -9.223143577575684 \n",
      "Root Mean Squared Error -- train: 0.4155656099319458, -- test: 0.7529557943344116 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.393832206726074, -- test: -9.297235488891602 \n",
      "Root Mean Squared Error -- train: 0.428048312664032, -- test: 0.7557151317596436 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.1965668201446533, -- test: -9.539684295654297 \n",
      "Root Mean Squared Error -- train: 0.4148995578289032, -- test: 0.764674961566925 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.887519836425781\n",
      "Test Root MSE of all sampled models: 0.7773491144180298\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.600104331970215\n",
      "Test Root MSE of all models in window: 0.7655544877052307\n",
      "\n",
      "############### EM step 134 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -3.010375738143921 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 135 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.1488335132598877, -- test: -9.747425079345703 \n",
      "Root Mean Squared Error -- train: 0.41263547539711, -- test: 0.7743715643882751 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.098773956298828, -- test: -9.806757926940918 \n",
      "Root Mean Squared Error -- train: 0.4091934263706207, -- test: 0.7765333652496338 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.392271041870117, -- test: -9.649751663208008 \n",
      "Root Mean Squared Error -- train: 0.4289804995059967, -- test: 0.7707995176315308 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.0900113582611084, -- test: -9.505420684814453 \n",
      "Root Mean Squared Error -- train: 0.4085879623889923, -- test: 0.7654906511306763 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.107710361480713, -- test: -9.584251403808594 \n",
      "Root Mean Squared Error -- train: 0.40981000661849976, -- test: 0.7683948874473572 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.098198652267456, -- test: -9.144320487976074 \n",
      "Root Mean Squared Error -- train: 0.4091537296772003, -- test: 0.7520444989204407 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.104337692260742, -- test: -9.965381622314453 \n",
      "Root Mean Squared Error -- train: 0.4095773994922638, -- test: 0.78228360414505 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.1016385555267334, -- test: -9.920403480529785 \n",
      "Root Mean Squared Error -- train: 0.4093911945819855, -- test: 0.7806574106216431 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.1227452754974365, -- test: -9.604765892028809 \n",
      "Root Mean Squared Error -- train: 0.4108452796936035, -- test: 0.7691488265991211 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.228952646255493, -- test: -9.243424415588379 \n",
      "Root Mean Squared Error -- train: 0.4180854260921478, -- test: 0.7557585835456848 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.852208137512207\n",
      "Test Root MSE of all sampled models: 0.7781853079795837\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.519290924072266\n",
      "Test Root MSE of all models in window: 0.7663061618804932\n",
      "\n",
      "############### EM step 135 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.6187803745269775 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 136 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.0938568115234375, -- test: -9.232438087463379 \n",
      "Root Mean Squared Error -- train: 0.40983620285987854, -- test: 0.7574242949485779 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.48075795173645, -- test: -9.833966255187988 \n",
      "Root Mean Squared Error -- train: 0.43583881855010986, -- test: 0.7796664834022522 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.08128023147583, -- test: -10.005863189697266 \n",
      "Root Mean Squared Error -- train: 0.4089632034301758, -- test: 0.7859069108963013 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.2981245517730713, -- test: -9.576990127563477 \n",
      "Root Mean Squared Error -- train: 0.42376336455345154, -- test: 0.7702431678771973 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.094869375228882, -- test: -9.975488662719727 \n",
      "Root Mean Squared Error -- train: 0.40990641713142395, -- test: 0.7848078608512878 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.592247724533081, -- test: -9.618213653564453 \n",
      "Root Mean Squared Error -- train: 0.4430485963821411, -- test: 0.7717625498771667 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.115006446838379, -- test: -9.355685234069824 \n",
      "Root Mean Squared Error -- train: 0.41130009293556213, -- test: 0.7620344161987305 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.066828727722168, -- test: -9.381324768066406 \n",
      "Root Mean Squared Error -- train: 0.4079577624797821, -- test: 0.7629899382591248 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.0664725303649902, -- test: -9.546319961547852 \n",
      "Root Mean Squared Error -- train: 0.40793293714523315, -- test: 0.7691107988357544 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.1677212715148926, -- test: -9.465498924255371 \n",
      "Root Mean Squared Error -- train: 0.41492629051208496, -- test: 0.7661186456680298 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.952108383178711\n",
      "Test Root MSE of all sampled models: 0.746832549571991\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.290131568908691\n",
      "Test Root MSE of all models in window: 0.7668291330337524\n",
      "\n",
      "############### EM step 136 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.6414726972579956 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 137 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.0939090251922607, -- test: -9.2959566116333 \n",
      "Root Mean Squared Error -- train: 0.41080111265182495, -- test: 0.761843740940094 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.0847647190093994, -- test: -9.470266342163086 \n",
      "Root Mean Squared Error -- train: 0.410164475440979, -- test: 0.7683547139167786 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.051119089126587, -- test: -9.661334037780762 \n",
      "Root Mean Squared Error -- train: 0.4078134596347809, -- test: 0.7754288911819458 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.0589942932128906, -- test: -9.286306381225586 \n",
      "Root Mean Squared Error -- train: 0.4083649516105652, -- test: 0.761481761932373 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.051877021789551, -- test: -9.329907417297363 \n",
      "Root Mean Squared Error -- train: 0.40786653757095337, -- test: 0.7631162405014038 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.070690155029297, -- test: -9.660307884216309 \n",
      "Root Mean Squared Error -- train: 0.4091826379299164, -- test: 0.7753910422325134 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.578418254852295, -- test: -9.29068374633789 \n",
      "Root Mean Squared Error -- train: 0.443227618932724, -- test: 0.7616459727287292 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.11846661567688, -- test: -9.29137897491455 \n",
      "Root Mean Squared Error -- train: 0.41250598430633545, -- test: 0.7616720795631409 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.1193034648895264, -- test: -9.159992218017578 \n",
      "Root Mean Squared Error -- train: 0.4125639796257019, -- test: 0.7567262649536133 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.061596393585205, -- test: -9.476434707641602 \n",
      "Root Mean Squared Error -- train: 0.4085470139980316, -- test: 0.7685840725898743 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.338223457336426\n",
      "Test Root MSE of all sampled models: 0.763427734375\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.291213035583496\n",
      "Test Root MSE of all models in window: 0.7674309611320496\n",
      "\n",
      "############### EM step 137 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.145406723022461 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 138 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -3.1943087577819824, -- test: -10.089385986328125 \n",
      "Root Mean Squared Error -- train: 0.48249125480651855, -- test: 0.7931725978851318 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.1586790084838867, -- test: -9.726773262023926 \n",
      "Root Mean Squared Error -- train: 0.4162576496601105, -- test: 0.7799230813980103 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.3434438705444336, -- test: -9.174461364746094 \n",
      "Root Mean Squared Error -- train: 0.42882466316223145, -- test: 0.7592980265617371 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.1497912406921387, -- test: -9.35720157623291 \n",
      "Root Mean Squared Error -- train: 0.4156435430049896, -- test: 0.7661835551261902 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.0796380043029785, -- test: -9.166871070861816 \n",
      "Root Mean Squared Error -- train: 0.4107641577720642, -- test: 0.7590106129646301 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.0435783863067627, -- test: -9.591111183166504 \n",
      "Root Mean Squared Error -- train: 0.4082334041595459, -- test: 0.7749078273773193 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.2447338104248047, -- test: -9.390403747558594 \n",
      "Root Mean Squared Error -- train: 0.42215731739997864, -- test: 0.7674279808998108 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.0860235691070557, -- test: -9.807883262634277 \n",
      "Root Mean Squared Error -- train: 0.41121068596839905, -- test: 0.7829062342643738 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.2999372482299805, -- test: -9.372705459594727 \n",
      "Root Mean Squared Error -- train: 0.4258989095687866, -- test: 0.7667648792266846 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.1175341606140137, -- test: -9.423723220825195 \n",
      "Root Mean Squared Error -- train: 0.4134071171283722, -- test: 0.7686747312545776 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.706145286560059\n",
      "Test Root MSE of all sampled models: 0.779162585735321\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.346243858337402\n",
      "Test Root MSE of all models in window: 0.7682918906211853\n",
      "\n",
      "############### EM step 138 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.18149995803833 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 139 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.3477094173431396, -- test: -8.837884902954102 \n",
      "Root Mean Squared Error -- train: 0.43012821674346924, -- test: 0.7484399080276489 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.1830780506134033, -- test: -9.556838989257812 \n",
      "Root Mean Squared Error -- train: 0.4189201891422272, -- test: 0.7757060527801514 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.0420453548431396, -- test: -9.2918119430542 \n",
      "Root Mean Squared Error -- train: 0.4090745449066162, -- test: 0.7657679915428162 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.0263476371765137, -- test: -9.36945915222168 \n",
      "Root Mean Squared Error -- train: 0.40796393156051636, -- test: 0.7686929106712341 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.2709240913391113, -- test: -9.230772018432617 \n",
      "Root Mean Squared Error -- train: 0.4249374568462372, -- test: 0.7634607553482056 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.045525074005127, -- test: -9.410257339477539 \n",
      "Root Mean Squared Error -- train: 0.40932029485702515, -- test: 0.7702254056930542 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.038149356842041, -- test: -9.367785453796387 \n",
      "Root Mean Squared Error -- train: 0.4087991714477539, -- test: 0.7686299681663513 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.163174867630005, -- test: -9.358423233032227 \n",
      "Root Mean Squared Error -- train: 0.41754475235939026, -- test: 0.7682779431343079 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.028667449951172, -- test: -9.638443946838379 \n",
      "Root Mean Squared Error -- train: 0.4081282913684845, -- test: 0.778740644454956 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.0458219051361084, -- test: -9.450606346130371 \n",
      "Root Mean Squared Error -- train: 0.4093412756919861, -- test: 0.7717378735542297 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.390368461608887\n",
      "Test Root MSE of all sampled models: 0.7694786787033081\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.339008331298828\n",
      "Test Root MSE of all models in window: 0.7690995335578918\n",
      "\n",
      "############### EM step 139 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.4457978010177612 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 140 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.146343946456909, -- test: -9.51182746887207 \n",
      "Root Mean Squared Error -- train: 0.41732537746429443, -- test: 0.7760388851165771 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.2252585887908936, -- test: -9.573660850524902 \n",
      "Root Mean Squared Error -- train: 0.4227847158908844, -- test: 0.7783508896827698 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.0997982025146484, -- test: -9.11964225769043 \n",
      "Root Mean Squared Error -- train: 0.41407155990600586, -- test: 0.7612114548683167 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.020585298538208, -- test: -9.379820823669434 \n",
      "Root Mean Squared Error -- train: 0.40847456455230713, -- test: 0.7710798978805542 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.010154962539673, -- test: -9.295836448669434 \n",
      "Root Mean Squared Error -- train: 0.4077318608760834, -- test: 0.7679083347320557 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.502897262573242, -- test: -9.121037483215332 \n",
      "Root Mean Squared Error -- train: 0.441455602645874, -- test: 0.7612646818161011 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.0133979320526123, -- test: -9.425976753234863 \n",
      "Root Mean Squared Error -- train: 0.4079628884792328, -- test: 0.7728174328804016 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.033902645111084, -- test: -9.244824409484863 \n",
      "Root Mean Squared Error -- train: 0.4094208776950836, -- test: 0.7659754157066345 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.07417368888855, -- test: -9.443670272827148 \n",
      "Root Mean Squared Error -- train: 0.4122692942619324, -- test: 0.7734824419021606 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.015951633453369, -- test: -9.64820671081543 \n",
      "Root Mean Squared Error -- train: 0.4081447720527649, -- test: 0.7811290621757507 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.056173324584961\n",
      "Test Root MSE of all sampled models: 0.7587846517562866\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.487348556518555\n",
      "Test Root MSE of all models in window: 0.769687831401825\n",
      "\n",
      "############### EM step 140 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.615321397781372 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 141 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.0980026721954346, -- test: -9.425149917602539 \n",
      "Root Mean Squared Error -- train: 0.41490134596824646, -- test: 0.7748311758041382 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.000797748565674, -- test: -9.425031661987305 \n",
      "Root Mean Squared Error -- train: 0.4079977869987488, -- test: 0.77482670545578 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.002720355987549, -- test: -9.332657814025879 \n",
      "Root Mean Squared Error -- train: 0.40813547372817993, -- test: 0.7713350653648376 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.0100691318511963, -- test: -9.489252090454102 \n",
      "Root Mean Squared Error -- train: 0.4086613059043884, -- test: 0.7772448658943176 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.0283851623535156, -- test: -9.55794906616211 \n",
      "Root Mean Squared Error -- train: 0.40996891260147095, -- test: 0.7798234224319458 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.2739193439483643, -- test: -9.182513236999512 \n",
      "Root Mean Squared Error -- train: 0.42711150646209717, -- test: 0.7656258344650269 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.0822913646698, -- test: -9.743703842163086 \n",
      "Root Mean Squared Error -- train: 0.4137933552265167, -- test: 0.786753237247467 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.024033546447754, -- test: -9.559062957763672 \n",
      "Root Mean Squared Error -- train: 0.4096585810184479, -- test: 0.7798651456832886 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.253765344619751, -- test: -9.063722610473633 \n",
      "Root Mean Squared Error -- train: 0.4257304072380066, -- test: 0.7610784769058228 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.171680450439453, -- test: -9.647884368896484 \n",
      "Root Mean Squared Error -- train: 0.4200584292411804, -- test: 0.7831861972808838 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.76681900024414\n",
      "Test Root MSE of all sampled models: 0.7876112461090088\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.83055305480957\n",
      "Test Root MSE of all models in window: 0.7707769870758057\n",
      "\n",
      "############### EM step 141 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.9851230382919312 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 142 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.0137925148010254, -- test: -9.36939811706543 \n",
      "Root Mean Squared Error -- train: 0.4098590016365051, -- test: 0.7747549414634705 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.256157875061035, -- test: -9.129555702209473 \n",
      "Root Mean Squared Error -- train: 0.4268808960914612, -- test: 0.7656047344207764 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.2727744579315186, -- test: -9.049535751342773 \n",
      "Root Mean Squared Error -- train: 0.4280231297016144, -- test: 0.7625274658203125 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.9898654222488403, -- test: -9.389740943908691 \n",
      "Root Mean Squared Error -- train: 0.40814006328582764, -- test: 0.7755261659622192 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.0134851932525635, -- test: -9.371255874633789 \n",
      "Root Mean Squared Error -- train: 0.409837007522583, -- test: 0.7748254537582397 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.0673577785491943, -- test: -9.035213470458984 \n",
      "Root Mean Squared Error -- train: 0.4136813282966614, -- test: 0.7619754076004028 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.9978522062301636, -- test: -9.315099716186523 \n",
      "Root Mean Squared Error -- train: 0.4087146520614624, -- test: 0.772692859172821 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.054185628890991, -- test: -9.121482849121094 \n",
      "Root Mean Squared Error -- train: 0.4127446711063385, -- test: 0.7652949094772339 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.131878137588501, -- test: -9.626250267028809 \n",
      "Root Mean Squared Error -- train: 0.418239027261734, -- test: 0.7844357490539551 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.019310712814331, -- test: -9.477531433105469 \n",
      "Root Mean Squared Error -- train: 0.41025441884994507, -- test: 0.7788452506065369 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.16015911102295\n",
      "Test Root MSE of all sampled models: 0.7667784094810486\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.760807037353516\n",
      "Test Root MSE of all models in window: 0.7709118723869324\n",
      "\n",
      "############### EM step 142 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.989796757698059 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 143 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.029128074645996, -- test: -9.155001640319824 \n",
      "Root Mean Squared Error -- train: 0.4118882119655609, -- test: 0.7685790061950684 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.9983290433883667, -- test: -9.497671127319336 \n",
      "Root Mean Squared Error -- train: 0.4096730053424835, -- test: 0.7816404104232788 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.0374438762664795, -- test: -9.35457992553711 \n",
      "Root Mean Squared Error -- train: 0.41248422861099243, -- test: 0.7762129902839661 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.994951605796814, -- test: -9.696136474609375 \n",
      "Root Mean Squared Error -- train: 0.4094293713569641, -- test: 0.7891063690185547 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.4630351066589355, -- test: -9.56035041809082 \n",
      "Root Mean Squared Error -- train: 0.4419175088405609, -- test: 0.7840059995651245 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.1474175453186035, -- test: -9.394617080688477 \n",
      "Root Mean Squared Error -- train: 0.4202874004840851, -- test: 0.7777354121208191 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.976002812385559, -- test: -9.410616874694824 \n",
      "Root Mean Squared Error -- train: 0.4080597460269928, -- test: 0.7783430218696594 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.974203109741211, -- test: -8.982414245605469 \n",
      "Root Mean Squared Error -- train: 0.4079294204711914, -- test: 0.7619158029556274 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.1106762886047363, -- test: -9.724211692810059 \n",
      "Root Mean Squared Error -- train: 0.41769665479660034, -- test: 0.7901568412780762 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.1810591220855713, -- test: -8.920812606811523 \n",
      "Root Mean Squared Error -- train: 0.4226456582546234, -- test: 0.7595233917236328 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.666715621948242\n",
      "Test Root MSE of all sampled models: 0.7495741248130798\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.711585998535156\n",
      "Test Root MSE of all models in window: 0.7706907987594604\n",
      "\n",
      "############### EM step 143 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3444418907165527 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 144 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.1377291679382324, -- test: -8.725738525390625 \n",
      "Root Mean Squared Error -- train: 0.4205344319343567, -- test: 0.7537923455238342 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.975151538848877, -- test: -9.516372680664062 \n",
      "Root Mean Squared Error -- train: 0.4088904857635498, -- test: 0.7843274474143982 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.0361812114715576, -- test: -9.29577350616455 \n",
      "Root Mean Squared Error -- train: 0.41329991817474365, -- test: 0.7759286165237427 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.9701398611068726, -- test: -9.591033935546875 \n",
      "Root Mean Squared Error -- train: 0.4085262715816498, -- test: 0.7871498465538025 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.9752882719039917, -- test: -9.594104766845703 \n",
      "Root Mean Squared Error -- train: 0.4089004099369049, -- test: 0.7872657179832458 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.0413339138031006, -- test: -9.374046325683594 \n",
      "Root Mean Squared Error -- train: 0.4136700928211212, -- test: 0.7789190411567688 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.9709954261779785, -- test: -9.343332290649414 \n",
      "Root Mean Squared Error -- train: 0.4085884690284729, -- test: 0.7777469754219055 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.9758515357971191, -- test: -9.46608829498291 \n",
      "Root Mean Squared Error -- train: 0.4089413285255432, -- test: 0.7824209332466125 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.0229926109313965, -- test: -9.27634048461914 \n",
      "Root Mean Squared Error -- train: 0.4123510420322418, -- test: 0.7751843333244324 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.9934184551239014, -- test: -9.19087028503418 \n",
      "Root Mean Squared Error -- train: 0.41021525859832764, -- test: 0.7719025611877441 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.785028457641602\n",
      "Test Root MSE of all sampled models: 0.7561249136924744\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.674352645874023\n",
      "Test Root MSE of all models in window: 0.7708200216293335\n",
      "\n",
      "############### EM step 144 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.7763144969940186 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 145 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.94911789894104, -- test: -9.087442398071289 \n",
      "Root Mean Squared Error -- train: 0.4079088568687439, -- test: 0.7699081897735596 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.9767686128616333, -- test: -9.426095008850098 \n",
      "Root Mean Squared Error -- train: 0.4099282920360565, -- test: 0.7829343676567078 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.9534130096435547, -- test: -8.91701889038086 \n",
      "Root Mean Squared Error -- train: 0.4082231819629669, -- test: 0.7632688283920288 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.963491439819336, -- test: -9.43908405303955 \n",
      "Root Mean Squared Error -- train: 0.40895986557006836, -- test: 0.7834296226501465 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.9789959192276, -- test: -9.081037521362305 \n",
      "Root Mean Squared Error -- train: 0.41009053587913513, -- test: 0.7696597576141357 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.9721856117248535, -- test: -9.77747917175293 \n",
      "Root Mean Squared Error -- train: 0.4095942974090576, -- test: 0.7962250113487244 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.1511008739471436, -- test: -8.682746887207031 \n",
      "Root Mean Squared Error -- train: 0.4224381744861603, -- test: 0.754046618938446 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.1142122745513916, -- test: -9.028412818908691 \n",
      "Root Mean Squared Error -- train: 0.41982218623161316, -- test: 0.767615020275116 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.0876543521881104, -- test: -9.427604675292969 \n",
      "Root Mean Squared Error -- train: 0.41792863607406616, -- test: 0.782991886138916 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.9577295780181885, -- test: -9.151607513427734 \n",
      "Root Mean Squared Error -- train: 0.4085388779640198, -- test: 0.7723931670188904 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.752091407775879\n",
      "Test Root MSE of all sampled models: 0.795272171497345\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.65129566192627\n",
      "Test Root MSE of all models in window: 0.7714179754257202\n",
      "\n",
      "############### EM step 145 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.9979498386383057 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 146 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.9367711544036865, -- test: -9.271586418151855 \n",
      "Root Mean Squared Error -- train: 0.40791237354278564, -- test: 0.7790300250053406 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.966985821723938, -- test: -8.908049583435059 \n",
      "Root Mean Squared Error -- train: 0.4101305305957794, -- test: 0.764889121055603 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.455976724624634, -- test: -9.13173770904541 \n",
      "Root Mean Squared Error -- train: 0.44449251890182495, -- test: 0.7736207842826843 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.9440953731536865, -- test: -8.932546615600586 \n",
      "Root Mean Squared Error -- train: 0.4084511697292328, -- test: 0.7658502459526062 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.9947344064712524, -- test: -9.191705703735352 \n",
      "Root Mean Squared Error -- train: 0.4121571481227875, -- test: 0.7759448885917664 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.955112099647522, -- test: -9.249283790588379 \n",
      "Root Mean Squared Error -- train: 0.40926027297973633, -- test: 0.7781698703765869 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.995706558227539, -- test: -9.14721965789795 \n",
      "Root Mean Squared Error -- train: 0.41222795844078064, -- test: 0.7742214202880859 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.2843430042266846, -- test: -9.144119262695312 \n",
      "Root Mean Squared Error -- train: 0.43274250626564026, -- test: 0.7741012573242188 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.9913231134414673, -- test: -8.871548652648926 \n",
      "Root Mean Squared Error -- train: 0.4119085669517517, -- test: 0.7634548544883728 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.9728366136550903, -- test: -8.777256965637207 \n",
      "Root Mean Squared Error -- train: 0.41055867075920105, -- test: 0.7597372531890869 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.662714958190918\n",
      "Test Root MSE of all sampled models: 0.7551964521408081\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.632585525512695\n",
      "Test Root MSE of all models in window: 0.7713346481323242\n",
      "\n",
      "############### EM step 146 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.1604530811309814 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 147 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.9583125114440918, -- test: -8.797384262084961 \n",
      "Root Mean Squared Error -- train: 0.41041234135627747, -- test: 0.7625004649162292 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.9838776588439941, -- test: -8.914793968200684 \n",
      "Root Mean Squared Error -- train: 0.41228875517845154, -- test: 0.7671353220939636 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.9721195697784424, -- test: -9.17688274383545 \n",
      "Root Mean Squared Error -- train: 0.411426842212677, -- test: 0.7773817777633667 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.9272515773773193, -- test: -9.094598770141602 \n",
      "Root Mean Squared Error -- train: 0.4081209599971771, -- test: 0.7741795182228088 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.1196632385253906, -- test: -9.253807067871094 \n",
      "Root Mean Squared Error -- train: 0.4221152067184448, -- test: 0.7803637385368347 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.9404727220535278, -- test: -8.830500602722168 \n",
      "Root Mean Squared Error -- train: 0.4090978801250458, -- test: 0.7638105750083923 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.9949685335159302, -- test: -8.918779373168945 \n",
      "Root Mean Squared Error -- train: 0.41310015320777893, -- test: 0.7672922015190125 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.018094301223755, -- test: -9.180135726928711 \n",
      "Root Mean Squared Error -- train: 0.4147868752479553, -- test: 0.7775081396102905 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.0247952938079834, -- test: -8.779119491577148 \n",
      "Root Mean Squared Error -- train: 0.41527432203292847, -- test: 0.761776864528656 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.012014150619507, -- test: -8.585371971130371 \n",
      "Root Mean Squared Error -- train: 0.41434407234191895, -- test: 0.7540588974952698 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.654797554016113\n",
      "Test Root MSE of all sampled models: 0.7957265377044678\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.616416931152344\n",
      "Test Root MSE of all models in window: 0.771317720413208\n",
      "\n",
      "############### EM step 147 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.675548791885376 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 148 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.969449758529663, -- test: -9.477925300598145 \n",
      "Root Mean Squared Error -- train: 0.41213709115982056, -- test: 0.7910014390945435 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.944270372390747, -- test: -9.2302827835083 \n",
      "Root Mean Squared Error -- train: 0.41027840971946716, -- test: 0.7814405560493469 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.0429258346557617, -- test: -8.734886169433594 \n",
      "Root Mean Squared Error -- train: 0.41751357913017273, -- test: 0.7619545459747314 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.002037286758423, -- test: -8.317849159240723 \n",
      "Root Mean Squared Error -- train: 0.4145302474498749, -- test: 0.7451556921005249 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.928526520729065, -- test: -9.056500434875488 \n",
      "Root Mean Squared Error -- train: 0.40911194682121277, -- test: 0.7746608257293701 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.327873468399048, -- test: -9.286869049072266 \n",
      "Root Mean Squared Error -- train: 0.43773993849754333, -- test: 0.7836355566978455 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.2232019901275635, -- test: -8.767919540405273 \n",
      "Root Mean Squared Error -- train: 0.43042051792144775, -- test: 0.7632693648338318 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.082693338394165, -- test: -8.66318416595459 \n",
      "Root Mean Squared Error -- train: 0.42039480805397034, -- test: 0.7590927481651306 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.9094206094741821, -- test: -8.966379165649414 \n",
      "Root Mean Squared Error -- train: 0.40769192576408386, -- test: 0.7711214423179626 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.2696361541748047, -- test: -8.7151460647583 \n",
      "Root Mean Squared Error -- train: 0.43368279933929443, -- test: 0.7611677050590515 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.161545753479004\n",
      "Test Root MSE of all sampled models: 0.7787659764289856\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.590978622436523\n",
      "Test Root MSE of all models in window: 0.771700918674469\n",
      "\n",
      "############### EM step 148 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.3927905559539795 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 149 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.0013840198516846, -- test: -9.157193183898926 \n",
      "Root Mean Squared Error -- train: 0.4154099225997925, -- test: 0.780607283115387 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.9577776193618774, -- test: -8.847848892211914 \n",
      "Root Mean Squared Error -- train: 0.4121938645839691, -- test: 0.7684176564216614 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.9381163120269775, -- test: -9.217227935791016 \n",
      "Root Mean Squared Error -- train: 0.41073548793792725, -- test: 0.7829509377479553 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.106998920440674, -- test: -8.7681245803833 \n",
      "Root Mean Squared Error -- train: 0.4230981767177582, -- test: 0.765244722366333 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.9148205518722534, -- test: -8.953124046325684 \n",
      "Root Mean Squared Error -- train: 0.40900084376335144, -- test: 0.7725875973701477 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.105616569519043, -- test: -8.931229591369629 \n",
      "Root Mean Squared Error -- train: 0.42299845814704895, -- test: 0.7717221975326538 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.0494916439056396, -- test: -8.361611366271973 \n",
      "Root Mean Squared Error -- train: 0.41892942786216736, -- test: 0.7488566637039185 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.9063854217529297, -- test: -8.813283920288086 \n",
      "Root Mean Squared Error -- train: 0.4083709418773651, -- test: 0.7670435905456543 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.903120756149292, -- test: -9.220817565917969 \n",
      "Root Mean Squared Error -- train: 0.4081268906593323, -- test: 0.7830908298492432 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.9107692241668701, -- test: -9.064830780029297 \n",
      "Root Mean Squared Error -- train: 0.4086984395980835, -- test: 0.7769877314567566 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.941335678100586\n",
      "Test Root MSE of all sampled models: 0.772121787071228\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.563542366027832\n",
      "Test Root MSE of all models in window: 0.7720457315444946\n",
      "\n",
      "############### EM step 149 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.9726157188415527 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 150 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.894085168838501, -- test: -8.823103904724121 \n",
      "Root Mean Squared Error -- train: 0.4083859920501709, -- test: 0.7694814801216125 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.9883395433425903, -- test: -8.909610748291016 \n",
      "Root Mean Squared Error -- train: 0.415409117937088, -- test: 0.7729241847991943 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.9320042133331299, -- test: -8.636356353759766 \n",
      "Root Mean Squared Error -- train: 0.4112258553504944, -- test: 0.7619965672492981 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.9240283966064453, -- test: -8.812617301940918 \n",
      "Root Mean Squared Error -- train: 0.41063016653060913, -- test: 0.7690631747245789 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.895772933959961, -- test: -9.230724334716797 \n",
      "Root Mean Squared Error -- train: 0.40851280093193054, -- test: 0.7855715751647949 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.885695219039917, -- test: -9.037944793701172 \n",
      "Root Mean Squared Error -- train: 0.4077549874782562, -- test: 0.7780033946037292 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.23256778717041, -- test: -8.605822563171387 \n",
      "Root Mean Squared Error -- train: 0.43307751417160034, -- test: 0.7607657313346863 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.115387439727783, -- test: -8.873849868774414 \n",
      "Root Mean Squared Error -- train: 0.42469197511672974, -- test: 0.7715028524398804 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.364595413208008, -- test: -8.910305976867676 \n",
      "Root Mean Squared Error -- train: 0.4423351287841797, -- test: 0.7729518413543701 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.975232720375061, -- test: -8.344874382019043 \n",
      "Root Mean Squared Error -- train: 0.4144396185874939, -- test: 0.7501644492149353 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.59338092803955\n",
      "Test Root MSE of all sampled models: 0.7602636218070984\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.524313926696777\n",
      "Test Root MSE of all models in window: 0.7720839977264404\n",
      "\n",
      "############### EM step 150 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.9916678071022034 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 151 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.875864863395691, -- test: -8.7774019241333 \n",
      "Root Mean Squared Error -- train: 0.4079045355319977, -- test: 0.7696104645729065 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.9984920024871826, -- test: -9.201062202453613 \n",
      "Root Mean Squared Error -- train: 0.4170776903629303, -- test: 0.7864130735397339 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.909562587738037, -- test: -8.678832054138184 \n",
      "Root Mean Squared Error -- train: 0.4104457497596741, -- test: 0.7656481862068176 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.001943588256836, -- test: -8.684232711791992 \n",
      "Root Mean Squared Error -- train: 0.4173329472541809, -- test: 0.7658658027648926 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.906582236289978, -- test: -9.060911178588867 \n",
      "Root Mean Squared Error -- train: 0.4102216362953186, -- test: 0.7808945775032043 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8923918008804321, -- test: -8.703614234924316 \n",
      "Root Mean Squared Error -- train: 0.4091528356075287, -- test: 0.7666463255882263 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.8767927885055542, -- test: -8.84941291809082 \n",
      "Root Mean Squared Error -- train: 0.4079747498035431, -- test: 0.7724921703338623 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.9209078550338745, -- test: -9.250789642333984 \n",
      "Root Mean Squared Error -- train: 0.4112977683544159, -- test: 0.7883618474006653 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.0336363315582275, -- test: -9.029391288757324 \n",
      "Root Mean Squared Error -- train: 0.4196696877479553, -- test: 0.7796481251716614 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.9090728759765625, -- test: -8.359068870544434 \n",
      "Root Mean Squared Error -- train: 0.4104089140892029, -- test: 0.7526510953903198 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.81719970703125\n",
      "Test Root MSE of all sampled models: 0.77120441198349\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.511414527893066\n",
      "Test Root MSE of all models in window: 0.7720620036125183\n",
      "\n",
      "############### EM step 151 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.126863956451416 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 152 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.0104432106018066, -- test: -8.663982391357422 \n",
      "Root Mean Squared Error -- train: 0.4188874661922455, -- test: 0.7670011520385742 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.8719491958618164, -- test: -8.654956817626953 \n",
      "Root Mean Squared Error -- train: 0.40850183367729187, -- test: 0.7666359543800354 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.992639422416687, -- test: -8.60622501373291 \n",
      "Root Mean Squared Error -- train: 0.41756680607795715, -- test: 0.764661431312561 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.8765618801116943, -- test: -9.036321640014648 \n",
      "Root Mean Squared Error -- train: 0.4088519811630249, -- test: 0.7819161415100098 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.91378653049469, -- test: -9.291923522949219 \n",
      "Root Mean Squared Error -- train: 0.4116668105125427, -- test: 0.7919923663139343 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8681366443634033, -- test: -8.662786483764648 \n",
      "Root Mean Squared Error -- train: 0.40821215510368347, -- test: 0.7669528126716614 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.8787317276000977, -- test: -8.667640686035156 \n",
      "Root Mean Squared Error -- train: 0.40901657938957214, -- test: 0.7671491503715515 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.2344255447387695, -- test: -9.24917984008789 \n",
      "Root Mean Squared Error -- train: 0.4351595640182495, -- test: 0.7903162837028503 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.878303050994873, -- test: -9.104783058166504 \n",
      "Root Mean Squared Error -- train: 0.40898406505584717, -- test: 0.7846276760101318 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.945157527923584, -- test: -8.030352592468262 \n",
      "Root Mean Squared Error -- train: 0.41402414441108704, -- test: 0.7409296035766602 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.52563762664795\n",
      "Test Root MSE of all sampled models: 0.7613849639892578\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.462427139282227\n",
      "Test Root MSE of all models in window: 0.7719433307647705\n",
      "\n",
      "############### EM step 152 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7016570568084717 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 153 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.0050480365753174, -- test: -8.843049049377441 \n",
      "Root Mean Squared Error -- train: 0.4194014072418213, -- test: 0.7761585116386414 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.878903865814209, -- test: -8.791487693786621 \n",
      "Root Mean Squared Error -- train: 0.40991368889808655, -- test: 0.7740839123725891 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.8595548868179321, -- test: -8.587397575378418 \n",
      "Root Mean Squared Error -- train: 0.40843889117240906, -- test: 0.7658169269561768 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.9885469675064087, -- test: -8.686059951782227 \n",
      "Root Mean Squared Error -- train: 0.41817259788513184, -- test: 0.7698243856430054 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.8652158975601196, -- test: -8.87929916381836 \n",
      "Root Mean Squared Error -- train: 0.4088709354400635, -- test: 0.7776137590408325 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8504949808120728, -- test: -8.6790189743042 \n",
      "Root Mean Squared Error -- train: 0.4077465236186981, -- test: 0.7695391774177551 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.8552463054656982, -- test: -8.822949409484863 \n",
      "Root Mean Squared Error -- train: 0.4081098139286041, -- test: 0.7753504514694214 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.8758808374404907, -- test: -8.981295585632324 \n",
      "Root Mean Squared Error -- train: 0.4096836447715759, -- test: 0.7816938161849976 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.8936082124710083, -- test: -8.770623207092285 \n",
      "Root Mean Squared Error -- train: 0.41103094816207886, -- test: 0.7732428312301636 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.9380139112472534, -- test: -8.729960441589355 \n",
      "Root Mean Squared Error -- train: 0.4143866002559662, -- test: 0.7716009616851807 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.335920333862305\n",
      "Test Root MSE of all sampled models: 0.755506157875061\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.413978576660156\n",
      "Test Root MSE of all models in window: 0.7716248631477356\n",
      "\n",
      "############### EM step 153 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.2611067295074463 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 154 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.8581452369689941, -- test: -8.544008255004883 \n",
      "Root Mean Squared Error -- train: 0.40922075510025024, -- test: 0.7659865021705627 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.8906385898590088, -- test: -8.804190635681152 \n",
      "Root Mean Squared Error -- train: 0.411702960729599, -- test: 0.776563823223114 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.9182641506195068, -- test: -8.816121101379395 \n",
      "Root Mean Squared Error -- train: 0.41380155086517334, -- test: 0.7770454287528992 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -2.21551251411438, -- test: -8.441827774047852 \n",
      "Root Mean Squared Error -- train: 0.43574342131614685, -- test: 0.7617923021316528 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.8422913551330566, -- test: -8.94076919555664 \n",
      "Root Mean Squared Error -- train: 0.4080042243003845, -- test: 0.7820590138435364 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.858975887298584, -- test: -8.199893951416016 \n",
      "Root Mean Squared Error -- train: 0.40928441286087036, -- test: 0.7517682909965515 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.870137333869934, -- test: -8.060821533203125 \n",
      "Root Mean Squared Error -- train: 0.4101385772228241, -- test: 0.7459452748298645 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.3189597129821777, -- test: -8.663763999938965 \n",
      "Root Mean Squared Error -- train: 0.44312477111816406, -- test: 0.7708730101585388 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.8529812097549438, -- test: -8.628769874572754 \n",
      "Root Mean Squared Error -- train: 0.4088248908519745, -- test: 0.7694483995437622 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.005868673324585, -- test: -8.355840682983398 \n",
      "Root Mean Squared Error -- train: 0.42038726806640625, -- test: 0.7582448124885559 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.103446006774902\n",
      "Test Root MSE of all sampled models: 0.788554310798645\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.377601623535156\n",
      "Test Root MSE of all models in window: 0.7715806365013123\n",
      "\n",
      "############### EM step 154 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.5998635292053223 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 155 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.8361328840255737, -- test: -8.4700288772583 \n",
      "Root Mean Squared Error -- train: 0.40840062499046326, -- test: 0.7648522853851318 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.8305201530456543, -- test: -8.920955657958984 \n",
      "Root Mean Squared Error -- train: 0.4079671800136566, -- test: 0.7832150459289551 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.8467388153076172, -- test: -8.817946434020996 \n",
      "Root Mean Squared Error -- train: 0.40921837091445923, -- test: 0.7790584564208984 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.8438571691513062, -- test: -8.869502067565918 \n",
      "Root Mean Squared Error -- train: 0.4089963436126709, -- test: 0.7811415791511536 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.9467540979385376, -- test: -8.418719291687012 \n",
      "Root Mean Squared Error -- train: 0.4168510138988495, -- test: 0.7627347111701965 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.1765987873077393, -- test: -8.307044982910156 \n",
      "Root Mean Squared Error -- train: 0.4338828921318054, -- test: 0.7581057548522949 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.8987925052642822, -- test: -8.510294914245605 \n",
      "Root Mean Squared Error -- train: 0.41320839524269104, -- test: 0.7665098309516907 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.9619760513305664, -- test: -8.469804763793945 \n",
      "Root Mean Squared Error -- train: 0.41800040006637573, -- test: 0.7648430466651917 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.935617446899414, -- test: -8.289778709411621 \n",
      "Root Mean Squared Error -- train: 0.41600799560546875, -- test: 0.7573875188827515 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.066925525665283, -- test: -8.655010223388672 \n",
      "Root Mean Squared Error -- train: 0.42584091424942017, -- test: 0.7724379301071167 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.238905906677246\n",
      "Test Root MSE of all sampled models: 0.755267322063446\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.34554672241211\n",
      "Test Root MSE of all models in window: 0.7715162038803101\n",
      "\n",
      "############### EM step 155 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7802423238754272 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 156 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.8640886545181274, -- test: -8.392040252685547 \n",
      "Root Mean Squared Error -- train: 0.4114230275154114, -- test: 0.7635102272033691 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.0450494289398193, -- test: -8.731377601623535 \n",
      "Root Mean Squared Error -- train: 0.4251311421394348, -- test: 0.7774649262428284 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.98410165309906, -- test: -8.313522338867188 \n",
      "Root Mean Squared Error -- train: 0.42056411504745483, -- test: 0.7602448463439941 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.8703863620758057, -- test: -8.537698745727539 \n",
      "Root Mean Squared Error -- train: 0.41190776228904724, -- test: 0.7695313096046448 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.8220770359039307, -- test: -8.258923530578613 \n",
      "Root Mean Squared Error -- train: 0.4081747233867645, -- test: 0.7579658627510071 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8864284753799438, -- test: -8.341728210449219 \n",
      "Root Mean Squared Error -- train: 0.4131399095058441, -- test: 0.7614194750785828 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.92353355884552, -- test: -8.351029396057129 \n",
      "Root Mean Squared Error -- train: 0.4159758985042572, -- test: 0.7618064880371094 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.8302570581436157, -- test: -8.780374526977539 \n",
      "Root Mean Squared Error -- train: 0.40880918502807617, -- test: 0.7794593572616577 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.8248635530471802, -- test: -8.552935600280762 \n",
      "Root Mean Squared Error -- train: 0.40839096903800964, -- test: 0.7701583504676819 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -2.1430985927581787, -- test: -8.718683242797852 \n",
      "Root Mean Squared Error -- train: 0.43237704038619995, -- test: 0.7769474983215332 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.001311302185059\n",
      "Test Root MSE of all sampled models: 0.788389265537262\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.298667907714844\n",
      "Test Root MSE of all models in window: 0.7714565396308899\n",
      "\n",
      "############### EM step 156 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.1305108070373535 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 157 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.996894359588623, -- test: -8.702117919921875 \n",
      "Root Mean Squared Error -- train: 0.4224362373352051, -- test: 0.7782031893730164 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.819162130355835, -- test: -8.258471488952637 \n",
      "Root Mean Squared Error -- train: 0.40881556272506714, -- test: 0.7598277926445007 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.858840823173523, -- test: -8.191553115844727 \n",
      "Root Mean Squared Error -- train: 0.41189542412757874, -- test: 0.7570173740386963 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.9850095510482788, -- test: -8.641059875488281 \n",
      "Root Mean Squared Error -- train: 0.42153915762901306, -- test: 0.7757000923156738 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.8166520595550537, -- test: -8.428611755371094 \n",
      "Root Mean Squared Error -- train: 0.4086199402809143, -- test: 0.7669269442558289 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.80953848361969, -- test: -8.378321647644043 \n",
      "Root Mean Squared Error -- train: 0.4080650508403778, -- test: 0.7648354172706604 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.8852870464324951, -- test: -7.78665018081665 \n",
      "Root Mean Squared Error -- train: 0.41393545269966125, -- test: 0.7397847771644592 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.821616291999817, -- test: -8.791446685791016 \n",
      "Root Mean Squared Error -- train: 0.4090067148208618, -- test: 0.7818508744239807 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.8374419212341309, -- test: -8.485106468200684 \n",
      "Root Mean Squared Error -- train: 0.41023731231689453, -- test: 0.769269585609436 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.828033447265625, -- test: -9.015314102172852 \n",
      "Root Mean Squared Error -- train: 0.4095061719417572, -- test: 0.7909184098243713 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.195006370544434\n",
      "Test Root MSE of all sampled models: 0.798122227191925\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.264699935913086\n",
      "Test Root MSE of all models in window: 0.7716836929321289\n",
      "\n",
      "############### EM step 157 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.503181219100952 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 158 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.9186862707138062, -- test: -8.427764892578125 \n",
      "Root Mean Squared Error -- train: 0.417409747838974, -- test: 0.7688381671905518 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.8353615999221802, -- test: -8.456799507141113 \n",
      "Root Mean Squared Error -- train: 0.41096749901771545, -- test: 0.770046591758728 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.914090633392334, -- test: -8.59975814819336 \n",
      "Root Mean Squared Error -- train: 0.41705700755119324, -- test: 0.7759687900543213 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.8000380992889404, -- test: -8.512840270996094 \n",
      "Root Mean Squared Error -- train: 0.4082057476043701, -- test: 0.7723734974861145 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -2.1198251247406006, -- test: -8.032967567443848 \n",
      "Root Mean Squared Error -- train: 0.4325656592845917, -- test: 0.7522146701812744 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -2.007784366607666, -- test: -8.08176040649414 \n",
      "Root Mean Squared Error -- train: 0.42419013381004333, -- test: 0.7542890310287476 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.8394969701766968, -- test: -8.237642288208008 \n",
      "Root Mean Squared Error -- train: 0.41128960251808167, -- test: 0.7608780860900879 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.800744891166687, -- test: -8.139203071594238 \n",
      "Root Mean Squared Error -- train: 0.40826117992401123, -- test: 0.7567237615585327 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.8025813102722168, -- test: -8.467559814453125 \n",
      "Root Mean Squared Error -- train: 0.40840521454811096, -- test: 0.7704938650131226 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.8063831329345703, -- test: -8.738860130310059 \n",
      "Root Mean Squared Error -- train: 0.4087032079696655, -- test: 0.7816883325576782 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.775115489959717\n",
      "Test Root MSE of all sampled models: 0.7411561012268066\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.192486763000488\n",
      "Test Root MSE of all models in window: 0.7712512612342834\n",
      "\n",
      "############### EM step 158 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.401573657989502 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 159 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.8786978721618652, -- test: -8.225905418395996 \n",
      "Root Mean Squared Error -- train: 0.41521117091178894, -- test: 0.7622613310813904 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.240448236465454, -- test: -8.192028999328613 \n",
      "Root Mean Squared Error -- train: 0.4423689842224121, -- test: 0.7608293890953064 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.833733081817627, -- test: -8.769026756286621 \n",
      "Root Mean Squared Error -- train: 0.4117104113101959, -- test: 0.7848625183105469 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.8014014959335327, -- test: -8.286197662353516 \n",
      "Root Mean Squared Error -- train: 0.4091746509075165, -- test: 0.7648032307624817 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.8375104665756226, -- test: -8.590507507324219 \n",
      "Root Mean Squared Error -- train: 0.4120056629180908, -- test: 0.7775061726570129 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8252869844436646, -- test: -8.438028335571289 \n",
      "Root Mean Squared Error -- train: 0.411049485206604, -- test: 0.7711673378944397 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.1291520595550537, -- test: -7.952643394470215 \n",
      "Root Mean Squared Error -- train: 0.43419456481933594, -- test: 0.7506325840950012 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.7870525121688843, -- test: -8.343345642089844 \n",
      "Root Mean Squared Error -- train: 0.4080442190170288, -- test: 0.7672048211097717 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.989663004875183, -- test: -8.245630264282227 \n",
      "Root Mean Squared Error -- train: 0.4237268567085266, -- test: 0.7630938291549683 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.794050931930542, -- test: -8.054169654846191 \n",
      "Root Mean Squared Error -- train: 0.4085959494113922, -- test: 0.7549740076065063 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.5415239334106445\n",
      "Test Root MSE of all sampled models: 0.7327898144721985\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.097168922424316\n",
      "Test Root MSE of all models in window: 0.7706226110458374\n",
      "\n",
      "############### EM step 159 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.32026207447052 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 160 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.9836184978485107, -- test: -8.032501220703125 \n",
      "Root Mean Squared Error -- train: 0.424149751663208, -- test: 0.7558576464653015 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.7931690216064453, -- test: -7.983595371246338 \n",
      "Root Mean Squared Error -- train: 0.40936437249183655, -- test: 0.753761351108551 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.7807087898254395, -- test: -8.1659574508667 \n",
      "Root Mean Squared Error -- train: 0.40837836265563965, -- test: 0.7615488171577454 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.8156546354293823, -- test: -8.66365909576416 \n",
      "Root Mean Squared Error -- train: 0.4111377000808716, -- test: 0.7824080586433411 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.7775551080703735, -- test: -8.169489860534668 \n",
      "Root Mean Squared Error -- train: 0.40812841057777405, -- test: 0.761698842048645 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8022396564483643, -- test: -8.309402465820312 \n",
      "Root Mean Squared Error -- train: 0.41008061170578003, -- test: 0.7676189541816711 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.7962430715560913, -- test: -8.38017749786377 \n",
      "Root Mean Squared Error -- train: 0.4096072316169739, -- test: 0.7705962657928467 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.8299884796142578, -- test: -8.352662086486816 \n",
      "Root Mean Squared Error -- train: 0.4122641384601593, -- test: 0.7694401741027832 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.0611703395843506, -- test: -8.116265296936035 \n",
      "Root Mean Squared Error -- train: 0.43002477288246155, -- test: 0.7594347596168518 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.861852765083313, -- test: -8.341979026794434 \n",
      "Root Mean Squared Error -- train: 0.41475731134414673, -- test: 0.7689907550811768 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.741077423095703\n",
      "Test Root MSE of all sampled models: 0.7856031060218811\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.082987785339355\n",
      "Test Root MSE of all models in window: 0.7708126306533813\n",
      "\n",
      "############### EM step 160 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.209582805633545 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 161 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.78342604637146, -- test: -8.363295555114746 \n",
      "Root Mean Squared Error -- train: 0.4094420075416565, -- test: 0.7717623710632324 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.8580056428909302, -- test: -8.592721939086914 \n",
      "Root Mean Squared Error -- train: 0.41532355546951294, -- test: 0.7813703417778015 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.827321171760559, -- test: -8.521966934204102 \n",
      "Root Mean Squared Error -- train: 0.41291382908821106, -- test: 0.7784199714660645 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.825331211090088, -- test: -8.691168785095215 \n",
      "Root Mean Squared Error -- train: 0.4127570688724518, -- test: 0.7854572534561157 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.8857156038284302, -- test: -8.549151420593262 \n",
      "Root Mean Squared Error -- train: 0.4174876809120178, -- test: 0.7795549035072327 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8536840677261353, -- test: -8.44321060180664 \n",
      "Root Mean Squared Error -- train: 0.4149850010871887, -- test: 0.7751226425170898 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.200955629348755, -- test: -8.390951156616211 \n",
      "Root Mean Squared Error -- train: 0.4413616955280304, -- test: 0.7729268670082092 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.7744866609573364, -- test: -8.381438255310059 \n",
      "Root Mean Squared Error -- train: 0.4087313413619995, -- test: 0.7725265026092529 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.7787011861801147, -- test: -8.518937110900879 \n",
      "Root Mean Squared Error -- train: 0.4090665578842163, -- test: 0.7782933712005615 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.8847215175628662, -- test: -8.474677085876465 \n",
      "Root Mean Squared Error -- train: 0.4174102544784546, -- test: 0.7764416933059692 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -9.29496955871582\n",
      "Test Root MSE of all sampled models: 0.8100716471672058\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -8.065950393676758\n",
      "Test Root MSE of all models in window: 0.7711232304573059\n",
      "\n",
      "############### EM step 161 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.5719208717346191 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 162 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.7881343364715576, -- test: -8.418815612792969 \n",
      "Root Mean Squared Error -- train: 0.4106537997722626, -- test: 0.7759553790092468 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -2.07436203956604, -- test: -8.431103706359863 \n",
      "Root Mean Squared Error -- train: 0.43283742666244507, -- test: 0.7764729261398315 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.7556012868881226, -- test: -8.469077110290527 \n",
      "Root Mean Squared Error -- train: 0.4080560505390167, -- test: 0.7780697345733643 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.755442500114441, -- test: -8.284737586975098 \n",
      "Root Mean Squared Error -- train: 0.40804335474967957, -- test: 0.7702867388725281 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.9763976335525513, -- test: -8.656988143920898 \n",
      "Root Mean Squared Error -- train: 0.4253750741481781, -- test: 0.7859242558479309 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8777199983596802, -- test: -8.153039932250977 \n",
      "Root Mean Squared Error -- train: 0.4177236557006836, -- test: 0.7646777629852295 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.7595785856246948, -- test: -8.019153594970703 \n",
      "Root Mean Squared Error -- train: 0.4083745777606964, -- test: 0.7589331865310669 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.7643400430679321, -- test: -7.980630397796631 \n",
      "Root Mean Squared Error -- train: 0.40875548124313354, -- test: 0.7572721838951111 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.7755461931228638, -- test: -8.394244194030762 \n",
      "Root Mean Squared Error -- train: 0.409650593996048, -- test: 0.7749196290969849 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.7584017515182495, -- test: -8.269159317016602 \n",
      "Root Mean Squared Error -- train: 0.4082803428173065, -- test: 0.7696254253387451 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.447625160217285\n",
      "Test Root MSE of all sampled models: 0.7339051365852356\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.920919895172119\n",
      "Test Root MSE of all models in window: 0.7705271244049072\n",
      "\n",
      "############### EM step 162 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.972694993019104 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 163 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.8304320573806763, -- test: -8.425848960876465 \n",
      "Root Mean Squared Error -- train: 0.4148596227169037, -- test: 0.7781206965446472 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.7471177577972412, -- test: -8.100343704223633 \n",
      "Root Mean Squared Error -- train: 0.40820854902267456, -- test: 0.7642537355422974 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.8182682991027832, -- test: -8.168510437011719 \n",
      "Root Mean Squared Error -- train: 0.41389527916908264, -- test: 0.767178475856781 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.837059497833252, -- test: -8.267912864685059 \n",
      "Root Mean Squared Error -- train: 0.4153841435909271, -- test: 0.7714235782623291 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.7494131326675415, -- test: -8.212223052978516 \n",
      "Root Mean Squared Error -- train: 0.4083932340145111, -- test: 0.769048273563385 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.7951157093048096, -- test: -7.973813533782959 \n",
      "Root Mean Squared Error -- train: 0.4120533764362335, -- test: 0.7587950825691223 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.7551672458648682, -- test: -8.2107572555542 \n",
      "Root Mean Squared Error -- train: 0.4088558554649353, -- test: 0.7689855694770813 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.961417317390442, -- test: -8.1060209274292 \n",
      "Root Mean Squared Error -- train: 0.4251059889793396, -- test: 0.7644977569580078 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.7967631816864014, -- test: -7.942734241485596 \n",
      "Root Mean Squared Error -- train: 0.4121847152709961, -- test: 0.7574482560157776 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.7952213287353516, -- test: -8.168034553527832 \n",
      "Root Mean Squared Error -- train: 0.41206181049346924, -- test: 0.7671581506729126 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.721665859222412\n",
      "Test Root MSE of all sampled models: 0.7477982044219971\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.8254008293151855\n",
      "Test Root MSE of all models in window: 0.7701699733734131\n",
      "\n",
      "############### EM step 163 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.659385919570923 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 164 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.7386630773544312, -- test: -8.224398612976074 \n",
      "Root Mean Squared Error -- train: 0.4083874523639679, -- test: 0.7714808583259583 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.8154457807540894, -- test: -7.9961371421813965 \n",
      "Root Mean Squared Error -- train: 0.41455045342445374, -- test: 0.7616463899612427 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.7485134601593018, -- test: -8.172121047973633 \n",
      "Root Mean Squared Error -- train: 0.4091832935810089, -- test: 0.769239604473114 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.808178186416626, -- test: -8.000319480895996 \n",
      "Root Mean Squared Error -- train: 0.41397103667259216, -- test: 0.7618277668952942 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.7349369525909424, -- test: -8.121687889099121 \n",
      "Root Mean Squared Error -- train: 0.40808603167533875, -- test: 0.7670712471008301 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8394395112991333, -- test: -8.243063926696777 \n",
      "Root Mean Squared Error -- train: 0.4164576232433319, -- test: 0.7722793817520142 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.7385653257369995, -- test: -8.159693717956543 \n",
      "Root Mean Squared Error -- train: 0.40837955474853516, -- test: 0.7687058448791504 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.7980093955993652, -- test: -8.323860168457031 \n",
      "Root Mean Squared Error -- train: 0.41315898299217224, -- test: 0.7757269740104675 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.7401108741760254, -- test: -8.37159538269043 \n",
      "Root Mean Squared Error -- train: 0.40850454568862915, -- test: 0.7777566313743591 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.7419480085372925, -- test: -8.072637557983398 \n",
      "Root Mean Squared Error -- train: 0.40865305066108704, -- test: 0.7649564743041992 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.561227798461914\n",
      "Test Root MSE of all sampled models: 0.7857679724693298\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.8118815422058105\n",
      "Test Root MSE of all models in window: 0.7702500224113464\n",
      "\n",
      "############### EM step 164 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.958362340927124 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 165 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.776668667793274, -- test: -8.263176918029785 \n",
      "Root Mean Squared Error -- train: 0.4122829735279083, -- test: 0.7749777436256409 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.7882285118103027, -- test: -7.912667751312256 \n",
      "Root Mean Squared Error -- train: 0.4132126271724701, -- test: 0.7598168849945068 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -2.124255895614624, -- test: -7.8383941650390625 \n",
      "Root Mean Squared Error -- train: 0.4393770396709442, -- test: 0.7565652132034302 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 10:01:38.929963: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.7818233966827393, -- test: -8.371685028076172 \n",
      "Root Mean Squared Error -- train: 0.41269776225090027, -- test: 0.7796114087104797 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.7280884981155396, -- test: -8.173208236694336 \n",
      "Root Mean Squared Error -- train: 0.4083530604839325, -- test: 0.771114706993103 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.9192728996276855, -- test: -8.064432144165039 \n",
      "Root Mean Squared Error -- train: 0.42360854148864746, -- test: 0.7664180994033813 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -2.019239664077759, -- test: -7.7634687423706055 \n",
      "Root Mean Squared Error -- train: 0.4313705563545227, -- test: 0.7532708644866943 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.8457934856414795, -- test: -8.353829383850098 \n",
      "Root Mean Squared Error -- train: 0.41781115531921387, -- test: 0.778850793838501 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -2.2646067142486572, -- test: -7.791641712188721 \n",
      "Root Mean Squared Error -- train: 0.4498549997806549, -- test: 0.754511296749115 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.7561379671096802, -- test: -7.894379138946533 \n",
      "Root Mean Squared Error -- train: 0.41062673926353455, -- test: 0.7590175271034241 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.819128036499023\n",
      "Test Root MSE of all sampled models: 0.7557194232940674\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.777701377868652\n",
      "Test Root MSE of all models in window: 0.7702462673187256\n",
      "\n",
      "############### EM step 165 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.720160961151123 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 166 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.7206964492797852, -- test: -8.22170639038086 \n",
      "Root Mean Squared Error -- train: 0.4085676968097687, -- test: 0.7750259637832642 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.718801498413086, -- test: -8.268836975097656 \n",
      "Root Mean Squared Error -- train: 0.4084129333496094, -- test: 0.7770519256591797 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.7969063520431519, -- test: -8.062956809997559 \n",
      "Root Mean Squared Error -- train: 0.41474348306655884, -- test: 0.7681624889373779 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.7635456323623657, -- test: -8.314925193786621 \n",
      "Root Mean Squared Error -- train: 0.4120514690876007, -- test: 0.7790279984474182 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.734760046005249, -- test: -8.275038719177246 \n",
      "Root Mean Squared Error -- train: 0.40971437096595764, -- test: 0.7773180603981018 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.836690902709961, -- test: -7.914474964141846 \n",
      "Root Mean Squared Error -- train: 0.41793128848075867, -- test: 0.7616870999336243 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.713180422782898, -- test: -7.968516826629639 \n",
      "Root Mean Squared Error -- train: 0.40795353055000305, -- test: 0.7640502452850342 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.7195192575454712, -- test: -8.043326377868652 \n",
      "Root Mean Squared Error -- train: 0.40847158432006836, -- test: 0.7673096060752869 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.782761573791504, -- test: -7.689237117767334 \n",
      "Root Mean Squared Error -- train: 0.413604199886322, -- test: 0.7517577409744263 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.731786847114563, -- test: -8.286388397216797 \n",
      "Root Mean Squared Error -- train: 0.4094722270965576, -- test: 0.7778050303459167 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.705499649047852\n",
      "Test Root MSE of all sampled models: 0.7955771684646606\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.7572736740112305\n",
      "Test Root MSE of all models in window: 0.7704988121986389\n",
      "\n",
      "############### EM step 166 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.8261244297027588 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 167 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.7514218091964722, -- test: -7.808740139007568 \n",
      "Root Mean Squared Error -- train: 0.41189277172088623, -- test: 0.7588234543800354 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.712787389755249, -- test: -8.24142837524414 \n",
      "Root Mean Squared Error -- train: 0.408735990524292, -- test: 0.7777054309844971 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.9572052955627441, -- test: -8.037782669067383 \n",
      "Root Mean Squared Error -- train: 0.4283152222633362, -- test: 0.7688762545585632 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.7037134170532227, -- test: -8.29980182647705 \n",
      "Root Mean Squared Error -- train: 0.40799105167388916, -- test: 0.7802177667617798 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.7986433506011963, -- test: -7.84525203704834 \n",
      "Root Mean Squared Error -- train: 0.41571861505508423, -- test: 0.7604348659515381 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8586703538894653, -- test: -8.067583084106445 \n",
      "Root Mean Squared Error -- train: 0.4205317199230194, -- test: 0.7701746225357056 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.707276701927185, -- test: -8.125617980957031 \n",
      "Root Mean Squared Error -- train: 0.4082837402820587, -- test: 0.7726967930793762 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.7258485555648804, -- test: -8.035250663757324 \n",
      "Root Mean Squared Error -- train: 0.40980595350265503, -- test: 0.7687658667564392 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.7150107622146606, -- test: -7.953004837036133 \n",
      "Root Mean Squared Error -- train: 0.4089183509349823, -- test: 0.7651707530021667 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.803323745727539, -- test: -8.183615684509277 \n",
      "Root Mean Squared Error -- train: 0.41609591245651245, -- test: 0.7752091884613037 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.953402519226074\n",
      "Test Root MSE of all sampled models: 0.7200419902801514\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.569418430328369\n",
      "Test Root MSE of all models in window: 0.7703378796577454\n",
      "\n",
      "############### EM step 167 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.8200600147247314 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 168 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.7007673978805542, -- test: -7.9457011222839355 \n",
      "Root Mean Squared Error -- train: 0.40859779715538025, -- test: 0.7667315006256104 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.7498551607131958, -- test: -8.017434120178223 \n",
      "Root Mean Squared Error -- train: 0.412626713514328, -- test: 0.7698780298233032 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6965663433074951, -- test: -7.974003314971924 \n",
      "Root Mean Squared Error -- train: 0.4082511365413666, -- test: 0.7679744958877563 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.6994915008544922, -- test: -7.858749866485596 \n",
      "Root Mean Squared Error -- train: 0.4084925353527069, -- test: 0.7628999948501587 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.739383339881897, -- test: -8.205157279968262 \n",
      "Root Mean Squared Error -- train: 0.4117705225944519, -- test: 0.7780521512031555 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.6964070796966553, -- test: -8.177794456481934 \n",
      "Root Mean Squared Error -- train: 0.408238023519516, -- test: 0.7768660187721252 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.7851850986480713, -- test: -7.913602828979492 \n",
      "Root Mean Squared Error -- train: 0.41550227999687195, -- test: 0.7653193473815918 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.7065565586090088, -- test: -8.160118103027344 \n",
      "Root Mean Squared Error -- train: 0.4090750217437744, -- test: 0.7760988473892212 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.7170639038085938, -- test: -8.049633026123047 \n",
      "Root Mean Squared Error -- train: 0.4099397361278534, -- test: 0.7712861895561218 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.7099868059158325, -- test: -7.955718994140625 \n",
      "Root Mean Squared Error -- train: 0.4093575179576874, -- test: 0.7671716809272766 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.160113334655762\n",
      "Test Root MSE of all sampled models: 0.7760985493659973\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.557799816131592\n",
      "Test Root MSE of all models in window: 0.7702786326408386\n",
      "\n",
      "############### EM step 168 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.7480419278144836 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 169 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.6936012506484985, -- test: -7.972736835479736 \n",
      "Root Mean Squared Error -- train: 0.40881073474884033, -- test: 0.7697094082832336 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.7730101346969604, -- test: -8.34021282196045 \n",
      "Root Mean Squared Error -- train: 0.41533732414245605, -- test: 0.785712480545044 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.7019339799880981, -- test: -7.981662750244141 \n",
      "Root Mean Squared Error -- train: 0.40950050950050354, -- test: 0.7701020240783691 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.9626506567001343, -- test: -8.05013370513916 \n",
      "Root Mean Squared Error -- train: 0.43052375316619873, -- test: 0.7731074690818787 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.699131727218628, -- test: -7.619114398956299 \n",
      "Root Mean Squared Error -- train: 0.40926864743232727, -- test: 0.7539889812469482 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.7187527418136597, -- test: -7.912416458129883 \n",
      "Root Mean Squared Error -- train: 0.4108891785144806, -- test: 0.7670506238937378 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.7462825775146484, -- test: -7.901381015777588 \n",
      "Root Mean Squared Error -- train: 0.41315212845802307, -- test: 0.7665631771087646 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.6814879179000854, -- test: -8.073949813842773 \n",
      "Root Mean Squared Error -- train: 0.4078059792518616, -- test: 0.7741501331329346 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.7137477397918701, -- test: -7.9560227394104 \n",
      "Root Mean Squared Error -- train: 0.410476416349411, -- test: 0.7689735889434814 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.6934765577316284, -- test: -7.988864898681641 \n",
      "Root Mean Squared Error -- train: 0.4088004231452942, -- test: 0.7704187035560608 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.083045959472656\n",
      "Test Root MSE of all sampled models: 0.7745479345321655\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.538336277008057\n",
      "Test Root MSE of all models in window: 0.7703434228897095\n",
      "\n",
      "############### EM step 169 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7504194974899292 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 170 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.7296031713485718, -- test: -8.213957786560059 \n",
      "Root Mean Squared Error -- train: 0.4125947058200836, -- test: 0.7820676565170288 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.932788610458374, -- test: -8.158173561096191 \n",
      "Root Mean Squared Error -- train: 0.4290284216403961, -- test: 0.7796362638473511 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6918940544128418, -- test: -7.689019680023193 \n",
      "Root Mean Squared Error -- train: 0.40947219729423523, -- test: 0.7588787078857422 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.7365481853485107, -- test: -7.943413257598877 \n",
      "Root Mean Squared Error -- train: 0.41316720843315125, -- test: 0.7702035903930664 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.6822863817214966, -- test: -7.997941970825195 \n",
      "Root Mean Squared Error -- train: 0.40867283940315247, -- test: 0.7726095914840698 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.7619998455047607, -- test: -7.654219150543213 \n",
      "Root Mean Squared Error -- train: 0.415258526802063, -- test: 0.7573163509368896 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.6740736961364746, -- test: -7.924558639526367 \n",
      "Root Mean Squared Error -- train: 0.4079882800579071, -- test: 0.7693700194358826 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.6784839630126953, -- test: -7.91275691986084 \n",
      "Root Mean Squared Error -- train: 0.40835604071617126, -- test: 0.7688477039337158 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.7671809196472168, -- test: -7.936992645263672 \n",
      "Root Mean Squared Error -- train: 0.41568300127983093, -- test: 0.7699198722839355 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.6808032989501953, -- test: -7.673651218414307 \n",
      "Root Mean Squared Error -- train: 0.40854930877685547, -- test: 0.7581890821456909 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.6255598068237305\n",
      "Test Root MSE of all sampled models: 0.7560271620750427\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.485998153686523\n",
      "Test Root MSE of all models in window: 0.7700976133346558\n",
      "\n",
      "############### EM step 170 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.6472115516662598 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 171 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.6921113729476929, -- test: -7.823275566101074 \n",
      "Root Mean Squared Error -- train: 0.41028866171836853, -- test: 0.766638994216919 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.6887422800064087, -- test: -8.080721855163574 \n",
      "Root Mean Squared Error -- train: 0.41000768542289734, -- test: 0.7780397534370422 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.685512900352478, -- test: -8.112201690673828 \n",
      "Root Mean Squared Error -- train: 0.4097381830215454, -- test: 0.779422402381897 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.6690202951431274, -- test: -7.847462177276611 \n",
      "Root Mean Squared Error -- train: 0.40835919976234436, -- test: 0.7677172422409058 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.6670256853103638, -- test: -7.810234546661377 \n",
      "Root Mean Squared Error -- train: 0.40819209814071655, -- test: 0.7660569548606873 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.6925958395004272, -- test: -8.10595989227295 \n",
      "Root Mean Squared Error -- train: 0.4103289842605591, -- test: 0.7791483998298645 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.7091065645217896, -- test: -7.738376617431641 \n",
      "Root Mean Squared Error -- train: 0.4117029309272766, -- test: 0.7628419995307922 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.6693787574768066, -- test: -7.897884368896484 \n",
      "Root Mean Squared Error -- train: 0.40838921070098877, -- test: 0.7699604034423828 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.6676748991012573, -- test: -7.804062366485596 \n",
      "Root Mean Squared Error -- train: 0.4082464873790741, -- test: 0.7657813429832458 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.6677199602127075, -- test: -7.662073135375977 \n",
      "Root Mean Squared Error -- train: 0.40825024247169495, -- test: 0.7594132423400879 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.125911712646484\n",
      "Test Root MSE of all sampled models: 0.7800237536430359\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.474637031555176\n",
      "Test Root MSE of all models in window: 0.7701470851898193\n",
      "\n",
      "############### EM step 171 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.127981662750244 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 172 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.6761341094970703, -- test: -8.181565284729004 \n",
      "Root Mean Squared Error -- train: 0.40976282954216003, -- test: 0.7842962741851807 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.6914182901382446, -- test: -8.088693618774414 \n",
      "Root Mean Squared Error -- train: 0.4110429584980011, -- test: 0.7802155017852783 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.9917993545532227, -- test: -7.7991557121276855 \n",
      "Root Mean Squared Error -- train: 0.43543770909309387, -- test: 0.767353892326355 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.6895318031311035, -- test: -7.941622734069824 \n",
      "Root Mean Squared Error -- train: 0.41088515520095825, -- test: 0.7737091779708862 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.6817231178283691, -- test: -7.758248329162598 \n",
      "Root Mean Squared Error -- train: 0.41023141145706177, -- test: 0.7655192017555237 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.6608895063400269, -- test: -8.1815767288208 \n",
      "Root Mean Squared Error -- train: 0.40848207473754883, -- test: 0.7842967510223389 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.6985886096954346, -- test: -8.045315742492676 \n",
      "Root Mean Squared Error -- train: 0.4116421341896057, -- test: 0.7783020734786987 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.6583746671676636, -- test: -7.861408710479736 \n",
      "Root Mean Squared Error -- train: 0.4082704484462738, -- test: 0.7701373100280762 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.655964732170105, -- test: -7.937801361083984 \n",
      "Root Mean Squared Error -- train: 0.4080674946308136, -- test: 0.7735393047332764 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.6595722436904907, -- test: -7.655755519866943 \n",
      "Root Mean Squared Error -- train: 0.408371239900589, -- test: 0.7609033584594727 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.714119911193848\n",
      "Test Root MSE of all sampled models: 0.8072986006736755\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.467655181884766\n",
      "Test Root MSE of all models in window: 0.7706838846206665\n",
      "\n",
      "############### EM step 172 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2998439073562622 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 173 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.771647572517395, -- test: -7.598377704620361 \n",
      "Root Mean Squared Error -- train: 0.41851136088371277, -- test: 0.7600362300872803 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.7027324438095093, -- test: -7.829616069793701 \n",
      "Root Mean Squared Error -- train: 0.4127846956253052, -- test: 0.7704731225967407 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6846160888671875, -- test: -7.789892673492432 \n",
      "Root Mean Squared Error -- train: 0.4112659990787506, -- test: 0.7686902284622192 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.6466494798660278, -- test: -7.806057929992676 \n",
      "Root Mean Squared Error -- train: 0.40806499123573303, -- test: 0.7694162726402283 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.6652027368545532, -- test: -7.730654239654541 \n",
      "Root Mean Squared Error -- train: 0.4096323549747467, -- test: 0.7660239338874817 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.7610782384872437, -- test: -7.539703369140625 \n",
      "Root Mean Squared Error -- train: 0.4176381528377533, -- test: 0.7573651075363159 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.7443273067474365, -- test: -7.9128947257995605 \n",
      "Root Mean Squared Error -- train: 0.4162505269050598, -- test: 0.7741973996162415 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.74637770652771, -- test: -7.957003116607666 \n",
      "Root Mean Squared Error -- train: 0.4164206385612488, -- test: 0.7761627435684204 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.7073477506637573, -- test: -7.739320755004883 \n",
      "Root Mean Squared Error -- train: 0.4131706953048706, -- test: 0.7664145231246948 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.7254444360733032, -- test: -7.62142276763916 \n",
      "Root Mean Squared Error -- train: 0.41468071937561035, -- test: 0.7610827684402466 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.903094291687012\n",
      "Test Root MSE of all sampled models: 0.7737600207328796\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.444867134094238\n",
      "Test Root MSE of all models in window: 0.7709855437278748\n",
      "\n",
      "############### EM step 173 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.4103062152862549 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 174 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.7488666772842407, -- test: -7.808233261108398 \n",
      "Root Mean Squared Error -- train: 0.41742244362831116, -- test: 0.7712416052818298 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.6650004386901855, -- test: -7.609610557556152 \n",
      "Root Mean Squared Error -- train: 0.4103906452655792, -- test: 0.762251615524292 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.8162723779678345, -- test: -7.610296249389648 \n",
      "Root Mean Squared Error -- train: 0.4229894280433655, -- test: 0.7622827887535095 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.6406067609786987, -- test: -7.7306389808654785 \n",
      "Root Mean Squared Error -- train: 0.40832260251045227, -- test: 0.7677420973777771 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.6471145153045654, -- test: -7.7463178634643555 \n",
      "Root Mean Squared Error -- train: 0.40887534618377686, -- test: 0.7684505581855774 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.8118821382522583, -- test: -7.8962721824646 \n",
      "Root Mean Squared Error -- train: 0.42262908816337585, -- test: 0.7751930356025696 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.63979971408844, -- test: -7.7746262550354 \n",
      "Root Mean Squared Error -- train: 0.4082540273666382, -- test: 0.769727885723114 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.6499825716018677, -- test: -7.5971760749816895 \n",
      "Root Mean Squared Error -- train: 0.4091186821460724, -- test: 0.7616851925849915 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.6591616868972778, -- test: -7.647314071655273 \n",
      "Root Mean Squared Error -- train: 0.4098966121673584, -- test: 0.7639662027359009 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.6580888032913208, -- test: -7.542315483093262 \n",
      "Root Mean Squared Error -- train: 0.4098057448863983, -- test: 0.759181559085846 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.222088813781738\n",
      "Test Root MSE of all sampled models: 0.7443991303443909\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.411442279815674\n",
      "Test Root MSE of all models in window: 0.7701655626296997\n",
      "\n",
      "############### EM step 174 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.9098201990127563 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 175 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.684978723526001, -- test: -7.475535869598389 \n",
      "Root Mean Squared Error -- train: 0.41286492347717285, -- test: 0.757830798625946 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.6301367282867432, -- test: -7.4895195960998535 \n",
      "Root Mean Squared Error -- train: 0.4082065522670746, -- test: 0.7584739923477173 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6400198936462402, -- test: -7.481828212738037 \n",
      "Root Mean Squared Error -- train: 0.40904995799064636, -- test: 0.7581202983856201 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.646613597869873, -- test: -7.635155200958252 \n",
      "Root Mean Squared Error -- train: 0.40961170196533203, -- test: 0.7651404142379761 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.6411665678024292, -- test: -7.926249980926514 \n",
      "Root Mean Squared Error -- train: 0.4091476798057556, -- test: 0.7782940864562988 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.6546926498413086, -- test: -7.822492599487305 \n",
      "Root Mean Squared Error -- train: 0.4102988839149475, -- test: 0.7736312747001648 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.6279306411743164, -- test: -7.765387535095215 \n",
      "Root Mean Squared Error -- train: 0.4080180525779724, -- test: 0.7710529565811157 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.6581839323043823, -- test: -7.656764984130859 \n",
      "Root Mean Squared Error -- train: 0.41059550642967224, -- test: 0.7661246061325073 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.8027729988098145, -- test: -7.529318332672119 \n",
      "Root Mean Squared Error -- train: 0.422696977853775, -- test: 0.7603015899658203 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.649491548538208, -- test: -7.839189052581787 \n",
      "Root Mean Squared Error -- train: 0.4098565876483917, -- test: 0.7743834257125854 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.560366153717041\n",
      "Test Root MSE of all sampled models: 0.7617242932319641\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.341408729553223\n",
      "Test Root MSE of all models in window: 0.7704168558120728\n",
      "\n",
      "############### EM step 175 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.3389086723327637 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 176 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.6831459999084473, -- test: -7.871799468994141 \n",
      "Root Mean Squared Error -- train: 0.4135217070579529, -- test: 0.7776585221290588 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.621811866760254, -- test: -7.364507675170898 \n",
      "Root Mean Squared Error -- train: 0.4082908034324646, -- test: 0.7544518113136292 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6415040493011475, -- test: -7.649881362915039 \n",
      "Root Mean Squared Error -- train: 0.409977525472641, -- test: 0.7675929069519043 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.6425565481185913, -- test: -7.7566399574279785 \n",
      "Root Mean Squared Error -- train: 0.41006746888160706, -- test: 0.7724515795707703 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.6229521036148071, -- test: -7.534412860870361 \n",
      "Root Mean Squared Error -- train: 0.4083886444568634, -- test: 0.7623029351234436 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.6460727453231812, -- test: -7.501955509185791 \n",
      "Root Mean Squared Error -- train: 0.410367876291275, -- test: 0.7608093619346619 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.7289386987686157, -- test: -7.666008949279785 \n",
      "Root Mean Squared Error -- train: 0.41738441586494446, -- test: 0.7683287858963013 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.6344857215881348, -- test: -7.881793022155762 \n",
      "Root Mean Squared Error -- train: 0.40937718749046326, -- test: 0.7781087160110474 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.6208752393722534, -- test: -7.396985054016113 \n",
      "Root Mean Squared Error -- train: 0.408210426568985, -- test: 0.7559587955474854 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.6762391328811646, -- test: -7.5274858474731445 \n",
      "Root Mean Squared Error -- train: 0.4129359722137451, -- test: 0.7619844675064087 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.32336139678955\n",
      "Test Root MSE of all sampled models: 0.7977480292320251\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.333569526672363\n",
      "Test Root MSE of all models in window: 0.7708477973937988\n",
      "\n",
      "############### EM step 176 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.967066764831543 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 177 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.758952021598816, -- test: -7.514707088470459 \n",
      "Root Mean Squared Error -- train: 0.4206961393356323, -- test: 0.7630966305732727 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.806072473526001, -- test: -7.692626953125 \n",
      "Root Mean Squared Error -- train: 0.4246216118335724, -- test: 0.7712625861167908 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6824138164520264, -- test: -7.718364715576172 \n",
      "Root Mean Squared Error -- train: 0.4142405688762665, -- test: 0.7724366784095764 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.6623107194900513, -- test: -7.779415130615234 \n",
      "Root Mean Squared Error -- train: 0.41252824664115906, -- test: 0.7752146124839783 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.6122325658798218, -- test: -7.724471569061279 \n",
      "Root Mean Squared Error -- train: 0.4082314670085907, -- test: 0.7727149724960327 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.6211587190628052, -- test: -7.517137050628662 \n",
      "Root Mean Squared Error -- train: 0.4090006649494171, -- test: 0.7632087469100952 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.7367984056472778, -- test: -7.387342929840088 \n",
      "Root Mean Squared Error -- train: 0.4188378155231476, -- test: 0.7571969628334045 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.9345145225524902, -- test: -7.89603328704834 \n",
      "Root Mean Squared Error -- train: 0.4351421296596527, -- test: 0.7804934978485107 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.608826994895935, -- test: -7.836127281188965 \n",
      "Root Mean Squared Error -- train: 0.4079376459121704, -- test: 0.7777862548828125 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.6243661642074585, -- test: -7.604231357574463 \n",
      "Root Mean Squared Error -- train: 0.40927672386169434, -- test: 0.7672163248062134 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.066944122314453\n",
      "Test Root MSE of all sampled models: 0.7881662845611572\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.313856601715088\n",
      "Test Root MSE of all models in window: 0.7710329294204712\n",
      "\n",
      "############### EM step 177 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3946844339370728 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 178 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.7124265432357788, -- test: -7.568623065948486 \n",
      "Root Mean Squared Error -- train: 0.4175608456134796, -- test: 0.7672632336616516 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.6832822561264038, -- test: -7.483675956726074 \n",
      "Root Mean Squared Error -- train: 0.4150843918323517, -- test: 0.763336718082428 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6178104877471924, -- test: -7.377040863037109 \n",
      "Root Mean Squared Error -- train: 0.4094665050506592, -- test: 0.7583786845207214 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.9104844331741333, -- test: -7.792804718017578 \n",
      "Root Mean Squared Error -- train: 0.4340161383152008, -- test: 0.7775309085845947 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.648686170578003, -- test: -7.685985088348389 \n",
      "Root Mean Squared Error -- train: 0.4121253788471222, -- test: 0.7726554870605469 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.6431673765182495, -- test: -7.378607273101807 \n",
      "Root Mean Squared Error -- train: 0.4116513729095459, -- test: 0.7584517598152161 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.6047409772872925, -- test: -7.417564868927002 \n",
      "Root Mean Squared Error -- train: 0.40833577513694763, -- test: 0.7602666616439819 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.9113961458206177, -- test: -7.645466327667236 \n",
      "Root Mean Squared Error -- train: 0.43409040570259094, -- test: 0.7707981467247009 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.6549479961395264, -- test: -7.606759548187256 \n",
      "Root Mean Squared Error -- train: 0.412662535905838, -- test: 0.7690197229385376 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.6597708463668823, -- test: -7.41232442855835 \n",
      "Root Mean Squared Error -- train: 0.4130757451057434, -- test: 0.760022759437561 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.977497100830078\n",
      "Test Root MSE of all sampled models: 0.7858890295028687\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.2526469230651855\n",
      "Test Root MSE of all models in window: 0.7711883187294006\n",
      "\n",
      "############### EM step 178 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.9381450414657593 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 179 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.6022306680679321, -- test: -7.649942398071289 \n",
      "Root Mean Squared Error -- train: 0.4088793694972992, -- test: 0.7727210521697998 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.7141480445861816, -- test: -7.453985691070557 \n",
      "Root Mean Squared Error -- train: 0.418495237827301, -- test: 0.7636542916297913 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.7958468198776245, -- test: -7.7652668952941895 \n",
      "Root Mean Squared Error -- train: 0.4253774881362915, -- test: 0.7780076861381531 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.65640389919281, -- test: -7.3658766746521 \n",
      "Root Mean Squared Error -- train: 0.4135618209838867, -- test: 0.7595422267913818 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.598354697227478, -- test: -7.599978446960449 \n",
      "Root Mean Squared Error -- train: 0.40854230523109436, -- test: 0.7704194188117981 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.5995455980300903, -- test: -7.763743877410889 \n",
      "Root Mean Squared Error -- train: 0.4086458683013916, -- test: 0.7779381275177002 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.625223994255066, -- test: -7.56871223449707 \n",
      "Root Mean Squared Error -- train: 0.41087332367897034, -- test: 0.768975555896759 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.6272705793380737, -- test: -7.863193988800049 \n",
      "Root Mean Squared Error -- train: 0.41105031967163086, -- test: 0.7824687361717224 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.615486979484558, -- test: -7.66547966003418 \n",
      "Root Mean Squared Error -- train: 0.4100300967693329, -- test: 0.7734354138374329 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.622848629951477, -- test: -7.590090274810791 \n",
      "Root Mean Squared Error -- train: 0.4106677770614624, -- test: 0.7699630856513977 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.00386905670166\n",
      "Test Root MSE of all sampled models: 0.7424084544181824\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.198545455932617\n",
      "Test Root MSE of all models in window: 0.7711162567138672\n",
      "\n",
      "############### EM step 179 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7362971305847168 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 180 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5961155891418457, -- test: -7.458620071411133 \n",
      "Root Mean Squared Error -- train: 0.4091093838214874, -- test: 0.7655715346336365 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.6321412324905396, -- test: -7.369356155395508 \n",
      "Root Mean Squared Error -- train: 0.41224220395088196, -- test: 0.7613961696624756 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.590196967124939, -- test: -7.383503437042236 \n",
      "Root Mean Squared Error -- train: 0.4085924029350281, -- test: 0.7620594501495361 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.7482128143310547, -- test: -7.476961612701416 \n",
      "Root Mean Squared Error -- train: 0.4221777319908142, -- test: 0.766426682472229 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.6335313320159912, -- test: -7.56576681137085 \n",
      "Root Mean Squared Error -- train: 0.41236260533332825, -- test: 0.7705535292625427 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.593712329864502, -- test: -7.510709762573242 \n",
      "Root Mean Squared Error -- train: 0.40889957547187805, -- test: 0.7679975628852844 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5970231294631958, -- test: -7.497846603393555 \n",
      "Root Mean Squared Error -- train: 0.4091885983943939, -- test: 0.7673991918563843 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.602361798286438, -- test: -7.582398891448975 \n",
      "Root Mean Squared Error -- train: 0.40965425968170166, -- test: 0.7713239789009094 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.590997576713562, -- test: -7.584408760070801 \n",
      "Root Mean Squared Error -- train: 0.408662348985672, -- test: 0.7714170813560486 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.5860595703125, -- test: -7.427310943603516 \n",
      "Root Mean Squared Error -- train: 0.40823063254356384, -- test: 0.7641096711158752 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.368359565734863\n",
      "Test Root MSE of all sampled models: 0.7613494396209717\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.142388343811035\n",
      "Test Root MSE of all models in window: 0.7709009647369385\n",
      "\n",
      "############### EM step 180 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.735182762145996 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 181 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -2.0259592533111572, -- test: -7.458964824676514 \n",
      "Root Mean Squared Error -- train: 0.4459192454814911, -- test: 0.7672954797744751 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.5779486894607544, -- test: -7.28154182434082 \n",
      "Root Mean Squared Error -- train: 0.40828007459640503, -- test: 0.7589529156684875 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.8130950927734375, -- test: -7.157246112823486 \n",
      "Root Mean Squared Error -- train: 0.4284482002258301, -- test: 0.7530534267425537 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.8186792135238647, -- test: -7.902560234069824 \n",
      "Root Mean Squared Error -- train: 0.4289155602455139, -- test: 0.7877669930458069 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.631072998046875, -- test: -7.367171764373779 \n",
      "Root Mean Squared Error -- train: 0.41292259097099304, -- test: 0.7629906535148621 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.5831235647201538, -- test: -7.404056549072266 \n",
      "Root Mean Squared Error -- train: 0.40873464941978455, -- test: 0.7647233009338379 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.6772757768630981, -- test: -7.380622386932373 \n",
      "Root Mean Squared Error -- train: 0.41691821813583374, -- test: 0.7636229991912842 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.5943881273269653, -- test: -7.537023544311523 \n",
      "Root Mean Squared Error -- train: 0.40972232818603516, -- test: 0.7709371447563171 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.750106930732727, -- test: -7.438694000244141 \n",
      "Root Mean Squared Error -- train: 0.4231400787830353, -- test: 0.76634681224823 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.5897786617279053, -- test: -7.5838494300842285 \n",
      "Root Mean Squared Error -- train: 0.4093184471130371, -- test: 0.773113489151001 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.183642387390137\n",
      "Test Root MSE of all sampled models: 0.7543101906776428\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -7.040936470031738\n",
      "Test Root MSE of all models in window: 0.770628035068512\n",
      "\n",
      "############### EM step 181 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.5692238807678223 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 182 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5706902742385864, -- test: -7.457707405090332 \n",
      "Root Mean Squared Error -- train: 0.4083576798439026, -- test: 0.768851101398468 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.8157322406768799, -- test: -7.100888729095459 \n",
      "Root Mean Squared Error -- train: 0.42944180965423584, -- test: 0.7519376277923584 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.572150707244873, -- test: -7.60603141784668 \n",
      "Root Mean Squared Error -- train: 0.408486545085907, -- test: 0.7757733464241028 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.5690468549728394, -- test: -7.427312850952148 \n",
      "Root Mean Squared Error -- train: 0.4082126021385193, -- test: 0.7674248814582825 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5788933038711548, -- test: -7.2876081466674805 \n",
      "Root Mean Squared Error -- train: 0.4090811014175415, -- test: 0.7608351707458496 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.5824244022369385, -- test: -7.542752265930176 \n",
      "Root Mean Squared Error -- train: 0.4093920886516571, -- test: 0.7728277444839478 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5970615148544312, -- test: -7.855058670043945 \n",
      "Root Mean Squared Error -- train: 0.4106787145137787, -- test: 0.7872584462165833 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -2.0962910652160645, -- test: -7.275889873504639 \n",
      "Root Mean Squared Error -- train: 0.4523769021034241, -- test: 0.7602798938751221 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5713281631469727, -- test: -7.543276786804199 \n",
      "Root Mean Squared Error -- train: 0.40841397643089294, -- test: 0.7728521823883057 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.569697618484497, -- test: -7.472067832946777 \n",
      "Root Mean Squared Error -- train: 0.40827006101608276, -- test: 0.7695240378379822 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.843756675720215\n",
      "Test Root MSE of all sampled models: 0.7395095229148865\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.9851202964782715\n",
      "Test Root MSE of all models in window: 0.7703643441200256\n",
      "\n",
      "############### EM step 182 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.686941385269165 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 183 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.997707724571228, -- test: -7.330850601196289 \n",
      "Root Mean Squared Error -- train: 0.44531363248825073, -- test: 0.7645766735076904 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.573277235031128, -- test: -7.2532196044921875 \n",
      "Root Mean Squared Error -- train: 0.4093448519706726, -- test: 0.7608908414840698 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.5885947942733765, -- test: -7.2785964012146 \n",
      "Root Mean Squared Error -- train: 0.41069772839546204, -- test: 0.7620975971221924 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.6010571718215942, -- test: -7.194464683532715 \n",
      "Root Mean Squared Error -- train: 0.4117951989173889, -- test: 0.7580891847610474 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5601962804794312, -- test: -7.398681640625 \n",
      "Root Mean Squared Error -- train: 0.4081859290599823, -- test: 0.7677828669548035 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.9753652811050415, -- test: -6.960778713226318 \n",
      "Root Mean Squared Error -- train: 0.44349291920661926, -- test: 0.7468423843383789 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.6141594648361206, -- test: -7.3835272789001465 \n",
      "Root Mean Squared Error -- train: 0.41294583678245544, -- test: 0.7670676708221436 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.5706720352172852, -- test: -7.522600173950195 \n",
      "Root Mean Squared Error -- train: 0.4091143012046814, -- test: 0.7736057043075562 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.6072696447372437, -- test: -7.691038131713867 \n",
      "Root Mean Squared Error -- train: 0.4123411774635315, -- test: 0.7814508676528931 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.5983587503433228, -- test: -7.349698543548584 \n",
      "Root Mean Squared Error -- train: 0.4115578234195709, -- test: 0.7654688954353333 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -8.130078315734863\n",
      "Test Root MSE of all sampled models: 0.8015389442443848\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.978182315826416\n",
      "Test Root MSE of all models in window: 0.7707523107528687\n",
      "\n",
      "############### EM step 183 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.5019015073776245 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 184 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5507192611694336, -- test: -7.382001876831055 \n",
      "Root Mean Squared Error -- train: 0.4080911874771118, -- test: 0.7686843872070312 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.557989239692688, -- test: -7.195955276489258 \n",
      "Root Mean Squared Error -- train: 0.4087388217449188, -- test: 0.7598271369934082 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6225284337997437, -- test: -7.3628387451171875 \n",
      "Root Mean Squared Error -- train: 0.41444405913352966, -- test: 0.7677767872810364 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.5708173513412476, -- test: -7.352231025695801 \n",
      "Root Mean Squared Error -- train: 0.4098791480064392, -- test: 0.7672739624977112 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5825361013412476, -- test: -7.491563320159912 \n",
      "Root Mean Squared Error -- train: 0.41091811656951904, -- test: 0.7738529443740845 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.7311193943023682, -- test: -7.69293212890625 \n",
      "Root Mean Squared Error -- train: 0.4238702058792114, -- test: 0.7832635641098022 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5853281021118164, -- test: -7.216119766235352 \n",
      "Root Mean Squared Error -- train: 0.4111652374267578, -- test: 0.760792076587677 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.5517125129699707, -- test: -7.317725658416748 \n",
      "Root Mean Squared Error -- train: 0.40817970037460327, -- test: 0.7656359076499939 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.714189887046814, -- test: -7.288578033447266 \n",
      "Root Mean Squared Error -- train: 0.42241448163986206, -- test: 0.7642495632171631 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.7108817100524902, -- test: -7.405834197998047 \n",
      "Root Mean Squared Error -- train: 0.42212945222854614, -- test: 0.7698116898536682 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.54745626449585\n",
      "Test Root MSE of all sampled models: 0.7764764428138733\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.96425724029541\n",
      "Test Root MSE of all models in window: 0.7707886099815369\n",
      "\n",
      "############### EM step 184 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7619378566741943 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 185 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.546933889389038, -- test: -7.296504020690918 \n",
      "Root Mean Squared Error -- train: 0.40850377082824707, -- test: 0.7663162350654602 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.549666166305542, -- test: -7.462425708770752 \n",
      "Root Mean Squared Error -- train: 0.40874820947647095, -- test: 0.7741908431053162 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.5459966659545898, -- test: -7.272237777709961 \n",
      "Root Mean Squared Error -- train: 0.4084198772907257, -- test: 0.7651577591896057 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.5442492961883545, -- test: -7.383306503295898 \n",
      "Root Mean Squared Error -- train: 0.4082634449005127, -- test: 0.7704458832740784 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.584047555923462, -- test: -7.353429794311523 \n",
      "Root Mean Squared Error -- train: 0.41181161999702454, -- test: 0.7690269947052002 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.6097946166992188, -- test: -7.462831974029541 \n",
      "Root Mean Squared Error -- train: 0.4140908420085907, -- test: 0.7742100358009338 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5457422733306885, -- test: -7.291463851928711 \n",
      "Root Mean Squared Error -- train: 0.4083971083164215, -- test: 0.7660757303237915 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.5963053703308105, -- test: -7.12576961517334 \n",
      "Root Mean Squared Error -- train: 0.4128982722759247, -- test: 0.7581278085708618 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5487654209136963, -- test: -7.636910438537598 \n",
      "Root Mean Squared Error -- train: 0.4086676239967346, -- test: 0.7823863625526428 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.6069777011871338, -- test: -7.176624774932861 \n",
      "Root Mean Squared Error -- train: 0.4138420820236206, -- test: 0.7605760097503662 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.625925064086914\n",
      "Test Root MSE of all sampled models: 0.7818729877471924\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.943967342376709\n",
      "Test Root MSE of all models in window: 0.7709886431694031\n",
      "\n",
      "############### EM step 185 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.6775490045547485 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 186 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.603733777999878, -- test: -7.4415998458862305 \n",
      "Root Mean Squared Error -- train: 0.41432106494903564, -- test: 0.7749167084693909 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.5377182960510254, -- test: -7.285095691680908 \n",
      "Root Mean Squared Error -- train: 0.40842700004577637, -- test: 0.7674630284309387 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.7111623287200928, -- test: -7.267294406890869 \n",
      "Root Mean Squared Error -- train: 0.42373737692832947, -- test: 0.7666106224060059 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.5465346574783325, -- test: -7.562549591064453 \n",
      "Root Mean Squared Error -- train: 0.40921908617019653, -- test: 0.7806282639503479 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5602717399597168, -- test: -7.233370304107666 \n",
      "Root Mean Squared Error -- train: 0.41045019030570984, -- test: 0.764983594417572 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.539228081703186, -- test: -7.506438732147217 \n",
      "Root Mean Squared Error -- train: 0.4085627794265747, -- test: 0.7779837846755981 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5449659824371338, -- test: -7.6033430099487305 \n",
      "Root Mean Squared Error -- train: 0.4090782701969147, -- test: 0.782545268535614 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.656960368156433, -- test: -7.213834762573242 \n",
      "Root Mean Squared Error -- train: 0.4190129339694977, -- test: 0.7640450596809387 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5462785959243774, -- test: -7.196844100952148 \n",
      "Root Mean Squared Error -- train: 0.409196138381958, -- test: 0.7632278203964233 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.5566315650939941, -- test: -7.432680606842041 \n",
      "Root Mean Squared Error -- train: 0.4101243317127228, -- test: 0.7744938731193542 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.071683406829834\n",
      "Test Root MSE of all sampled models: 0.7571808695793152\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.916721343994141\n",
      "Test Root MSE of all models in window: 0.7710595726966858\n",
      "\n",
      "############### EM step 186 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.6136438846588135 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 187 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5369330644607544, -- test: -7.111598014831543 \n",
      "Root Mean Squared Error -- train: 0.4091036021709442, -- test: 0.760782778263092 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.5320476293563843, -- test: -7.276362895965576 \n",
      "Root Mean Squared Error -- train: 0.40866270661354065, -- test: 0.7687331438064575 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.5252124071121216, -- test: -7.312493801116943 \n",
      "Root Mean Squared Error -- train: 0.4080450236797333, -- test: 0.7704655528068542 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.5819088220596313, -- test: -7.320703029632568 \n",
      "Root Mean Squared Error -- train: 0.41314050555229187, -- test: 0.770858645439148 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5769768953323364, -- test: -7.1984477043151855 \n",
      "Root Mean Squared Error -- train: 0.41269975900650024, -- test: 0.7649838328361511 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.5750212669372559, -- test: -7.296205520629883 \n",
      "Root Mean Squared Error -- train: 0.41252487897872925, -- test: 0.7696849703788757 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5304830074310303, -- test: -7.291041851043701 \n",
      "Root Mean Squared Error -- train: 0.4085213541984558, -- test: 0.7694374322891235 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.5509459972381592, -- test: -7.514544486999512 \n",
      "Root Mean Squared Error -- train: 0.41036564111709595, -- test: 0.7800827026367188 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5361719131469727, -- test: -7.028615951538086 \n",
      "Root Mean Squared Error -- train: 0.40903493762016296, -- test: 0.7567470669746399 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.5832797288894653, -- test: -7.070510387420654 \n",
      "Root Mean Squared Error -- train: 0.4132629632949829, -- test: 0.7587872743606567 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.914000034332275\n",
      "Test Root MSE of all sampled models: 0.7987551689147949\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.9026618003845215\n",
      "Test Root MSE of all models in window: 0.7714713215827942\n",
      "\n",
      "############### EM step 187 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.4881150722503662 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 188 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5567327737808228, -- test: -6.8740105628967285 \n",
      "Root Mean Squared Error -- train: 0.4116319715976715, -- test: 0.7507975697517395 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.5696768760681152, -- test: -6.984461784362793 \n",
      "Root Mean Squared Error -- train: 0.41279610991477966, -- test: 0.7562317848205566 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.566719889640808, -- test: -6.934103965759277 \n",
      "Root Mean Squared Error -- train: 0.41253045201301575, -- test: 0.75375896692276 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.520573377609253, -- test: -7.16989803314209 \n",
      "Root Mean Squared Error -- train: 0.40836232900619507, -- test: 0.7652685046195984 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5246376991271973, -- test: -6.967296123504639 \n",
      "Root Mean Squared Error -- train: 0.4087311327457428, -- test: 0.7553897500038147 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.5447078943252563, -- test: -7.24525260925293 \n",
      "Root Mean Squared Error -- train: 0.41054752469062805, -- test: 0.7689104080200195 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5470921993255615, -- test: -7.039346218109131 \n",
      "Root Mean Squared Error -- train: 0.4107627868652344, -- test: 0.7589176297187805 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.554341435432434, -- test: -7.016287326812744 \n",
      "Root Mean Squared Error -- train: 0.41141653060913086, -- test: 0.7577903270721436 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5691405534744263, -- test: -7.126129150390625 \n",
      "Root Mean Squared Error -- train: 0.41274791955947876, -- test: 0.7631451487541199 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.5249507427215576, -- test: -7.077699661254883 \n",
      "Root Mean Squared Error -- train: 0.40875953435897827, -- test: 0.7607888579368591 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.080006122589111\n",
      "Test Root MSE of all sampled models: 0.7609012126922607\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.893729209899902\n",
      "Test Root MSE of all models in window: 0.77141273021698\n",
      "\n",
      "############### EM step 188 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.6382554769515991 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 189 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5350422859191895, -- test: -7.097957611083984 \n",
      "Root Mean Squared Error -- train: 0.4104151427745819, -- test: 0.7634322643280029 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.6659293174743652, -- test: -7.148753643035889 \n",
      "Root Mean Squared Error -- train: 0.4221261739730835, -- test: 0.7659064531326294 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.5214351415634155, -- test: -7.263051986694336 \n",
      "Root Mean Squared Error -- train: 0.4091784358024597, -- test: 0.7714446783065796 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.6376975774765015, -- test: -6.829026699066162 \n",
      "Root Mean Squared Error -- train: 0.4196278154850006, -- test: 0.750197172164917 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5129681825637817, -- test: -6.989760875701904 \n",
      "Root Mean Squared Error -- train: 0.40840697288513184, -- test: 0.7581352591514587 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.5124499797821045, -- test: -7.031353950500488 \n",
      "Root Mean Squared Error -- train: 0.40835967659950256, -- test: 0.7601760029792786 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.53556227684021, -- test: -7.184834003448486 \n",
      "Root Mean Squared Error -- train: 0.41046231985092163, -- test: 0.7676590085029602 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.5160719156265259, -- test: -7.076198577880859 \n",
      "Root Mean Squared Error -- train: 0.4086899161338806, -- test: 0.7623699903488159 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5151541233062744, -- test: -7.050601959228516 \n",
      "Root Mean Squared Error -- train: 0.40860626101493835, -- test: 0.7611184120178223 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.5133168697357178, -- test: -7.256460666656494 \n",
      "Root Mean Squared Error -- train: 0.4084387719631195, -- test: 0.771126389503479 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.883492946624756\n",
      "Test Root MSE of all sampled models: 0.7528964877128601\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.873654842376709\n",
      "Test Root MSE of all models in window: 0.771200954914093\n",
      "\n",
      "############### EM step 189 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3063716888427734 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 190 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.515358328819275, -- test: -7.035058498382568 \n",
      "Root Mean Squared Error -- train: 0.4093491733074188, -- test: 0.7619808912277222 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.5473082065582275, -- test: -7.284482479095459 \n",
      "Root Mean Squared Error -- train: 0.41225916147232056, -- test: 0.7741315364837646 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.5553786754608154, -- test: -7.367510795593262 \n",
      "Root Mean Squared Error -- train: 0.4129909873008728, -- test: 0.7781341671943665 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.5075010061264038, -- test: -7.243377208709717 \n",
      "Root Mean Squared Error -- train: 0.40863037109375, -- test: 0.772142231464386 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.718051552772522, -- test: -6.84860372543335 \n",
      "Root Mean Squared Error -- train: 0.427474707365036, -- test: 0.7527696490287781 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.502887487411499, -- test: -7.002662181854248 \n",
      "Root Mean Squared Error -- train: 0.4082077145576477, -- test: 0.7603884339332581 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5304430723190308, -- test: -7.077852725982666 \n",
      "Root Mean Squared Error -- train: 0.4107256829738617, -- test: 0.7640793323516846 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.5172148942947388, -- test: -7.0466389656066895 \n",
      "Root Mean Squared Error -- train: 0.409518837928772, -- test: 0.7625492811203003 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5040162801742554, -- test: -7.075389862060547 \n",
      "Root Mean Squared Error -- train: 0.4083111882209778, -- test: 0.763958752155304 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.6694830656051636, -- test: -6.973234176635742 \n",
      "Root Mean Squared Error -- train: 0.4232022762298584, -- test: 0.7589390277862549 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.7939133644104\n",
      "Test Root MSE of all sampled models: 0.7983741760253906\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.8609466552734375\n",
      "Test Root MSE of all models in window: 0.7714196443557739\n",
      "\n",
      "############### EM step 190 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.8651856184005737 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 191 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5083043575286865, -- test: -7.408172607421875 \n",
      "Root Mean Squared Error -- train: 0.40943706035614014, -- test: 0.7817798852920532 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.5260578393936157, -- test: -7.049307823181152 \n",
      "Root Mean Squared Error -- train: 0.4110637307167053, -- test: 0.7643303871154785 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6125242710113525, -- test: -7.1963090896606445 \n",
      "Root Mean Squared Error -- train: 0.4188959300518036, -- test: 0.7715259194374084 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.5236457586288452, -- test: -6.957241058349609 \n",
      "Root Mean Squared Error -- train: 0.4108431041240692, -- test: 0.7597891688346863 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5002233982086182, -- test: -7.043807506561279 \n",
      "Root Mean Squared Error -- train: 0.4086945354938507, -- test: 0.7640599012374878 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.5614938735961914, -- test: -7.0567827224731445 \n",
      "Root Mean Squared Error -- train: 0.4142914414405823, -- test: 0.7646979093551636 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5004594326019287, -- test: -6.964512825012207 \n",
      "Root Mean Squared Error -- train: 0.40871623158454895, -- test: 0.760148823261261 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.5316847562789917, -- test: -7.345172882080078 \n",
      "Root Mean Squared Error -- train: 0.411577969789505, -- test: 0.7787448763847351 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5053284168243408, -- test: -7.135127067565918 \n",
      "Root Mean Squared Error -- train: 0.40916377305984497, -- test: 0.7685393691062927 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.4967703819274902, -- test: -7.097417831420898 \n",
      "Root Mean Squared Error -- train: 0.4083768129348755, -- test: 0.7666928172111511 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.579349517822266\n",
      "Test Root MSE of all sampled models: 0.7408578991889954\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.716997146606445\n",
      "Test Root MSE of all models in window: 0.7708533406257629\n",
      "\n",
      "############### EM step 191 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.6365948915481567 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 192 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5146781206130981, -- test: -6.733965873718262 \n",
      "Root Mean Squared Error -- train: 0.41075772047042847, -- test: 0.7502766847610474 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.6692979335784912, -- test: -6.808612823486328 \n",
      "Root Mean Squared Error -- train: 0.4247349202632904, -- test: 0.7540245056152344 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.5475119352340698, -- test: -6.8075385093688965 \n",
      "Root Mean Squared Error -- train: 0.4137653410434723, -- test: 0.7539706230163574 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.5864251852035522, -- test: -6.711464881896973 \n",
      "Root Mean Squared Error -- train: 0.4173016846179962, -- test: 0.7491433024406433 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5564848184585571, -- test: -7.099348068237305 \n",
      "Root Mean Squared Error -- train: 0.41458338499069214, -- test: 0.7684471011161804 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.6081048250198364, -- test: -7.074370861053467 \n",
      "Root Mean Squared Error -- train: 0.4192589819431305, -- test: 0.7672187089920044 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4955074787139893, -- test: -7.029355525970459 \n",
      "Root Mean Squared Error -- train: 0.4089914560317993, -- test: 0.7649998664855957 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.556793212890625, -- test: -7.326699733734131 \n",
      "Root Mean Squared Error -- train: 0.4146115183830261, -- test: 0.7795396447181702 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5868910551071167, -- test: -7.195724010467529 \n",
      "Root Mean Squared Error -- train: 0.4173438251018524, -- test: 0.7731688022613525 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.5104974508285522, -- test: -7.0990729331970215 \n",
      "Root Mean Squared Error -- train: 0.41037318110466003, -- test: 0.7684336304664612 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.856508731842041\n",
      "Test Root MSE of all sampled models: 0.7564194202423096\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.703672409057617\n",
      "Test Root MSE of all models in window: 0.7708049416542053\n",
      "\n",
      "############### EM step 192 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.451041579246521 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 193 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5583128929138184, -- test: -7.042425155639648 \n",
      "Root Mean Squared Error -- train: 0.4154910147190094, -- test: 0.7672852873802185 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4873231649398804, -- test: -7.205913543701172 \n",
      "Root Mean Squared Error -- train: 0.40895795822143555, -- test: 0.7753264307975769 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.4861198663711548, -- test: -7.005910873413086 \n",
      "Root Mean Squared Error -- train: 0.40884631872177124, -- test: 0.7654777765274048 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4827569723129272, -- test: -6.9620537757873535 \n",
      "Root Mean Squared Error -- train: 0.40853413939476013, -- test: 0.7633011937141418 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.4860968589782715, -- test: -6.847408294677734 \n",
      "Root Mean Squared Error -- train: 0.40884414315223694, -- test: 0.7575818300247192 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.4836267232894897, -- test: -7.385214328765869 \n",
      "Root Mean Squared Error -- train: 0.4086149036884308, -- test: 0.7840504050254822 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4843871593475342, -- test: -6.797649383544922 \n",
      "Root Mean Squared Error -- train: 0.40868550539016724, -- test: 0.7550860643386841 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.7106178998947144, -- test: -6.559455394744873 \n",
      "Root Mean Squared Error -- train: 0.42917194962501526, -- test: 0.7430225610733032 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5004316568374634, -- test: -7.020159721374512 \n",
      "Root Mean Squared Error -- train: 0.41017213463783264, -- test: 0.766183614730835 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.5104258060455322, -- test: -7.152251720428467 \n",
      "Root Mean Squared Error -- train: 0.41109541058540344, -- test: 0.7726962566375732 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.43301248550415\n",
      "Test Root MSE of all sampled models: 0.7863597273826599\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.699192523956299\n",
      "Test Root MSE of all models in window: 0.7709923982620239\n",
      "\n",
      "############### EM step 193 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7441318035125732 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 194 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.7067140340805054, -- test: -6.493638515472412 \n",
      "Root Mean Squared Error -- train: 0.4296112656593323, -- test: 0.7412416934967041 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4917023181915283, -- test: -6.714654445648193 \n",
      "Root Mean Squared Error -- train: 0.41009390354156494, -- test: 0.7525195479393005 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.4838345050811768, -- test: -7.065722465515137 \n",
      "Root Mean Squared Error -- train: 0.4093620777130127, -- test: 0.7700942754745483 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4796996116638184, -- test: -6.9109206199646 \n",
      "Root Mean Squared Error -- train: 0.4089769423007965, -- test: 0.7623946666717529 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.4714431762695312, -- test: -6.990068435668945 \n",
      "Root Mean Squared Error -- train: 0.4082067906856537, -- test: 0.766340970993042 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.4950613975524902, -- test: -6.909168243408203 \n",
      "Root Mean Squared Error -- train: 0.4104059636592865, -- test: 0.7623070478439331 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.476643681526184, -- test: -6.7138824462890625 \n",
      "Root Mean Squared Error -- train: 0.40869206190109253, -- test: 0.7524803876876831 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4967787265777588, -- test: -7.2265119552612305 \n",
      "Root Mean Squared Error -- train: 0.41056543588638306, -- test: 0.7780108451843262 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.473185420036316, -- test: -6.909469127655029 \n",
      "Root Mean Squared Error -- train: 0.40836942195892334, -- test: 0.7623221278190613 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.4876646995544434, -- test: -7.0224528312683105 \n",
      "Root Mean Squared Error -- train: 0.40971851348876953, -- test: 0.7679498195648193 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.881902694702148\n",
      "Test Root MSE of all sampled models: 0.8094793558120728\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.686920642852783\n",
      "Test Root MSE of all models in window: 0.7713662385940552\n",
      "\n",
      "############### EM step 194 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1889532804489136 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 195 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.463559865951538, -- test: -6.993974685668945 \n",
      "Root Mean Squared Error -- train: 0.40817707777023315, -- test: 0.7681499719619751 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.5025476217269897, -- test: -6.935812473297119 \n",
      "Root Mean Squared Error -- train: 0.4118175506591797, -- test: 0.7652457356452942 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.630088448524475, -- test: -7.122371673583984 \n",
      "Root Mean Squared Error -- train: 0.42350804805755615, -- test: 0.774522602558136 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.472379446029663, -- test: -6.84152364730835 \n",
      "Root Mean Squared Error -- train: 0.40900343656539917, -- test: 0.7605140209197998 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.6418527364730835, -- test: -7.115356922149658 \n",
      "Root Mean Squared Error -- train: 0.42457014322280884, -- test: 0.774175763130188 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.4737584590911865, -- test: -7.0233941078186035 \n",
      "Root Mean Squared Error -- train: 0.4091324806213379, -- test: 0.7696147561073303 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.477183222770691, -- test: -7.012747764587402 \n",
      "Root Mean Squared Error -- train: 0.4094528257846832, -- test: 0.7690849304199219 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.6435550451278687, -- test: -6.732522487640381 \n",
      "Root Mean Squared Error -- train: 0.42472365498542786, -- test: 0.7550071477890015 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5793695449829102, -- test: -6.768957138061523 \n",
      "Root Mean Squared Error -- train: 0.41889816522598267, -- test: 0.7568522691726685 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.5825828313827515, -- test: -6.7343525886535645 \n",
      "Root Mean Squared Error -- train: 0.41919174790382385, -- test: 0.7550999522209167 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.394112586975098\n",
      "Test Root MSE of all sampled models: 0.7376481294631958\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.6062846183776855\n",
      "Test Root MSE of all models in window: 0.7705591917037964\n",
      "\n",
      "############### EM step 195 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.088091492652893 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 196 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5077345371246338, -- test: -7.188068389892578 \n",
      "Root Mean Squared Error -- train: 0.41299960017204285, -- test: 0.7793603539466858 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.5589185953140259, -- test: -7.096205234527588 \n",
      "Root Mean Squared Error -- train: 0.41773778200149536, -- test: 0.7748148441314697 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.457148790359497, -- test: -6.99867057800293 \n",
      "Root Mean Squared Error -- train: 0.40826278924942017, -- test: 0.7699593305587769 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4701801538467407, -- test: -6.914861679077148 \n",
      "Root Mean Squared Error -- train: 0.4094882607460022, -- test: 0.7657623887062073 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5112732648849487, -- test: -6.907028675079346 \n",
      "Root Mean Squared Error -- train: 0.41332894563674927, -- test: 0.7653690576553345 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.543956995010376, -- test: -6.973936557769775 \n",
      "Root Mean Squared Error -- train: 0.4163583815097809, -- test: 0.76872318983078 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4521043300628662, -- test: -7.051787853240967 \n",
      "Root Mean Squared Error -- train: 0.40778735280036926, -- test: 0.7726074457168579 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4686181545257568, -- test: -7.001535415649414 \n",
      "Root Mean Squared Error -- train: 0.4093415439128876, -- test: 0.7701023817062378 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.4663549661636353, -- test: -6.904290676116943 \n",
      "Root Mean Squared Error -- train: 0.40912893414497375, -- test: 0.7652315497398376 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.8570250272750854, -- test: -7.227622032165527 \n",
      "Root Mean Squared Error -- train: 0.4443310797214508, -- test: 0.7813094258308411 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.131132125854492\n",
      "Test Root MSE of all sampled models: 0.7253420948982239\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.486846923828125\n",
      "Test Root MSE of all models in window: 0.770190954208374\n",
      "\n",
      "############### EM step 196 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.9658443927764893 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 197 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5409783124923706, -- test: -6.97468376159668 \n",
      "Root Mean Squared Error -- train: 0.41680970788002014, -- test: 0.7703743577003479 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4738422632217407, -- test: -7.011313438415527 \n",
      "Root Mean Squared Error -- train: 0.410541296005249, -- test: 0.7722086310386658 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.4518930912017822, -- test: -6.951806545257568 \n",
      "Root Mean Squared Error -- train: 0.40847107768058777, -- test: 0.7692264914512634 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4765783548355103, -- test: -6.892630100250244 \n",
      "Root Mean Squared Error -- train: 0.4107986390590668, -- test: 0.7662493586540222 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.72072434425354, -- test: -6.866487979888916 \n",
      "Root Mean Squared Error -- train: 0.43314599990844727, -- test: 0.7649304866790771 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.4797937870025635, -- test: -7.116126537322998 \n",
      "Root Mean Squared Error -- train: 0.4111008644104004, -- test: 0.7774335741996765 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4895689487457275, -- test: -7.087841033935547 \n",
      "Root Mean Squared Error -- train: 0.4120182693004608, -- test: 0.7760269641876221 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4777110815048218, -- test: -7.028702259063721 \n",
      "Root Mean Squared Error -- train: 0.4109051823616028, -- test: 0.7730779647827148 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.4555408954620361, -- test: -6.862379550933838 \n",
      "Root Mean Squared Error -- train: 0.408815860748291, -- test: 0.7647230625152588 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.451096534729004, -- test: -6.8613667488098145 \n",
      "Root Mean Squared Error -- train: 0.40839576721191406, -- test: 0.764671802520752 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.85726261138916\n",
      "Test Root MSE of all sampled models: 0.7644645571708679\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.4450531005859375\n",
      "Test Root MSE of all models in window: 0.7703418135643005\n",
      "\n",
      "############### EM step 197 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3666223287582397 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 198 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.4800469875335693, -- test: -6.994404315948486 \n",
      "Root Mean Squared Error -- train: 0.4118286371231079, -- test: 0.7729639410972595 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4519870281219482, -- test: -6.9268927574157715 \n",
      "Root Mean Squared Error -- train: 0.4091767370700836, -- test: 0.7695679664611816 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.4498693943023682, -- test: -6.7374491691589355 \n",
      "Root Mean Squared Error -- train: 0.40897589921951294, -- test: 0.7599576115608215 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.5652188062667847, -- test: -6.769908428192139 \n",
      "Root Mean Squared Error -- train: 0.4197755455970764, -- test: 0.7616128325462341 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.4540821313858032, -- test: -7.135054111480713 \n",
      "Root Mean Squared Error -- train: 0.4093753397464752, -- test: 0.7799913287162781 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.5804765224456787, -- test: -6.793566703796387 \n",
      "Root Mean Squared Error -- train: 0.421183317899704, -- test: 0.7628170251846313 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5786499977111816, -- test: -7.015146255493164 \n",
      "Root Mean Squared Error -- train: 0.42101502418518066, -- test: 0.774004340171814 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4520381689071655, -- test: -6.857884407043457 \n",
      "Root Mean Squared Error -- train: 0.4091815948486328, -- test: 0.7660812139511108 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.4417961835861206, -- test: -6.8822784423828125 \n",
      "Root Mean Squared Error -- train: 0.40820935368537903, -- test: 0.7673155665397644 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.442913293838501, -- test: -7.073408126831055 \n",
      "Root Mean Squared Error -- train: 0.408315509557724, -- test: 0.7769190669059753 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.292565822601318\n",
      "Test Root MSE of all sampled models: 0.7877869009971619\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.437444686889648\n",
      "Test Root MSE of all models in window: 0.7703715562820435\n",
      "\n",
      "############### EM step 198 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.5774366855621338 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 199 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.476761817932129, -- test: -6.493917942047119 \n",
      "Root Mean Squared Error -- train: 0.4122242033481598, -- test: 0.7489683032035828 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4430551528930664, -- test: -6.8781418800354 \n",
      "Root Mean Squared Error -- train: 0.4090254008769989, -- test: 0.7686995267868042 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.594179630279541, -- test: -6.709962368011475 \n",
      "Root Mean Squared Error -- train: 0.4231785237789154, -- test: 0.7601259350776672 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.517877459526062, -- test: -6.657766342163086 \n",
      "Root Mean Squared Error -- train: 0.41609281301498413, -- test: 0.7574453353881836 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.4433330297470093, -- test: -6.713125228881836 \n",
      "Root Mean Squared Error -- train: 0.4090518653392792, -- test: 0.7602881193161011 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.4526691436767578, -- test: -6.651334762573242 \n",
      "Root Mean Squared Error -- train: 0.40994030237197876, -- test: 0.7571144104003906 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4652167558670044, -- test: -6.824380874633789 \n",
      "Root Mean Squared Error -- train: 0.4111313819885254, -- test: 0.7659692168235779 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4358371496200562, -- test: -6.809588432312012 \n",
      "Root Mean Squared Error -- train: 0.40833714604377747, -- test: 0.7652163505554199 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.443795084953308, -- test: -6.895839214324951 \n",
      "Root Mean Squared Error -- train: 0.4090958833694458, -- test: 0.7695962190628052 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.457985281944275, -- test: -6.702368259429932 \n",
      "Root Mean Squared Error -- train: 0.41044536232948303, -- test: 0.7597365975379944 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.528753280639648\n",
      "Test Root MSE of all sampled models: 0.696943998336792\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.3157453536987305\n",
      "Test Root MSE of all models in window: 0.7694989442825317\n",
      "\n",
      "############### EM step 199 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1354552507400513 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 200 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5819792747497559, -- test: -6.70588493347168 \n",
      "Root Mean Squared Error -- train: 0.4227696359157562, -- test: 0.761456310749054 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4348251819610596, -- test: -6.530701160430908 \n",
      "Root Mean Squared Error -- train: 0.4089198112487793, -- test: 0.7523981332778931 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.4340506792068481, -- test: -6.770782470703125 \n",
      "Root Mean Squared Error -- train: 0.4088457226753235, -- test: 0.7647847533226013 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4977911710739136, -- test: -6.7689337730407715 \n",
      "Root Mean Squared Error -- train: 0.4149026572704315, -- test: 0.7646901607513428 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5721834897994995, -- test: -6.924087047576904 \n",
      "Root Mean Squared Error -- train: 0.42186176776885986, -- test: 0.7725903391838074 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.521397352218628, -- test: -6.816741943359375 \n",
      "Root Mean Squared Error -- train: 0.4171235263347626, -- test: 0.7671331763267517 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4917387962341309, -- test: -6.463259220123291 \n",
      "Root Mean Squared Error -- train: 0.4143312871456146, -- test: 0.7488818168640137 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.434114694595337, -- test: -6.616466045379639 \n",
      "Root Mean Squared Error -- train: 0.40885183215141296, -- test: 0.7568463683128357 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.451995849609375, -- test: -6.851420879364014 \n",
      "Root Mean Squared Error -- train: 0.4105599820613861, -- test: 0.7689003944396973 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.4673820734024048, -- test: -6.995217323303223 \n",
      "Root Mean Squared Error -- train: 0.4120241403579712, -- test: 0.7761853337287903 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.243661403656006\n",
      "Test Root MSE of all sampled models: 0.7886134386062622\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.3096232414245605\n",
      "Test Root MSE of all models in window: 0.7697538137435913\n",
      "\n",
      "############### EM step 200 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7282319068908691 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 201 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.447263479232788, -- test: -6.621191024780273 \n",
      "Root Mean Squared Error -- train: 0.4108004868030548, -- test: 0.7586421370506287 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4268256425857544, -- test: -6.528454780578613 \n",
      "Root Mean Squared Error -- train: 0.40884003043174744, -- test: 0.7538214325904846 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.4637140035629272, -- test: -6.627866744995117 \n",
      "Root Mean Squared Error -- train: 0.4123716652393341, -- test: 0.7589879631996155 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.468032956123352, -- test: -6.660550117492676 \n",
      "Root Mean Squared Error -- train: 0.4127831757068634, -- test: 0.760678768157959 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5667240619659424, -- test: -7.001836776733398 \n",
      "Root Mean Squared Error -- train: 0.4220772087574005, -- test: 0.7781161069869995 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.5832065343856812, -- test: -7.149108409881592 \n",
      "Root Mean Squared Error -- train: 0.42360952496528625, -- test: 0.7855210900306702 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4282867908477783, -- test: -6.865548610687256 \n",
      "Root Mean Squared Error -- train: 0.40898051857948303, -- test: 0.7712000608444214 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4619760513305664, -- test: -6.821539402008057 \n",
      "Root Mean Squared Error -- train: 0.4122059643268585, -- test: 0.7689535021781921 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.427010416984558, -- test: -6.73391056060791 \n",
      "Root Mean Squared Error -- train: 0.4088578224182129, -- test: 0.764460563659668 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.4437834024429321, -- test: -6.812074184417725 \n",
      "Root Mean Squared Error -- train: 0.41046732664108276, -- test: 0.7684694528579712 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.743927001953125\n",
      "Test Root MSE of all sampled models: 0.7649755477905273\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.297542095184326\n",
      "Test Root MSE of all models in window: 0.7699089050292969\n",
      "\n",
      "############### EM step 201 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.44119489192962646 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 202 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5132144689559937, -- test: -6.517505645751953 \n",
      "Root Mean Squared Error -- train: 0.41773003339767456, -- test: 0.7546976208686829 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4358694553375244, -- test: -6.865299224853516 \n",
      "Root Mean Squared Error -- train: 0.4103562831878662, -- test: 0.7726742625236511 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.4143587350845337, -- test: -6.6886725425720215 \n",
      "Root Mean Squared Error -- train: 0.4082818627357483, -- test: 0.7635977268218994 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.412725567817688, -- test: -6.778420448303223 \n",
      "Root Mean Squared Error -- train: 0.4081239402294159, -- test: 0.7682231664657593 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5419663190841675, -- test: -6.870647430419922 \n",
      "Root Mean Squared Error -- train: 0.42043811082839966, -- test: 0.7729474306106567 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.416205883026123, -- test: -6.720645904541016 \n",
      "Root Mean Squared Error -- train: 0.4084603786468506, -- test: 0.765248715877533 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5264570713043213, -- test: -6.749400615692139 \n",
      "Root Mean Squared Error -- train: 0.4189795255661011, -- test: 0.7667304873466492 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4188092947006226, -- test: -6.781029224395752 \n",
      "Root Mean Squared Error -- train: 0.40871191024780273, -- test: 0.7683571577072144 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.4273960590362549, -- test: -6.958977222442627 \n",
      "Root Mean Squared Error -- train: 0.4095403850078583, -- test: 0.7774451971054077 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.4311244487762451, -- test: -6.598208427429199 \n",
      "Root Mean Squared Error -- train: 0.40989959239959717, -- test: 0.758906900882721 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.683681488037109\n",
      "Test Root MSE of all sampled models: 0.763339638710022\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.271172523498535\n",
      "Test Root MSE of all models in window: 0.7697781920433044\n",
      "\n",
      "############### EM step 202 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -2.4056761264801025 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 203 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.427388310432434, -- test: -6.4013237953186035 \n",
      "Root Mean Squared Error -- train: 0.4102240800857544, -- test: 0.7501176595687866 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4098827838897705, -- test: -6.535358428955078 \n",
      "Root Mean Squared Error -- train: 0.40852874517440796, -- test: 0.7571685910224915 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6015350818634033, -- test: -6.49140739440918 \n",
      "Root Mean Squared Error -- train: 0.4267226457595825, -- test: 0.7548638582229614 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.563515543937683, -- test: -6.678426742553711 \n",
      "Root Mean Squared Error -- train: 0.42317554354667664, -- test: 0.7646231055259705 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.4741472005844116, -- test: -6.617626190185547 \n",
      "Root Mean Squared Error -- train: 0.4147184491157532, -- test: 0.76146399974823 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.436734914779663, -- test: -6.4474310874938965 \n",
      "Root Mean Squared Error -- train: 0.41112637519836426, -- test: 0.7525506019592285 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4170867204666138, -- test: -6.380667686462402 \n",
      "Root Mean Squared Error -- train: 0.40922728180885315, -- test: 0.7490251660346985 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4137226343154907, -- test: -6.6104326248168945 \n",
      "Root Mean Squared Error -- train: 0.40890124440193176, -- test: 0.7610894441604614 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5391420125961304, -- test: -6.659109592437744 \n",
      "Root Mean Squared Error -- train: 0.42088592052459717, -- test: 0.7636208534240723 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.4070892333984375, -- test: -6.8569254875183105 \n",
      "Root Mean Squared Error -- train: 0.40825754404067993, -- test: 0.7738229632377625 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.1187543869018555\n",
      "Test Root MSE of all sampled models: 0.7871231436729431\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.260336399078369\n",
      "Test Root MSE of all models in window: 0.7701865434646606\n",
      "\n",
      "############### EM step 203 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.343239188194275 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 204 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.4362415075302124, -- test: -6.703996181488037 \n",
      "Root Mean Squared Error -- train: 0.41175973415374756, -- test: 0.7674938440322876 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4068342447280884, -- test: -6.71114444732666 \n",
      "Root Mean Squared Error -- train: 0.40890607237815857, -- test: 0.7678645849227905 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.403424859046936, -- test: -6.64718770980835 \n",
      "Root Mean Squared Error -- train: 0.4085739552974701, -- test: 0.7645408511161804 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4102756977081299, -- test: -6.797198295593262 \n",
      "Root Mean Squared Error -- train: 0.40924108028411865, -- test: 0.7723141312599182 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5113086700439453, -- test: -6.637872219085693 \n",
      "Root Mean Squared Error -- train: 0.4189559519290924, -- test: 0.7640556693077087 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.4114623069763184, -- test: -6.693419933319092 \n",
      "Root Mean Squared Error -- train: 0.4093565046787262, -- test: 0.766944944858551 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4774222373962402, -- test: -6.737863063812256 \n",
      "Root Mean Squared Error -- train: 0.41572287678718567, -- test: 0.769248902797699 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.461739420890808, -- test: -6.408547401428223 \n",
      "Root Mean Squared Error -- train: 0.41421806812286377, -- test: 0.7520096898078918 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.4054700136184692, -- test: -6.658224582672119 \n",
      "Root Mean Squared Error -- train: 0.4087732434272766, -- test: 0.7651155591011047 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.408622145652771, -- test: -6.568411827087402 \n",
      "Root Mean Squared Error -- train: 0.4090801477432251, -- test: 0.7604271173477173 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.994062900543213\n",
      "Test Root MSE of all sampled models: 0.7823978662490845\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.237005710601807\n",
      "Test Root MSE of all models in window: 0.769920825958252\n",
      "\n",
      "############### EM step 204 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.611072301864624 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 205 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.3965412378311157, -- test: -6.589023590087891 \n",
      "Root Mean Squared Error -- train: 0.40857845544815063, -- test: 0.7630510926246643 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4825794696807861, -- test: -6.356722831726074 \n",
      "Root Mean Squared Error -- train: 0.41691485047340393, -- test: 0.750777542591095 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.6368542909622192, -- test: -6.451092720031738 \n",
      "Root Mean Squared Error -- train: 0.43145954608917236, -- test: 0.7557875514030457 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4856151342391968, -- test: -6.608689785003662 \n",
      "Root Mean Squared Error -- train: 0.41720589995384216, -- test: 0.7640811204910278 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.405285120010376, -- test: -6.72315788269043 \n",
      "Root Mean Squared Error -- train: 0.40943342447280884, -- test: 0.770048975944519 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.4080348014831543, -- test: -6.856905937194824 \n",
      "Root Mean Squared Error -- train: 0.4097019135951996, -- test: 0.7769639492034912 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5182361602783203, -- test: -6.394260883331299 \n",
      "Root Mean Squared Error -- train: 0.42032119631767273, -- test: 0.7527743577957153 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3973788022994995, -- test: -6.7838945388793945 \n",
      "Root Mean Squared Error -- train: 0.4086604416370392, -- test: 0.7731968760490417 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.4956090450286865, -- test: -6.8187737464904785 \n",
      "Root Mean Squared Error -- train: 0.4181627631187439, -- test: 0.7749987840652466 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.4404691457748413, -- test: -6.810051441192627 \n",
      "Root Mean Squared Error -- train: 0.41285571455955505, -- test: 0.7745485305786133 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.132142543792725\n",
      "Test Root MSE of all sampled models: 0.7910040020942688\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.244802951812744\n",
      "Test Root MSE of all models in window: 0.7701717615127563\n",
      "\n",
      "############### EM step 205 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.6934518814086914 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 206 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.3995606899261475, -- test: -6.673812389373779 \n",
      "Root Mean Squared Error -- train: 0.4095587134361267, -- test: 0.7690574526786804 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3953276872634888, -- test: -6.726250171661377 \n",
      "Root Mean Squared Error -- train: 0.409143328666687, -- test: 0.771791398525238 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.4030323028564453, -- test: -6.636788368225098 \n",
      "Root Mean Squared Error -- train: 0.4098990261554718, -- test: 0.7671212553977966 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3946353197097778, -- test: -6.76708984375 \n",
      "Root Mean Squared Error -- train: 0.4090753495693207, -- test: 0.7739139795303345 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.398181676864624, -- test: -6.815591812133789 \n",
      "Root Mean Squared Error -- train: 0.4094234108924866, -- test: 0.7764272689819336 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.4072450399398804, -- test: -6.632650375366211 \n",
      "Root Mean Squared Error -- train: 0.41031166911125183, -- test: 0.7669045329093933 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3908162117004395, -- test: -6.631868839263916 \n",
      "Root Mean Squared Error -- train: 0.40870019793510437, -- test: 0.7668635249137878 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.391049861907959, -- test: -6.540500640869141 \n",
      "Root Mean Squared Error -- train: 0.4087231457233429, -- test: 0.7620627284049988 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.5150432586669922, -- test: -6.4410786628723145 \n",
      "Root Mean Squared Error -- train: 0.4207323491573334, -- test: 0.7568041682243347 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3892877101898193, -- test: -6.604772567749023 \n",
      "Root Mean Squared Error -- train: 0.4085499048233032, -- test: 0.7654430270195007 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.032437801361084\n",
      "Test Root MSE of all sampled models: 0.7875657081604004\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.215087890625\n",
      "Test Root MSE of all models in window: 0.7701365351676941\n",
      "\n",
      "############### EM step 206 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1691040992736816 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 207 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.3904203176498413, -- test: -6.852811813354492 \n",
      "Root Mean Squared Error -- train: 0.4093307852745056, -- test: 0.7799186110496521 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3903311491012573, -- test: -6.542343616485596 \n",
      "Root Mean Squared Error -- train: 0.40932196378707886, -- test: 0.7636907696723938 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.4230889081954956, -- test: -6.590671539306641 \n",
      "Root Mean Squared Error -- train: 0.4125378429889679, -- test: 0.7662394046783447 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3859986066818237, -- test: -6.720428466796875 \n",
      "Root Mean Squared Error -- train: 0.40889474749565125, -- test: 0.773040771484375 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5313568115234375, -- test: -6.6376543045043945 \n",
      "Root Mean Squared Error -- train: 0.4229927062988281, -- test: 0.7687090635299683 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.388841152191162, -- test: -6.616729736328125 \n",
      "Root Mean Squared Error -- train: 0.4091750979423523, -- test: 0.7676101326942444 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4581279754638672, -- test: -6.652566909790039 \n",
      "Root Mean Squared Error -- train: 0.41595014929771423, -- test: 0.7694912552833557 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.383432388305664, -- test: -6.480588912963867 \n",
      "Root Mean Squared Error -- train: 0.4086414873600006, -- test: 0.760421633720398 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.385968804359436, -- test: -6.559796333312988 \n",
      "Root Mean Squared Error -- train: 0.40889182686805725, -- test: 0.7646121382713318 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3817386627197266, -- test: -6.5802001953125 \n",
      "Root Mean Squared Error -- train: 0.40847426652908325, -- test: 0.7656879425048828 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.583444118499756\n",
      "Test Root MSE of all sampled models: 0.7658588290214539\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.191351413726807\n",
      "Test Root MSE of all models in window: 0.7703822255134583\n",
      "\n",
      "############### EM step 207 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.8283746242523193 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 208 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.454599380493164, -- test: -6.444718837738037 \n",
      "Root Mean Squared Error -- train: 0.4163084626197815, -- test: 0.7600682973861694 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3850414752960205, -- test: -6.363961219787598 \n",
      "Root Mean Squared Error -- train: 0.4094824194908142, -- test: 0.755750834941864 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.3883514404296875, -- test: -6.508565902709961 \n",
      "Root Mean Squared Error -- train: 0.4098098576068878, -- test: 0.7634643912315369 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4327584505081177, -- test: -6.721566200256348 \n",
      "Root Mean Squared Error -- train: 0.4141772389411926, -- test: 0.7746863961219788 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.5946084260940552, -- test: -6.692332744598389 \n",
      "Root Mean Squared Error -- train: 0.4297195076942444, -- test: 0.7731558680534363 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3749459981918335, -- test: -6.6173858642578125 \n",
      "Root Mean Squared Error -- train: 0.40848225355148315, -- test: 0.7692180871963501 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4378795623779297, -- test: -6.385557651519775 \n",
      "Root Mean Squared Error -- train: 0.4146779179573059, -- test: 0.7569078803062439 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4083449840545654, -- test: -6.7880120277404785 \n",
      "Root Mean Squared Error -- train: 0.4117819368839264, -- test: 0.7781540155410767 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.379404067993164, -- test: -6.416280746459961 \n",
      "Root Mean Squared Error -- train: 0.40892425179481506, -- test: 0.758550763130188 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3746412992477417, -- test: -6.547907829284668 \n",
      "Root Mean Squared Error -- train: 0.40845203399658203, -- test: 0.7655494809150696 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.631374359130859\n",
      "Test Root MSE of all sampled models: 0.7153962254524231\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.088491439819336\n",
      "Test Root MSE of all models in window: 0.7698323130607605\n",
      "\n",
      "############### EM step 208 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.9171844124794006 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 209 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.3753881454467773, -- test: -6.041863441467285 \n",
      "Root Mean Squared Error -- train: 0.4091831147670746, -- test: 0.7397316694259644 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3799103498458862, -- test: -6.427655220031738 \n",
      "Root Mean Squared Error -- train: 0.4096325933933258, -- test: 0.7606576085090637 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.3706696033477783, -- test: -6.480123996734619 \n",
      "Root Mean Squared Error -- train: 0.40871360898017883, -- test: 0.7634592652320862 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3681188821792603, -- test: -6.47176456451416 \n",
      "Root Mean Squared Error -- train: 0.4084596037864685, -- test: 0.7630136013031006 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.4259545803070068, -- test: -6.431108474731445 \n",
      "Root Mean Squared Error -- train: 0.4141812324523926, -- test: 0.7608422636985779 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3805792331695557, -- test: -6.52177619934082 \n",
      "Root Mean Squared Error -- train: 0.409699022769928, -- test: 0.7656760811805725 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5182693004608154, -- test: -6.5491414070129395 \n",
      "Root Mean Squared Error -- train: 0.4231535792350769, -- test: 0.7671290040016174 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3963035345077515, -- test: -6.640512466430664 \n",
      "Root Mean Squared Error -- train: 0.411257803440094, -- test: 0.771960437297821 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.3777097463607788, -- test: -6.540075778961182 \n",
      "Root Mean Squared Error -- train: 0.4094139337539673, -- test: 0.76664799451828 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.4227453470230103, -- test: -6.7532877922058105 \n",
      "Root Mean Squared Error -- train: 0.413865864276886, -- test: 0.7778823375701904 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.50271463394165\n",
      "Test Root MSE of all sampled models: 0.7646624445915222\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.080573558807373\n",
      "Test Root MSE of all models in window: 0.7698816061019897\n",
      "\n",
      "############### EM step 209 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7296029329299927 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 210 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.3671975135803223, -- test: -6.59675407409668 \n",
      "Root Mean Squared Error -- train: 0.40903401374816895, -- test: 0.7711976766586304 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.420458197593689, -- test: -6.45339298248291 \n",
      "Root Mean Squared Error -- train: 0.4143212139606476, -- test: 0.7635629177093506 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.364224910736084, -- test: -6.500082015991211 \n",
      "Root Mean Squared Error -- train: 0.4087368845939636, -- test: 0.7660577297210693 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4498865604400635, -- test: -6.3662824630737305 \n",
      "Root Mean Squared Error -- train: 0.41721388697624207, -- test: 0.7588863372802734 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3751531839370728, -- test: -6.606846332550049 \n",
      "Root Mean Squared Error -- train: 0.4098280966281891, -- test: 0.7717323899269104 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3666115999221802, -- test: -6.3623738288879395 \n",
      "Root Mean Squared Error -- train: 0.4089754819869995, -- test: 0.7586758136749268 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4355971813201904, -- test: -6.509371757507324 \n",
      "Root Mean Squared Error -- train: 0.41581180691719055, -- test: 0.7665531635284424 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3652069568634033, -- test: -6.401958465576172 \n",
      "Root Mean Squared Error -- train: 0.4088350832462311, -- test: 0.760805070400238 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.3797956705093384, -- test: -6.608404636383057 \n",
      "Root Mean Squared Error -- train: 0.41029077768325806, -- test: 0.7718148231506348 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.680335521697998, -- test: -6.884912014007568 \n",
      "Root Mean Squared Error -- train: 0.43920737504959106, -- test: 0.7863195538520813 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.459187030792236\n",
      "Test Root MSE of all sampled models: 0.7638729214668274\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.021870136260986\n",
      "Test Root MSE of all models in window: 0.7700437307357788\n",
      "\n",
      "############### EM step 210 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.0719751119613647 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 211 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.355084776878357, -- test: -6.259530544281006 \n",
      "Root Mean Squared Error -- train: 0.4084697365760803, -- test: 0.754587709903717 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.4470179080963135, -- test: -6.268016815185547 \n",
      "Root Mean Squared Error -- train: 0.41760432720184326, -- test: 0.7550491094589233 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.3622913360595703, -- test: -6.2481818199157715 \n",
      "Root Mean Squared Error -- train: 0.4091931879520416, -- test: 0.7539701461791992 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3619613647460938, -- test: -6.3347063064575195 \n",
      "Root Mean Squared Error -- train: 0.4091600775718689, -- test: 0.7586652040481567 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3533661365509033, -- test: -6.656457424163818 \n",
      "Root Mean Squared Error -- train: 0.408297061920166, -- test: 0.7758750915527344 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3714998960494995, -- test: -6.413394927978516 \n",
      "Root Mean Squared Error -- train: 0.41011568903923035, -- test: 0.762910008430481 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3776222467422485, -- test: -6.388199329376221 \n",
      "Root Mean Squared Error -- train: 0.4107278883457184, -- test: 0.7615534067153931 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.400753378868103, -- test: -6.1832685470581055 \n",
      "Root Mean Squared Error -- train: 0.4130327105522156, -- test: 0.7504284977912903 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.3640422821044922, -- test: -6.412033557891846 \n",
      "Root Mean Squared Error -- train: 0.40936875343322754, -- test: 0.762836754322052 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3900915384292603, -- test: -6.501835823059082 \n",
      "Root Mean Squared Error -- train: 0.41197195649147034, -- test: 0.7676528096199036 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.0465240478515625\n",
      "Test Root MSE of all sampled models: 0.7962403297424316\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.013671398162842\n",
      "Test Root MSE of all models in window: 0.7700140476226807\n",
      "\n",
      "############### EM step 211 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.509387731552124 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 212 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.3764190673828125, -- test: -6.524728298187256 \n",
      "Root Mean Squared Error -- train: 0.4112645089626312, -- test: 0.7703890800476074 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3515855073928833, -- test: -6.404530048370361 \n",
      "Root Mean Squared Error -- train: 0.40876829624176025, -- test: 0.7639317512512207 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.3659807443618774, -- test: -6.485482215881348 \n",
      "Root Mean Squared Error -- train: 0.41021713614463806, -- test: 0.7682866454124451 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.372847557067871, -- test: -6.534191131591797 \n",
      "Root Mean Squared Error -- train: 0.41090643405914307, -- test: 0.7708951234817505 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3982996940612793, -- test: -6.403719425201416 \n",
      "Root Mean Squared Error -- train: 0.4134514033794403, -- test: 0.7638880610466003 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.5485703945159912, -- test: -6.270074367523193 \n",
      "Root Mean Squared Error -- train: 0.42816871404647827, -- test: 0.7566431760787964 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3976531028747559, -- test: -6.508139133453369 \n",
      "Root Mean Squared Error -- train: 0.4133869707584381, -- test: 0.7695010304450989 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3547371625900269, -- test: -6.3947858810424805 \n",
      "Root Mean Squared Error -- train: 0.4090859591960907, -- test: 0.7634058594703674 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.3519145250320435, -- test: -6.475466728210449 \n",
      "Root Mean Squared Error -- train: 0.40880146622657776, -- test: 0.7677491903305054 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.421281337738037, -- test: -6.262186050415039 \n",
      "Root Mean Squared Error -- train: 0.4157359302043915, -- test: 0.756213366985321 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.706491470336914\n",
      "Test Root MSE of all sampled models: 0.7800522446632385\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -6.007258415222168\n",
      "Test Root MSE of all models in window: 0.7704386711120605\n",
      "\n",
      "############### EM step 212 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2899223566055298 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 213 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.4959475994110107, -- test: -6.603802680969238 \n",
      "Root Mean Squared Error -- train: 0.4237552285194397, -- test: 0.7761190533638 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3452565670013428, -- test: -6.467836380004883 \n",
      "Root Mean Squared Error -- train: 0.40877294540405273, -- test: 0.7688344717025757 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.3855279684066772, -- test: -6.536298751831055 \n",
      "Root Mean Squared Error -- train: 0.412830114364624, -- test: 0.7725110650062561 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3449411392211914, -- test: -6.640018939971924 \n",
      "Root Mean Squared Error -- train: 0.4087410271167755, -- test: 0.7780479192733765 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3406498432159424, -- test: -6.3935651779174805 \n",
      "Root Mean Squared Error -- train: 0.4083062708377838, -- test: 0.7648260593414307 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.358310341835022, -- test: -6.269451141357422 \n",
      "Root Mean Squared Error -- train: 0.41009244322776794, -- test: 0.7580801844596863 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3475297689437866, -- test: -6.30075740814209 \n",
      "Root Mean Squared Error -- train: 0.40900304913520813, -- test: 0.7597874402999878 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.5990914106369019, -- test: -6.4645161628723145 \n",
      "Root Mean Squared Error -- train: 0.4337118864059448, -- test: 0.7686557173728943 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.3588430881500244, -- test: -6.3326592445373535 \n",
      "Root Mean Squared Error -- train: 0.41014620661735535, -- test: 0.7615231871604919 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3473458290100098, -- test: -6.43977165222168 \n",
      "Root Mean Squared Error -- train: 0.4089844524860382, -- test: 0.767322301864624 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -7.3767900466918945\n",
      "Test Root MSE of all sampled models: 0.8162985444068909\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.990901470184326\n",
      "Test Root MSE of all models in window: 0.771196186542511\n",
      "\n",
      "############### EM step 213 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2036762237548828 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 214 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.3379521369934082, -- test: -6.506724834442139 \n",
      "Root Mean Squared Error -- train: 0.4086660146713257, -- test: 0.7724069952964783 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3798916339874268, -- test: -6.292721748352051 \n",
      "Root Mean Squared Error -- train: 0.4129088819026947, -- test: 0.7608058452606201 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.362061858177185, -- test: -6.37961483001709 \n",
      "Root Mean Squared Error -- train: 0.41111046075820923, -- test: 0.7655376195907593 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.405158519744873, -- test: -6.341633319854736 \n",
      "Root Mean Squared Error -- train: 0.41544413566589355, -- test: 0.7634729146957397 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3377808332443237, -- test: -6.365871429443359 \n",
      "Root Mean Squared Error -- train: 0.40864861011505127, -- test: 0.7647911310195923 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.4053475856781006, -- test: -6.276968002319336 \n",
      "Root Mean Squared Error -- train: 0.41546303033828735, -- test: 0.7599449157714844 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3847107887268066, -- test: -6.336440563201904 \n",
      "Root Mean Squared Error -- train: 0.41339364647865295, -- test: 0.7631902694702148 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3363234996795654, -- test: -6.409852504730225 \n",
      "Root Mean Squared Error -- train: 0.4085003435611725, -- test: 0.7671772241592407 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.433980941772461, -- test: -6.302734851837158 \n",
      "Root Mean Squared Error -- train: 0.41831734776496887, -- test: 0.7613525986671448 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.336569905281067, -- test: -6.326542377471924 \n",
      "Root Mean Squared Error -- train: 0.4085254371166229, -- test: 0.7626510262489319 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.301886558532715\n",
      "Test Root MSE of all sampled models: 0.7613063454627991\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.967462539672852\n",
      "Test Root MSE of all models in window: 0.7708920836448669\n",
      "\n",
      "############### EM step 214 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.599306583404541 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 215 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.3632458448410034, -- test: -6.089768886566162 \n",
      "Root Mean Squared Error -- train: 0.4118783473968506, -- test: 0.7510891556739807 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3378440141677856, -- test: -6.224161148071289 \n",
      "Root Mean Squared Error -- train: 0.40929654240608215, -- test: 0.7585195302963257 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.3534177541732788, -- test: -6.025730609893799 \n",
      "Root Mean Squared Error -- train: 0.4108813405036926, -- test: 0.7475226521492004 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3325042724609375, -- test: -6.195926666259766 \n",
      "Root Mean Squared Error -- train: 0.4087517261505127, -- test: 0.7569645643234253 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3678454160690308, -- test: -6.5003790855407715 \n",
      "Root Mean Squared Error -- train: 0.4123440980911255, -- test: 0.7735670208930969 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.4140278100967407, -- test: -6.1847825050354 \n",
      "Root Mean Squared Error -- train: 0.41699182987213135, -- test: 0.7563498616218567 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.4551280736923218, -- test: -6.034216403961182 \n",
      "Root Mean Squared Error -- train: 0.421085000038147, -- test: 0.7479962706565857 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3483840227127075, -- test: -6.294564247131348 \n",
      "Root Mean Squared Error -- train: 0.41036975383758545, -- test: 0.762382984161377 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.3405730724334717, -- test: -6.22965145111084 \n",
      "Root Mean Squared Error -- train: 0.4095746576786041, -- test: 0.7588216066360474 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3386276960372925, -- test: -6.2518792152404785 \n",
      "Root Mean Squared Error -- train: 0.40937644243240356, -- test: 0.7600429654121399 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.021689414978027\n",
      "Test Root MSE of all sampled models: 0.7472970485687256\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.814614772796631\n",
      "Test Root MSE of all models in window: 0.7705091834068298\n",
      "\n",
      "############### EM step 215 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2569588422775269 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 216 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.5022209882736206, -- test: -6.391345977783203 \n",
      "Root Mean Squared Error -- train: 0.4264043867588043, -- test: 0.7691383957862854 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3496975898742676, -- test: -6.228275299072266 \n",
      "Root Mean Squared Error -- train: 0.41114217042922974, -- test: 0.7602019906044006 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.3604124784469604, -- test: -6.188107967376709 \n",
      "Root Mean Squared Error -- train: 0.41223281621932983, -- test: 0.7579846382141113 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3565807342529297, -- test: -6.320690155029297 \n",
      "Root Mean Squared Error -- train: 0.41184312105178833, -- test: 0.765279233455658 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3680921792984009, -- test: -6.155641078948975 \n",
      "Root Mean Squared Error -- train: 0.4130127429962158, -- test: 0.7561875581741333 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3255200386047363, -- test: -6.3832221031188965 \n",
      "Root Mean Squared Error -- train: 0.4086705148220062, -- test: 0.7686956524848938 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3231253623962402, -- test: -6.482194900512695 \n",
      "Root Mean Squared Error -- train: 0.40842488408088684, -- test: 0.7740722298622131 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3748128414154053, -- test: -6.258267879486084 \n",
      "Root Mean Squared Error -- train: 0.4136940836906433, -- test: 0.7618534564971924 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.4377607107162476, -- test: -6.260627269744873 \n",
      "Root Mean Squared Error -- train: 0.4200218617916107, -- test: 0.7619832158088684 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.331717848777771, -- test: -6.373848915100098 \n",
      "Root Mean Squared Error -- train: 0.40930551290512085, -- test: 0.7681844830513 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.325312614440918\n",
      "Test Root MSE of all sampled models: 0.7655323147773743\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.752580642700195\n",
      "Test Root MSE of all models in window: 0.7702970504760742\n",
      "\n",
      "############### EM step 216 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.586806058883667 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 217 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.3186893463134766, -- test: -6.194575309753418 \n",
      "Root Mean Squared Error -- train: 0.4086079001426697, -- test: 0.7598130106925964 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3780030012130737, -- test: -6.39887809753418 \n",
      "Root Mean Squared Error -- train: 0.41467127203941345, -- test: 0.7710447311401367 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.5177429914474487, -- test: -6.409665107727051 \n",
      "Root Mean Squared Error -- train: 0.42861732840538025, -- test: 0.7716332077980042 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3179932832717896, -- test: -6.338416576385498 \n",
      "Root Mean Squared Error -- train: 0.4085361957550049, -- test: 0.767737865447998 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3301658630371094, -- test: -6.237738609313965 \n",
      "Root Mean Squared Error -- train: 0.4097880721092224, -- test: 0.7621996998786926 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3580105304718018, -- test: -6.171764373779297 \n",
      "Root Mean Squared Error -- train: 0.41263747215270996, -- test: 0.7585485577583313 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3513633012771606, -- test: -6.366980075836182 \n",
      "Root Mean Squared Error -- train: 0.41195905208587646, -- test: 0.7693018317222595 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.362163782119751, -- test: -6.4157891273498535 \n",
      "Root Mean Squared Error -- train: 0.4130608141422272, -- test: 0.7719671130180359 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.3189691305160522, -- test: -6.254586696624756 \n",
      "Root Mean Squared Error -- train: 0.4086367189884186, -- test: 0.7631292939186096 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3539468050003052, -- test: -6.160623550415039 \n",
      "Root Mean Squared Error -- train: 0.41222283244132996, -- test: 0.7579303979873657 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.866614818572998\n",
      "Test Root MSE of all sampled models: 0.7414274215698242\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.732931613922119\n",
      "Test Root MSE of all models in window: 0.7701228857040405\n",
      "\n",
      "############### EM step 217 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2286653518676758 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 218 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.3841973543167114, -- test: -6.124464511871338 \n",
      "Root Mean Squared Error -- train: 0.41594821214675903, -- test: 0.7573676705360413 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3540843725204468, -- test: -6.169692516326904 \n",
      "Root Mean Squared Error -- train: 0.4128778278827667, -- test: 0.7598868608474731 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.3561853170394897, -- test: -6.207201957702637 \n",
      "Root Mean Squared Error -- train: 0.41309279203414917, -- test: 0.7619696855545044 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4028810262680054, -- test: -6.110424041748047 \n",
      "Root Mean Squared Error -- train: 0.4178418517112732, -- test: 0.7565839290618896 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3127254247665405, -- test: -6.2651047706604 \n",
      "Root Mean Squared Error -- train: 0.40862321853637695, -- test: 0.7651739120483398 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3172225952148438, -- test: -6.209497451782227 \n",
      "Root Mean Squared Error -- train: 0.4090879559516907, -- test: 0.7620970010757446 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.313167691230774, -- test: -6.239221572875977 \n",
      "Root Mean Squared Error -- train: 0.4086689352989197, -- test: 0.7637432217597961 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3378229141235352, -- test: -6.338904857635498 \n",
      "Root Mean Squared Error -- train: 0.4112102687358856, -- test: 0.7692384719848633 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.3111664056777954, -- test: -6.293128490447998 \n",
      "Root Mean Squared Error -- train: 0.40846192836761475, -- test: 0.7667198181152344 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3508425951004028, -- test: -6.434057712554932 \n",
      "Root Mean Squared Error -- train: 0.41254591941833496, -- test: 0.7744475603103638 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.091177940368652\n",
      "Test Root MSE of all sampled models: 0.7555082440376282\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.7195844650268555\n",
      "Test Root MSE of all models in window: 0.7699641585350037\n",
      "\n",
      "############### EM step 218 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3881829977035522 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 219 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.347496509552002, -- test: -5.844343185424805 \n",
      "Root Mean Squared Error -- train: 0.41284239292144775, -- test: 0.7429884672164917 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3133002519607544, -- test: -6.3026957511901855 \n",
      "Root Mean Squared Error -- train: 0.4093128442764282, -- test: 0.7687176465988159 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.3052914142608643, -- test: -6.198421478271484 \n",
      "Root Mean Squared Error -- train: 0.4084818363189697, -- test: 0.7629405856132507 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3286441564559937, -- test: -6.25123405456543 \n",
      "Root Mean Squared Error -- train: 0.4109002947807312, -- test: 0.7658719420433044 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3208236694335938, -- test: -6.246605396270752 \n",
      "Root Mean Squared Error -- train: 0.41009196639060974, -- test: 0.7656154632568359 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3076905012130737, -- test: -6.176368236541748 \n",
      "Root Mean Squared Error -- train: 0.40873095393180847, -- test: 0.7617131471633911 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.326828956604004, -- test: -6.231328964233398 \n",
      "Root Mean Squared Error -- train: 0.4107128381729126, -- test: 0.7647684216499329 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4798320531845093, -- test: -6.509471893310547 \n",
      "Root Mean Squared Error -- train: 0.4262259602546692, -- test: 0.7800470590591431 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.3392342329025269, -- test: -6.16409969329834 \n",
      "Root Mean Squared Error -- train: 0.4119923710823059, -- test: 0.7610293626785278 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3103898763656616, -- test: -6.218117713928223 \n",
      "Root Mean Squared Error -- train: 0.4090110659599304, -- test: 0.7640350461006165 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.51042366027832\n",
      "Test Root MSE of all sampled models: 0.7800987362861633\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.702274799346924\n",
      "Test Root MSE of all models in window: 0.7700896263122559\n",
      "\n",
      "############### EM step 219 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.959980845451355 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 220 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.4242324829101562, -- test: -6.3201680183410645 \n",
      "Root Mean Squared Error -- train: 0.4213380217552185, -- test: 0.7712083458900452 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3549120426177979, -- test: -6.11302375793457 \n",
      "Root Mean Squared Error -- train: 0.41426825523376465, -- test: 0.7596771121025085 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.3311057090759277, -- test: -6.163873672485352 \n",
      "Root Mean Squared Error -- train: 0.41181230545043945, -- test: 0.7625240087509155 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.406660795211792, -- test: -6.239916801452637 \n",
      "Root Mean Squared Error -- train: 0.4195571839809418, -- test: 0.7667616009712219 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3441921472549438, -- test: -6.3546648025512695 \n",
      "Root Mean Squared Error -- train: 0.4131641387939453, -- test: 0.7731119990348816 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3088855743408203, -- test: -6.291549205780029 \n",
      "Root Mean Squared Error -- train: 0.4095067083835602, -- test: 0.7696254849433899 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3245948553085327, -- test: -6.138833045959473 \n",
      "Root Mean Squared Error -- train: 0.41113805770874023, -- test: 0.7611234188079834 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.4266387224197388, -- test: -6.028481483459473 \n",
      "Root Mean Squared Error -- train: 0.42158129811286926, -- test: 0.754920244216919 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.3019092082977295, -- test: -6.149892807006836 \n",
      "Root Mean Squared Error -- train: 0.40878012776374817, -- test: 0.761742353439331 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3256285190582275, -- test: -6.137595176696777 \n",
      "Root Mean Squared Error -- train: 0.4112451672554016, -- test: 0.7610540390014648 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.430812358856201\n",
      "Test Root MSE of all sampled models: 0.7772976160049438\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.689190864562988\n",
      "Test Root MSE of all models in window: 0.7702338695526123\n",
      "\n",
      "############### EM step 220 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.6616473197937012 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 221 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.4591857194900513, -- test: -5.95744514465332 \n",
      "Root Mean Squared Error -- train: 0.42551830410957336, -- test: 0.7523122429847717 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3129924535751343, -- test: -6.059611797332764 \n",
      "Root Mean Squared Error -- train: 0.4105561375617981, -- test: 0.7581002116203308 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2970380783081055, -- test: -6.08187198638916 \n",
      "Root Mean Squared Error -- train: 0.40889015793800354, -- test: 0.7593554854393005 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3417298793792725, -- test: -6.147354602813721 \n",
      "Root Mean Squared Error -- train: 0.4135400056838989, -- test: 0.7630360126495361 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.315738558769226, -- test: -6.073526382446289 \n",
      "Root Mean Squared Error -- train: 0.4108422100543976, -- test: 0.7588850855827332 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3163319826126099, -- test: -6.259393692016602 \n",
      "Root Mean Squared Error -- train: 0.41090402007102966, -- test: 0.7692924737930298 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.2966729402542114, -- test: -6.039424896240234 \n",
      "Root Mean Squared Error -- train: 0.4088519513607025, -- test: 0.7569600939750671 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3079530000686646, -- test: -6.073786735534668 \n",
      "Root Mean Squared Error -- train: 0.41003066301345825, -- test: 0.7588997483253479 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.4145705699920654, -- test: -6.207186222076416 \n",
      "Root Mean Squared Error -- train: 0.42100855708122253, -- test: 0.7663834095001221 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3328866958618164, -- test: -6.0982842445373535 \n",
      "Root Mean Squared Error -- train: 0.4126241207122803, -- test: 0.760279655456543 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.318192005157471\n",
      "Test Root MSE of all sampled models: 0.7150343060493469\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.646628379821777\n",
      "Test Root MSE of all models in window: 0.769891619682312\n",
      "\n",
      "############### EM step 221 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.4381519556045532 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 222 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.4860434532165527, -- test: -5.690434455871582 \n",
      "Root Mean Squared Error -- train: 0.42888060212135315, -- test: 0.738357663154602 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3448594808578491, -- test: -6.064202785491943 \n",
      "Root Mean Squared Error -- train: 0.4144976735115051, -- test: 0.7597931027412415 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2942396402359009, -- test: -6.123262405395508 \n",
      "Root Mean Squared Error -- train: 0.4092177748680115, -- test: 0.7631250023841858 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.2913929224014282, -- test: -6.089360237121582 \n",
      "Root Mean Squared Error -- train: 0.4089187681674957, -- test: 0.7612141370773315 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.301155686378479, -- test: -6.094461441040039 \n",
      "Root Mean Squared Error -- train: 0.409943163394928, -- test: 0.7615020275115967 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.304793357849121, -- test: -5.943902492523193 \n",
      "Root Mean Squared Error -- train: 0.4103241562843323, -- test: 0.7529605627059937 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.2962206602096558, -- test: -6.135682582855225 \n",
      "Root Mean Squared Error -- train: 0.40942567586898804, -- test: 0.7638238668441772 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3248765468597412, -- test: -6.06500244140625 \n",
      "Root Mean Squared Error -- train: 0.41242140531539917, -- test: 0.759838342666626 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2944540977478027, -- test: -6.139155864715576 \n",
      "Root Mean Squared Error -- train: 0.4092402458190918, -- test: 0.764019250869751 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.390907645225525, -- test: -6.1249895095825195 \n",
      "Root Mean Squared Error -- train: 0.4192430078983307, -- test: 0.7632222771644592 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.2935919761657715\n",
      "Test Root MSE of all sampled models: 0.7726539969444275\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.6344780921936035\n",
      "Test Root MSE of all models in window: 0.7695981860160828\n",
      "\n",
      "############### EM step 222 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1917413473129272 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 223 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2881885766983032, -- test: -6.130545616149902 \n",
      "Root Mean Squared Error -- train: 0.4091942012310028, -- test: 0.7649623155593872 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.2935049533843994, -- test: -5.872920513153076 \n",
      "Root Mean Squared Error -- train: 0.4097541868686676, -- test: 0.7502954602241516 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.288875937461853, -- test: -6.268802642822266 \n",
      "Root Mean Squared Error -- train: 0.4092666506767273, -- test: 0.7727186679840088 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.2987051010131836, -- test: -5.9286417961120605 \n",
      "Root Mean Squared Error -- train: 0.41030123829841614, -- test: 0.7534919381141663 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.2969202995300293, -- test: -6.016231060028076 \n",
      "Root Mean Squared Error -- train: 0.4101135730743408, -- test: 0.7584893107414246 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.446541428565979, -- test: -5.917524337768555 \n",
      "Root Mean Squared Error -- train: 0.42555877566337585, -- test: 0.7528551816940308 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3122341632843018, -- test: -5.940998077392578 \n",
      "Root Mean Squared Error -- train: 0.41172102093696594, -- test: 0.7541989088058472 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3058425188064575, -- test: -5.944823741912842 \n",
      "Root Mean Squared Error -- train: 0.4110508859157562, -- test: 0.7544176578521729 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2872551679611206, -- test: -6.292033672332764 \n",
      "Root Mean Squared Error -- train: 0.40909579396247864, -- test: 0.7740142941474915 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.3106688261032104, -- test: -6.19818115234375 \n",
      "Root Mean Squared Error -- train: 0.41155698895454407, -- test: 0.7687665224075317 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.929074287414551\n",
      "Test Root MSE of all sampled models: 0.6939178705215454\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.5459980964660645\n",
      "Test Root MSE of all models in window: 0.7689253687858582\n",
      "\n",
      "############### EM step 223 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.4326834678649902 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 224 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2881883382797241, -- test: -5.789153575897217 \n",
      "Root Mean Squared Error -- train: 0.4098098576068878, -- test: 0.7468584179878235 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.2793474197387695, -- test: -5.894481658935547 \n",
      "Root Mean Squared Error -- train: 0.40887451171875, -- test: 0.7529412508010864 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2795531749725342, -- test: -6.032638072967529 \n",
      "Root Mean Squared Error -- train: 0.4088963270187378, -- test: 0.7608462572097778 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.4066498279571533, -- test: -5.885568618774414 \n",
      "Root Mean Squared Error -- train: 0.42214304208755493, -- test: 0.7524284720420837 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.2818154096603394, -- test: -5.928718090057373 \n",
      "Root Mean Squared Error -- train: 0.4091358184814453, -- test: 0.7549079060554504 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.2790037393569946, -- test: -6.057944297790527 \n",
      "Root Mean Squared Error -- train: 0.4088381230831146, -- test: 0.7622853517532349 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3052785396575928, -- test: -6.1429829597473145 \n",
      "Root Mean Squared Error -- train: 0.41161200404167175, -- test: 0.7671014070510864 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.2861460447311401, -- test: -6.008072376251221 \n",
      "Root Mean Squared Error -- train: 0.40959399938583374, -- test: 0.7594466805458069 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2942237854003906, -- test: -6.166039943695068 \n",
      "Root Mean Squared Error -- train: 0.4104471802711487, -- test: 0.7684020400047302 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.31382155418396, -- test: -5.934838771820068 \n",
      "Root Mean Squared Error -- train: 0.41250985860824585, -- test: 0.7552589178085327 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.199872016906738\n",
      "Test Root MSE of all sampled models: 0.7118683457374573\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.478514194488525\n",
      "Test Root MSE of all models in window: 0.7681149244308472\n",
      "\n",
      "############### EM step 224 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1127465963363647 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 225 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.271937608718872, -- test: -6.080185413360596 \n",
      "Root Mean Squared Error -- train: 0.4086909592151642, -- test: 0.76495760679245 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.2876391410827637, -- test: -5.818439483642578 \n",
      "Root Mean Squared Error -- train: 0.4103580415248871, -- test: 0.7499322295188904 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.300405502319336, -- test: -6.00376033782959 \n",
      "Root Mean Squared Error -- train: 0.4117085337638855, -- test: 0.7606011629104614 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.2767947912216187, -- test: -5.855688095092773 \n",
      "Root Mean Squared Error -- train: 0.40920737385749817, -- test: 0.7520887851715088 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3199890851974487, -- test: -6.0379157066345215 \n",
      "Root Mean Squared Error -- train: 0.4137715697288513, -- test: 0.7625511884689331 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.2960807085037231, -- test: -6.016695976257324 \n",
      "Root Mean Squared Error -- train: 0.4112515449523926, -- test: 0.761340320110321 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.29500412940979, -- test: -5.827970027923584 \n",
      "Root Mean Squared Error -- train: 0.4111377000808716, -- test: 0.7504845857620239 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3648399114608765, -- test: -5.965116024017334 \n",
      "Root Mean Squared Error -- train: 0.41845816373825073, -- test: 0.7583888173103333 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2814288139343262, -- test: -6.02347469329834 \n",
      "Root Mean Squared Error -- train: 0.4096994698047638, -- test: 0.7617272734642029 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2922160625457764, -- test: -6.0842204093933105 \n",
      "Root Mean Squared Error -- train: 0.4108427166938782, -- test: 0.7651869654655457 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.002162456512451\n",
      "Test Root MSE of all sampled models: 0.7605098485946655\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.459257125854492\n",
      "Test Root MSE of all models in window: 0.7677871584892273\n",
      "\n",
      "############### EM step 225 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.7467820644378662 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 226 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2801837921142578, -- test: -6.141915321350098 \n",
      "Root Mean Squared Error -- train: 0.4101882576942444, -- test: 0.769915759563446 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.2642592191696167, -- test: -6.0459184646606445 \n",
      "Root Mean Squared Error -- train: 0.40848976373672485, -- test: 0.7644527554512024 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.4152231216430664, -- test: -6.235074520111084 \n",
      "Root Mean Squared Error -- train: 0.42431798577308655, -- test: 0.7751805186271667 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3001559972763062, -- test: -5.981532573699951 \n",
      "Root Mean Squared Error -- train: 0.41230854392051697, -- test: 0.7607667446136475 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.2880618572235107, -- test: -6.14879035949707 \n",
      "Root Mean Squared Error -- train: 0.41102591156959534, -- test: 0.7703055143356323 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.2666101455688477, -- test: -5.8974714279174805 \n",
      "Root Mean Squared Error -- train: 0.4087409973144531, -- test: 0.7559272050857544 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.3074599504470825, -- test: -5.909160614013672 \n",
      "Root Mean Squared Error -- train: 0.41308122873306274, -- test: 0.7566020488739014 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.316402554512024, -- test: -5.964972019195557 \n",
      "Root Mean Squared Error -- train: 0.41402530670166016, -- test: 0.7598158121109009 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2661904096603394, -- test: -5.854772567749023 \n",
      "Root Mean Squared Error -- train: 0.40869614481925964, -- test: 0.7534570693969727 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2813916206359863, -- test: -6.076618671417236 \n",
      "Root Mean Squared Error -- train: 0.4103168249130249, -- test: 0.7662041187286377 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.769461154937744\n",
      "Test Root MSE of all sampled models: 0.748497486114502\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.440434455871582\n",
      "Test Root MSE of all models in window: 0.7675107717514038\n",
      "\n",
      "############### EM step 226 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.8588815331459045 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 227 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2792940139770508, -- test: -5.861424446105957 \n",
      "Root Mean Squared Error -- train: 0.41069430112838745, -- test: 0.7552198171615601 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.306815266609192, -- test: -5.9111762046813965 \n",
      "Root Mean Squared Error -- train: 0.41362109780311584, -- test: 0.7581019401550293 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.402599573135376, -- test: -5.802120208740234 \n",
      "Root Mean Squared Error -- train: 0.42364993691444397, -- test: 0.7517700791358948 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.2618247270584106, -- test: -5.965518951416016 \n",
      "Root Mean Squared Error -- train: 0.4088256061077118, -- test: 0.7612374424934387 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.270283579826355, -- test: -5.825592041015625 \n",
      "Root Mean Squared Error -- train: 0.40973150730133057, -- test: 0.7531372904777527 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.262684941291809, -- test: -6.068054676055908 \n",
      "Root Mean Squared Error -- train: 0.4089178442955017, -- test: 0.7671186327934265 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.5770964622497559, -- test: -6.1065802574157715 \n",
      "Root Mean Squared Error -- train: 0.44133469462394714, -- test: 0.7693168520927429 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.272688627243042, -- test: -5.988037109375 \n",
      "Root Mean Squared Error -- train: 0.4099887013435364, -- test: 0.7625328898429871 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2682368755340576, -- test: -6.045131683349609 \n",
      "Root Mean Squared Error -- train: 0.4095125198364258, -- test: 0.7658078074455261 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.265426754951477, -- test: -6.024339199066162 \n",
      "Root Mean Squared Error -- train: 0.4092116057872772, -- test: 0.7646167874336243 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.457869052886963\n",
      "Test Root MSE of all sampled models: 0.7314231991767883\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.425161838531494\n",
      "Test Root MSE of all models in window: 0.7670882344245911\n",
      "\n",
      "############### EM step 227 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.0135670900344849 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 228 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2673239707946777, -- test: -5.961099624633789 \n",
      "Root Mean Squared Error -- train: 0.4100005328655243, -- test: 0.7623460292816162 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.2651251554489136, -- test: -5.986136436462402 \n",
      "Root Mean Squared Error -- train: 0.40976449847221375, -- test: 0.7637897729873657 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2920715808868408, -- test: -5.954362869262695 \n",
      "Root Mean Squared Error -- train: 0.41264796257019043, -- test: 0.7619571089744568 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.296014428138733, -- test: -5.880712985992432 \n",
      "Root Mean Squared Error -- train: 0.41306817531585693, -- test: 0.7576919198036194 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.2545990943908691, -- test: -6.0544843673706055 \n",
      "Root Mean Squared Error -- train: 0.4086326062679291, -- test: 0.767717182636261 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.334433913230896, -- test: -5.993957996368408 \n",
      "Root Mean Squared Error -- train: 0.41714075207710266, -- test: 0.7642402648925781 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.2557119131088257, -- test: -5.916953086853027 \n",
      "Root Mean Squared Error -- train: 0.4087524116039276, -- test: 0.7597936391830444 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.352980136871338, -- test: -5.764569282531738 \n",
      "Root Mean Squared Error -- train: 0.4190925061702728, -- test: 0.7509168386459351 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2869374752044678, -- test: -5.776821136474609 \n",
      "Root Mean Squared Error -- train: 0.4121001362800598, -- test: 0.7516343593597412 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.269639253616333, -- test: -5.826990127563477 \n",
      "Root Mean Squared Error -- train: 0.41024893522262573, -- test: 0.7545657157897949 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.620817184448242\n",
      "Test Root MSE of all sampled models: 0.7424454689025879\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.398082256317139\n",
      "Test Root MSE of all models in window: 0.7665337324142456\n",
      "\n",
      "############### EM step 228 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.627901315689087 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 229 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2638282775878906, -- test: -5.782792568206787 \n",
      "Root Mean Squared Error -- train: 0.4102238416671753, -- test: 0.7533580660820007 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.2551387548446655, -- test: -5.9586181640625 \n",
      "Root Mean Squared Error -- train: 0.4092870354652405, -- test: 0.7635987997055054 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2564642429351807, -- test: -5.997923374176025 \n",
      "Root Mean Squared Error -- train: 0.4094300866127014, -- test: 0.7658693790435791 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.2847199440002441, -- test: -5.779250621795654 \n",
      "Root Mean Squared Error -- train: 0.41246750950813293, -- test: 0.7531503438949585 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.3078693151474, -- test: -5.808364391326904 \n",
      "Root Mean Squared Error -- train: 0.4149394929409027, -- test: 0.7548561096191406 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.2632842063903809, -- test: -5.824397087097168 \n",
      "Root Mean Squared Error -- train: 0.41016528010368347, -- test: 0.7557938694953918 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.2508108615875244, -- test: -5.813950061798096 \n",
      "Root Mean Squared Error -- train: 0.40881961584091187, -- test: 0.7551829814910889 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.2559441328048706, -- test: -5.885034084320068 \n",
      "Root Mean Squared Error -- train: 0.4093739688396454, -- test: 0.7593298554420471 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.4064080715179443, -- test: -6.0216803550720215 \n",
      "Root Mean Squared Error -- train: 0.42530107498168945, -- test: 0.7672384977340698 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2830678224563599, -- test: -5.917697906494141 \n",
      "Root Mean Squared Error -- train: 0.4122905433177948, -- test: 0.7612277269363403 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.654655933380127\n",
      "Test Root MSE of all sampled models: 0.7458063364028931\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.377050399780273\n",
      "Test Root MSE of all models in window: 0.7660151720046997\n",
      "\n",
      "############### EM step 229 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1229615211486816 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 230 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2535698413848877, -- test: -6.008329391479492 \n",
      "Root Mean Squared Error -- train: 0.40970608592033386, -- test: 0.7678549885749817 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.5552293062210083, -- test: -5.707726001739502 \n",
      "Root Mean Squared Error -- train: 0.441152960062027, -- test: 0.7502919435501099 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2515969276428223, -- test: -5.942718029022217 \n",
      "Root Mean Squared Error -- train: 0.40949246287345886, -- test: 0.7640559673309326 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.3023386001586914, -- test: -5.838897705078125 \n",
      "Root Mean Squared Error -- train: 0.4149515926837921, -- test: 0.7580057978630066 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.2457246780395508, -- test: -5.878476619720459 \n",
      "Root Mean Squared Error -- train: 0.40885597467422485, -- test: 0.7603179812431335 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.3229153156280518, -- test: -5.956067085266113 \n",
      "Root Mean Squared Error -- train: 0.4171449840068817, -- test: 0.7648304104804993 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.273379921913147, -- test: -6.072864532470703 \n",
      "Root Mean Squared Error -- train: 0.4118448793888092, -- test: 0.7715734243392944 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3417105674743652, -- test: -5.797057628631592 \n",
      "Root Mean Squared Error -- train: 0.41913849115371704, -- test: 0.7555537819862366 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2647463083267212, -- test: -5.974076747894287 \n",
      "Root Mean Squared Error -- train: 0.4109141230583191, -- test: 0.7658740282058716 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2622146606445312, -- test: -5.9768476486206055 \n",
      "Root Mean Squared Error -- train: 0.41064080595970154, -- test: 0.7660344839096069 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.739140510559082\n",
      "Test Root MSE of all sampled models: 0.8089644312858582\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.370440483093262\n",
      "Test Root MSE of all models in window: 0.7664796113967896\n",
      "\n",
      "############### EM step 230 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.425173282623291 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 231 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2816674709320068, -- test: -5.968628406524658 \n",
      "Root Mean Squared Error -- train: 0.41333770751953125, -- test: 0.7669529318809509 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3014415502548218, -- test: -6.097583770751953 \n",
      "Root Mean Squared Error -- train: 0.41546231508255005, -- test: 0.7744030356407166 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2721378803253174, -- test: -5.878830432891846 \n",
      "Root Mean Squared Error -- train: 0.4123099148273468, -- test: 0.7617219686508179 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.2751644849777222, -- test: -6.071097373962402 \n",
      "Root Mean Squared Error -- train: 0.4126366376876831, -- test: 0.7728787064552307 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.315737247467041, -- test: -5.922986030578613 \n",
      "Root Mean Squared Error -- train: 0.41699156165122986, -- test: 0.7642985582351685 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.251155972480774, -- test: -6.008520603179932 \n",
      "Root Mean Squared Error -- train: 0.4100378751754761, -- test: 0.769265353679657 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.2720152139663696, -- test: -6.20111083984375 \n",
      "Root Mean Squared Error -- train: 0.41229671239852905, -- test: 0.7803326845169067 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.274944543838501, -- test: -6.0986809730529785 \n",
      "Root Mean Squared Error -- train: 0.4126129150390625, -- test: 0.7744661569595337 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.235543131828308, -- test: -5.955134868621826 \n",
      "Root Mean Squared Error -- train: 0.4083390235900879, -- test: 0.7661691904067993 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2634904384613037, -- test: -6.034146308898926 \n",
      "Root Mean Squared Error -- train: 0.4113750755786896, -- test: 0.7707471251487732 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.642624378204346\n",
      "Test Root MSE of all sampled models: 0.8051306009292603\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.373701572418213\n",
      "Test Root MSE of all models in window: 0.7669625282287598\n",
      "\n",
      "############### EM step 231 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.4751900434494019 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 232 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2412009239196777, -- test: -5.846810340881348 \n",
      "Root Mean Squared Error -- train: 0.40955281257629395, -- test: 0.7612444758415222 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.2847412824630737, -- test: -5.893316745758057 \n",
      "Root Mean Squared Error -- train: 0.41427791118621826, -- test: 0.7639704942703247 \n",
      "\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2020787000656128, -- test: -5.900514125823975 \n",
      "Root Mean Squared Error -- train: 0.4087642431259155, -- test: 0.7727969884872437 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.2250945568084717, -- test: -5.825870513916016 \n",
      "Root Mean Squared Error -- train: 0.41133347153663635, -- test: 0.7683630585670471 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2039432525634766, -- test: -5.6600141525268555 \n",
      "Root Mean Squared Error -- train: 0.40897297859191895, -- test: 0.7584182024002075 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.2034697532653809, -- test: -5.752647876739502 \n",
      "Root Mean Squared Error -- train: 0.4089199900627136, -- test: 0.7639885544776917 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.206251859664917, -- test: -5.562986850738525 \n",
      "Root Mean Squared Error -- train: 0.4092312753200531, -- test: 0.7525393962860107 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.2212215662002563, -- test: -5.671550750732422 \n",
      "Root Mean Squared Error -- train: 0.4109022617340088, -- test: 0.759114146232605 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.2395278215408325, -- test: -5.635166645050049 \n",
      "Root Mean Squared Error -- train: 0.4129365086555481, -- test: 0.7569170594215393 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.2124944925308228, -- test: -5.772707939147949 \n",
      "Root Mean Squared Error -- train: 0.40992894768714905, -- test: 0.765189528465271 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2270764112472534, -- test: -5.636563777923584 \n",
      "Root Mean Squared Error -- train: 0.4115539789199829, -- test: 0.757001519203186 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2564232349395752, -- test: -5.702976226806641 \n",
      "Root Mean Squared Error -- train: 0.4148051142692566, -- test: 0.761006772518158 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.6652092933654785\n",
      "Test Root MSE of all sampled models: 0.7587317228317261\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.232995986938477\n",
      "Test Root MSE of all models in window: 0.7667293548583984\n",
      "\n",
      "############### EM step 238 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.153831958770752 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 239 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2707866430282593, -- test: -5.667652606964111 \n",
      "Root Mean Squared Error -- train: 0.41698282957077026, -- test: 0.7602375149726868 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.201130747795105, -- test: -5.4523701667785645 \n",
      "Root Mean Squared Error -- train: 0.4092347323894501, -- test: 0.7471116781234741 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2004505395889282, -- test: -5.744241237640381 \n",
      "Root Mean Squared Error -- train: 0.4091583490371704, -- test: 0.7648528218269348 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.2130489349365234, -- test: -5.687864780426025 \n",
      "Root Mean Squared Error -- train: 0.41057077050209045, -- test: 0.7614582180976868 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.2002524137496948, -- test: -5.791266918182373 \n",
      "Root Mean Squared Error -- train: 0.4091360569000244, -- test: 0.7676728367805481 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.2021597623825073, -- test: -5.578561305999756 \n",
      "Root Mean Squared Error -- train: 0.4093502461910248, -- test: 0.7548333406448364 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.2468857765197754, -- test: -5.830507278442383 \n",
      "Root Mean Squared Error -- train: 0.4143405556678772, -- test: 0.7700181603431702 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.2488994598388672, -- test: -5.75814151763916 \n",
      "Root Mean Squared Error -- train: 0.4145638644695282, -- test: 0.7656874060630798 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2124392986297607, -- test: -5.547074794769287 \n",
      "Root Mean Squared Error -- train: 0.410502552986145, -- test: 0.7529140114784241 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2869833707809448, -- test: -5.637383460998535 \n",
      "Root Mean Squared Error -- train: 0.4187638759613037, -- test: 0.7584056854248047 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.9346699714660645\n",
      "Test Root MSE of all sampled models: 0.77620929479599\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.22941780090332\n",
      "Test Root MSE of all models in window: 0.7669055461883545\n",
      "\n",
      "############### EM step 239 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.022775411605835 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 240 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1903049945831299, -- test: -5.526768684387207 \n",
      "Root Mean Squared Error -- train: 0.40858086943626404, -- test: 0.7529915571212769 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.3498657941818237, -- test: -5.804476261138916 \n",
      "Root Mean Squared Error -- train: 0.42621415853500366, -- test: 0.7698155641555786 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2174793481826782, -- test: -5.32111930847168 \n",
      "Root Mean Squared Error -- train: 0.4116373062133789, -- test: 0.7402865886688232 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1968514919281006, -- test: -5.630283355712891 \n",
      "Root Mean Squared Error -- train: 0.40931928157806396, -- test: 0.7593062520027161 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1978859901428223, -- test: -5.627790451049805 \n",
      "Root Mean Squared Error -- train: 0.40943580865859985, -- test: 0.7591547966003418 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.19465172290802, -- test: -5.530402660369873 \n",
      "Root Mean Squared Error -- train: 0.40907129645347595, -- test: 0.7532141804695129 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.194624662399292, -- test: -5.693174839019775 \n",
      "Root Mean Squared Error -- train: 0.4090682566165924, -- test: 0.7631173133850098 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.2017476558685303, -- test: -5.755034923553467 \n",
      "Root Mean Squared Error -- train: 0.4098706543445587, -- test: 0.7668473124504089 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2189048528671265, -- test: -5.713348865509033 \n",
      "Root Mean Squared Error -- train: 0.41179701685905457, -- test: 0.7643357515335083 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2102237939834595, -- test: -5.6900835037231445 \n",
      "Root Mean Squared Error -- train: 0.4108234643936157, -- test: 0.7629303932189941 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.829410552978516\n",
      "Test Root MSE of all sampled models: 0.771308183670044\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.2215471267700195\n",
      "Test Root MSE of all models in window: 0.7667381167411804\n",
      "\n",
      "############### EM step 240 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.4304492473602295 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 241 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2051812410354614, -- test: -5.739203453063965 \n",
      "Root Mean Squared Error -- train: 0.4108317792415619, -- test: 0.7672572135925293 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1936510801315308, -- test: -5.633669376373291 \n",
      "Root Mean Squared Error -- train: 0.4095301330089569, -- test: 0.7608612775802612 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2017760276794434, -- test: -5.680604934692383 \n",
      "Root Mean Squared Error -- train: 0.4104478061199188, -- test: 0.7637124061584473 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1980469226837158, -- test: -5.583693981170654 \n",
      "Root Mean Squared Error -- train: 0.4100268483161926, -- test: 0.7578136920928955 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.198071837425232, -- test: -5.683431625366211 \n",
      "Root Mean Squared Error -- train: 0.41002967953681946, -- test: 0.7638837695121765 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1942012310028076, -- test: -5.678330898284912 \n",
      "Root Mean Squared Error -- train: 0.40959233045578003, -- test: 0.763574481010437 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.2164925336837769, -- test: -5.592012882232666 \n",
      "Root Mean Squared Error -- train: 0.4121047258377075, -- test: 0.7583218216896057 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.2118204832077026, -- test: -5.752483367919922 \n",
      "Root Mean Squared Error -- train: 0.411579430103302, -- test: 0.768058180809021 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1897891759872437, -- test: -5.585360050201416 \n",
      "Root Mean Squared Error -- train: 0.4090932309627533, -- test: 0.7579154968261719 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.213395357131958, -- test: -5.598312854766846 \n",
      "Root Mean Squared Error -- train: 0.41175657510757446, -- test: 0.7587064504623413 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.791391372680664\n",
      "Test Root MSE of all sampled models: 0.7077468633651733\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.1816182136535645\n",
      "Test Root MSE of all models in window: 0.7661646008491516\n",
      "\n",
      "############### EM step 241 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.0095350742340088 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 242 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.187619686126709, -- test: -5.67540168762207 \n",
      "Root Mean Squared Error -- train: 0.409407377243042, -- test: 0.7647281885147095 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1969573497772217, -- test: -5.48756217956543 \n",
      "Root Mean Squared Error -- train: 0.41046616435050964, -- test: 0.7532246112823486 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1837135553359985, -- test: -5.485332012176514 \n",
      "Root Mean Squared Error -- train: 0.4089636504650116, -- test: 0.7530869245529175 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1859371662139893, -- test: -5.426652908325195 \n",
      "Root Mean Squared Error -- train: 0.4092163145542145, -- test: 0.7494564652442932 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1872568130493164, -- test: -5.573551654815674 \n",
      "Root Mean Squared Error -- train: 0.4093661904335022, -- test: 0.7585123777389526 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1846903562545776, -- test: -5.5538129806518555 \n",
      "Root Mean Squared Error -- train: 0.40907466411590576, -- test: 0.7573017477989197 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.2160662412643433, -- test: -5.708684921264648 \n",
      "Root Mean Squared Error -- train: 0.4126243591308594, -- test: 0.7667484879493713 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1849653720855713, -- test: -5.620261192321777 \n",
      "Root Mean Squared Error -- train: 0.40910592675209045, -- test: 0.7613692879676819 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 10:28:05.398716: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.186184048652649, -- test: -5.534194469451904 \n",
      "Root Mean Squared Error -- train: 0.4092443585395813, -- test: 0.7560966610908508 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2577035427093506, -- test: -5.7005615234375 \n",
      "Root Mean Squared Error -- train: 0.41728833317756653, -- test: 0.7662559151649475 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.904663562774658\n",
      "Test Root MSE of all sampled models: 0.7785384058952332\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.177648544311523\n",
      "Test Root MSE of all models in window: 0.7664563059806824\n",
      "\n",
      "############### EM step 242 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.339181900024414 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 243 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1806222200393677, -- test: -5.638113975524902 \n",
      "Root Mean Squared Error -- train: 0.40917402505874634, -- test: 0.7637956738471985 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1751880645751953, -- test: -5.64939022064209 \n",
      "Root Mean Squared Error -- train: 0.4085538983345032, -- test: 0.7644842863082886 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1903176307678223, -- test: -5.405460357666016 \n",
      "Root Mean Squared Error -- train: 0.4102781116962433, -- test: 0.7494486570358276 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1767668724060059, -- test: -5.750978469848633 \n",
      "Root Mean Squared Error -- train: 0.40873414278030396, -- test: 0.7706594467163086 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1956042051315308, -- test: -5.684423923492432 \n",
      "Root Mean Squared Error -- train: 0.4108789265155792, -- test: 0.7666194438934326 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1929935216903687, -- test: -5.525106906890869 \n",
      "Root Mean Squared Error -- train: 0.4105823040008545, -- test: 0.7568607926368713 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1809132099151611, -- test: -5.622858047485352 \n",
      "Root Mean Squared Error -- train: 0.40920722484588623, -- test: 0.7628632187843323 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1944345235824585, -- test: -5.629986763000488 \n",
      "Root Mean Squared Error -- train: 0.4107460081577301, -- test: 0.7632990479469299 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.261399507522583, -- test: -5.6607489585876465 \n",
      "Root Mean Squared Error -- train: 0.41828376054763794, -- test: 0.7651771306991577 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.190566062927246, -- test: -5.760560989379883 \n",
      "Root Mean Squared Error -- train: 0.4103063642978668, -- test: 0.7712393999099731 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.091639995574951\n",
      "Test Root MSE of all sampled models: 0.7910155057907104\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.173475742340088\n",
      "Test Root MSE of all models in window: 0.7668119072914124\n",
      "\n",
      "############### EM step 243 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.159028172492981 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 244 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1947673559188843, -- test: -5.906036376953125 \n",
      "Root Mean Squared Error -- train: 0.41134610772132874, -- test: 0.781353771686554 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1795843839645386, -- test: -5.631809711456299 \n",
      "Root Mean Squared Error -- train: 0.4096137583255768, -- test: 0.7647396326065063 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1996350288391113, -- test: -5.657223701477051 \n",
      "Root Mean Squared Error -- train: 0.41189998388290405, -- test: 0.7662944793701172 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.187294602394104, -- test: -5.615396022796631 \n",
      "Root Mean Squared Error -- train: 0.4104943871498108, -- test: 0.7637337446212769 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1982982158660889, -- test: -5.56185245513916 \n",
      "Root Mean Squared Error -- train: 0.41174793243408203, -- test: 0.7604430913925171 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.209614634513855, -- test: -5.6036458015441895 \n",
      "Root Mean Squared Error -- train: 0.4130331575870514, -- test: 0.7630127668380737 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1788280010223389, -- test: -5.592457294464111 \n",
      "Root Mean Squared Error -- train: 0.4095272719860077, -- test: 0.7623257637023926 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.2064337730407715, -- test: -5.304142951965332 \n",
      "Root Mean Squared Error -- train: 0.4126722812652588, -- test: 0.7444016933441162 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1877777576446533, -- test: -5.627943515777588 \n",
      "Root Mean Squared Error -- train: 0.41054949164390564, -- test: 0.7645028829574585 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.260953426361084, -- test: -5.4377851486206055 \n",
      "Root Mean Squared Error -- train: 0.41881421208381653, -- test: 0.752763032913208 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.647617340087891\n",
      "Test Root MSE of all sampled models: 0.7657070755958557\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.166226863861084\n",
      "Test Root MSE of all models in window: 0.7665078639984131\n",
      "\n",
      "############### EM step 244 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1365718841552734 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 245 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1693834066390991, -- test: -5.652562141418457 \n",
      "Root Mean Squared Error -- train: 0.4089970290660858, -- test: 0.7673327922821045 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1756662130355835, -- test: -5.694282054901123 \n",
      "Root Mean Squared Error -- train: 0.4097185432910919, -- test: 0.7698845863342285 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.241753101348877, -- test: -5.558173179626465 \n",
      "Root Mean Squared Error -- train: 0.4172325134277344, -- test: 0.761527955532074 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1915498971939087, -- test: -5.638803005218506 \n",
      "Root Mean Squared Error -- train: 0.4115370213985443, -- test: 0.7664893865585327 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1694902181625366, -- test: -5.545566558837891 \n",
      "Root Mean Squared Error -- train: 0.40900930762290955, -- test: 0.7607493996620178 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1697226762771606, -- test: -5.632604598999023 \n",
      "Root Mean Squared Error -- train: 0.4090360403060913, -- test: 0.7661091089248657 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1679718494415283, -- test: -5.565595626831055 \n",
      "Root Mean Squared Error -- train: 0.4088347256183624, -- test: 0.7619861364364624 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1938798427581787, -- test: -5.4689106941223145 \n",
      "Root Mean Squared Error -- train: 0.41180312633514404, -- test: 0.7559974789619446 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.180410623550415, -- test: -5.471047401428223 \n",
      "Root Mean Squared Error -- train: 0.4102625846862793, -- test: 0.7561303377151489 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2098572254180908, -- test: -5.474644184112549 \n",
      "Root Mean Squared Error -- train: 0.41362303495407104, -- test: 0.7563539743423462 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.560973644256592\n",
      "Test Root MSE of all sampled models: 0.7617008686065674\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.101541042327881\n",
      "Test Root MSE of all models in window: 0.766572892665863\n",
      "\n",
      "############### EM step 245 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1067167520523071 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 246 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1844887733459473, -- test: -5.767646312713623 \n",
      "Root Mean Squared Error -- train: 0.4112803637981415, -- test: 0.7756785750389099 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.2165368795394897, -- test: -5.793238639831543 \n",
      "Root Mean Squared Error -- train: 0.4149409532546997, -- test: 0.7772338390350342 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2043505907058716, -- test: -5.710190296173096 \n",
      "Root Mean Squared Error -- train: 0.41355282068252563, -- test: 0.7721754908561707 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1735076904296875, -- test: -5.509906768798828 \n",
      "Root Mean Squared Error -- train: 0.41001856327056885, -- test: 0.7598378658294678 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1626006364822388, -- test: -5.7313432693481445 \n",
      "Root Mean Squared Error -- train: 0.4087614119052887, -- test: 0.7734670042991638 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.2962933778762817, -- test: -5.3194499015808105 \n",
      "Root Mean Squared Error -- train: 0.42391374707221985, -- test: 0.7479169368743896 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.219678282737732, -- test: -5.595016956329346 \n",
      "Root Mean Squared Error -- train: 0.41529807448387146, -- test: 0.7651050090789795 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1840243339538574, -- test: -5.658194541931152 \n",
      "Root Mean Squared Error -- train: 0.4112270772457123, -- test: 0.7689915299415588 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1658421754837036, -- test: -5.471587657928467 \n",
      "Root Mean Squared Error -- train: 0.4091354012489319, -- test: 0.757454514503479 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1638675928115845, -- test: -5.614213466644287 \n",
      "Root Mean Squared Error -- train: 0.40890762209892273, -- test: 0.7662880420684814 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.334483623504639\n",
      "Test Root MSE of all sampled models: 0.7488647699356079\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.080505847930908\n",
      "Test Root MSE of all models in window: 0.7660958170890808\n",
      "\n",
      "############### EM step 246 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.127901554107666 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 247 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2808589935302734, -- test: -5.525911331176758 \n",
      "Root Mean Squared Error -- train: 0.42276516556739807, -- test: 0.7621213793754578 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.192123532295227, -- test: -5.684165000915527 \n",
      "Root Mean Squared Error -- train: 0.4127047657966614, -- test: 0.7718932032585144 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1617884635925293, -- test: -5.422402858734131 \n",
      "Root Mean Squared Error -- train: 0.4092088043689728, -- test: 0.75566166639328 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1737911701202393, -- test: -5.669529914855957 \n",
      "Root Mean Squared Error -- train: 0.4105955958366394, -- test: 0.7709947228431702 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1592659950256348, -- test: -5.640010833740234 \n",
      "Root Mean Squared Error -- train: 0.408916711807251, -- test: 0.7691792249679565 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1587951183319092, -- test: -5.609461784362793 \n",
      "Root Mean Squared Error -- train: 0.4088621735572815, -- test: 0.7672959566116333 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.170248031616211, -- test: -5.487119674682617 \n",
      "Root Mean Squared Error -- train: 0.41018667817115784, -- test: 0.759706974029541 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1738677024841309, -- test: -5.425292491912842 \n",
      "Root Mean Squared Error -- train: 0.41060441732406616, -- test: 0.7558427453041077 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1646218299865723, -- test: -5.603020191192627 \n",
      "Root Mean Squared Error -- train: 0.40953660011291504, -- test: 0.7668982148170471 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1789592504501343, -- test: -5.517775058746338 \n",
      "Root Mean Squared Error -- train: 0.41119128465652466, -- test: 0.7616155743598938 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 10:29:49.445957: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -6.184823989868164\n",
      "Test Root MSE of all sampled models: 0.8020238876342773\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.07893180847168\n",
      "Test Root MSE of all models in window: 0.7663381695747375\n",
      "\n",
      "############### EM step 247 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.244832992553711 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 248 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1682347059249878, -- test: -5.6876301765441895 \n",
      "Root Mean Squared Error -- train: 0.41049888730049133, -- test: 0.7734212279319763 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.2897409200668335, -- test: -5.550744533538818 \n",
      "Root Mean Squared Error -- train: 0.4243362545967102, -- test: 0.7649616599082947 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.154451847076416, -- test: -5.634617328643799 \n",
      "Root Mean Squared Error -- train: 0.4088996946811676, -- test: 0.7701560854911804 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.155005931854248, -- test: -5.439998626708984 \n",
      "Root Mean Squared Error -- train: 0.4089640974998474, -- test: 0.758048415184021 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1832301616668701, -- test: -5.503437519073486 \n",
      "Root Mean Squared Error -- train: 0.4122317135334015, -- test: 0.7620161771774292 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1548491716384888, -- test: -5.479123592376709 \n",
      "Root Mean Squared Error -- train: 0.4089459180831909, -- test: 0.7604978680610657 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.156253457069397, -- test: -5.509578704833984 \n",
      "Root Mean Squared Error -- train: 0.40910911560058594, -- test: 0.7623991966247559 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1649471521377563, -- test: -5.566413402557373 \n",
      "Root Mean Squared Error -- train: 0.4101180136203766, -- test: 0.7659347057342529 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1944595575332642, -- test: -5.401535511016846 \n",
      "Root Mean Squared Error -- train: 0.4135246276855469, -- test: 0.7556326389312744 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2673094272613525, -- test: -5.512572765350342 \n",
      "Root Mean Squared Error -- train: 0.4218159019947052, -- test: 0.7625858187675476 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.951708793640137\n",
      "Test Root MSE of all sampled models: 0.7267835736274719\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.058852672576904\n",
      "Test Root MSE of all models in window: 0.7658901214599609\n",
      "\n",
      "############### EM step 248 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.119697093963623 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 249 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.157426118850708, -- test: -5.318143844604492 \n",
      "Root Mean Squared Error -- train: 0.40978366136550903, -- test: 0.7516304850578308 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.160456895828247, -- test: -5.372840404510498 \n",
      "Root Mean Squared Error -- train: 0.4101364016532898, -- test: 0.7550945281982422 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1678842306137085, -- test: -5.419108867645264 \n",
      "Root Mean Squared Error -- train: 0.41099950671195984, -- test: 0.7580123543739319 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1703124046325684, -- test: -5.602814197540283 \n",
      "Root Mean Squared Error -- train: 0.4112812876701355, -- test: 0.7694883942604065 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.149166464805603, -- test: -5.415685653686523 \n",
      "Root Mean Squared Error -- train: 0.40882086753845215, -- test: 0.7577968239784241 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1510428190231323, -- test: -5.496016979217529 \n",
      "Root Mean Squared Error -- train: 0.40903979539871216, -- test: 0.7628377676010132 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1870198249816895, -- test: -5.304831504821777 \n",
      "Root Mean Squared Error -- train: 0.41321492195129395, -- test: 0.7507849335670471 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.17837393283844, -- test: -5.640637397766113 \n",
      "Root Mean Squared Error -- train: 0.4122154116630554, -- test: 0.7718299031257629 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1492611169815063, -- test: -5.540043830871582 \n",
      "Root Mean Squared Error -- train: 0.408831924200058, -- test: 0.7655864357948303 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2560596466064453, -- test: -5.602296352386475 \n",
      "Root Mean Squared Error -- train: 0.4211110472679138, -- test: 0.7694562077522278 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.415380954742432\n",
      "Test Root MSE of all sampled models: 0.7577776312828064\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.023378372192383\n",
      "Test Root MSE of all models in window: 0.7658653259277344\n",
      "\n",
      "############### EM step 249 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.4050861597061157 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 250 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1537023782730103, -- test: -5.60800313949585 \n",
      "Root Mean Squared Error -- train: 0.4098956882953644, -- test: 0.7711300253868103 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1452423334121704, -- test: -5.492802619934082 \n",
      "Root Mean Squared Error -- train: 0.40890607237815857, -- test: 0.7639421820640564 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2015336751937866, -- test: -5.431554794311523 \n",
      "Root Mean Squared Error -- train: 0.41544637084007263, -- test: 0.7600930333137512 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1457569599151611, -- test: -5.446129322052002 \n",
      "Root Mean Squared Error -- train: 0.4089663624763489, -- test: 0.7610107660293579 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1572489738464355, -- test: -5.473087787628174 \n",
      "Root Mean Squared Error -- train: 0.4103098213672638, -- test: 0.7627053260803223 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.179337739944458, -- test: -5.5404887199401855 \n",
      "Root Mean Squared Error -- train: 0.4128798842430115, -- test: 0.7669256925582886 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1973203420639038, -- test: -5.278651237487793 \n",
      "Root Mean Squared Error -- train: 0.41496041417121887, -- test: 0.7503975629806519 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1509405374526978, -- test: -5.564095973968506 \n",
      "Root Mean Squared Error -- train: 0.40957289934158325, -- test: 0.7683984637260437 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2160879373550415, -- test: -5.6024274826049805 \n",
      "Root Mean Squared Error -- train: 0.41712069511413574, -- test: 0.7707836627960205 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1494168043136597, -- test: -5.558438777923584 \n",
      "Root Mean Squared Error -- train: 0.40939468145370483, -- test: 0.7680457234382629 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.868188858032227\n",
      "Test Root MSE of all sampled models: 0.7871224880218506\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -5.019320487976074\n",
      "Test Root MSE of all models in window: 0.7660288214683533\n",
      "\n",
      "############### EM step 250 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.9273958206176758 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 251 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.2153998613357544, -- test: -5.254624843597412 \n",
      "Root Mean Squared Error -- train: 0.4175926744937897, -- test: 0.7501119375228882 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.220395803451538, -- test: -5.3883233070373535 \n",
      "Root Mean Squared Error -- train: 0.4181673228740692, -- test: 0.7586303949356079 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1713367700576782, -- test: -5.613250732421875 \n",
      "Root Mean Squared Error -- train: 0.41248995065689087, -- test: 0.7727496027946472 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1520943641662598, -- test: -5.216381072998047 \n",
      "Root Mean Squared Error -- train: 0.41024166345596313, -- test: 0.7476574182510376 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1557961702346802, -- test: -5.342845916748047 \n",
      "Root Mean Squared Error -- train: 0.41067513823509216, -- test: 0.7557436227798462 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.2201110124588013, -- test: -5.322929859161377 \n",
      "Root Mean Squared Error -- train: 0.4181345999240875, -- test: 0.7544759511947632 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1576759815216064, -- test: -5.348453521728516 \n",
      "Root Mean Squared Error -- train: 0.41089507937431335, -- test: 0.7561001181602478 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1448018550872803, -- test: -5.353823184967041 \n",
      "Root Mean Squared Error -- train: 0.40938636660575867, -- test: 0.7564414739608765 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1577937602996826, -- test: -5.482193470001221 \n",
      "Root Mean Squared Error -- train: 0.41090884804725647, -- test: 0.7645546197891235 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1747678518295288, -- test: -5.572038173675537 \n",
      "Root Mean Squared Error -- train: 0.4128895103931427, -- test: 0.7701819539070129 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.8172149658203125\n",
      "Test Root MSE of all sampled models: 0.7853335738182068\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.993560791015625\n",
      "Test Root MSE of all models in window: 0.766273021697998\n",
      "\n",
      "############### EM step 251 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.152825117111206 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 252 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1337286233901978, -- test: -5.468832015991211 \n",
      "Root Mean Squared Error -- train: 0.40861180424690247, -- test: 0.7649881839752197 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1375830173492432, -- test: -5.502530574798584 \n",
      "Root Mean Squared Error -- train: 0.4090666174888611, -- test: 0.767110288143158 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1373138427734375, -- test: -5.270120620727539 \n",
      "Root Mean Squared Error -- train: 0.4090348184108734, -- test: 0.7523533701896667 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1606159210205078, -- test: -5.604534149169922 \n",
      "Root Mean Squared Error -- train: 0.41177380084991455, -- test: 0.7734981179237366 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.2402859926223755, -- test: -5.187122344970703 \n",
      "Root Mean Squared Error -- train: 0.42100366950035095, -- test: 0.7470127940177917 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.136000156402588, -- test: -5.376748561859131 \n",
      "Root Mean Squared Error -- train: 0.4088799059391022, -- test: 0.7591593265533447 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1772223711013794, -- test: -5.191397666931152 \n",
      "Root Mean Squared Error -- train: 0.4137146472930908, -- test: 0.7472888231277466 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1505831480026245, -- test: -5.546206474304199 \n",
      "Root Mean Squared Error -- train: 0.4105967581272125, -- test: 0.7698518633842468 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.143955111503601, -- test: -5.427966117858887 \n",
      "Root Mean Squared Error -- train: 0.40981733798980713, -- test: 0.7624068856239319 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1443854570388794, -- test: -5.3143134117126465 \n",
      "Root Mean Squared Error -- train: 0.4098680019378662, -- test: 0.755181610584259 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.170009613037109\n",
      "Test Root MSE of all sampled models: 0.7459068298339844\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.983047008514404\n",
      "Test Root MSE of all models in window: 0.7661780714988708\n",
      "\n",
      "############### EM step 252 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1543636322021484 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 253 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.137935996055603, -- test: -5.346722602844238 \n",
      "Root Mean Squared Error -- train: 0.4096360206604004, -- test: 0.7585065364837646 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1475776433944702, -- test: -5.292585372924805 \n",
      "Root Mean Squared Error -- train: 0.41077399253845215, -- test: 0.7550432085990906 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1392306089401245, -- test: -5.4330973625183105 \n",
      "Root Mean Squared Error -- train: 0.40978896617889404, -- test: 0.7639998197555542 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1314750909805298, -- test: -5.295327186584473 \n",
      "Root Mean Squared Error -- train: 0.40887171030044556, -- test: 0.7552189230918884 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1457531452178955, -- test: -5.241591930389404 \n",
      "Root Mean Squared Error -- train: 0.4105588495731354, -- test: 0.7517662048339844 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.183254361152649, -- test: -5.294311046600342 \n",
      "Root Mean Squared Error -- train: 0.41495755314826965, -- test: 0.7551538348197937 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.135287880897522, -- test: -5.34162712097168 \n",
      "Root Mean Squared Error -- train: 0.40932291746139526, -- test: 0.7581812739372253 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1885097026824951, -- test: -5.594073295593262 \n",
      "Root Mean Squared Error -- train: 0.4155702590942383, -- test: 0.774133563041687 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.2043535709381104, -- test: -5.525738716125488 \n",
      "Root Mean Squared Error -- train: 0.4174119830131531, -- test: 0.7698480486869812 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1335643529891968, -- test: -5.293741226196289 \n",
      "Root Mean Squared Error -- train: 0.40911903977394104, -- test: 0.7551172971725464 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.295281887054443\n",
      "Test Root MSE of all sampled models: 0.7552160024642944\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.972877502441406\n",
      "Test Root MSE of all models in window: 0.7658387422561646\n",
      "\n",
      "############### EM step 253 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3184400796890259 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 254 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.146660327911377, -- test: -5.334704399108887 \n",
      "Root Mean Squared Error -- train: 0.4112018644809723, -- test: 0.759009838104248 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1405775547027588, -- test: -5.294865131378174 \n",
      "Root Mean Squared Error -- train: 0.4104824364185333, -- test: 0.7564550042152405 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2442539930343628, -- test: -5.111166000366211 \n",
      "Root Mean Squared Error -- train: 0.4225771725177765, -- test: 0.7445613741874695 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.15031099319458, -- test: -5.454543590545654 \n",
      "Root Mean Squared Error -- train: 0.41163304448127747, -- test: 0.7666435241699219 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1637953519821167, -- test: -5.318731784820557 \n",
      "Root Mean Squared Error -- train: 0.41322171688079834, -- test: 0.7579866647720337 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1261000633239746, -- test: -5.341775417327881 \n",
      "Root Mean Squared Error -- train: 0.4087650179862976, -- test: 0.7594624161720276 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1502219438552856, -- test: -5.351650238037109 \n",
      "Root Mean Squared Error -- train: 0.4116225242614746, -- test: 0.7600939869880676 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1336684226989746, -- test: -5.253556728363037 \n",
      "Root Mean Squared Error -- train: 0.40966370701789856, -- test: 0.7537968754768372 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1551724672317505, -- test: -5.376572132110596 \n",
      "Root Mean Squared Error -- train: 0.4122065007686615, -- test: 0.7616854310035706 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.190827488899231, -- test: -5.199820041656494 \n",
      "Root Mean Squared Error -- train: 0.4163883924484253, -- test: 0.7503249049186707 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.386462211608887\n",
      "Test Root MSE of all sampled models: 0.7623162269592285\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.965131759643555\n",
      "Test Root MSE of all models in window: 0.7659092545509338\n",
      "\n",
      "############### EM step 254 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1148147583007812 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 255 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.122619867324829, -- test: -5.55117654800415 \n",
      "Root Mean Squared Error -- train: 0.40887749195098877, -- test: 0.7740360498428345 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.148875117301941, -- test: -5.3598456382751465 \n",
      "Root Mean Squared Error -- train: 0.4119971990585327, -- test: 0.7618856430053711 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.134353756904602, -- test: -5.409855365753174 \n",
      "Root Mean Squared Error -- train: 0.4102746546268463, -- test: 0.7650801539421082 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.200426697731018, -- test: -5.154638767242432 \n",
      "Root Mean Squared Error -- train: 0.4180549085140228, -- test: 0.7486350536346436 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1244739294052124, -- test: -5.347623348236084 \n",
      "Root Mean Squared Error -- train: 0.4090985953807831, -- test: 0.7611029744148254 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.120732069015503, -- test: -5.281271457672119 \n",
      "Root Mean Squared Error -- train: 0.40865224599838257, -- test: 0.7568393349647522 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1253846883773804, -- test: -5.316362380981445 \n",
      "Root Mean Squared Error -- train: 0.40920713543891907, -- test: 0.759097158908844 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1266640424728394, -- test: -5.373449802398682 \n",
      "Root Mean Squared Error -- train: 0.40935957431793213, -- test: 0.7627559900283813 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1332379579544067, -- test: -5.117284774780273 \n",
      "Root Mean Squared Error -- train: 0.4101420044898987, -- test: 0.7461976408958435 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1350340843200684, -- test: -5.390948295593262 \n",
      "Root Mean Squared Error -- train: 0.4103555381298065, -- test: 0.7638739347457886 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.2347517013549805\n",
      "Test Root MSE of all sampled models: 0.7538357973098755\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.951328754425049\n",
      "Test Root MSE of all models in window: 0.7655577659606934\n",
      "\n",
      "############### EM step 255 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.7989699840545654 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 256 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1778793334960938, -- test: -5.414850234985352 \n",
      "Root Mean Squared Error -- train: 0.4159422516822815, -- test: 0.7666373252868652 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1185822486877441, -- test: -5.461855411529541 \n",
      "Root Mean Squared Error -- train: 0.40890565514564514, -- test: 0.7696322202682495 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1318182945251465, -- test: -5.306624889373779 \n",
      "Root Mean Squared Error -- train: 0.4104868173599243, -- test: 0.759696900844574 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1176260709762573, -- test: -5.273298740386963 \n",
      "Root Mean Squared Error -- train: 0.408791184425354, -- test: 0.7575470209121704 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1350245475769043, -- test: -5.345544338226318 \n",
      "Root Mean Squared Error -- train: 0.41086888313293457, -- test: 0.762200117111206 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1340723037719727, -- test: -5.275529384613037 \n",
      "Root Mean Squared Error -- train: 0.410755455493927, -- test: 0.7576910853385925 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1537367105484009, -- test: -5.190112113952637 \n",
      "Root Mean Squared Error -- train: 0.4130918085575104, -- test: 0.7521534562110901 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1194102764129639, -- test: -5.337923049926758 \n",
      "Root Mean Squared Error -- train: 0.40900474786758423, -- test: 0.761710524559021 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.129982590675354, -- test: -5.364625453948975 \n",
      "Root Mean Squared Error -- train: 0.4102678596973419, -- test: 0.763424277305603 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.136371374130249, -- test: -5.230167865753174 \n",
      "Root Mean Squared Error -- train: 0.41102927923202515, -- test: 0.7547553181648254 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.4104180335998535\n",
      "Test Root MSE of all sampled models: 0.7663543224334717\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.933441638946533\n",
      "Test Root MSE of all models in window: 0.7652298808097839\n",
      "\n",
      "############### EM step 256 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.40394127368927 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 257 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.166489601135254, -- test: -5.225246429443359 \n",
      "Root Mean Squared Error -- train: 0.4151338040828705, -- test: 0.7556780576705933 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1454030275344849, -- test: -5.329315662384033 \n",
      "Root Mean Squared Error -- train: 0.4126313626766205, -- test: 0.7624122500419617 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1597148180007935, -- test: -5.384912490844727 \n",
      "Root Mean Squared Error -- train: 0.41433149576187134, -- test: 0.7659857273101807 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.129045844078064, -- test: -5.348292350769043 \n",
      "Root Mean Squared Error -- train: 0.4106796979904175, -- test: 0.7636339068412781 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1330410242080688, -- test: -5.320150852203369 \n",
      "Root Mean Squared Error -- train: 0.4111572206020355, -- test: 0.7618216276168823 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.115987777709961, -- test: -5.320807456970215 \n",
      "Root Mean Squared Error -- train: 0.4091149568557739, -- test: 0.7618640065193176 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1942298412322998, -- test: -5.204936981201172 \n",
      "Root Mean Squared Error -- train: 0.41840311884880066, -- test: 0.7543568015098572 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.20151948928833, -- test: -5.195734977722168 \n",
      "Root Mean Squared Error -- train: 0.4192579984664917, -- test: 0.7537573575973511 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1228667497634888, -- test: -5.284918785095215 \n",
      "Root Mean Squared Error -- train: 0.4099399745464325, -- test: 0.75954669713974 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.120253324508667, -- test: -5.360419750213623 \n",
      "Root Mean Squared Error -- train: 0.4096267521381378, -- test: 0.7644135355949402 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.295034885406494\n",
      "Test Root MSE of all sampled models: 0.7602006196975708\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.924471855163574\n",
      "Test Root MSE of all models in window: 0.765418529510498\n",
      "\n",
      "############### EM step 257 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.5298802852630615 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 258 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.115025520324707, -- test: -5.3830790519714355 \n",
      "Root Mean Squared Error -- train: 0.4095337688922882, -- test: 0.7671666145324707 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1093515157699585, -- test: -5.417566299438477 \n",
      "Root Mean Squared Error -- train: 0.40885016322135925, -- test: 0.7693796157836914 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.145364761352539, -- test: -5.18153190612793 \n",
      "Root Mean Squared Error -- train: 0.41316986083984375, -- test: 0.7541036009788513 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1340842247009277, -- test: -5.163028717041016 \n",
      "Root Mean Squared Error -- train: 0.4118216931819916, -- test: 0.7528929114341736 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1145719289779663, -- test: -5.288236618041992 \n",
      "Root Mean Squared Error -- train: 0.40947917103767395, -- test: 0.7610474228858948 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1123820543289185, -- test: -5.427301406860352 \n",
      "Root Mean Squared Error -- train: 0.40921542048454285, -- test: 0.7700031399726868 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1110223531723022, -- test: -5.317601203918457 \n",
      "Root Mean Squared Error -- train: 0.4090515673160553, -- test: 0.7629472613334656 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1172107458114624, -- test: -5.290339469909668 \n",
      "Root Mean Squared Error -- train: 0.40979671478271484, -- test: 0.7611836194992065 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1238720417022705, -- test: -5.177647590637207 \n",
      "Root Mean Squared Error -- train: 0.4105973243713379, -- test: 0.7538496255874634 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1627038717269897, -- test: -5.43891716003418 \n",
      "Root Mean Squared Error -- train: 0.4152336120605469, -- test: 0.7707465291023254 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.1783127784729\n",
      "Test Root MSE of all sampled models: 0.7538930773735046\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.9143757820129395\n",
      "Test Root MSE of all models in window: 0.7656254768371582\n",
      "\n",
      "############### EM step 258 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.7402740120887756 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 259 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1299573183059692, -- test: -5.430713653564453 \n",
      "Root Mean Squared Error -- train: 0.4118473529815674, -- test: 0.7714820504188538 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1369941234588623, -- test: -5.131499767303467 \n",
      "Root Mean Squared Error -- train: 0.4126918315887451, -- test: 0.7520484328269958 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2473279237747192, -- test: -4.972006797790527 \n",
      "Root Mean Squared Error -- train: 0.42571380734443665, -- test: 0.7414815425872803 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1435970067977905, -- test: -5.120767593383789 \n",
      "Root Mean Squared Error -- train: 0.413482666015625, -- test: 0.7513421177864075 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1669172048568726, -- test: -5.127681732177734 \n",
      "Root Mean Squared Error -- train: 0.41626372933387756, -- test: 0.7517972588539124 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.109122395515442, -- test: -5.224760055541992 \n",
      "Root Mean Squared Error -- train: 0.40933674573898315, -- test: 0.7581590414047241 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.2042787075042725, -- test: -5.101990222930908 \n",
      "Root Mean Squared Error -- train: 0.4206809401512146, -- test: 0.750104546546936 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1332087516784668, -- test: -5.385934829711914 \n",
      "Root Mean Squared Error -- train: 0.4122377634048462, -- test: 0.7686050534248352 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1533507108688354, -- test: -5.330422878265381 \n",
      "Root Mean Squared Error -- train: 0.4146481156349182, -- test: 0.7650232911109924 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1056734323501587, -- test: -5.291489124298096 \n",
      "Root Mean Squared Error -- train: 0.40891966223716736, -- test: 0.7625012397766113 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.800077438354492\n",
      "Test Root MSE of all sampled models: 0.794816792011261\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.910616397857666\n",
      "Test Root MSE of all models in window: 0.7657215595245361\n",
      "\n",
      "############### EM step 259 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.820351243019104 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 260 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.143038034439087, -- test: -5.217418193817139 \n",
      "Root Mean Squared Error -- train: 0.41392573714256287, -- test: 0.7588823437690735 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1049244403839111, -- test: -5.294841766357422 \n",
      "Root Mean Squared Error -- train: 0.40932872891426086, -- test: 0.7639307379722595 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.2192801237106323, -- test: -5.247528553009033 \n",
      "Root Mean Squared Error -- train: 0.4229716360569, -- test: 0.76084965467453 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1476446390151978, -- test: -5.171118259429932 \n",
      "Root Mean Squared Error -- train: 0.4144779145717621, -- test: 0.7558472156524658 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.106343150138855, -- test: -5.191776275634766 \n",
      "Root Mean Squared Error -- train: 0.40950077772140503, -- test: 0.7572028636932373 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1308971643447876, -- test: -5.207791328430176 \n",
      "Root Mean Squared Error -- train: 0.41246697306632996, -- test: 0.7582522630691528 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1136316061019897, -- test: -5.2015767097473145 \n",
      "Root Mean Squared Error -- train: 0.4103834331035614, -- test: 0.7578452229499817 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1784638166427612, -- test: -5.192580699920654 \n",
      "Root Mean Squared Error -- train: 0.4181532561779022, -- test: 0.7572556138038635 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1289324760437012, -- test: -5.184781074523926 \n",
      "Root Mean Squared Error -- train: 0.41223040223121643, -- test: 0.7567440867424011 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.137039065361023, -- test: -5.209487438201904 \n",
      "Root Mean Squared Error -- train: 0.4132055640220642, -- test: 0.7583633065223694 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.030972003936768\n",
      "Test Root MSE of all sampled models: 0.746584951877594\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.8894147872924805\n",
      "Test Root MSE of all models in window: 0.7650694251060486\n",
      "\n",
      "############### EM step 260 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.445328950881958 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 261 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1188122034072876, -- test: -5.104065418243408 \n",
      "Root Mean Squared Error -- train: 0.4115264415740967, -- test: 0.7526507377624512 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1033028364181519, -- test: -5.18310546875 \n",
      "Root Mean Squared Error -- train: 0.40964436531066895, -- test: 0.7578650116920471 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1048564910888672, -- test: -5.054789066314697 \n",
      "Root Mean Squared Error -- train: 0.40983331203460693, -- test: 0.7493816018104553 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.176546573638916, -- test: -5.237806797027588 \n",
      "Root Mean Squared Error -- train: 0.41845816373825073, -- test: 0.7614527344703674 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1099587678909302, -- test: -5.155947208404541 \n",
      "Root Mean Squared Error -- train: 0.4104531705379486, -- test: 0.7560774087905884 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.098800539970398, -- test: -5.1849589347839355 \n",
      "Root Mean Squared Error -- train: 0.4090964198112488, -- test: 0.7579869031906128 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1103686094284058, -- test: -5.211956024169922 \n",
      "Root Mean Squared Error -- train: 0.4105028808116913, -- test: 0.7597594261169434 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.103024959564209, -- test: -5.2027130126953125 \n",
      "Root Mean Squared Error -- train: 0.4096105694770813, -- test: 0.7591530084609985 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.1029473543167114, -- test: -5.248612880706787 \n",
      "Root Mean Squared Error -- train: 0.4096011817455292, -- test: 0.762159526348114 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0985366106033325, -- test: -5.137300968170166 \n",
      "Root Mean Squared Error -- train: 0.40906429290771484, -- test: 0.7548477053642273 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.055744171142578\n",
      "Test Root MSE of all sampled models: 0.7494450807571411\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.881197929382324\n",
      "Test Root MSE of all models in window: 0.7652216553688049\n",
      "\n",
      "############### EM step 261 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.7439911365509033 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 262 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1841357946395874, -- test: -5.203958511352539 \n",
      "Root Mean Squared Error -- train: 0.41987845301628113, -- test: 0.7604297399520874 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.098832368850708, -- test: -5.157735824584961 \n",
      "Root Mean Squared Error -- train: 0.4095951020717621, -- test: 0.7573845386505127 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0927573442459106, -- test: -5.2305402755737305 \n",
      "Root Mean Squared Error -- train: 0.40885287523269653, -- test: 0.7621753811836243 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1751883029937744, -- test: -5.2719340324401855 \n",
      "Root Mean Squared Error -- train: 0.4188116490840912, -- test: 0.7648859024047852 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0939083099365234, -- test: -5.175657749176025 \n",
      "Root Mean Squared Error -- train: 0.40899357199668884, -- test: 0.7585667371749878 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1592590808868408, -- test: -5.056245803833008 \n",
      "Root Mean Squared Error -- train: 0.4169057607650757, -- test: 0.7506550550460815 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.094068169593811, -- test: -5.235604286193848 \n",
      "Root Mean Squared Error -- train: 0.40901312232017517, -- test: 0.7625074982643127 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1123108863830566, -- test: -5.210526943206787 \n",
      "Root Mean Squared Error -- train: 0.41123703122138977, -- test: 0.7608614563941956 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.095009684562683, -- test: -5.070303440093994 \n",
      "Root Mean Squared Error -- train: 0.40912818908691406, -- test: 0.7515907883644104 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0984264612197876, -- test: -5.1473612785339355 \n",
      "Root Mean Squared Error -- train: 0.40954554080963135, -- test: 0.7566994428634644 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.895362377166748\n",
      "Test Root MSE of all sampled models: 0.7398620247840881\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.864664077758789\n",
      "Test Root MSE of all models in window: 0.7651436924934387\n",
      "\n",
      "############### EM step 262 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.5547220706939697 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 263 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.093613862991333, -- test: -5.419558048248291 \n",
      "Root Mean Squared Error -- train: 0.40946900844573975, -- test: 0.7757420539855957 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1549261808395386, -- test: -5.075523853302002 \n",
      "Root Mean Squared Error -- train: 0.4169144034385681, -- test: 0.7531611323356628 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.098734736442566, -- test: -5.106054782867432 \n",
      "Root Mean Squared Error -- train: 0.41009601950645447, -- test: 0.7551923990249634 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0927766561508179, -- test: -5.272384166717529 \n",
      "Root Mean Squared Error -- train: 0.4093663990497589, -- test: 0.7661636471748352 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.094355821609497, -- test: -5.260880947113037 \n",
      "Root Mean Squared Error -- train: 0.4095599055290222, -- test: 0.7654098868370056 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.122084379196167, -- test: -5.272477626800537 \n",
      "Root Mean Squared Error -- train: 0.4129429757595062, -- test: 0.7661697268486023 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0983643531799316, -- test: -5.162741661071777 \n",
      "Root Mean Squared Error -- train: 0.41005071997642517, -- test: 0.7589492797851562 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0906503200531006, -- test: -5.1328206062316895 \n",
      "Root Mean Squared Error -- train: 0.40910571813583374, -- test: 0.7569685578346252 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0902515649795532, -- test: -5.215467929840088 \n",
      "Root Mean Squared Error -- train: 0.40905678272247314, -- test: 0.7624272108078003 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0931607484817505, -- test: -5.090083122253418 \n",
      "Root Mean Squared Error -- train: 0.40941348671913147, -- test: 0.7541305422782898 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.626455307006836\n",
      "Test Root MSE of all sampled models: 0.789010763168335\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.86059045791626\n",
      "Test Root MSE of all models in window: 0.7651773691177368\n",
      "\n",
      "############### EM step 263 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2089115381240845 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 264 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1413494348526, -- test: -5.349363327026367 \n",
      "Root Mean Squared Error -- train: 0.4158044159412384, -- test: 0.7724533081054688 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1006578207015991, -- test: -5.137124061584473 \n",
      "Root Mean Squared Error -- train: 0.410847008228302, -- test: 0.758491575717926 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.127076506614685, -- test: -4.995187759399414 \n",
      "Root Mean Squared Error -- train: 0.41407233476638794, -- test: 0.7490093111991882 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1531713008880615, -- test: -5.2645158767700195 \n",
      "Root Mean Squared Error -- train: 0.4172336459159851, -- test: 0.7669022679328918 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0868030786514282, -- test: -5.2522687911987305 \n",
      "Root Mean Squared Error -- train: 0.4091453552246094, -- test: 0.7660976052284241 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0939760208129883, -- test: -4.946976184844971 \n",
      "Root Mean Squared Error -- train: 0.41002723574638367, -- test: 0.7457610964775085 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.093301773071289, -- test: -5.1233415603637695 \n",
      "Root Mean Squared Error -- train: 0.40994441509246826, -- test: 0.7575759887695312 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1075122356414795, -- test: -5.02804708480835 \n",
      "Root Mean Squared Error -- train: 0.4116862714290619, -- test: 0.7512151002883911 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.085193157196045, -- test: -5.1436333656311035 \n",
      "Root Mean Squared Error -- train: 0.4089471697807312, -- test: 0.7589234709739685 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1288155317306519, -- test: -5.105711936950684 \n",
      "Root Mean Squared Error -- train: 0.41428378224372864, -- test: 0.7564032077789307 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.628339767456055\n",
      "Test Root MSE of all sampled models: 0.7239264845848083\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.842292785644531\n",
      "Test Root MSE of all models in window: 0.764866828918457\n",
      "\n",
      "############### EM step 264 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.0075839757919312 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 265 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.10245680809021, -- test: -4.96237850189209 \n",
      "Root Mean Squared Error -- train: 0.4115777313709259, -- test: 0.7480021715164185 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.083221197128296, -- test: -5.042764186859131 \n",
      "Root Mean Squared Error -- train: 0.40920916199684143, -- test: 0.7534133195877075 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0831124782562256, -- test: -5.083785533905029 \n",
      "Root Mean Squared Error -- train: 0.40919575095176697, -- test: 0.7561597228050232 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1212153434753418, -- test: -5.15882682800293 \n",
      "Root Mean Squared Error -- train: 0.4138745367527008, -- test: 0.7611581087112427 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0951132774353027, -- test: -5.066976547241211 \n",
      "Root Mean Squared Error -- train: 0.4106751084327698, -- test: 0.7550355792045593 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0822113752365112, -- test: -5.0152058601379395 \n",
      "Root Mean Squared Error -- train: 0.4090844690799713, -- test: 0.7515625953674316 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0855811834335327, -- test: -4.978671073913574 \n",
      "Root Mean Squared Error -- train: 0.40950050950050354, -- test: 0.7491021156311035 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.145593285560608, -- test: -5.121494293212891 \n",
      "Root Mean Squared Error -- train: 0.41684040427207947, -- test: 0.7586755752563477 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0815447568893433, -- test: -5.1169657707214355 \n",
      "Root Mean Squared Error -- train: 0.4090021252632141, -- test: 0.7583738565444946 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.091676115989685, -- test: -4.9591145515441895 \n",
      "Root Mean Squared Error -- train: 0.4102519750595093, -- test: 0.7477816343307495 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.790276527404785\n",
      "Test Root MSE of all sampled models: 0.8019853830337524\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.832868576049805\n",
      "Test Root MSE of all models in window: 0.7649344205856323\n",
      "\n",
      "############### EM step 265 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3124645948410034 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 266 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.079351544380188, -- test: -5.308395862579346 \n",
      "Root Mean Squared Error -- train: 0.40924182534217834, -- test: 0.7722886204719543 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0756464004516602, -- test: -5.17811393737793 \n",
      "Root Mean Squared Error -- train: 0.408782422542572, -- test: 0.763685405254364 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1509945392608643, -- test: -5.176019191741943 \n",
      "Root Mean Squared Error -- train: 0.4180258512496948, -- test: 0.7635462284088135 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1495131254196167, -- test: -5.109143257141113 \n",
      "Root Mean Squared Error -- train: 0.41784605383872986, -- test: 0.759091317653656 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0835902690887451, -- test: -4.968880653381348 \n",
      "Root Mean Squared Error -- train: 0.4097667634487152, -- test: 0.7496618032455444 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0805860757827759, -- test: -5.033157825469971 \n",
      "Root Mean Squared Error -- train: 0.4093948006629944, -- test: 0.7539976239204407 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0855674743652344, -- test: -5.185389995574951 \n",
      "Root Mean Squared Error -- train: 0.4100114405155182, -- test: 0.7641684412956238 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1035761833190918, -- test: -5.121638298034668 \n",
      "Root Mean Squared Error -- train: 0.4122329354286194, -- test: 0.7599256634712219 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0774997472763062, -- test: -5.164215564727783 \n",
      "Root Mean Squared Error -- train: 0.4090122878551483, -- test: 0.7627618312835693 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1357319355010986, -- test: -5.078304290771484 \n",
      "Root Mean Squared Error -- train: 0.4161700904369354, -- test: 0.7570281624794006 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.553383827209473\n",
      "Test Root MSE of all sampled models: 0.7882124185562134\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.815780162811279\n",
      "Test Root MSE of all models in window: 0.7656129598617554\n",
      "\n",
      "############### EM step 266 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.9292409420013428 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 267 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.097414493560791, -- test: -4.978071689605713 \n",
      "Root Mean Squared Error -- train: 0.4119809567928314, -- test: 0.7514841556549072 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.08170485496521, -- test: -4.949420928955078 \n",
      "Root Mean Squared Error -- train: 0.4100356698036194, -- test: 0.7495413422584534 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0783305168151855, -- test: -5.110058307647705 \n",
      "Root Mean Squared Error -- train: 0.4096166789531708, -- test: 0.7603702545166016 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0810693502426147, -- test: -5.0378313064575195 \n",
      "Root Mean Squared Error -- train: 0.40995681285858154, -- test: 0.7555204629898071 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0736855268478394, -- test: -5.086940765380859 \n",
      "Root Mean Squared Error -- train: 0.40903913974761963, -- test: 0.758821427822113 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.074295997619629, -- test: -4.984048366546631 \n",
      "Root Mean Squared Error -- train: 0.4091150462627411, -- test: 0.7518887519836426 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1605077981948853, -- test: -5.167380332946777 \n",
      "Root Mean Squared Error -- train: 0.4197027087211609, -- test: 0.7641973495483398 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.077322244644165, -- test: -5.140252590179443 \n",
      "Root Mean Squared Error -- train: 0.4094913601875305, -- test: 0.7623885869979858 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0752679109573364, -- test: -5.060574531555176 \n",
      "Root Mean Squared Error -- train: 0.40923598408699036, -- test: 0.7570509314537048 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0796942710876465, -- test: -5.08920955657959 \n",
      "Root Mean Squared Error -- train: 0.40978607535362244, -- test: 0.7589735388755798 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.524423122406006\n",
      "Test Root MSE of all sampled models: 0.7201061844825745\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.727966785430908\n",
      "Test Root MSE of all models in window: 0.7650601267814636\n",
      "\n",
      "############### EM step 267 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1580406427383423 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 268 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.1204811334609985, -- test: -4.809205532073975 \n",
      "Root Mean Squared Error -- train: 0.4153349995613098, -- test: 0.741141676902771 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0807790756225586, -- test: -4.779826641082764 \n",
      "Root Mean Squared Error -- train: 0.4104239046573639, -- test: 0.7391144037246704 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0736212730407715, -- test: -4.925504207611084 \n",
      "Root Mean Squared Error -- train: 0.40953218936920166, -- test: 0.749113142490387 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1279488801956177, -- test: -4.750289440155029 \n",
      "Root Mean Squared Error -- train: 0.4162522852420807, -- test: 0.7370705604553223 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.1043033599853516, -- test: -5.015650749206543 \n",
      "Root Mean Squared Error -- train: 0.41334086656570435, -- test: 0.7552340626716614 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.07254958152771, -- test: -4.88453483581543 \n",
      "Root Mean Squared Error -- train: 0.40939852595329285, -- test: 0.7463146448135376 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0754072666168213, -- test: -4.988480567932129 \n",
      "Root Mean Squared Error -- train: 0.4097549021244049, -- test: 0.7533944845199585 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0814861059188843, -- test: -5.203853607177734 \n",
      "Root Mean Squared Error -- train: 0.41051185131073, -- test: 0.7678559422492981 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0898444652557373, -- test: -4.85898494720459 \n",
      "Root Mean Squared Error -- train: 0.4115504324436188, -- test: 0.7445641756057739 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.069450855255127, -- test: -5.065687656402588 \n",
      "Root Mean Squared Error -- train: 0.4090117812156677, -- test: 0.7586103081703186 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.326681137084961\n",
      "Test Root MSE of all sampled models: 0.7759825587272644\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.723388195037842\n",
      "Test Root MSE of all models in window: 0.7650748491287231\n",
      "\n",
      "############### EM step 268 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2137603759765625 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 269 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0732097625732422, -- test: -5.192869663238525 \n",
      "Root Mean Squared Error -- train: 0.40998515486717224, -- test: 0.7683661580085754 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0730828046798706, -- test: -5.088967800140381 \n",
      "Root Mean Squared Error -- train: 0.4099693298339844, -- test: 0.7614037394523621 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.213456630706787, -- test: -5.181802749633789 \n",
      "Root Mean Squared Error -- train: 0.427158385515213, -- test: 0.7676275968551636 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0731761455535889, -- test: -5.055292129516602 \n",
      "Root Mean Squared Error -- train: 0.40998098254203796, -- test: 0.759133517742157 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0649044513702393, -- test: -4.998383045196533 \n",
      "Root Mean Squared Error -- train: 0.40894556045532227, -- test: 0.7552814483642578 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.066306233406067, -- test: -5.053096294403076 \n",
      "Root Mean Squared Error -- train: 0.40912121534347534, -- test: 0.7589852809906006 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0830868482589722, -- test: -4.9888997077941895 \n",
      "Root Mean Squared Error -- train: 0.4112181067466736, -- test: 0.754637598991394 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.3774433135986328, -- test: -4.707869052886963 \n",
      "Root Mean Squared Error -- train: 0.4464014768600464, -- test: 0.7353026270866394 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0807842016220093, -- test: -4.9639716148376465 \n",
      "Root Mean Squared Error -- train: 0.4109310209751129, -- test: 0.7529425621032715 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.08670973777771, -- test: -5.007457256317139 \n",
      "Root Mean Squared Error -- train: 0.41166940331459045, -- test: 0.7558969259262085 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.914264678955078\n",
      "Test Root MSE of all sampled models: 0.7495512962341309\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.7074408531188965\n",
      "Test Root MSE of all models in window: 0.765010416507721\n",
      "\n",
      "############### EM step 269 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.9361370205879211 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 270 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0811336040496826, -- test: -4.9774651527404785 \n",
      "Root Mean Squared Error -- train: 0.4114728569984436, -- test: 0.7550548911094666 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.1186888217926025, -- test: -4.8990983963012695 \n",
      "Root Mean Squared Error -- train: 0.41614067554473877, -- test: 0.749697744846344 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.061881422996521, -- test: -4.967820644378662 \n",
      "Root Mean Squared Error -- train: 0.4090593159198761, -- test: 0.7543976902961731 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0631176233291626, -- test: -5.102546215057373 \n",
      "Root Mean Squared Error -- train: 0.40921470522880554, -- test: 0.7635276913642883 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0753976106643677, -- test: -5.136271953582764 \n",
      "Root Mean Squared Error -- train: 0.4107552170753479, -- test: 0.7657960653305054 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.065584659576416, -- test: -5.11367654800415 \n",
      "Root Mean Squared Error -- train: 0.40952467918395996, -- test: 0.7642770409584045 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0617858171463013, -- test: -5.084247589111328 \n",
      "Root Mean Squared Error -- train: 0.40904727578163147, -- test: 0.7622939348220825 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0777658224105835, -- test: -4.975816249847412 \n",
      "Root Mean Squared Error -- train: 0.4110516607761383, -- test: 0.7549425363540649 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0640946626663208, -- test: -5.006358623504639 \n",
      "Root Mean Squared Error -- train: 0.40933749079704285, -- test: 0.7570204734802246 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0650779008865356, -- test: -4.883824348449707 \n",
      "Root Mean Squared Error -- train: 0.40946102142333984, -- test: 0.7486490607261658 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.093682289123535\n",
      "Test Root MSE of all sampled models: 0.7629303336143494\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.693231105804443\n",
      "Test Root MSE of all models in window: 0.7648362517356873\n",
      "\n",
      "############### EM step 270 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.303491473197937 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 271 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0661180019378662, -- test: -5.074788570404053 \n",
      "Root Mean Squared Error -- train: 0.41009321808815, -- test: 0.7628817558288574 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0723389387130737, -- test: -5.113137722015381 \n",
      "Root Mean Squared Error -- train: 0.41087543964385986, -- test: 0.765471875667572 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.059066891670227, -- test: -5.059398651123047 \n",
      "Root Mean Squared Error -- train: 0.40920478105545044, -- test: 0.7618396878242493 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.2295889854431152, -- test: -4.821483612060547 \n",
      "Root Mean Squared Error -- train: 0.4301760196685791, -- test: 0.745546817779541 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0965180397033691, -- test: -5.137371063232422 \n",
      "Root Mean Squared Error -- train: 0.413901686668396, -- test: 0.7671042084693909 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.1455386877059937, -- test: -4.93983793258667 \n",
      "Root Mean Squared Error -- train: 0.41997018456459045, -- test: 0.7536960244178772 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0609142780303955, -- test: -4.992917060852051 \n",
      "Root Mean Squared Error -- train: 0.40943771600723267, -- test: 0.7573222517967224 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.1245309114456177, -- test: -4.976411819458008 \n",
      "Root Mean Squared Error -- train: 0.41738033294677734, -- test: 0.7561965584754944 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.058563232421875, -- test: -5.008355617523193 \n",
      "Root Mean Squared Error -- train: 0.4091412425041199, -- test: 0.7583736777305603 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0563398599624634, -- test: -5.077316761016846 \n",
      "Root Mean Squared Error -- train: 0.4088606536388397, -- test: 0.7630528211593628 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.990684986114502\n",
      "Test Root MSE of all sampled models: 0.7571700811386108\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.684300899505615\n",
      "Test Root MSE of all models in window: 0.7643182277679443\n",
      "\n",
      "############### EM step 271 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.350594162940979 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 272 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0752193927764893, -- test: -5.407352447509766 \n",
      "Root Mean Squared Error -- train: 0.41175007820129395, -- test: 0.7863516807556152 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.073300838470459, -- test: -5.253044605255127 \n",
      "Root Mean Squared Error -- train: 0.4115086495876312, -- test: 0.7761202454566956 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0699777603149414, -- test: -5.141383171081543 \n",
      "Root Mean Squared Error -- train: 0.41109010577201843, -- test: 0.7686315774917603 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.084744930267334, -- test: -5.070855140686035 \n",
      "Root Mean Squared Error -- train: 0.4129467010498047, -- test: 0.7638636827468872 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0707398653030396, -- test: -4.889349460601807 \n",
      "Root Mean Squared Error -- train: 0.4111861288547516, -- test: 0.7514544129371643 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.092073678970337, -- test: -4.988860607147217 \n",
      "Root Mean Squared Error -- train: 0.41386500000953674, -- test: 0.7582829594612122 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0850496292114258, -- test: -4.952559947967529 \n",
      "Root Mean Squared Error -- train: 0.4129849076271057, -- test: 0.7557991743087769 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.055977702140808, -- test: -4.9137983322143555 \n",
      "Root Mean Squared Error -- train: 0.40932220220565796, -- test: 0.7531378269195557 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0629338026046753, -- test: -4.923467636108398 \n",
      "Root Mean Squared Error -- train: 0.4102015793323517, -- test: 0.7538026571273804 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0621241331100464, -- test: -4.945396900177002 \n",
      "Root Mean Squared Error -- train: 0.4100992977619171, -- test: 0.7553080320358276 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.376321315765381\n",
      "Test Root MSE of all sampled models: 0.7843049168586731\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.681108474731445\n",
      "Test Root MSE of all models in window: 0.7644268274307251\n",
      "\n",
      "############### EM step 272 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.6995049118995667 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 273 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.072046160697937, -- test: -5.012110233306885 \n",
      "Root Mean Squared Error -- train: 0.41184407472610474, -- test: 0.7610657811164856 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0877337455749512, -- test: -5.012691497802734 \n",
      "Root Mean Squared Error -- train: 0.4138193130493164, -- test: 0.7611055374145508 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1327177286148071, -- test: -4.827737808227539 \n",
      "Root Mean Squared Error -- train: 0.4194316267967224, -- test: 0.7483675479888916 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0578029155731201, -- test: -5.074296951293945 \n",
      "Root Mean Squared Error -- train: 0.41004249453544617, -- test: 0.7653012871742249 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.082159161567688, -- test: -4.864374160766602 \n",
      "Root Mean Squared Error -- train: 0.41311851143836975, -- test: 0.750907838344574 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.049338698387146, -- test: -4.9580159187316895 \n",
      "Root Mean Squared Error -- train: 0.40896809101104736, -- test: 0.7573623061180115 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1005703210830688, -- test: -4.8593668937683105 \n",
      "Root Mean Squared Error -- train: 0.41542860865592957, -- test: 0.7505611777305603 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0782227516174316, -- test: -4.958160400390625 \n",
      "Root Mean Squared Error -- train: 0.4126228988170624, -- test: 0.7573722004890442 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.04975426197052, -- test: -5.0727434158325195 \n",
      "Root Mean Squared Error -- train: 0.40902090072631836, -- test: 0.7651957273483276 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.065752387046814, -- test: -4.981210231781006 \n",
      "Root Mean Squared Error -- train: 0.4110489785671234, -- test: 0.7589524388313293 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.1348958015441895\n",
      "Test Root MSE of all sampled models: 0.7694061994552612\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.670990467071533\n",
      "Test Root MSE of all models in window: 0.7646768689155579\n",
      "\n",
      "############### EM step 273 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2401002645492554 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 274 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0852662324905396, -- test: -5.0983171463012695 \n",
      "Root Mean Squared Error -- train: 0.4140118360519409, -- test: 0.7681524157524109 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0471805334091187, -- test: -5.0926618576049805 \n",
      "Root Mean Squared Error -- train: 0.4091852605342865, -- test: 0.7677682638168335 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0440647602081299, -- test: -5.019637584686279 \n",
      "Root Mean Squared Error -- train: 0.40878790616989136, -- test: 0.7627909183502197 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0612174272537231, -- test: -4.971764087677002 \n",
      "Root Mean Squared Error -- train: 0.4109707474708557, -- test: 0.7595102190971375 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.044620394706726, -- test: -4.981683731079102 \n",
      "Root Mean Squared Error -- train: 0.4088588058948517, -- test: 0.7601912021636963 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.052929162979126, -- test: -4.933708667755127 \n",
      "Root Mean Squared Error -- train: 0.4099174439907074, -- test: 0.7568920850753784 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0453588962554932, -- test: -4.9678192138671875 \n",
      "Root Mean Squared Error -- train: 0.4089529812335968, -- test: 0.7592392563819885 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0674283504486084, -- test: -4.951457500457764 \n",
      "Root Mean Squared Error -- train: 0.41175830364227295, -- test: 0.7581143379211426 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0865100622177124, -- test: -5.048284530639648 \n",
      "Root Mean Squared Error -- train: 0.41416850686073303, -- test: 0.7647473812103271 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0483044385910034, -- test: -4.961921691894531 \n",
      "Root Mean Squared Error -- train: 0.40932852029800415, -- test: 0.7588340044021606 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.460488319396973\n",
      "Test Root MSE of all sampled models: 0.7923640012741089\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.663483619689941\n",
      "Test Root MSE of all models in window: 0.7649913430213928\n",
      "\n",
      "############### EM step 274 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1458278894424438 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 275 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0431114435195923, -- test: -5.115563869476318 \n",
      "Root Mean Squared Error -- train: 0.4091576337814331, -- test: 0.7705498337745667 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0452274084091187, -- test: -4.954555034637451 \n",
      "Root Mean Squared Error -- train: 0.4094282388687134, -- test: 0.7595336437225342 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0443716049194336, -- test: -5.121847152709961 \n",
      "Root Mean Squared Error -- train: 0.40931880474090576, -- test: 0.7709764242172241 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0416830778121948, -- test: -4.977315425872803 \n",
      "Root Mean Squared Error -- train: 0.40897485613822937, -- test: 0.7611005306243896 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0446257591247559, -- test: -4.986322402954102 \n",
      "Root Mean Squared Error -- train: 0.40935131907463074, -- test: 0.7617197632789612 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.06206476688385, -- test: -5.047933578491211 \n",
      "Root Mean Squared Error -- train: 0.41157519817352295, -- test: 0.7659417986869812 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0496087074279785, -- test: -4.823551654815674 \n",
      "Root Mean Squared Error -- train: 0.4099879860877991, -- test: 0.7504510879516602 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0591269731521606, -- test: -4.961078643798828 \n",
      "Root Mean Squared Error -- train: 0.4112014174461365, -- test: 0.7599830627441406 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0433224439620972, -- test: -5.0456061363220215 \n",
      "Root Mean Squared Error -- train: 0.40918460488319397, -- test: 0.7657827734947205 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0430610179901123, -- test: -4.966126918792725 \n",
      "Root Mean Squared Error -- train: 0.40915119647979736, -- test: 0.7603306770324707 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.226771354675293\n",
      "Test Root MSE of all sampled models: 0.7780675292015076\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.6559953689575195\n",
      "Test Root MSE of all models in window: 0.7647865414619446\n",
      "\n",
      "############### EM step 275 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2569857835769653 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 276 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0661436319351196, -- test: -4.8037590980529785 \n",
      "Root Mean Squared Error -- train: 0.41259726881980896, -- test: 0.7502697110176086 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.060954213142395, -- test: -4.927096843719482 \n",
      "Root Mean Squared Error -- train: 0.41193607449531555, -- test: 0.758855938911438 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1343563795089722, -- test: -4.80292272567749 \n",
      "Root Mean Squared Error -- train: 0.4211921691894531, -- test: 0.7502111792564392 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1266040802001953, -- test: -4.689247131347656 \n",
      "Root Mean Squared Error -- train: 0.42022421956062317, -- test: 0.7422090172767639 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0964890718460083, -- test: -4.986861705780029 \n",
      "Root Mean Squared Error -- train: 0.41644275188446045, -- test: 0.7629817724227905 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0434023141860962, -- test: -4.968557834625244 \n",
      "Root Mean Squared Error -- train: 0.40969178080558777, -- test: 0.7617205381393433 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0390160083770752, -- test: -4.903599739074707 \n",
      "Root Mean Squared Error -- train: 0.40912896394729614, -- test: 0.7572277188301086 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0421717166900635, -- test: -4.933317184448242 \n",
      "Root Mean Squared Error -- train: 0.40953394770622253, -- test: 0.7592864036560059 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0424938201904297, -- test: -4.8063130378723145 \n",
      "Root Mean Squared Error -- train: 0.4095752537250519, -- test: 0.75044846534729 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.042055368423462, -- test: -4.803525924682617 \n",
      "Root Mean Squared Error -- train: 0.4095190167427063, -- test: 0.7502533793449402 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.56601619720459\n",
      "Test Root MSE of all sampled models: 0.7334356307983398\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.5912370681762695\n",
      "Test Root MSE of all models in window: 0.7642363905906677\n",
      "\n",
      "############### EM step 276 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.9080644845962524 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 277 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0551737546920776, -- test: -5.087127208709717 \n",
      "Root Mean Squared Error -- train: 0.41168949007987976, -- test: 0.771070122718811 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0370923280715942, -- test: -5.072007656097412 \n",
      "Root Mean Squared Error -- train: 0.4093678295612335, -- test: 0.7700358629226685 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0352154970169067, -- test: -4.973260402679443 \n",
      "Root Mean Squared Error -- train: 0.4091261029243469, -- test: 0.7632462978363037 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0376020669937134, -- test: -4.952917098999023 \n",
      "Root Mean Squared Error -- train: 0.4094334542751312, -- test: 0.7618400454521179 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.045013427734375, -- test: -4.8764729499816895 \n",
      "Root Mean Squared Error -- train: 0.4103865325450897, -- test: 0.7565324306488037 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0994259119033813, -- test: -4.787832260131836 \n",
      "Root Mean Squared Error -- train: 0.4173169434070587, -- test: 0.750330924987793 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0349608659744263, -- test: -4.883790493011475 \n",
      "Root Mean Squared Error -- train: 0.4090932607650757, -- test: 0.7570420503616333 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0384641885757446, -- test: -4.875555515289307 \n",
      "Root Mean Squared Error -- train: 0.409544438123703, -- test: 0.7564685344696045 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0419018268585205, -- test: -4.948958873748779 \n",
      "Root Mean Squared Error -- train: 0.4099866449832916, -- test: 0.761566162109375 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.044283390045166, -- test: -4.9885334968566895 \n",
      "Root Mean Squared Error -- train: 0.41029274463653564, -- test: 0.7643004059791565 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.850530624389648\n",
      "Test Root MSE of all sampled models: 0.7547228336334229\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.582829475402832\n",
      "Test Root MSE of all models in window: 0.7639189958572388\n",
      "\n",
      "############### EM step 277 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1683722734451294 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 278 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0337607860565186, -- test: -4.90804386138916 \n",
      "Root Mean Squared Error -- train: 0.40942585468292236, -- test: 0.7599287033081055 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0955147743225098, -- test: -4.949622631072998 \n",
      "Root Mean Squared Error -- train: 0.4173278212547302, -- test: 0.7628173828125 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0565361976623535, -- test: -4.85745096206665 \n",
      "Root Mean Squared Error -- train: 0.41235780715942383, -- test: 0.7563989162445068 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0310626029968262, -- test: -4.9155354499816895 \n",
      "Root Mean Squared Error -- train: 0.40907713770866394, -- test: 0.7604499459266663 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0322940349578857, -- test: -4.911924362182617 \n",
      "Root Mean Squared Error -- train: 0.4092363119125366, -- test: 0.760198712348938 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0338631868362427, -- test: -4.9107513427734375 \n",
      "Root Mean Squared Error -- train: 0.4094391167163849, -- test: 0.7601171135902405 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0484994649887085, -- test: -4.857389450073242 \n",
      "Root Mean Squared Error -- train: 0.4113256335258484, -- test: 0.756394624710083 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0322438478469849, -- test: -4.980452060699463 \n",
      "Root Mean Squared Error -- train: 0.4092298150062561, -- test: 0.7649521231651306 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0426390171051025, -- test: -4.920034885406494 \n",
      "Root Mean Squared Error -- train: 0.41057127714157104, -- test: 0.7607628703117371 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1103386878967285, -- test: -4.847358226776123 \n",
      "Root Mean Squared Error -- train: 0.4192025363445282, -- test: 0.7556928396224976 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.658803939819336\n",
      "Test Root MSE of all sampled models: 0.742377519607544\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.569733142852783\n",
      "Test Root MSE of all models in window: 0.7639186978340149\n",
      "\n",
      "############### EM step 278 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.971164882183075 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 279 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.023112177848816, -- test: -5.036677360534668 \n",
      "Root Mean Squared Error -- train: 0.4085260331630707, -- test: 0.7700331211090088 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0559240579605103, -- test: -5.080329418182373 \n",
      "Root Mean Squared Error -- train: 0.41276708245277405, -- test: 0.7730360627174377 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0413240194320679, -- test: -4.968233108520508 \n",
      "Root Mean Squared Error -- train: 0.41088536381721497, -- test: 0.7653008103370667 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.028016209602356, -- test: -4.991459846496582 \n",
      "Root Mean Squared Error -- train: 0.4091626703739166, -- test: 0.7669099569320679 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0377110242843628, -- test: -4.844326972961426 \n",
      "Root Mean Squared Error -- train: 0.41041839122772217, -- test: 0.7566584944725037 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0302187204360962, -- test: -4.948606491088867 \n",
      "Root Mean Squared Error -- train: 0.4094482958316803, -- test: 0.7639383673667908 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1467351913452148, -- test: -4.840948104858398 \n",
      "Root Mean Squared Error -- train: 0.4242837131023407, -- test: 0.7564215064048767 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0491504669189453, -- test: -4.830572605133057 \n",
      "Root Mean Squared Error -- train: 0.41189515590667725, -- test: 0.7556930184364319 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0293216705322266, -- test: -4.973904609680176 \n",
      "Root Mean Squared Error -- train: 0.4093320071697235, -- test: 0.7656940221786499 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.027370810508728, -- test: -4.9045000076293945 \n",
      "Root Mean Squared Error -- train: 0.4090789556503296, -- test: 0.7608677744865417 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.283529281616211\n",
      "Test Root MSE of all sampled models: 0.7868642807006836\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.558871746063232\n",
      "Test Root MSE of all models in window: 0.7641798257827759\n",
      "\n",
      "############### EM step 279 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.8117429614067078 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 280 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0404129028320312, -- test: -5.0278849601745605 \n",
      "Root Mean Squared Error -- train: 0.4112391471862793, -- test: 0.7706002593040466 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0219768285751343, -- test: -5.076788425445557 \n",
      "Root Mean Squared Error -- train: 0.4088447391986847, -- test: 0.7739725112915039 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0260871648788452, -- test: -4.887811660766602 \n",
      "Root Mean Squared Error -- train: 0.4093797504901886, -- test: 0.7608583569526672 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0619831085205078, -- test: -4.815347194671631 \n",
      "Root Mean Squared Error -- train: 0.4140230119228363, -- test: 0.7557693123817444 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0540052652359009, -- test: -4.956927299499512 \n",
      "Root Mean Squared Error -- train: 0.4129955768585205, -- test: 0.765680730342865 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0285003185272217, -- test: -4.829228401184082 \n",
      "Root Mean Squared Error -- train: 0.40969353914260864, -- test: 0.756746768951416 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.025232195854187, -- test: -4.865738868713379 \n",
      "Root Mean Squared Error -- train: 0.40926849842071533, -- test: 0.759311854839325 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0590747594833374, -- test: -4.932729721069336 \n",
      "Root Mean Squared Error -- train: 0.413648784160614, -- test: 0.763995885848999 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0383273363113403, -- test: -4.8694281578063965 \n",
      "Root Mean Squared Error -- train: 0.41096895933151245, -- test: 0.7595705986022949 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0239938497543335, -- test: -4.869630813598633 \n",
      "Root Mean Squared Error -- train: 0.4091073274612427, -- test: 0.7595847845077515 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.629938125610352\n",
      "Test Root MSE of all sampled models: 0.7425895929336548\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.5428571701049805\n",
      "Test Root MSE of all models in window: 0.764063835144043\n",
      "\n",
      "############### EM step 280 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.3927700519561768 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 281 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.016508936882019, -- test: -4.914971351623535 \n",
      "Root Mean Squared Error -- train: 0.4086094796657562, -- test: 0.7639496326446533 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0456901788711548, -- test: -5.042489051818848 \n",
      "Root Mean Squared Error -- train: 0.41240817308425903, -- test: 0.7728180289268494 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.1537230014801025, -- test: -4.984584331512451 \n",
      "Root Mean Squared Error -- train: 0.42617693543434143, -- test: 0.7688036561012268 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0971558094024658, -- test: -5.021157264709473 \n",
      "Root Mean Squared Error -- train: 0.41902390122413635, -- test: 0.7713415622711182 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0300281047821045, -- test: -4.912760257720947 \n",
      "Root Mean Squared Error -- train: 0.4103737473487854, -- test: 0.7637948989868164 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.020103096961975, -- test: -4.901235103607178 \n",
      "Root Mean Squared Error -- train: 0.40907928347587585, -- test: 0.7629880905151367 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0543667078018188, -- test: -4.990869045257568 \n",
      "Root Mean Squared Error -- train: 0.41353094577789307, -- test: 0.7692403793334961 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0231980085372925, -- test: -5.081516265869141 \n",
      "Root Mean Squared Error -- train: 0.4094833731651306, -- test: 0.7755120396614075 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0205804109573364, -- test: -4.8415141105651855 \n",
      "Root Mean Squared Error -- train: 0.4091416001319885, -- test: 0.758793830871582 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0813086032867432, -- test: -5.0783772468566895 \n",
      "Root Mean Squared Error -- train: 0.4169979989528656, -- test: 0.7752956748008728 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.498724937438965\n",
      "Test Root MSE of all sampled models: 0.8037468194961548\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.511026859283447\n",
      "Test Root MSE of all models in window: 0.7647188901901245\n",
      "\n",
      "############### EM step 281 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.8424232006072998 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 282 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0238319635391235, -- test: -4.951860427856445 \n",
      "Root Mean Squared Error -- train: 0.41003531217575073, -- test: 0.7676976919174194 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0639182329177856, -- test: -5.090909957885742 \n",
      "Root Mean Squared Error -- train: 0.41524413228034973, -- test: 0.7773486971855164 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0184296369552612, -- test: -4.960869789123535 \n",
      "Root Mean Squared Error -- train: 0.40932828187942505, -- test: 0.7683266401290894 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0267090797424316, -- test: -5.008999824523926 \n",
      "Root Mean Squared Error -- train: 0.41041135787963867, -- test: 0.7716781497001648 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0181618928909302, -- test: -5.016167640686035 \n",
      "Root Mean Squared Error -- train: 0.40929320454597473, -- test: 0.7721760869026184 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0184211730957031, -- test: -4.843776702880859 \n",
      "Root Mean Squared Error -- train: 0.4093271493911743, -- test: 0.7601112723350525 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0642826557159424, -- test: -4.85906982421875 \n",
      "Root Mean Squared Error -- train: 0.4152911901473999, -- test: 0.7611892819404602 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0206336975097656, -- test: -4.799283027648926 \n",
      "Root Mean Squared Error -- train: 0.4096168577671051, -- test: 0.7569661736488342 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0243847370147705, -- test: -5.073797702789307 \n",
      "Root Mean Squared Error -- train: 0.4101075828075409, -- test: 0.7761675119400024 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0184301137924194, -- test: -4.9155497550964355 \n",
      "Root Mean Squared Error -- train: 0.4093283414840698, -- test: 0.7651574611663818 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.630255699157715\n",
      "Test Root MSE of all sampled models: 0.8137008547782898\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.507809638977051\n",
      "Test Root MSE of all models in window: 0.7648485898971558\n",
      "\n",
      "############### EM step 282 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.5664242506027222 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 283 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0793483257293701, -- test: -5.017071723937988 \n",
      "Root Mean Squared Error -- train: 0.41773760318756104, -- test: 0.7734705805778503 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0230731964111328, -- test: -4.870008945465088 \n",
      "Root Mean Squared Error -- train: 0.410425066947937, -- test: 0.7631716132164001 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.034663438796997, -- test: -4.782037734985352 \n",
      "Root Mean Squared Error -- train: 0.4119417667388916, -- test: 0.7569438219070435 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.015756607055664, -- test: -4.762608051300049 \n",
      "Root Mean Squared Error -- train: 0.4094647765159607, -- test: 0.7555614113807678 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0157191753387451, -- test: -4.753298759460449 \n",
      "Root Mean Squared Error -- train: 0.40945982933044434, -- test: 0.754898190498352 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0354660749435425, -- test: -4.70560884475708 \n",
      "Root Mean Squared Error -- train: 0.4120466113090515, -- test: 0.7514913082122803 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0274125337600708, -- test: -4.901518821716309 \n",
      "Root Mean Squared Error -- train: 0.4109935462474823, -- test: 0.7653899192810059 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0194238424301147, -- test: -4.90151834487915 \n",
      "Root Mean Squared Error -- train: 0.40994638204574585, -- test: 0.7653899192810059 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0125224590301514, -- test: -4.841012477874756 \n",
      "Root Mean Squared Error -- train: 0.40903955698013306, -- test: 0.7611244320869446 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0242507457733154, -- test: -4.816234111785889 \n",
      "Root Mean Squared Error -- train: 0.41057947278022766, -- test: 0.759370744228363 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.018609046936035\n",
      "Test Root MSE of all sampled models: 0.7735775709152222\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.502965450286865\n",
      "Test Root MSE of all models in window: 0.7648189663887024\n",
      "\n",
      "############### EM step 283 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.0597268342971802 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 284 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.015605092048645, -- test: -4.674819469451904 \n",
      "Root Mean Squared Error -- train: 0.4099290668964386, -- test: 0.7504639029502869 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0106191635131836, -- test: -4.704106330871582 \n",
      "Root Mean Squared Error -- train: 0.40927180647850037, -- test: 0.7525680661201477 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.011857271194458, -- test: -4.865591049194336 \n",
      "Root Mean Squared Error -- train: 0.40943509340286255, -- test: 0.7640662789344788 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0581563711166382, -- test: -4.793682098388672 \n",
      "Root Mean Squared Error -- train: 0.41549596190452576, -- test: 0.7589676380157471 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0961347818374634, -- test: -4.820153713226318 \n",
      "Root Mean Squared Error -- train: 0.4204023480415344, -- test: 0.7608485817909241 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.008593201637268, -- test: -4.879395008087158 \n",
      "Root Mean Squared Error -- train: 0.40900444984436035, -- test: 0.7650412321090698 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.039446234703064, -- test: -4.779901027679443 \n",
      "Root Mean Squared Error -- train: 0.4130573868751526, -- test: 0.7579866647720337 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.014707326889038, -- test: -4.752330780029297 \n",
      "Root Mean Squared Error -- train: 0.40981078147888184, -- test: 0.7560201287269592 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0192533731460571, -- test: -4.923245429992676 \n",
      "Root Mean Squared Error -- train: 0.4104093313217163, -- test: 0.7681297063827515 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.060044288635254, -- test: -4.911365509033203 \n",
      "Root Mean Squared Error -- train: 0.4157412350177765, -- test: 0.7672942280769348 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.196727275848389\n",
      "Test Root MSE of all sampled models: 0.7871189713478088\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.4944586753845215\n",
      "Test Root MSE of all models in window: 0.7648732662200928\n",
      "\n",
      "############### EM step 284 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.0136862993240356 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 285 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0212665796279907, -- test: -4.911240100860596 \n",
      "Root Mean Squared Error -- train: 0.4111558496952057, -- test: 0.7684884667396545 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0261112451553345, -- test: -4.859011650085449 \n",
      "Root Mean Squared Error -- train: 0.4117937982082367, -- test: 0.7647973299026489 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0162080526351929, -- test: -4.930384635925293 \n",
      "Root Mean Squared Error -- train: 0.41048872470855713, -- test: 0.7698370814323425 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0297331809997559, -- test: -4.782176971435547 \n",
      "Root Mean Squared Error -- train: 0.41227003931999207, -- test: 0.7593345642089844 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0066202878952026, -- test: -5.003552436828613 \n",
      "Root Mean Squared Error -- train: 0.40922123193740845, -- test: 0.7749693989753723 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0211683511734009, -- test: -4.850070476531982 \n",
      "Root Mean Squared Error -- train: 0.41114288568496704, -- test: 0.764163613319397 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0289053916931152, -- test: -4.834534168243408 \n",
      "Root Mean Squared Error -- train: 0.412161260843277, -- test: 0.7630612850189209 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0693427324295044, -- test: -4.982085704803467 \n",
      "Root Mean Squared Error -- train: 0.41744309663772583, -- test: 0.7734671831130981 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.018503189086914, -- test: -4.8542399406433105 \n",
      "Root Mean Squared Error -- train: 0.4107915461063385, -- test: 0.7644591927528381 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.1505216360092163, -- test: -4.727297782897949 \n",
      "Root Mean Squared Error -- train: 0.42784982919692993, -- test: 0.7554086446762085 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.083847999572754\n",
      "Test Root MSE of all sampled models: 0.7805630564689636\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.487115859985352\n",
      "Test Root MSE of all models in window: 0.7651107311248779\n",
      "\n",
      "############### EM step 285 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.895407497882843 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 286 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9998292922973633, -- test: -4.939327239990234 \n",
      "Root Mean Squared Error -- train: 0.40878793597221375, -- test: 0.7716525197029114 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0177181959152222, -- test: -4.710020542144775 \n",
      "Root Mean Squared Error -- train: 0.41116011142730713, -- test: 0.7553245425224304 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0021758079528809, -- test: -4.834073066711426 \n",
      "Root Mean Squared Error -- train: 0.40909987688064575, -- test: 0.7642010450363159 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.002306342124939, -- test: -4.865301609039307 \n",
      "Root Mean Squared Error -- train: 0.4091172516345978, -- test: 0.7664194107055664 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0513890981674194, -- test: -4.805856704711914 \n",
      "Root Mean Squared Error -- train: 0.4155883193016052, -- test: 0.762191116809845 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0022599697113037, -- test: -4.763346195220947 \n",
      "Root Mean Squared Error -- train: 0.40911105275154114, -- test: 0.7591529488563538 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.004726529121399, -- test: -4.811715602874756 \n",
      "Root Mean Squared Error -- train: 0.40943869948387146, -- test: 0.7626089453697205 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0147874355316162, -- test: -4.8353095054626465 \n",
      "Root Mean Squared Error -- train: 0.4107724130153656, -- test: 0.7642890214920044 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0356026887893677, -- test: -4.971670150756836 \n",
      "Root Mean Squared Error -- train: 0.41351810097694397, -- test: 0.7739277482032776 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0022200345993042, -- test: -4.858865737915039 \n",
      "Root Mean Squared Error -- train: 0.4091057777404785, -- test: 0.7659627795219421 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.240446090698242\n",
      "Test Root MSE of all sampled models: 0.7207346558570862\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.467363357543945\n",
      "Test Root MSE of all models in window: 0.7643277049064636\n",
      "\n",
      "############### EM step 286 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.1523106098175049 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 287 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0296335220336914, -- test: -4.674644947052002 \n",
      "Root Mean Squared Error -- train: 0.4132111072540283, -- test: 0.7539334297180176 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -0.9971584677696228, -- test: -4.65934944152832 \n",
      "Root Mean Squared Error -- train: 0.4089014232158661, -- test: 0.752825915813446 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0073602199554443, -- test: -4.787694931030273 \n",
      "Root Mean Squared Error -- train: 0.4102601706981659, -- test: 0.7620691657066345 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0636950731277466, -- test: -4.705530166625977 \n",
      "Root Mean Squared Error -- train: 0.41768357157707214, -- test: 0.7561647891998291 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.9992066025733948, -- test: -4.716700077056885 \n",
      "Root Mean Squared Error -- train: 0.4091745913028717, -- test: 0.7569701671600342 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0002224445343018, -- test: -4.673397541046143 \n",
      "Root Mean Squared Error -- train: 0.4093100130558014, -- test: 0.7538431882858276 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0027254819869995, -- test: -4.743033409118652 \n",
      "Root Mean Squared Error -- train: 0.4096434712409973, -- test: 0.758865475654602 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0069024562835693, -- test: -4.786285877227783 \n",
      "Root Mean Squared Error -- train: 0.4101993143558502, -- test: 0.7619683146476746 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0034902095794678, -- test: -4.824244499206543 \n",
      "Root Mean Squared Error -- train: 0.4097452759742737, -- test: 0.7646809816360474 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0503016710281372, -- test: -4.833463191986084 \n",
      "Root Mean Squared Error -- train: 0.41593071818351746, -- test: 0.7653383612632751 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.306105136871338\n",
      "Test Root MSE of all sampled models: 0.7983158230781555\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.454074859619141\n",
      "Test Root MSE of all models in window: 0.7647131085395813\n",
      "\n",
      "############### EM step 287 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.9799273610115051 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 288 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9994585514068604, -- test: -5.011803150177002 \n",
      "Root Mean Squared Error -- train: 0.4096732437610626, -- test: 0.779139518737793 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0233975648880005, -- test: -4.800983905792236 \n",
      "Root Mean Squared Error -- train: 0.4128592312335968, -- test: 0.7641860842704773 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0010875463485718, -- test: -4.71945858001709 \n",
      "Root Mean Squared Error -- train: 0.4098908305168152, -- test: 0.758324384689331 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.1025762557983398, -- test: -4.830827713012695 \n",
      "Root Mean Squared Error -- train: 0.42322608828544617, -- test: 0.766320526599884 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.9985665678977966, -- test: -4.7175164222717285 \n",
      "Root Mean Squared Error -- train: 0.40955406427383423, -- test: 0.7581841349601746 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.9967002868652344, -- test: -4.773317337036133 \n",
      "Root Mean Squared Error -- train: 0.40930458903312683, -- test: 0.7622018456459045 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9967247247695923, -- test: -4.7450852394104 \n",
      "Root Mean Squared Error -- train: 0.4093078374862671, -- test: 0.7601717710494995 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9963118433952332, -- test: -4.755988121032715 \n",
      "Root Mean Squared Error -- train: 0.4092526137828827, -- test: 0.7609564065933228 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.073765754699707, -- test: -4.8990373611450195 \n",
      "Root Mean Squared Error -- train: 0.41948357224464417, -- test: 0.7711770534515381 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.2726259231567383, -- test: -4.644685745239258 \n",
      "Root Mean Squared Error -- train: 0.444674551486969, -- test: 0.7529080510139465 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -3.9965620040893555\n",
      "Test Root MSE of all sampled models: 0.704216718673706\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.406350612640381\n",
      "Test Root MSE of all models in window: 0.7642444968223572\n",
      "\n",
      "############### EM step 288 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.278056263923645 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 289 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.011603832244873, -- test: -4.556342601776123 \n",
      "Root Mean Squared Error -- train: 0.41176965832710266, -- test: 0.7476125359535217 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -0.9954385757446289, -- test: -4.710038185119629 \n",
      "Root Mean Squared Error -- train: 0.40960782766342163, -- test: 0.7588196396827698 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.0143561363220215, -- test: -4.707118988037109 \n",
      "Root Mean Squared Error -- train: 0.41213661432266235, -- test: 0.7586082220077515 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.0142712593078613, -- test: -4.731024742126465 \n",
      "Root Mean Squared Error -- train: 0.41212528944015503, -- test: 0.7603370547294617 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.9958921670913696, -- test: -4.6457719802856445 \n",
      "Root Mean Squared Error -- train: 0.40966862440109253, -- test: 0.7541537284851074 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.9948593974113464, -- test: -4.800536155700684 \n",
      "Root Mean Squared Error -- train: 0.4095301628112793, -- test: 0.7653416395187378 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0477484464645386, -- test: -4.600761890411377 \n",
      "Root Mean Squared Error -- train: 0.4165627658367157, -- test: 0.7508686780929565 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9935358762741089, -- test: -4.86250114440918 \n",
      "Root Mean Squared Error -- train: 0.4093526601791382, -- test: 0.7697755694389343 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -1.0050400495529175, -- test: -4.7421183586120605 \n",
      "Root Mean Squared Error -- train: 0.4108932316303253, -- test: 0.7611379027366638 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0072448253631592, -- test: -4.614439487457275 \n",
      "Root Mean Squared Error -- train: 0.4111878573894501, -- test: 0.7518684267997742 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.860815525054932\n",
      "Test Root MSE of all sampled models: 0.7696552872657776\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.398510932922363\n",
      "Test Root MSE of all models in window: 0.7639468312263489\n",
      "\n",
      "############### EM step 289 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.9449605941772461 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 290 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9933752417564392, -- test: -4.792816638946533 \n",
      "Root Mean Squared Error -- train: 0.4097962975502014, -- test: 0.7659596800804138 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.007845163345337, -- test: -4.618716716766357 \n",
      "Root Mean Squared Error -- train: 0.4117375612258911, -- test: 0.7533296942710876 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -0.9924641251564026, -- test: -4.734757900238037 \n",
      "Root Mean Squared Error -- train: 0.4096737504005432, -- test: 0.7617710828781128 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.99870765209198, -- test: -4.6136932373046875 \n",
      "Root Mean Squared Error -- train: 0.4105127453804016, -- test: 0.752962052822113 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.9888237714767456, -- test: -4.621564865112305 \n",
      "Root Mean Squared Error -- train: 0.4091837406158447, -- test: 0.7535379528999329 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.9902332425117493, -- test: -4.704358100891113 \n",
      "Root Mean Squared Error -- train: 0.40937355160713196, -- test: 0.7595686912536621 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9918926358222961, -- test: -4.567156791687012 \n",
      "Root Mean Squared Error -- train: 0.40959689021110535, -- test: 0.7495483756065369 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9964471459388733, -- test: -4.672916889190674 \n",
      "Root Mean Squared Error -- train: 0.41020917892456055, -- test: 0.7572841644287109 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.9934261441230774, -- test: -4.601447105407715 \n",
      "Root Mean Squared Error -- train: 0.4098031222820282, -- test: 0.7520652413368225 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.048392653465271, -- test: -4.751020431518555 \n",
      "Root Mean Squared Error -- train: 0.417129248380661, -- test: 0.762946605682373 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.983338832855225\n",
      "Test Root MSE of all sampled models: 0.7795466184616089\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.389337539672852\n",
      "Test Root MSE of all models in window: 0.764335572719574\n",
      "\n",
      "############### EM step 290 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2496933937072754 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 291 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9951909780502319, -- test: -4.549445152282715 \n",
      "Root Mean Squared Error -- train: 0.4105130732059479, -- test: 0.7494025230407715 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -0.9902675151824951, -- test: -4.541499614715576 \n",
      "Root Mean Squared Error -- train: 0.4098493456840515, -- test: 0.7488159537315369 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -0.9867305159568787, -- test: -4.651365280151367 \n",
      "Root Mean Squared Error -- train: 0.40937185287475586, -- test: 0.7568856477737427 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.9881815910339355, -- test: -4.569446563720703 \n",
      "Root Mean Squared Error -- train: 0.40956780314445496, -- test: 0.750876784324646 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.9917432069778442, -- test: -4.6701579093933105 \n",
      "Root Mean Squared Error -- train: 0.41004839539527893, -- test: 0.7582573890686035 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.9861997365951538, -- test: -4.761774063110352 \n",
      "Root Mean Squared Error -- train: 0.40930017828941345, -- test: 0.7649095058441162 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9892932176589966, -- test: -4.601022720336914 \n",
      "Root Mean Squared Error -- train: 0.4097178876399994, -- test: 0.7531986236572266 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9904756546020508, -- test: -4.709575653076172 \n",
      "Root Mean Squared Error -- train: 0.4098774492740631, -- test: 0.7611265778541565 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.9929844737052917, -- test: -4.583739280700684 \n",
      "Root Mean Squared Error -- train: 0.4102157652378082, -- test: 0.7519286870956421 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -0.9869665503501892, -- test: -4.686315536499023 \n",
      "Root Mean Squared Error -- train: 0.4094037413597107, -- test: 0.7594348192214966 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -5.189591884613037\n",
      "Test Root MSE of all sampled models: 0.7952364683151245\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.346842288970947\n",
      "Test Root MSE of all models in window: 0.7647334933280945\n",
      "\n",
      "############### EM step 291 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.0557752847671509 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 292 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9909338355064392, -- test: -4.677423000335693 \n",
      "Root Mean Squared Error -- train: 0.41040897369384766, -- test: 0.7599589824676514 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.026748538017273, -- test: -4.533899784088135 \n",
      "Root Mean Squared Error -- train: 0.41522282361984253, -- test: 0.7494066953659058 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -0.9840524792671204, -- test: -4.715425968170166 \n",
      "Root Mean Squared Error -- train: 0.409477561712265, -- test: 0.7627285718917847 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.9865626692771912, -- test: -4.637143135070801 \n",
      "Root Mean Squared Error -- train: 0.40981754660606384, -- test: 0.7570123076438904 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0690542459487915, -- test: -4.465208053588867 \n",
      "Root Mean Squared Error -- train: 0.42083823680877686, -- test: 0.744303286075592 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.983864426612854, -- test: -4.656825542449951 \n",
      "Root Mean Squared Error -- train: 0.40945208072662354, -- test: 0.7584535479545593 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.0019804239273071, -- test: -4.548410892486572 \n",
      "Root Mean Squared Error -- train: 0.41189974546432495, -- test: 0.7504802942276001 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9863104224205017, -- test: -4.646618843078613 \n",
      "Root Mean Squared Error -- train: 0.40978342294692993, -- test: 0.7577065229415894 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.9835505485534668, -- test: -4.55701208114624 \n",
      "Root Mean Squared Error -- train: 0.4094095528125763, -- test: 0.7511159181594849 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -0.9848294258117676, -- test: -4.589725971221924 \n",
      "Root Mean Squared Error -- train: 0.40958282351493835, -- test: 0.7535287141799927 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.405945777893066\n",
      "Test Root MSE of all sampled models: 0.7398722171783447\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.3310441970825195\n",
      "Test Root MSE of all models in window: 0.7642647624015808\n",
      "\n",
      "############### EM step 292 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.9928585886955261 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 293 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9847329258918762, -- test: -4.678040981292725 \n",
      "Root Mean Squared Error -- train: 0.41003355383872986, -- test: 0.761167049407959 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -0.9984433650970459, -- test: -4.726173400878906 \n",
      "Root Mean Squared Error -- train: 0.41189098358154297, -- test: 0.7646795511245728 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -0.9803529977798462, -- test: -4.602296829223633 \n",
      "Root Mean Squared Error -- train: 0.40943843126296997, -- test: 0.755606472492218 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.9829447269439697, -- test: -4.578690052032471 \n",
      "Root Mean Squared Error -- train: 0.40979066491127014, -- test: 0.7538651823997498 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0099443197250366, -- test: -4.639913558959961 \n",
      "Root Mean Squared Error -- train: 0.41344261169433594, -- test: 0.7583732008934021 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0098639726638794, -- test: -4.718662738800049 \n",
      "Root Mean Squared Error -- train: 0.4134317934513092, -- test: 0.7641324996948242 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9821519255638123, -- test: -4.530361175537109 \n",
      "Root Mean Squared Error -- train: 0.409682959318161, -- test: 0.7502874135971069 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -1.0097694396972656, -- test: -4.721664905548096 \n",
      "Root Mean Squared Error -- train: 0.41341906785964966, -- test: 0.7643512487411499 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.9789101481437683, -- test: -4.621406078338623 \n",
      "Root Mean Squared Error -- train: 0.4092421531677246, -- test: 0.7570132613182068 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -0.9891415238380432, -- test: -4.518733024597168 \n",
      "Root Mean Squared Error -- train: 0.4106317162513733, -- test: 0.7494240999221802 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.255685329437256\n",
      "Test Root MSE of all sampled models: 0.729620635509491\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.313207149505615\n",
      "Test Root MSE of all models in window: 0.7634521126747131\n",
      "\n",
      "############### EM step 293 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.4766767919063568 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 294 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0174548625946045, -- test: -4.679013252258301 \n",
      "Root Mean Squared Error -- train: 0.4149011969566345, -- test: 0.762340247631073 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -0.9999797344207764, -- test: -4.437028884887695 \n",
      "Root Mean Squared Error -- train: 0.4125420153141022, -- test: 0.7444000840187073 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.001896619796753, -- test: -4.683822154998779 \n",
      "Root Mean Squared Error -- train: 0.41280147433280945, -- test: 0.7626924514770508 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -1.012723445892334, -- test: -4.57664680480957 \n",
      "Root Mean Squared Error -- train: 0.4142638146877289, -- test: 0.7548031210899353 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.997806966304779, -- test: -4.5779948234558105 \n",
      "Root Mean Squared Error -- train: 0.41224774718284607, -- test: 0.7549027800559998 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0144389867782593, -- test: -4.627597808837891 \n",
      "Root Mean Squared Error -- train: 0.4144950211048126, -- test: 0.7585639357566833 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9880366325378418, -- test: -4.697155475616455 \n",
      "Root Mean Squared Error -- train: 0.4109219014644623, -- test: 0.7636682987213135 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.977180004119873, -- test: -4.663455963134766 \n",
      "Root Mean Squared Error -- train: 0.40944358706474304, -- test: 0.7611995339393616 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.976950466632843, -- test: -4.59394645690918 \n",
      "Root Mean Squared Error -- train: 0.4094122648239136, -- test: 0.7560821175575256 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -0.9739142656326294, -- test: -4.611728191375732 \n",
      "Root Mean Squared Error -- train: 0.40899786353111267, -- test: 0.757394552230835 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.46281623840332\n",
      "Test Root MSE of all sampled models: 0.7463323473930359\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.302740573883057\n",
      "Test Root MSE of all models in window: 0.7635374069213867\n",
      "\n",
      "############### EM step 294 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.4333124160766602 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 295 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9821822643280029, -- test: -4.459090709686279 \n",
      "Root Mean Squared Error -- train: 0.410580575466156, -- test: 0.7471691966056824 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -0.9784508347511292, -- test: -4.713497638702393 \n",
      "Root Mean Squared Error -- train: 0.4100709557533264, -- test: 0.7660126090049744 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -1.008010745048523, -- test: -4.682524681091309 \n",
      "Root Mean Squared Error -- train: 0.4140908122062683, -- test: 0.7637433409690857 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.9874715805053711, -- test: -4.476873397827148 \n",
      "Root Mean Squared Error -- train: 0.411301851272583, -- test: 0.7485017776489258 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.9708274602890015, -- test: -4.656839370727539 \n",
      "Root Mean Squared Error -- train: 0.4090278446674347, -- test: 0.7618563771247864 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.9787216782569885, -- test: -4.626229286193848 \n",
      "Root Mean Squared Error -- train: 0.41010794043540955, -- test: 0.7596014738082886 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -1.1835675239562988, -- test: -4.411808967590332 \n",
      "Root Mean Squared Error -- train: 0.43720394372940063, -- test: 0.7436146140098572 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9746375679969788, -- test: -4.775592803955078 \n",
      "Root Mean Squared Error -- train: 0.4095495045185089, -- test: 0.7705419063568115 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.9790238738059998, -- test: -4.613300800323486 \n",
      "Root Mean Squared Error -- train: 0.4101492166519165, -- test: 0.758647084236145 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -0.9789989590644836, -- test: -4.616641521453857 \n",
      "Root Mean Squared Error -- train: 0.4101458489894867, -- test: 0.7588938474655151 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.043700695037842\n",
      "Test Root MSE of all sampled models: 0.7153360247612\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.253923416137695\n",
      "Test Root MSE of all models in window: 0.7634419798851013\n",
      "\n",
      "############### EM step 295 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.6555936932563782 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 296 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9735232591629028, -- test: -4.72081184387207 \n",
      "Root Mean Squared Error -- train: 0.40983298420906067, -- test: 0.7676573991775513 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -0.9756247401237488, -- test: -4.7242560386657715 \n",
      "Root Mean Squared Error -- train: 0.4101211428642273, -- test: 0.7679096460342407 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -0.9686014652252197, -- test: -4.645452499389648 \n",
      "Root Mean Squared Error -- train: 0.40915727615356445, -- test: 0.7621185183525085 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.9821167588233948, -- test: -4.5885090827941895 \n",
      "Root Mean Squared Error -- train: 0.41101011633872986, -- test: 0.7579063773155212 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0134721994400024, -- test: -4.660827159881592 \n",
      "Root Mean Squared Error -- train: 0.41527679562568665, -- test: 0.7632518410682678 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.9688873291015625, -- test: -4.66369104385376 \n",
      "Root Mean Squared Error -- train: 0.40919655561447144, -- test: 0.7634627819061279 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9696336984634399, -- test: -4.533215045928955 \n",
      "Root Mean Squared Error -- train: 0.4092991054058075, -- test: 0.7537937760353088 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9714409112930298, -- test: -4.688119888305664 \n",
      "Root Mean Squared Error -- train: 0.40954723954200745, -- test: 0.7652595043182373 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.9792392253875732, -- test: -4.623203754425049 \n",
      "Root Mean Squared Error -- train: 0.41061630845069885, -- test: 0.7604756355285645 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.00792396068573, -- test: -4.4377360343933105 \n",
      "Root Mean Squared Error -- train: 0.41452500224113464, -- test: 0.746638834476471 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.815617084503174\n",
      "Test Root MSE of all sampled models: 0.7745693325996399\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.245178699493408\n",
      "Test Root MSE of all models in window: 0.7635448575019836\n",
      "\n",
      "############### EM step 296 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2642444372177124 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 297 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -1.0219883918762207, -- test: -4.652313709259033 \n",
      "Root Mean Squared Error -- train: 0.41688841581344604, -- test: 0.763751745223999 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0012599229812622, -- test: -4.69401216506958 \n",
      "Root Mean Squared Error -- train: 0.41407448053359985, -- test: 0.7668249607086182 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -0.9724716544151306, -- test: -4.6796040534973145 \n",
      "Root Mean Squared Error -- train: 0.41013434529304504, -- test: 0.7657644152641296 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.9730610847473145, -- test: -4.585084438323975 \n",
      "Root Mean Squared Error -- train: 0.4102153778076172, -- test: 0.7587707042694092 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.9762991070747375, -- test: -4.563142776489258 \n",
      "Root Mean Squared Error -- train: 0.41066035628318787, -- test: 0.7571378350257874 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.9820798635482788, -- test: -4.519079208374023 \n",
      "Root Mean Squared Error -- train: 0.4114535450935364, -- test: 0.7538482546806335 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9920974969863892, -- test: -4.706237316131592 \n",
      "Root Mean Squared Error -- train: 0.41282451152801514, -- test: 0.7677236199378967 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9794082045555115, -- test: -4.620823860168457 \n",
      "Root Mean Squared Error -- train: 0.41108715534210205, -- test: 0.7614226341247559 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.9689779281616211, -- test: -4.5857253074646 \n",
      "Root Mean Squared Error -- train: 0.40965357422828674, -- test: 0.7588182687759399 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -0.9657042622566223, -- test: -4.636256217956543 \n",
      "Root Mean Squared Error -- train: 0.40920260548591614, -- test: 0.762565016746521 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -3.981456995010376\n",
      "Test Root MSE of all sampled models: 0.7124888896942139\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.230823993682861\n",
      "Test Root MSE of all models in window: 0.7627972960472107\n",
      "\n",
      "############### EM step 297 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.7877517938613892 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 298 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9651177525520325, -- test: -4.311563014984131 \n",
      "Root Mean Squared Error -- train: 0.40955474972724915, -- test: 0.7392154335975647 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -0.9654680490493774, -- test: -4.430380344390869 \n",
      "Root Mean Squared Error -- train: 0.4096031188964844, -- test: 0.7482549548149109 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -0.9664248824119568, -- test: -4.5753703117370605 \n",
      "Root Mean Squared Error -- train: 0.4097352921962738, -- test: 0.7591399550437927 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.9696632027626038, -- test: -4.504696846008301 \n",
      "Root Mean Squared Error -- train: 0.41018223762512207, -- test: 0.7538539171218872 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.9755328297615051, -- test: -4.5667643547058105 \n",
      "Root Mean Squared Error -- train: 0.4109911620616913, -- test: 0.7584981918334961 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.9650706052780151, -- test: -4.577584743499756 \n",
      "Root Mean Squared Error -- train: 0.40954822301864624, -- test: 0.7593050003051758 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9639176726341248, -- test: -4.585149765014648 \n",
      "Root Mean Squared Error -- train: 0.4093888998031616, -- test: 0.7598686218261719 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9780017137527466, -- test: -4.608872890472412 \n",
      "Root Mean Squared Error -- train: 0.411330908536911, -- test: 0.7616329789161682 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.9901277422904968, -- test: -4.517261505126953 \n",
      "Root Mean Squared Error -- train: 0.4129956066608429, -- test: 0.7547964453697205 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -0.9717944264411926, -- test: -4.50375509262085 \n",
      "Root Mean Squared Error -- train: 0.4104761481285095, -- test: 0.7537831664085388 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.348973751068115\n",
      "Test Root MSE of all sampled models: 0.7420734763145447\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.219727039337158\n",
      "Test Root MSE of all models in window: 0.763227105140686\n",
      "\n",
      "############### EM step 298 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.2427520751953125 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 299 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9613770842552185, -- test: -4.419477462768555 \n",
      "Root Mean Squared Error -- train: 0.40947863459587097, -- test: 0.7485249042510986 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -1.0050057172775269, -- test: -4.38192892074585 \n",
      "Root Mean Squared Error -- train: 0.4154830276966095, -- test: 0.745671808719635 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -0.9756060838699341, -- test: -4.505385875701904 \n",
      "Root Mean Squared Error -- train: 0.4114465117454529, -- test: 0.7550120949745178 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.9641744494438171, -- test: -4.5634002685546875 \n",
      "Root Mean Squared Error -- train: 0.4098662734031677, -- test: 0.7593615055084229 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.958558976650238, -- test: -4.5958452224731445 \n",
      "Root Mean Squared Error -- train: 0.40908774733543396, -- test: 0.7617831230163574 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -1.0675908327102661, -- test: -4.4083356857299805 \n",
      "Root Mean Squared Error -- train: 0.42394784092903137, -- test: 0.7476794719696045 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9589223861694336, -- test: -4.645745277404785 \n",
      "Root Mean Squared Error -- train: 0.40913817286491394, -- test: 0.7654926180839539 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9881427884101868, -- test: -4.595277309417725 \n",
      "Root Mean Squared Error -- train: 0.4131726026535034, -- test: 0.7617407441139221 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.961513102054596, -- test: -4.583129405975342 \n",
      "Root Mean Squared Error -- train: 0.4094974994659424, -- test: 0.7608349323272705 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.031705617904663, -- test: -4.5400261878967285 \n",
      "Root Mean Squared Error -- train: 0.41911518573760986, -- test: 0.7576121091842651 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -3.9446215629577637\n",
      "Test Root MSE of all sampled models: 0.7116014361381531\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.199586391448975\n",
      "Test Root MSE of all models in window: 0.7624621987342834\n",
      "\n",
      "############### EM step 299 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -0.8522554039955139 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### EM step 300 of total 300 steps. E Step:  ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9597917199134827, -- test: -4.294459342956543 \n",
      "Root Mean Squared Error -- train: 0.4096916913986206, -- test: 0.7400427460670471 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -0.9584456086158752, -- test: -4.4356584548950195 \n",
      "Root Mean Squared Error -- train: 0.4095045328140259, -- test: 0.7508301138877869 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -0.9561127424240112, -- test: -4.457605361938477 \n",
      "Root Mean Squared Error -- train: 0.4091799855232239, -- test: 0.7524928450584412 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.97959965467453, -- test: -4.53121280670166 \n",
      "Root Mean Squared Error -- train: 0.412435919046402, -- test: 0.7580431699752808 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -1.0207303762435913, -- test: -4.371720314025879 \n",
      "Root Mean Squared Error -- train: 0.418076753616333, -- test: 0.7459646463394165 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.9596748948097229, -- test: -4.448976516723633 \n",
      "Root Mean Squared Error -- train: 0.4096754789352417, -- test: 0.7518395781517029 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9574557542800903, -- test: -4.461126327514648 \n",
      "Root Mean Squared Error -- train: 0.4093668460845947, -- test: 0.7527593374252319 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9651662707328796, -- test: -4.382141590118408 \n",
      "Root Mean Squared Error -- train: 0.4104381203651428, -- test: 0.746759831905365 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.9680644869804382, -- test: -4.391882419586182 \n",
      "Root Mean Squared Error -- train: 0.41084006428718567, -- test: 0.747502326965332 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -1.0232828855514526, -- test: -4.467099189758301 \n",
      "Root Mean Squared Error -- train: 0.4184242784976959, -- test: 0.7532110214233398 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 1 \n",
      "Test Log Likelihood of all sampled models: -4.8606181144714355\n",
      "Test Root MSE of all sampled models: 0.78239905834198\n",
      "********************************************************************** \n",
      "\n",
      "********************  End of E step  ********************\n",
      "Number of all sampled models in window: 99 \n",
      "Test Log Likelihood of all models in window: -4.196512222290039\n",
      "Test Root MSE of all models in window: 0.7626407742500305\n",
      "\n",
      "############### EM step 300 of total 300 steps, M Step:  ###############\n",
      "**********************************************************************\n",
      "Q function is -1.233503818511963 averaged by 1 samples.\n",
      "********************************************************************** \n",
      "\n",
      "############### After 300 EM steps, fixing hyperparams and sample from posterior. ###############\n",
      "Sampling Epoch: 99\n",
      "Mean Log Likelihood -- train: -0.9585915207862854, -- test: -4.4187331199646 \n",
      "Root Mean Squared Error -- train: 0.4099660813808441, -- test: 0.7506445646286011 \n",
      "\n",
      "Sampling Epoch: 199\n",
      "Mean Log Likelihood -- train: -0.9582170248031616, -- test: -4.444234371185303 \n",
      "Root Mean Squared Error -- train: 0.40991389751434326, -- test: 0.7525832056999207 \n",
      "\n",
      "Sampling Epoch: 299\n",
      "Mean Log Likelihood -- train: -0.9554883241653442, -- test: -4.416261196136475 \n",
      "Root Mean Squared Error -- train: 0.4095333516597748, -- test: 0.7504563927650452 \n",
      "\n",
      "Sampling Epoch: 399\n",
      "Mean Log Likelihood -- train: -0.959195077419281, -- test: -4.4497857093811035 \n",
      "Root Mean Squared Error -- train: 0.4100501835346222, -- test: 0.7530044913291931 \n",
      "\n",
      "Sampling Epoch: 499\n",
      "Mean Log Likelihood -- train: -0.9681609272956848, -- test: -4.400170803070068 \n",
      "Root Mean Squared Error -- train: 0.41129758954048157, -- test: 0.7492304444313049 \n",
      "\n",
      "Sampling Epoch: 599\n",
      "Mean Log Likelihood -- train: -0.9531701803207397, -- test: -4.478410243988037 \n",
      "Root Mean Squared Error -- train: 0.40920981764793396, -- test: 0.7551733255386353 \n",
      "\n",
      "Sampling Epoch: 699\n",
      "Mean Log Likelihood -- train: -0.9686218500137329, -- test: -4.5272297859191895 \n",
      "Root Mean Squared Error -- train: 0.41136160492897034, -- test: 0.7588579654693604 \n",
      "\n",
      "Sampling Epoch: 799\n",
      "Mean Log Likelihood -- train: -0.9606747627258301, -- test: -4.4986572265625 \n",
      "Root Mean Squared Error -- train: 0.4102562963962555, -- test: 0.7567036151885986 \n",
      "\n",
      "Sampling Epoch: 899\n",
      "Mean Log Likelihood -- train: -0.9585573077201843, -- test: -4.486631870269775 \n",
      "Root Mean Squared Error -- train: 0.4099613130092621, -- test: 0.7557950615882874 \n",
      "\n",
      "Sampling Epoch: 999\n",
      "Mean Log Likelihood -- train: -0.9546159505844116, -- test: -4.574195384979248 \n",
      "Root Mean Squared Error -- train: 0.40941163897514343, -- test: 0.762385904788971 \n",
      "\n",
      "#################### Sample No.1 at Epoch 1049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.2 at Epoch 1099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1099\n",
      "Mean Log Likelihood -- train: -1.0263135433197021, -- test: -4.616523742675781 \n",
      "Root Mean Squared Error -- train: 0.41929805278778076, -- test: 0.7655515074729919 \n",
      "\n",
      "#################### Sample No.3 at Epoch 1149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.4 at Epoch 1199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1199\n",
      "Mean Log Likelihood -- train: -1.0151242017745972, -- test: -4.334960460662842 \n",
      "Root Mean Squared Error -- train: 0.4177705943584442, -- test: 0.7442408800125122 \n",
      "\n",
      "#################### Sample No.5 at Epoch 1249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.6 at Epoch 1299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1299\n",
      "Mean Log Likelihood -- train: -1.0118330717086792, -- test: -4.4032063484191895 \n",
      "Root Mean Squared Error -- train: 0.417320191860199, -- test: 0.749461829662323 \n",
      "\n",
      "#################### Sample No.7 at Epoch 1349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.8 at Epoch 1399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1399\n",
      "Mean Log Likelihood -- train: -1.0130486488342285, -- test: -5.342839241027832 \n",
      "Root Mean Squared Error -- train: 0.41748660802841187, -- test: 0.8179646730422974 \n",
      "\n",
      "#################### Sample No.9 at Epoch 1449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.10 at Epoch 1499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1499\n",
      "Mean Log Likelihood -- train: -1.0210245847702026, -- test: -4.395875930786133 \n",
      "Root Mean Squared Error -- train: 0.418576717376709, -- test: 0.7489027976989746 \n",
      "\n",
      "#################### Sample No.11 at Epoch 1549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.12 at Epoch 1599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1599\n",
      "Mean Log Likelihood -- train: -0.9900189638137817, -- test: -4.64585542678833 \n",
      "Root Mean Squared Error -- train: 0.4143228530883789, -- test: 0.7677375078201294 \n",
      "\n",
      "#################### Sample No.13 at Epoch 1649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.14 at Epoch 1699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1699\n",
      "Mean Log Likelihood -- train: -1.0208847522735596, -- test: -5.810390472412109 \n",
      "Root Mean Squared Error -- train: 0.41855767369270325, -- test: 0.8499964475631714 \n",
      "\n",
      "#################### Sample No.15 at Epoch 1749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.16 at Epoch 1799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1799\n",
      "Mean Log Likelihood -- train: -1.0794185400009155, -- test: -4.403625011444092 \n",
      "Root Mean Squared Error -- train: 0.4264730215072632, -- test: 0.7494937777519226 \n",
      "\n",
      "#################### Sample No.17 at Epoch 1849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.18 at Epoch 1899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1899\n",
      "Mean Log Likelihood -- train: -1.0505489110946655, -- test: -4.1289286613464355 \n",
      "Root Mean Squared Error -- train: 0.4225875735282898, -- test: 0.7282520532608032 \n",
      "\n",
      "#################### Sample No.19 at Epoch 1949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.20 at Epoch 1999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 1999\n",
      "Mean Log Likelihood -- train: -1.0949167013168335, -- test: -5.622308254241943 \n",
      "Root Mean Squared Error -- train: 0.4285443425178528, -- test: 0.8372582793235779 \n",
      "\n",
      "#################### Sample No.21 at Epoch 2049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.22 at Epoch 2099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2099\n",
      "Mean Log Likelihood -- train: -1.046055555343628, -- test: -5.042645454406738 \n",
      "Root Mean Squared Error -- train: 0.4219796359539032, -- test: 0.7967198491096497 \n",
      "\n",
      "#################### Sample No.23 at Epoch 2149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.24 at Epoch 2199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2199\n",
      "Mean Log Likelihood -- train: -1.051145315170288, -- test: -4.104744911193848 \n",
      "Root Mean Squared Error -- train: 0.4226682484149933, -- test: 0.7263520956039429 \n",
      "\n",
      "#################### Sample No.25 at Epoch 2249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.26 at Epoch 2299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2299\n",
      "Mean Log Likelihood -- train: -1.034688949584961, -- test: -6.008368968963623 \n",
      "Root Mean Squared Error -- train: 0.4204377830028534, -- test: 0.8632016777992249 \n",
      "\n",
      "#################### Sample No.27 at Epoch 2349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.28 at Epoch 2399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2399\n",
      "Mean Log Likelihood -- train: -1.039980173110962, -- test: -7.056905746459961 \n",
      "Root Mean Squared Error -- train: 0.42115625739097595, -- test: 0.9300187230110168 \n",
      "\n",
      "#################### Sample No.29 at Epoch 2449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.30 at Epoch 2499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2499\n",
      "Mean Log Likelihood -- train: -1.0209813117980957, -- test: -4.696455478668213 \n",
      "Root Mean Squared Error -- train: 0.4185708165168762, -- test: 0.7714940309524536 \n",
      "\n",
      "#################### Sample No.31 at Epoch 2549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.32 at Epoch 2599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2599\n",
      "Mean Log Likelihood -- train: -1.020438551902771, -- test: -5.019873142242432 \n",
      "Root Mean Squared Error -- train: 0.4184967577457428, -- test: 0.7950851917266846 \n",
      "\n",
      "#################### Sample No.33 at Epoch 2649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.34 at Epoch 2699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2699\n",
      "Mean Log Likelihood -- train: -1.0370606184005737, -- test: -4.4279465675354 \n",
      "Root Mean Squared Error -- train: 0.42075997591018677, -- test: 0.7513455748558044 \n",
      "\n",
      "#################### Sample No.35 at Epoch 2749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.36 at Epoch 2799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2799\n",
      "Mean Log Likelihood -- train: -1.021718978881836, -- test: -5.172723770141602 \n",
      "Root Mean Squared Error -- train: 0.41867151856422424, -- test: 0.8059943318367004 \n",
      "\n",
      "#################### Sample No.37 at Epoch 2849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.38 at Epoch 2899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2899\n",
      "Mean Log Likelihood -- train: -1.0597996711730957, -- test: -3.7473843097686768 \n",
      "Root Mean Squared Error -- train: 0.42383649945259094, -- test: 0.6976757049560547 \n",
      "\n",
      "#################### Sample No.39 at Epoch 2949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.40 at Epoch 2999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 2999\n",
      "Mean Log Likelihood -- train: -1.0525150299072266, -- test: -4.723618984222412 \n",
      "Root Mean Squared Error -- train: 0.42285335063934326, -- test: 0.7735030651092529 \n",
      "\n",
      "#################### Sample No.41 at Epoch 3049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.42 at Epoch 3099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3099\n",
      "Mean Log Likelihood -- train: -1.057687759399414, -- test: -4.559513092041016 \n",
      "Root Mean Squared Error -- train: 0.4235517084598541, -- test: 0.7612847685813904 \n",
      "\n",
      "#################### Sample No.43 at Epoch 3149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.44 at Epoch 3199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3199\n",
      "Mean Log Likelihood -- train: -1.055738925933838, -- test: -4.376816272735596 \n",
      "Root Mean Squared Error -- train: 0.4232887625694275, -- test: 0.7474472522735596 \n",
      "\n",
      "#################### Sample No.45 at Epoch 3249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.46 at Epoch 3299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3299\n",
      "Mean Log Likelihood -- train: -1.1389148235321045, -- test: -4.3597092628479 \n",
      "Root Mean Squared Error -- train: 0.4343707859516144, -- test: 0.7461384534835815 \n",
      "\n",
      "#################### Sample No.47 at Epoch 3349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.48 at Epoch 3399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3399\n",
      "Mean Log Likelihood -- train: -1.1601614952087402, -- test: -3.4895544052124023 \n",
      "Root Mean Squared Error -- train: 0.4371565580368042, -- test: 0.676231324672699 \n",
      "\n",
      "#################### Sample No.49 at Epoch 3449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.50 at Epoch 3499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3499\n",
      "Mean Log Likelihood -- train: -1.0337345600128174, -- test: -4.52557373046875 \n",
      "Root Mean Squared Error -- train: 0.42030805349349976, -- test: 0.7587332725524902 \n",
      "\n",
      "#################### Sample No.51 at Epoch 3549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.52 at Epoch 3599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3599\n",
      "Mean Log Likelihood -- train: -1.0995856523513794, -- test: -3.9484808444976807 \n",
      "Root Mean Squared Error -- train: 0.42916637659072876, -- test: 0.7139544486999512 \n",
      "\n",
      "#################### Sample No.53 at Epoch 3649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.54 at Epoch 3699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3699\n",
      "Mean Log Likelihood -- train: -1.0332437753677368, -- test: -4.630542755126953 \n",
      "Root Mean Squared Error -- train: 0.4202413558959961, -- test: 0.7665970921516418 \n",
      "\n",
      "#################### Sample No.55 at Epoch 3749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.56 at Epoch 3799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3799\n",
      "Mean Log Likelihood -- train: -1.0253310203552246, -- test: -3.629204034805298 \n",
      "Root Mean Squared Error -- train: 0.41916418075561523, -- test: 0.6879292726516724 \n",
      "\n",
      "#################### Sample No.57 at Epoch 3849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.58 at Epoch 3899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3899\n",
      "Mean Log Likelihood -- train: -1.0391556024551392, -- test: -5.18800163269043 \n",
      "Root Mean Squared Error -- train: 0.42104434967041016, -- test: 0.8070765733718872 \n",
      "\n",
      "#################### Sample No.59 at Epoch 3949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.60 at Epoch 3999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 3999\n",
      "Mean Log Likelihood -- train: -1.009313702583313, -- test: -3.8830926418304443 \n",
      "Root Mean Squared Error -- train: 0.41697511076927185, -- test: 0.7087022662162781 \n",
      "\n",
      "#################### Sample No.61 at Epoch 4049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.62 at Epoch 4099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4099\n",
      "Mean Log Likelihood -- train: -1.0115602016448975, -- test: -4.534711837768555 \n",
      "Root Mean Squared Error -- train: 0.4172828495502472, -- test: 0.7594211101531982 \n",
      "\n",
      "#################### Sample No.63 at Epoch 4149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.64 at Epoch 4199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4199\n",
      "Mean Log Likelihood -- train: -1.0374115705490112, -- test: -4.861575603485107 \n",
      "Root Mean Squared Error -- train: 0.4208076596260071, -- test: 0.7836271524429321 \n",
      "\n",
      "#################### Sample No.65 at Epoch 4249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.66 at Epoch 4299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4299\n",
      "Mean Log Likelihood -- train: -1.0448894500732422, -- test: -6.772767543792725 \n",
      "Root Mean Squared Error -- train: 0.4218217134475708, -- test: 0.9123957753181458 \n",
      "\n",
      "#################### Sample No.67 at Epoch 4349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.68 at Epoch 4399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4399\n",
      "Mean Log Likelihood -- train: -1.0133877992630005, -- test: -6.453123569488525 \n",
      "Root Mean Squared Error -- train: 0.4175330102443695, -- test: 0.8921546339988708 \n",
      "\n",
      "#################### Sample No.69 at Epoch 4449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.70 at Epoch 4499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4499\n",
      "Mean Log Likelihood -- train: -1.0319322347640991, -- test: -4.544872283935547 \n",
      "Root Mean Squared Error -- train: 0.42006298899650574, -- test: 0.7601851224899292 \n",
      "\n",
      "#################### Sample No.71 at Epoch 4549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.72 at Epoch 4599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4599\n",
      "Mean Log Likelihood -- train: -1.036797046661377, -- test: -5.787053108215332 \n",
      "Root Mean Squared Error -- train: 0.42072418332099915, -- test: 0.8484262824058533 \n",
      "\n",
      "#################### Sample No.73 at Epoch 4649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.74 at Epoch 4699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4699\n",
      "Mean Log Likelihood -- train: -1.013820767402649, -- test: -4.510636806488037 \n",
      "Root Mean Squared Error -- train: 0.41759222745895386, -- test: 0.7576075792312622 \n",
      "\n",
      "#################### Sample No.75 at Epoch 4749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.76 at Epoch 4799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4799\n",
      "Mean Log Likelihood -- train: -1.026124358177185, -- test: -4.5390305519104 \n",
      "Root Mean Squared Error -- train: 0.4192723035812378, -- test: 0.7597459554672241 \n",
      "\n",
      "#################### Sample No.77 at Epoch 4849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.78 at Epoch 4899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4899\n",
      "Mean Log Likelihood -- train: -1.0394418239593506, -- test: -4.748428821563721 \n",
      "Root Mean Squared Error -- train: 0.4210832118988037, -- test: 0.7753335237503052 \n",
      "\n",
      "#################### Sample No.79 at Epoch 4949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.80 at Epoch 4999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 4999\n",
      "Mean Log Likelihood -- train: -1.0213133096694946, -- test: -4.586243152618408 \n",
      "Root Mean Squared Error -- train: 0.4186161458492279, -- test: 0.7632882595062256 \n",
      "\n",
      "#################### Sample No.81 at Epoch 5049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.82 at Epoch 5099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5099\n",
      "Mean Log Likelihood -- train: -1.1765079498291016, -- test: -4.0452046394348145 \n",
      "Root Mean Squared Error -- train: 0.43928784132003784, -- test: 0.721653401851654 \n",
      "\n",
      "#################### Sample No.83 at Epoch 5149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.84 at Epoch 5199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5199\n",
      "Mean Log Likelihood -- train: -1.0825233459472656, -- test: -4.776190757751465 \n",
      "Root Mean Squared Error -- train: 0.4268887937068939, -- test: 0.777376651763916 \n",
      "\n",
      "#################### Sample No.85 at Epoch 5249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.86 at Epoch 5299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5299\n",
      "Mean Log Likelihood -- train: -1.0756797790527344, -- test: -5.32417106628418 \n",
      "Root Mean Squared Error -- train: 0.4259718656539917, -- test: 0.8166596293449402 \n",
      "\n",
      "#################### Sample No.87 at Epoch 5349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.88 at Epoch 5399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5399\n",
      "Mean Log Likelihood -- train: -1.0346131324768066, -- test: -4.557048797607422 \n",
      "Root Mean Squared Error -- train: 0.42042750120162964, -- test: 0.7610997557640076 \n",
      "\n",
      "#################### Sample No.89 at Epoch 5449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.90 at Epoch 5499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5499\n",
      "Mean Log Likelihood -- train: -1.0712838172912598, -- test: -7.088235855102539 \n",
      "Root Mean Squared Error -- train: 0.4253818392753601, -- test: 0.931941568851471 \n",
      "\n",
      "#################### Sample No.91 at Epoch 5549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.92 at Epoch 5599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5599\n",
      "Mean Log Likelihood -- train: -1.0484737157821655, -- test: -6.529318332672119 \n",
      "Root Mean Squared Error -- train: 0.42230692505836487, -- test: 0.8970210552215576 \n",
      "\n",
      "#################### Sample No.93 at Epoch 5649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.94 at Epoch 5699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5699\n",
      "Mean Log Likelihood -- train: -1.031101942062378, -- test: -5.960944175720215 \n",
      "Root Mean Squared Error -- train: 0.41995006799697876, -- test: 0.8600568771362305 \n",
      "\n",
      "#################### Sample No.95 at Epoch 5749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.96 at Epoch 5799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5799\n",
      "Mean Log Likelihood -- train: -1.0222668647766113, -- test: -4.7220234870910645 \n",
      "Root Mean Squared Error -- train: 0.4187462627887726, -- test: 0.773385226726532 \n",
      "\n",
      "#################### Sample No.97 at Epoch 5849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.98 at Epoch 5899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5899\n",
      "Mean Log Likelihood -- train: -1.008888840675354, -- test: -4.668535232543945 \n",
      "Root Mean Squared Error -- train: 0.41691693663597107, -- test: 0.7694235444068909 \n",
      "\n",
      "#################### Sample No.99 at Epoch 5949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.100 at Epoch 5999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 5999\n",
      "Mean Log Likelihood -- train: -1.045330286026001, -- test: -4.3995466232299805 \n",
      "Root Mean Squared Error -- train: 0.42188140749931335, -- test: 0.7491827607154846 \n",
      "\n",
      "#################### Sample No.101 at Epoch 6049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.102 at Epoch 6099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 6099\n",
      "Mean Log Likelihood -- train: -1.053976058959961, -- test: -5.657590866088867 \n",
      "Root Mean Squared Error -- train: 0.4230507016181946, -- test: 0.8396625518798828 \n",
      "\n",
      "#################### Sample No.103 at Epoch 6149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.104 at Epoch 6199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 6199\n",
      "Mean Log Likelihood -- train: -1.0166963338851929, -- test: -5.388400077819824 \n",
      "Root Mean Squared Error -- train: 0.4179855287075043, -- test: 0.8211410045623779 \n",
      "\n",
      "#################### Sample No.105 at Epoch 6249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.106 at Epoch 6299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 6299\n",
      "Mean Log Likelihood -- train: -1.0631847381591797, -- test: -5.256366729736328 \n",
      "Root Mean Squared Error -- train: 0.42429259419441223, -- test: 0.8119019865989685 \n",
      "\n",
      "#################### Sample No.107 at Epoch 6349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.108 at Epoch 6399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 6399\n",
      "Mean Log Likelihood -- train: -1.0051110982894897, -- test: -5.599240779876709 \n",
      "Root Mean Squared Error -- train: 0.41639891266822815, -- test: 0.8356826305389404 \n",
      "\n",
      "#################### Sample No.109 at Epoch 6449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.110 at Epoch 6499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 6499\n",
      "Mean Log Likelihood -- train: -1.0099689960479736, -- test: -5.099371433258057 \n",
      "Root Mean Squared Error -- train: 0.417064905166626, -- test: 0.8007776141166687 \n",
      "\n",
      "#################### Sample No.111 at Epoch 6549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.112 at Epoch 6599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 6599\n",
      "Mean Log Likelihood -- train: -1.0490281581878662, -- test: -4.489429473876953 \n",
      "Root Mean Squared Error -- train: 0.4223819077014923, -- test: 0.7560064792633057 \n",
      "\n",
      "#################### Sample No.113 at Epoch 6649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.114 at Epoch 6699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 6699\n",
      "Mean Log Likelihood -- train: -1.0218347311019897, -- test: -5.442533493041992 \n",
      "Root Mean Squared Error -- train: 0.4186873137950897, -- test: 0.8248990178108215 \n",
      "\n",
      "#################### Sample No.115 at Epoch 6749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.116 at Epoch 6799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 6799\n",
      "Mean Log Likelihood -- train: -0.9961689114570618, -- test: -5.241392135620117 \n",
      "Root Mean Squared Error -- train: 0.4151700735092163, -- test: 0.8108475208282471 \n",
      "\n",
      "#################### Sample No.117 at Epoch 6849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.118 at Epoch 6899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 6899\n",
      "Mean Log Likelihood -- train: -1.0352131128311157, -- test: -4.816952228546143 \n",
      "Root Mean Squared Error -- train: 0.42050901055336, -- test: 0.7803667783737183 \n",
      "\n",
      "#################### Sample No.119 at Epoch 6949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.120 at Epoch 6999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 6999\n",
      "Mean Log Likelihood -- train: -1.040067434310913, -- test: -3.976425886154175 \n",
      "Root Mean Squared Error -- train: 0.4211680591106415, -- test: 0.7161873579025269 \n",
      "\n",
      "#################### Sample No.121 at Epoch 7049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.122 at Epoch 7099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 7099\n",
      "Mean Log Likelihood -- train: -1.0403579473495483, -- test: -5.808151721954346 \n",
      "Root Mean Squared Error -- train: 0.4212075173854828, -- test: 0.8498458862304688 \n",
      "\n",
      "#################### Sample No.123 at Epoch 7149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.124 at Epoch 7199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 7199\n",
      "Mean Log Likelihood -- train: -1.0384678840637207, -- test: -4.3895182609558105 \n",
      "Root Mean Squared Error -- train: 0.4209510385990143, -- test: 0.7484175562858582 \n",
      "\n",
      "#################### Sample No.125 at Epoch 7249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.126 at Epoch 7299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 7299\n",
      "Mean Log Likelihood -- train: -1.0203436613082886, -- test: -4.053519248962402 \n",
      "Root Mean Squared Error -- train: 0.41848379373550415, -- test: 0.7223114371299744 \n",
      "\n",
      "#################### Sample No.127 at Epoch 7349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.128 at Epoch 7399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 7399\n",
      "Mean Log Likelihood -- train: -1.0311967134475708, -- test: -3.755889892578125 \n",
      "Root Mean Squared Error -- train: 0.41996297240257263, -- test: 0.698371946811676 \n",
      "\n",
      "#################### Sample No.129 at Epoch 7449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.130 at Epoch 7499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 7499\n",
      "Mean Log Likelihood -- train: -1.0532819032669067, -- test: -4.650006294250488 \n",
      "Root Mean Squared Error -- train: 0.4229569435119629, -- test: 0.7680463790893555 \n",
      "\n",
      "#################### Sample No.131 at Epoch 7549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.132 at Epoch 7599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 7599\n",
      "Mean Log Likelihood -- train: -1.0279408693313599, -- test: -4.244992256164551 \n",
      "Root Mean Squared Error -- train: 0.4195197522640228, -- test: 0.7373015880584717 \n",
      "\n",
      "#################### Sample No.133 at Epoch 7649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.134 at Epoch 7699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 7699\n",
      "Mean Log Likelihood -- train: -1.0497721433639526, -- test: -5.210899829864502 \n",
      "Root Mean Squared Error -- train: 0.42248255014419556, -- test: 0.8086960315704346 \n",
      "\n",
      "#################### Sample No.135 at Epoch 7749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.136 at Epoch 7799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 7799\n",
      "Mean Log Likelihood -- train: -1.0245434045791626, -- test: -6.433014392852783 \n",
      "Root Mean Squared Error -- train: 0.41905680298805237, -- test: 0.8908659219741821 \n",
      "\n",
      "#################### Sample No.137 at Epoch 7849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.138 at Epoch 7899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 7899\n",
      "Mean Log Likelihood -- train: -1.0214589834213257, -- test: -3.8490514755249023 \n",
      "Root Mean Squared Error -- train: 0.4186360538005829, -- test: 0.7059525847434998 \n",
      "\n",
      "#################### Sample No.139 at Epoch 7949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.140 at Epoch 7999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 7999\n",
      "Mean Log Likelihood -- train: -1.0856598615646362, -- test: -3.7950406074523926 \n",
      "Root Mean Squared Error -- train: 0.4273083806037903, -- test: 0.7015675902366638 \n",
      "\n",
      "#################### Sample No.141 at Epoch 8049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.142 at Epoch 8099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 8099\n",
      "Mean Log Likelihood -- train: -1.0387860536575317, -- test: -3.905940532684326 \n",
      "Root Mean Squared Error -- train: 0.42099422216415405, -- test: 0.7105419039726257 \n",
      "\n",
      "#################### Sample No.143 at Epoch 8149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.144 at Epoch 8199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 8199\n",
      "Mean Log Likelihood -- train: -1.000526785850525, -- test: -4.067785263061523 \n",
      "Root Mean Squared Error -- train: 0.4157693684101105, -- test: 0.7234390377998352 \n",
      "\n",
      "#################### Sample No.145 at Epoch 8249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.146 at Epoch 8299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 8299\n",
      "Mean Log Likelihood -- train: -1.0155060291290283, -- test: -3.4320788383483887 \n",
      "Root Mean Squared Error -- train: 0.41782277822494507, -- test: 0.6713575720787048 \n",
      "\n",
      "#################### Sample No.147 at Epoch 8349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.148 at Epoch 8399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 8399\n",
      "Mean Log Likelihood -- train: -1.0316405296325684, -- test: -3.9509241580963135 \n",
      "Root Mean Squared Error -- train: 0.4200233221054077, -- test: 0.7141498923301697 \n",
      "\n",
      "#################### Sample No.149 at Epoch 8449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.150 at Epoch 8499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 8499\n",
      "Mean Log Likelihood -- train: -1.021646499633789, -- test: -4.586943626403809 \n",
      "Root Mean Squared Error -- train: 0.41866162419319153, -- test: 0.7633407115936279 \n",
      "\n",
      "#################### Sample No.151 at Epoch 8549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.152 at Epoch 8599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 8599\n",
      "Mean Log Likelihood -- train: -1.0192033052444458, -- test: -6.059572219848633 \n",
      "Root Mean Squared Error -- train: 0.41832807660102844, -- test: 0.866584300994873 \n",
      "\n",
      "#################### Sample No.153 at Epoch 8649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.154 at Epoch 8699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 8699\n",
      "Mean Log Likelihood -- train: -1.0263516902923584, -- test: -4.888206958770752 \n",
      "Root Mean Squared Error -- train: 0.4193032383918762, -- test: 0.785566508769989 \n",
      "\n",
      "#################### Sample No.155 at Epoch 8749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.156 at Epoch 8799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 8799\n",
      "Mean Log Likelihood -- train: -1.0893133878707886, -- test: -4.400296688079834 \n",
      "Root Mean Squared Error -- train: 0.4277966022491455, -- test: 0.749239981174469 \n",
      "\n",
      "#################### Sample No.157 at Epoch 8849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.158 at Epoch 8899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 8899\n",
      "Mean Log Likelihood -- train: -1.0565035343170166, -- test: -3.8284406661987305 \n",
      "Root Mean Squared Error -- train: 0.4233919382095337, -- test: 0.7042824029922485 \n",
      "\n",
      "#################### Sample No.159 at Epoch 8949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.160 at Epoch 8999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 8999\n",
      "Mean Log Likelihood -- train: -1.008078932762146, -- test: -4.819842338562012 \n",
      "Root Mean Squared Error -- train: 0.4168058931827545, -- test: 0.7805783748626709 \n",
      "\n",
      "#################### Sample No.161 at Epoch 9049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.162 at Epoch 9099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 9099\n",
      "Mean Log Likelihood -- train: -0.9992960095405579, -- test: -4.1559157371521 \n",
      "Root Mean Squared Error -- train: 0.4156002104282379, -- test: 0.7303662300109863 \n",
      "\n",
      "#################### Sample No.163 at Epoch 9149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.164 at Epoch 9199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 9199\n",
      "Mean Log Likelihood -- train: -1.024800181388855, -- test: -5.298030376434326 \n",
      "Root Mean Squared Error -- train: 0.4190917909145355, -- test: 0.8148286938667297 \n",
      "\n",
      "#################### Sample No.165 at Epoch 9249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.166 at Epoch 9299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 9299\n",
      "Mean Log Likelihood -- train: -1.0214260816574097, -- test: -4.5465617179870605 \n",
      "Root Mean Squared Error -- train: 0.41863158345222473, -- test: 0.7603120803833008 \n",
      "\n",
      "#################### Sample No.167 at Epoch 9349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.168 at Epoch 9399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 9399\n",
      "Mean Log Likelihood -- train: -1.0301687717437744, -- test: -5.078775405883789 \n",
      "Root Mean Squared Error -- train: 0.4198230504989624, -- test: 0.7993068099021912 \n",
      "\n",
      "#################### Sample No.169 at Epoch 9449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.170 at Epoch 9499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 9499\n",
      "Mean Log Likelihood -- train: -1.0503262281417847, -- test: -4.434164524078369 \n",
      "Root Mean Squared Error -- train: 0.4225574731826782, -- test: 0.7518181800842285 \n",
      "\n",
      "#################### Sample No.171 at Epoch 9549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.172 at Epoch 9599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 9599\n",
      "Mean Log Likelihood -- train: -1.0352205038070679, -- test: -5.388844013214111 \n",
      "Root Mean Squared Error -- train: 0.42051002383232117, -- test: 0.8211718797683716 \n",
      "\n",
      "#################### Sample No.173 at Epoch 9649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.174 at Epoch 9699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 9699\n",
      "Mean Log Likelihood -- train: -1.0484402179718018, -- test: -4.52333927154541 \n",
      "Root Mean Squared Error -- train: 0.4223024249076843, -- test: 0.7585649490356445 \n",
      "\n",
      "#################### Sample No.175 at Epoch 9749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.176 at Epoch 9799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 9799\n",
      "Mean Log Likelihood -- train: -1.058472990989685, -- test: -6.194785118103027 \n",
      "Root Mean Squared Error -- train: 0.4236575961112976, -- test: 0.8754535913467407 \n",
      "\n",
      "#################### Sample No.177 at Epoch 9849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.178 at Epoch 9899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 9899\n",
      "Mean Log Likelihood -- train: -1.0243030786514282, -- test: -5.8470139503479 \n",
      "Root Mean Squared Error -- train: 0.4190240204334259, -- test: 0.8524546027183533 \n",
      "\n",
      "#################### Sample No.179 at Epoch 9949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.180 at Epoch 9999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 9999\n",
      "Mean Log Likelihood -- train: -1.0389988422393799, -- test: -5.645502090454102 \n",
      "Root Mean Squared Error -- train: 0.42102310061454773, -- test: 0.838839590549469 \n",
      "\n",
      "#################### Sample No.181 at Epoch 10049  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.182 at Epoch 10099  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 10099\n",
      "Mean Log Likelihood -- train: -1.0088576078414917, -- test: -4.573423385620117 \n",
      "Root Mean Squared Error -- train: 0.41691267490386963, -- test: 0.7623279690742493 \n",
      "\n",
      "#################### Sample No.183 at Epoch 10149  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.184 at Epoch 10199  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 10199\n",
      "Mean Log Likelihood -- train: -1.041039228439331, -- test: -4.456625461578369 \n",
      "Root Mean Squared Error -- train: 0.42129990458488464, -- test: 0.7535232901573181 \n",
      "\n",
      "#################### Sample No.185 at Epoch 10249  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.186 at Epoch 10299  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 10299\n",
      "Mean Log Likelihood -- train: -1.0596588850021362, -- test: -4.188169956207275 \n",
      "Root Mean Squared Error -- train: 0.42381754517555237, -- test: 0.7328851222991943 \n",
      "\n",
      "#################### Sample No.187 at Epoch 10349  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.188 at Epoch 10399  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 10399\n",
      "Mean Log Likelihood -- train: -1.0253957509994507, -- test: -5.865459442138672 \n",
      "Root Mean Squared Error -- train: 0.4191729724407196, -- test: 0.853689968585968 \n",
      "\n",
      "#################### Sample No.189 at Epoch 10449  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.190 at Epoch 10499  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 10499\n",
      "Mean Log Likelihood -- train: -1.0048476457595825, -- test: -5.853183746337891 \n",
      "Root Mean Squared Error -- train: 0.4163627028465271, -- test: 0.8528680801391602 \n",
      "\n",
      "#################### Sample No.191 at Epoch 10549  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.192 at Epoch 10599  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 10599\n",
      "Mean Log Likelihood -- train: -1.009021282196045, -- test: -4.7727437019348145 \n",
      "Root Mean Squared Error -- train: 0.4169350862503052, -- test: 0.777123212814331 \n",
      "\n",
      "#################### Sample No.193 at Epoch 10649  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.194 at Epoch 10699  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 10699\n",
      "Mean Log Likelihood -- train: -1.0582621097564697, -- test: -5.023716926574707 \n",
      "Root Mean Squared Error -- train: 0.42362919449806213, -- test: 0.795361340045929 \n",
      "\n",
      "#################### Sample No.195 at Epoch 10749  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.196 at Epoch 10799  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 10799\n",
      "Mean Log Likelihood -- train: -1.0157395601272583, -- test: -6.117623805999756 \n",
      "Root Mean Squared Error -- train: 0.4178547263145447, -- test: 0.8704032897949219 \n",
      "\n",
      "#################### Sample No.197 at Epoch 10849  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.198 at Epoch 10899  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 10899\n",
      "Mean Log Likelihood -- train: -1.0588873624801636, -- test: -5.167773246765137 \n",
      "Root Mean Squared Error -- train: 0.4237135052680969, -- test: 0.8056433200836182 \n",
      "\n",
      "#################### Sample No.199 at Epoch 10949  lr = 6.087738091409278e-10 ####################\n",
      "#################### Sample No.200 at Epoch 10999  lr = 6.087738091409278e-10 ####################\n",
      "Sampling Epoch: 10999\n",
      "Mean Log Likelihood -- train: -1.0170167684555054, -- test: -5.6608076095581055 \n",
      "Root Mean Squared Error -- train: 0.4180293381214142, -- test: 0.839881420135498 \n",
      "\n",
      "********************  End of Sampling  ********************\n",
      "Number of sampled models: 200 \n",
      "Test Log Likelihood of all sampled models: -3.475693702697754\n",
      "Test Root MSE of all sampled models: 0.7875556945800781\n",
      "********************************************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MCEM with Moving Windows settings and training\n",
    "total_EM_steps = 300\n",
    "_, _, lines, W = MCEM_windows_demo(sampler_EM, maximizer, sampler_fixing_hyper, total_EM_steps, ds_train,\n",
    "                                   num_samples_fixing_hyper=200,\n",
    "                                   window_size=100, \n",
    "                                   print_epoch_cycle_EM=100, print_epoch_cycle_fixing=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.106294334>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.05896678], dtype=float32)>,\n",
       " <tf.Variable 'log_amplitude:0' shape=() dtype=float32, numpy=0.02263656>,\n",
       " <tf.Variable 'log_inv_length_scale:0' shape=(1,) dtype=float32, numpy=array([0.1062974], dtype=float32)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Omega_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6ae4429340>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2kAAAEvCAYAAADfFon+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd5wU5f3A8c9sb7d7vffCHeXo/WjSixURuxCNxhpjEhNNYsGfSUzUWEiMsWAMioqCgiDSlN65O8r13vvd7t32MvP7A8VCERscOO/XS+Fmn515dnZ4br7zPM/3ESRJQiaTyWQymUwmk8lkvYPiXFdAJpPJZDKZTCaTyWRfkIM0mUwmk8lkMplMJutF5CBNJpPJZDKZTCaTyXoROUiTyWQymUwmk8lksl5EDtJkMplMJpPJZDKZrBeRgzSZTCaTyWQymUwm60VU5+Kg4eHhUnJy8rk4tEwm+5EcPHiwXZKkiHNdj+9DbptksguT3D7JZLLe6HRt0zkJ0pKTkzlw4MC5OLRMJvuRCIJQc67r8H3JbZNMdmGS2yeZTNYbna5tkoc7ymQymUwmk8lkMlkvIgdpMplMJpPJZDKZTNaLyEGaTCa7YAmCkCAIwqeCIBQKglAgCMK957pOMplMJrdNMpnsm5yTOWkymUx2lviB30iSlCsIQhBwUBCEjZIkFZ7risnODz6fj/r6etxu97muiuwM6HQ64uPjUavV57oq3+QHaZvk6/P8ch5dn7JeQA7SZDLZBUuSpCag6bO/9wiCUATEAXKQJjsj9fX1BAUFkZycjCAI57o6stOQJImOjg7q6+tJSUk519U5rR+qbZKvz/PH+XR9ynoHebijTCb7SRAEIRkYAuw9x1WRnUfcbjdhYWHyDfB5QBAEwsLCzrtepe/TNsnX5/njfL0+ZeeOHKTJZLILniAIJmAF8CtJkrq/9tptgiAcEAThQFtb27mpoKxXk2+Azx/n23d1urbps9e/sX063z7zT5n8Xcm+DTlIk8lkFzRBENQcuwl6U5KklV9/XZKklyRJGi5J0vCIiPN6rVvZt3V4OTwzAB4NPvbn4eVfefmDvAaabW4O11spbuqmy+k961W0Wq288MIL3+m9s2fPxmq1nrbMww8/zKZNm77T/r+vMzn2li1b2LVr11mq0dn1TW0TyO3TT9XayrVMf286A18fyPT3prO2cu13KiM7v8lz0mQy2QVLOPbY8lWgSJKkf5zr+sh6kcPL4cNfgs917Gdb3bGfAQbO54O8Bh5ceYTnZ0UC4A2INHQdKxti0Jy1an4epN15550nvOb3+1GpTv1r/KOPPvrG/T/22GPfq37fx5kce8uWLZhMJsaOHXsWanT2yG2T7FTWVq7l0V2P4g4cGxbZ5Gji0V2PAjAndc4Zl5Gd/3p1T5qn0oZ9bxP2fU04DjTjKmjHU23Db/MgSdK5rp5MJuv9coAbgcmCIOR/9t/sc10pWS+w+bEvArTP+VzHtgNPri/B5Qt85WVRkmixnX4+yQd5DeQ88QkpD6wl54lP+CCv4XtV84EHHqCiooLBgwdz//33s2XLFsaPH8+ll15Kv379ALj88ssZNmwY/fv356WXXjr+3uTkZNrb26murqZv377ceuut9O/fn+nTp+NyHfvsCxcu5L333jte/pFHHmHo0KFkZ2dTXFwMQFtbG9OmTaN///78/Oc/Jykpifb29hPqajKZuO++++jfvz9Tpkzh8+F5+fn5jB49moEDB3LFFVfQ1dV1Rseurq7mxRdf5JlnnmHw4MFs376dd999lwEDBjBo0CAmTJjwvc7tOXbBtE3V1dVkZWWxcOFC+vTpw/XXX8+mTZvIyckhIyODffv24XA4uPnmmxk5ciRDhgxh1apVx987fvx4hg4dytChQ4/3mm7ZsoVJkyYxb948srKyuP76638y933P5T53PPj6nDvg5rnc575VGdn5r1f3pDlyW3AeaDnpa4JagSraiDYhCE2yGV16MAqDnNJUJpN9QZKkHYA8CUB2Ilv9abc3Wl0nfdkbEE+5y8973z4P7hqsLh5ceQSAy4fEfadqPvHEExw9epT8/Hzg2M1rbm4uR48ePZ4hbsmSJYSGhuJyuRgxYgRXXnklYWFhX9lPWVkZb731Fi+//DLz589nxYoV3HDDDSccLzw8nNzcXF544QWeeuopXnnlFRYtWsTkyZN58MEH+fjjj3n11VdPWleHw8Hw4cN55plneOyxx1i0aBH//Oc/uemmm1i8eDETJ07k4YcfZtGiRTz77LNndOzbb78dk8nEb3/7WwCys7NZv349cXFx3ziUsze70Nqm8vJy3n33XZYsWcKIESNYtmwZO3bsYPXq1fzlL3+hX79+TJ48mSVLlmC1Whk5ciRTp04lMjKSjRs3otPpKCsr49prr+XAgQMA5OXlUVBQQGxsLDk5OezcuZNx48ad40/642t2NH/j9jMpIzv/9eogLXhOKpZpSUgAAQnR5Ud0+PB3uvC3ufA2OnDsb8a+qxEUoEk0YxgUgX5gBEqjHLDJZDKZ7BQs8ceGOJ5sOxAbrKfhJIGaRnnqASgn631z+QI8ub7kOwdpJzNy5MivpPB+/vnnef/99wGoq6ujrKzshCAtJSWFwYMHAzBs2DCqq6tPuu+5c+ceL7Ny5bFpUjt27Di+/5kzZxISEnLS9yoUCq6++moAbrjhBubOnYvNZsNqtTJx4kQAFixYwFVXXXXGx/66nJwcFi5cyPz584+Xlx2z6MMCChtPyD3yvfSLNfPIJf2/sVxKSgrZ2dkAx3tSBUEgOzub6upq6uvrWb16NU899RRwLCtlbW0tsbGx3H333eTn56NUKiktLT2+z5EjRxIff+zf4+DBg6murv5JBGnRxmiaHE0n3f5tysjOf706SFPoVaA/WRW/+AUhBSS89T24SzpxFXRgXVWBdU0l+gHhmHJi0Saaz16FZTKZTHZ+mPLwV+ekAaj1x7YD98/IPN4L9jmFIBBl0Z1yl6fqfTvV9u/KaDQe//uWLVvYtGkTu3fvxmAwMGnSpJOm+NZqtcf/rlQqjw93PFU5pVKJ3+//XvX8tpnszuTYL774Inv37mXt2rUMGzaMgwcPnhCQys6+L19fCoXi+M8KhQK/349SqWTFihVkZmZ+5X2PPvooUVFRHDp0CFEU0el0J93nD3E9ni/uHXrvV+abAeiUOu4deu+3KiM7//XqIG3zm69TlbuXgMOOz+NBEAQEpRKdKQiD2Yw5PJLQ2HjCEpOIHZlF1LQkfE0OnAdbcBxswXWoDU2SGfPURLTpwXLqU5lMJpMdM3D+sT83P3ZsiKMl/liA9tn2z3u+VJ5W4FgPWpRFd9qkIafqfYsN1n/nagYFBdHT03PK1202GyEhIRgMBoqLi9mzZ893Ptap5OTksHz5cn7/+9+zYcOG43PKvk4URd577z2uueYali1bxrhx47BYLISEhLB9+3bGjx/P0qVLj/eqnYmgoCC6u7/oHaqoqGDUqFGMGjWKdevWUVdXJwdpnzmTHq9zZcaMGSxevJjFixcjCAJ5eXkMGTIEm81GfHw8CoWC119/nUAg8M07u8B9nvjjudznaHY0E22M5t6h934lIciZlJGd/3p1kFZj7aY+KBJ9SDShej2heg1BKgUepxOnrYuGkkKKdmw5Xj44KobkwUNJGzqSuMlD8RzqpGdrHe2vHkWTYib44jQ0caZz94FkMplM1nsMnP9FsHYSlw+Jo6iom+hQAy02N3WdTlps7lMGa5/3vn15yKNereT+GZknlD1TYWFh5OTkMGDAAGbNmsWcOV+9CZs5cyYvvvgiffv2JTMzk9GjR3/nY53KI488wrXXXsvSpUsZM2YM0dHRBAUFnVDOaDSyb98+Hn/8cSIjI3nnnXcAeP3117n99ttxOp2kpqby2muvnfGxL7nkEubNm8eqVatYvHgxzzzzDGVlZUiSxJQpUxg0aNAP9jllP56HHnqIX/3qVwwcOBBRFElJSWHNmjXceeedXHnllfzvf/9j5syZX+kl/imbkzrnGwOuOalzmGN3HHvQVLUP6n4PUxynbdNk5xfhXGTLGT58uPT5xNDTaW5upqysjKqqKmpqaggEAuj1evr378/gwYOJi4vD7/XQVlNFY2kxdYVHqD1yCL/Xgz7ITNa4iQyYOB19o4auzdX4XB70gyMIn5WBxnzqISsymezbEwThoCRJw891Pb6PM22bZD8dBw8dQRueiPil35UKQSAuRH/SQO2DvAaeXF9Co9VFbLCe+2dk/qDz0c4Fj8eDUqlEpVKxe/du7rjjjuOJTL7MZDJht9vPfgW/pqioiL59+35l24XaPp3ss8p6tx/sO/v6MiJwbMj2Jc/Lgdp55HRtU6/uSYuOjiY6Oprx48fj8XioqKigsLCQ/Px8Dhw4QGRkJKNGjSI7O5vYPn0ZfvEVuJwODmzdQlF+HruPFrGjpBK0OkQE0AJFx/5Tq9SEhoUSGRlJbGwsqampREZGykMiZTKZTHZct8tP2NceZn6eiv9kQdrlQ+LO+6Ds62pra5k/fz6iKKLRaHj55ZfPdZVkMtnplhGRg7QLQq8O0r5Mq9XSr18/+vXrh9vtpqCggH379vHhhx+yceNGUlNT8Xq91NTU4PP5AAhNSEEtBrA31uFz9GAJjyAtaxhinR9HjwO73U+Ns4YjR45NDg8KCmLQoEEMGjSIiIiIc/lxZTKZTNYLBMSTjzY5XSr+C01GRgZ5eXnfWK439KLJZD8Z37CMiOz816uDtKJdjbRUdWMwazAGawmJNhASY0Rv0jFs2DCSkpLYtGkTpaWlFBYWAhAXF0dOTg7xsbF4bF04u224HXZqDuVStm83BSVHSBwwmPHDr8a/z4rSrEV5VSz1nlaKiorYuXMnO3bsICMjg/Hjx5OYmHiOz4JMJpPJzhWl4uSjK06Xil8mk8l+dN+wjIjs/Nerg7SuJicVeW247b6vbNeEeXGZa+l0NaJUKskeMIBgvZbSvbvo2LOVj7auQ/B5AVCgxKQOwagyE6VIQB2kRawR2Vn9JoJGgaknhKD/hJJ5xSSGXHcddrudvLw89uzZw5IlS8jIyGDmzJly9iiZTCb7CTLrVSgE4YQ5aadLxS+TyWQ/um9YRkR2/uvVQdrYK9MZe2U6gYCIw+qhpqyRXfu209BZjeBUoe8JQd3VSnXxckT/sWEWEeFxBFv6ESxEEqONI0g0InD6eWYBKUD96oOUr91BxJQsxk3LYfTo0ezbt49t27bxr3/9i5ycHCZOnIhK1atPmUwmk8l+QAaNiugQPS02N96AeEap+GUymexH9w3LiMjOf+dFxOHzedl9YBt79+5FpVKRGR+LsyAPa2MdglKNztSHSMUAkoxxRKrVKABRBc2ClQpFNZGZcQzIGYLPqOWgz0OB00WRw01Nh5Vmu52AQoNOSMbgVxBjlYh+fQ99dRIzpwzknkGD2LRpE9u3b6esrIy5c+cSGRl5rk+JTCaTyc6SEINGDspkMlnv8w3LiMjOb716UL0kSRQWFvKvf/2L3bt3E2M2Yao8SuPG1ej0Omb87JcsuP7vXJZwBaOCkwk3aKnxS2zv8XMwzInm4i6cOfv5n+VTZldupH9hEdeX1fKXhja2WqtxqmpIDG0iWV2C2XUUtaKDUqPI8iQ9D8WaGFFUycU7SqnPGsmUq66mu7ubl156iUOHDp3rUyOTyWSynwCr1coLL7zwnd47e/ZsrFbracs8/PDDbNq06Tvt//s6k2Nv2bKFXbt2naUayb4t+fqUr0/Zj6dX96StWbOGgwcPEqTTYm6spLuok/QRYxg+7QqMNVrsO5pxBprRZYViGBWJO7KC8JbN+Jo2UkwQSxyXkqtdQECnIjbQyAT7DsZpXYzTmzHaVYgOHwG3C5+vA5/QScBnx61pR92dQFnXIA4rk8iNiePPzW2oJLhk+hUkFxzk/fffp6mpiWnTpqFUKs/1aZLJZDLZBerzm+A777zzhNf8fv9ph+B/9NFH37j/xx577HvV7/s4k2Nv2bIFk8nE2LFjz0KNZN+WfH3K16fsx9OrgzRVbTWm9iaktgbi1Hr6qUOxlGgRW5voEVTgLsdvLqZTWY21rgJfo40CYSgrVX+kOBCNCZHxlR6mlDoYYQlB7xmI0aP+xuNKiIRbKhhiOcC87v1U70tkd59BrBIlPLFZjItMxLlvK11dXcybNw+1+pv3KZPJZLKfgMPLf9A5Ig888AAVFRUMHjyYadOmMWfOHB566CFCQkIoLi6mtLSUyy+/nLq6OtxuN/feey+33XYbAMnJyRw4cAC73c6sWbMYN24cu3btIi4ujlWrVqHX61m4cCEXX3wx8+bNIzk5mQULFvDhhx/i8/l49913ycrKoq2tjeuuu47GxkbGjBnDxo0bOXjwIOHh4V+pq8lk4tZbb2XDhg1ER0fz9ttvExERQX5+PrfffjtOp5O0tDSWLFlCSEjINx5bp9Px4osvolQqeeONN1i8eDHNzc0sWrQIpVKJxWJh27Zt3+vr+smRr0/5+pSdN3r1cEfF0UOEVFcwrsnKaCGNkJjrUIaNAn8jTsUSGrL/TeXElbRF51JTHcrfGx/lL/wRq1XPE6UVbCt18/dakVmCApPNR5Fb4CXcPICTGyQ7s6UeLqKbyXRzMT3chJ3/U7r4QOqm3RZJcO1U4otmMDzIyDVt63lzYxXXVXvZrTTw7tiZvG9z87+lS3G5XN/8YWQymUx2YTu8/Fi2NVsdIB3788NfHtv+HT3xxBOkpaWRn5/Pk08+CUBubi7PPfccpaWlACxZsoSDBw9y4MABnn/+eTo6Ok7YT1lZGXfddRcFBQUEBwezYsWKkx4vPDyc3Nxc7rjjDp566ikAFi1axOTJkykoKGDevHnU1tae9L0Oh4Phw4dTUFDAxIkTWbRoEQA33XQTf/vb3zh8+DDZ2dnHt3/TsZOTk7n99tu57777yM/PZ/z48Tz22GOsX7+eQ4cOsXr16m93Mn/q5OtTvj5l55UfrCdNEAQlcABokCTp4h9in0P++ADxnR2otrpRNSiwhro4MngDOu1WzIEG/IKWFu1E1ghXsT09GrMY4O/FlYwsEzFponBJPvZKAYoDAbySgNmnIMSnYJSgYIz0WcZHBWiMalRBagJGJe0a2Od28Y/2bsyCg7mCgsucoST4E/HqO7imdA9X1A7h70OMbMscQk1HM9Y3l3Hn9deh1+t/iI8tk8nOQ5Io4Wty4Kmy4Wu0Izp8iE4/0mep25UmDapIA5oYI5pkM6oQOYX7BWfzY19Nhw3Hft782A86uX/kyJGkpKQc//n555/n/fffB6Curo6ysrITlo1JSUlh8ODBAAwbNozq6uqT7nvu3LnHy6xcuRKAHTt2HN//zJkzCQkJOel7FQoFV199NQA33HADc+fOxWazYbVamThxIgALFizgqquuOuNjf11OTg4LFy5k/vz5x8vLzpB8fcrXp+y88kMOd7wXKALMP9QON3+6mRGF6YhCgNeSlmJJ3Et/VYAer8BHDiMbfEPoCL4BURnMoKbd3FUaylBPHFa1yBavj263iCQqiEKJxmPFpHKjioqi3apAFEWEMBsOZw+moDDMmhC6Gl0EOSRGA5MtFjoCbexy2/mvMYwcHNwTUBMnDcERaOAfu0J5P83C4vRoXjBZ6F6+kgevvhKdTr7xksl+KiRJwlNuxXW4HVdhB6Lj2JqOCrMGZZAGhUGF4rPFkANWN+6yLgh8FrSF6jCNjcU4MhqFRp7bekGw1X+77d+R0Wg8/vctW7awadMmdu/ejcFgYNKkSbjd7hPeo9Vqj/9dqVSecgTI5+WUSiV+v/971VMQTr/8zXc59osvvsjevXtZu3Ytw4YN4+DBg/I6pmdKvj6/Qr4+Zb3dDxKkCYIQD8wB/gz8+ofYJ8Cw8KF4UtroGbKWsT17UCqNJCffQUj0DXxa2UFbcyfDBRW/OeogrX4ALgny3H7qPRJOtYOqsCPUBxehDermynoj/bfWot7bin5oHL6kcAy+KkKDatGIHnCDZIJufRSN3n5UuUfh8Q5hihTMxbZ6bAaBG6QQpigc3BcIQ4uGK6qaGdYaxn1jjLwSn0X7Bx/xzNyL0WjkVM0y2YVMEiVcBe30fFqHr9GBoFWiywpFnxWKJsWCKlh78vcFJHwtDrxVNpxH2rGtqaTn01qCJiViGhODoOrVI9Bl38QS/9lQspNs/46CgoLo6ek55es2m42QkBAMBgPFxcXs2bPnOx/rVHJycli+fDm///3v2bBhA11dXSctJ4oi7733Htdccw3Lli1j3LhxWCwWQkJC2L59O+PHj2fp0qXHey3ORFBQEN3d3cd/rqioYNSoUYwaNYp169ZRV1cn3wSfKfn6lK9P2Xnlh+pJexb4HRD0A+0PAOPASsqNfyNgtxMffyOpKfdQ4NJybV41NU4PjzQLTDnciVaCCo9ImV8iZVgUl4yNIS4jmGbncHY37WZv9WYqPdvImuqkn78dQWjBK+pok9IodkylW4zEIRrwqzTExAUTFqFkYpAVlWcNJYVKjrYOw+WI41FlI2pTGbeLmdysCuGiQChJzi7e/ETi1xMNrIhKxbXuU16aM0Ve9Fomu4B5qmx0vlmMKlxPyLwMDIMjzyjAEpQCmlgTmlgTppw4PNU2ujfVYltbiX13I8GXpaHPDD0Ln0D2o5jy8LE5Pl8eUqbWH9v+HYWFhZGTk8OAAQOYNWsWc+bM+crrM2fO5MUXX6Rv375kZmYyevTo73ysU3nkkUe49tprWbp0KWPGjCE6OpqgoBN/3RuNRvbt28fjjz9OZGQk77zzDgCvv/768cQMqampvPbaa2d87EsuuYR58+axatUqFi9ezDPPPENZWRmSJDFlyhQGDRr0g33OC558fcrXp+y8Inw+X+I770AQLgZmS5J0pyAIk4DfnmxOmiAItwG3ASQmJg6rqan5xn1XVS2mq2sPffo8jNHYhyUN7Txa3kiaPcBD+xxkeqHDL3JEFMiamsiAiXHojF9kWnTVlWP/+FmCG1aixoHVH0OJZyxHSKTDaSCt2Y0kaumIGoJPKRJQOVH5DQiBYz1hBoualIGhZA1VUfTe29Q29cEuRpGoySUQcoS9nkv4uRCKUvCDqOe3E9Ts0OuY7LbxxozxKBTyU3HZT4cgCAclSRp+ruvxfQwfPlw6cODAN5aTJAl3aRe6jBAExbcbMnMy7tIurGsq8bc6CZqcgHlq0g+yX9n3V1RURN++fc/8DT9w9rzewOPxoFQqUalU7N69mzvuuIP8/PwTyplMJux2+9mv4Nec7Du7UNsn+fq8MK5P2U/X6dqmH6K7Jwe4VBCE2YAOMAuC8IYkSTd8uZAkSS8BL8GxhuZMdpyUdAfJyXfjFEXuKqplZVMnCwpc3NLgRwsc8UtEzkjimosSUKm/mNPRVVKCc82fie5eQyhQr5iII+smhPhUtI4GIutK6KrM46C/mTCbRFDTp4j6SAIKAZ/KhRAQUKti6fZkcnRbGgXblYj+ZBTsQy+ZaWQMUssA5puXskMVziDpYkIFP09vk/jTWB8bgyz8fNsBXp044luPeZbJZL2fIAg/aI+Xrk8IUfcMpuuDCno+OTaEMuz6vghq+UHP2fBBXgNPri+h0eoiNljP/TMyuXxI3Hfb2cD55/1N79fV1tYyf/58RFFEo9Hw8ssvn+sqyb4r+fo8r6ytXMtzuc/R7Ggm2hjNvUPvZU7qnG9+o+yC8L2DNEmSHgQeBPhST9oNp3vPmVIoVNS7vSw8UkV5bRfP73czFiVWEVqzw5l6dSZq7RfBmbWhnY63HyOpexlmJGqDLqcjaTqNtZXUrHsLr8sJgFKtITw8nJjgPnQqWunBhtLfDgoBReBYUOX3l6FQVRMcnohKl05PVxoB/yU4/NX4uleiM4xgV/ctJGv3YQp6lMbAA8Rh5s+7JLwj2/koJJzfHijgqeH95UBNJpN9I0GtJGReBpp4E9bVFbQvLST8xn5yoPYj+yCvgQdXHsHlCwDQYHXx4MojAN89ULvAZGRkkJeX943lekMvheyn50K9PtdWruXRXY/iDhxLtNLkaOLRXY8CyIHaT0Svnji1z2rnZ4erSD7YyYpGiFIqqdMp6X/nYAZEGo6X83kClC/7LwmVfyZN2UGRejqV+oGU5+fj3/8GBqOJpOAwQlUGgmobUDfWIPiLTnpMt1pBS4iZhggT3RoltrZGfK4K9EEWotNzaGtIQaG6CrWvGJdzB9XSaNr8KcyxPEoD9xEuJfG3fSruGt7Mm0QTVVTF7/qlnq1TJpPJzmOCIGAaE4ugUtC1ooyONwoJu7GfnFDkR/Tk+pLjAdrnXL4AT64vkYM0mUx2zjyX+9zxAO1z7oCb53Kfk4O0n4gfNEiTJGkLsOWH2t8rhQ1c/lErPxPVKBWwOcnLnmwfPcXbcRQq8EtKkuu7uav4ZbJUO8j3ZLHVNYFAazsK1UHilDoS6hqwdFYgAP64SBqi1RTFqqiziDh04FWBAFgCWixOgeB2N7EdNoaUWdF7wS9AQXoIHRYt1XkfoVJrsMSOxW4bgEUDZqmGRn8U73U+zozg53AJl6CXBvJsroafD23iH0CqpY15cRE/1GmRyWQXOOOIaCRJwrqynM53Sgi9Nkueo/YjabSePNX3l7dLkiSPiDhPfN959jJZb9HsaP5W22UXnl7dkzb6gzqmChqsCvjlSANlwRLBXitGHBj9Lq7NLecGx8t0+gQWt07G1+1DErpIb7GR1tpBt8nMzgF9KE92cjimmh5NJxq/gqhOHSNixzF3/FWkh/UhQh+BUnFs2KQoibyz9xV2L96A3ZhOcM8e+lR3MKisi1azmvw+0XTUbEGtP4BNMRaXuh/ZIVDqcbGu67eMMb+GQe1HJw7h2SM+bh7czq9KJGINOsaG/KDJL2Uy2QXMNDIGySNiW1tJl7aMkCsz5EDhRxAbrKfhJIFabLAeAJ1OR0dHB2FhYfL57+UkSaKjo0Ner1R2QYg2RtPkaDrpdtlPQ68O0tLjbbR26egavY9/hygJ1ZtQ6EOwdarxrVlDoriJDa39qbAFocFD//oO4rttOAcLbLksiJWRIu3+PARUhPXEMjrfjaRMo27qZYQPGEhiRCTR+q+uZ6QQFFw7+jaq+0xl04OP47bcx75ZewgN1NHH3sLEozV0+bTkRkWBuIGAqpDD0myyEyJpDnezu+4W+htXk6nREu7pyxPFVu7N1rLwUDmbR/cnQSevoSaTyc5M0Pg4RJePnk/qUIXqME9OPNdVuuDcPyPzK3PSAPRqJffPyAQgPj6e+vp62trazlUVZV8jSRIEpJMOA9bpdMTHf/d1v2Sy3uLeofd+ZU4agE6p496h957DWsnOpl4dpI2/Zy5IICi+GHtbvT2XoI9vo9newyutowkEIL21kzCbnzXJOWyYFI4/aTOStg29T8sEpZH0A3rEZgF1tpb6AWa6lHb+XNPBn2s6GKP1cWNqGhdHBqP5LGV+TVcxe1tyqVrQjxZnHl5FEAqyOEo0YXPiSKeUwZ5KfI1qWlvbsVbXcqh6Pn0y+mEZoqYg71J8rGeAxkBfWzz3ldTx54EZ3JRXxkcj+6JXyvNLZDLZmTFPS8Lf6aZ7Yw3aVAvaZMu5rtIF5fN5Z6fK7qhWq0lJSTmXVZR9TfcHu+ne4yfqV4NRR8sjVM4lq9XKsmXLuPPOO7/1e2fPns2yZcsIDg4+ZZmHH36YCRMmMHXq1O9Ry+/mTI69ZcsWNBoNY8eO/cGP//m8Mzm740/X914n7bs407WIPufyBthe1kbX6hVc1P0kmxuSaPQEEdbjJLnNRdGoi6mZOJgj0jvUuvII08YwJ2EBA/wZlL2xGL/LQdj0EehjyjELe1ErXDR7YjnqGs1m/SRqdXEEBxwM0XdR7xcoE7+YLK5ERCt68UtKvMov1mALxckI5zbG6T8hhQp66oy0l40mJvhWtGF6Sve20se0mf6qEXjR83xcI2/1H8zcqBD+2S9JHjYju+BcqOsQ9Qai20/L4jzwi0TdOxSFQf3Nb5LJLjTt5YgfP07T0flo1RWE3zsTwjPO6K0Xavt0rtfcqq6u5uKLL+bo0aMnvOb3+1GpenVfwPf26KOPYjKZ+O1vf3vG7znX35msd/mx10n70WwqbOG9g/XsKGnhcc9HDPBs4K3mfkgiDGizMuDK67BcPY/SyhXsLf4bGpWWezNvZ2hoMtaGg7QeWUz8GAlLagIqzUFUCgFloA8Kvwct7cQKKxni2sZq31w+MU3hU288SWIVF9n3ENUuom2yYvC6MfXYMbicEBBxq7U0hUXQnJbJ1vgprBdm0qerlMvC3mFQwmbsLQcRrb8mY+QgSvdNQW36lHTVBO5qDKPCWMwKoS/jQoO4NibsXJ9emUx2nlDoVIRdm0Xrvw/RtaKM0Bv6yg96ZD8t5Zvg3Z/R474SiSDMN18N4ZHnulbnnR963a0HHniAiooKBg8ezLRp05gzZw4PPfQQISEhFBcXU1payuWXX05dXR1ut5t7772X2267DYDk5GQOHDiA3W5n1qxZjBs3jl27dhEXF8eqVavQ6/UsXLiQiy++mHnz5pGcnMyCBQv48MMP8fl8vPvuu2RlZdHW1sZ1111HY2MjY8aMYePGjRw8eJDw8PCv1NVkMnHrrbeyYcMGoqOjefvtt4mIiCA/P5/bb78dp9NJWloaS5YsISQk5BuPrdPpePHFF1EqlbzxxhssXryY5uZmFi1ahFKpxGKxsG3btu/1fcl+2np1kFZ4uJmIsk7eDxzB5U7FpXiIGbFGDJoghAwdUiNYnylhNgOYzZ+PvakAJERC1cNJUvfBY7fhbW8nIDQRUFXj09XgCXIhBkmIFgijnZ/xEjfbXkao0+CsjaCjNZqAR0laSwvhbS0IgcBJ63e/UklDVDQ7B4/grZE/50NnFwvNL5IQ9TDettmkDllIQd5FGMzbiFVMYVFFD7cEt/FgCQwzG+ljlCc3y2SyM6OJD8I8LYnuj6txHWrDMFi+QZX9ROx/FT66HzFsKHb3PPT9Q9GkyNf/t/VjrLv1xBNPcPToUfLz84Fjw/9yc3M5evTo8WHCS5YsITQ0FJfLxYgRI7jyyisJC/vqg+qysjLeeustXn75ZebPn8+KFSu44YYTl9wNDw8nNzeXF154gaeeeopXXnmFRYsWMXnyZB588EE+/vhjXn311ZPW1eFwMHz4cJ555hkee+wxFi1axD//+U9uuukmFi9ezMSJE3n44YdZtGgRzz777Bkd+/bbb/9KT1p2djbr168nLi4Oq9X6nc6pTPa5Xh2kzXMFEL06JGkMkrYHlaebCrWaRpUXS2ge4aYGzCovIgF8gSB83mSUXTrUrT50Xj1qhR61JgaDNgPVl4YqdgkejuocVGg7CNd9TIK3BoXBhyaxG92AeuL89egOKQjsDyLf2Je6tAQcZi0BhQIEAbXoQxdwE97dSUxDG/PXf8h1H31AUVIqy6degym2gatjlkPQEeK9v2ZfQQ7TgvcTHhjBnw4f4Tc5Fm49WsXHwzPl+WkymeyMBU2Ix13YQdeqCrSpwSjNciKiM/FBXsMp55x9l3IAHF4Omx8DWz1Y4mHKwzBw/o/8SX6C8t6Atb+GjBn0BD+O1NCCeVrSua7Veelsrbs1cuTIr8zjfP7553n//fcBqKuro6ys7IQgLSUlhcGDBwMwbNgwqqurT7rvuXPnHi+zcuVKAHbs2HF8/zNnziQkJOSk71UoFFx99dUA3HDDDcydOxebzYbVamXixIkALFiwgKuuuuqMj/11OTk5LFy4kPnz5x8v/03OpHfz2/aA/tA9prJzo1cHaUVb/0KlV4vT241b0BKI0GP0dkFHgO5KJXUnTKcrARQgaBEEA4LChKCwIChD0akiCdFGEaLSEqZSM0YMYbwrFJ+URoXPwYeim4/q1SSbq5gaso1B/Y+gHmYjriGPxE0lbK0Zw+70Iei1IlEKBzq1D3d4CPXhaewdKGDpdpFVfJiHX11MTXQcy2csZMbA9wjOfJAY8V42FvfjUks5I9x9uDF/H/8ZPo4nKptYlCEvliqTyc6MoBAIuaoPLc/l0fV+GWE39ZOHPX6DD/IavpK9scHq4sGVRwC+EoCdrNyv3sln0YcFPHJJ/68Ga4eXw4e/BN9nqfttdcd+BjlQ+yGVfAyrfwmpFyFe9l/sT+ajHxCOOtp4rmt2Xjpb624ZjV98P1u2bGHTpk3s3r0bg8HApEmTcLvdJ7xHq/0i07ZSqcTlOvn6hZ+XUyqV+P3+71XPb9t2nsmxX3zxRfbu3cvatWsZNmwYBw8ePCEg/bIz6d08aZmtv4N1v2fO+BMfDv0YPaayc6NXd+OUekW6Azb8SgmdwYvJ5UFyJyCJg1FqhqMxjsUcNIpQfxLRjmAiHHrM6OiTHkFKkpKIkE5UQiF+1xbsPcupa1/MTvsSPvS+y8vdB1jtcFDjlUhWmbhfF8E60cxtXal01E3m3b23sLt4HN1GA54FDsZdtZk/1fyTPgXF7LVF4yh1oaxw0WKPpSYQTpvZxP5RI1lxxXycFhP3vf4Gnf/rT01LFJYBfyc8YxcfOcIR8PLzzlCG1Jbxn/o2dnT1nOvTLJPJziPqCAOWaUm4izpxF3We6+r0ek+uL/lKen0Aly/Ak+tLvrEcQJfTx4Mrj/BBXsMXGzc/9kWA9jmf69h22Q+j+Si8uxCis+HqpdgPdCB5AgRNSqDT3cm7pe/iF7/fTfpPzanW1/o+624FBQXR03Pq+xibzUZISAgGg4Hi4mL27NnznY91Kjk5OSxfvhyADRs20NXVddJyoijy3nvvAbBs2TLGjRuHxWIhJCSE7du3A7B06dLjvWpn4uufv6KiglGjRvHYY48RERFBXV3dad9/ut7N05ZRKHhOGzj2cOjw8m+9T9n5oVf3pPW5bBLVh3pwdw0GSY9f6cIWWsekKIgp2ElgRx74/WjjvWw3JOEPUnBd8iGMKt+xT6YDKQw+sIznqdDria2qJLa5nuiOBkyBauzCFlZHJdJqyaYvGUyyKRmtMDMqMIBqHHTYWxhY6kFt6qYsKQjHnS5mHf2I2R9s599x83gtejhTGnL5ueNjDvTtzx7VaGLVnRwZMpiSjCwmbt8Ci6H48jSSR7+JKHnZUT+KHG0C/yjbzZVR8dxbVMuWkVkEqZTn9mTLZLLzhmlcLI6DzVjXVKLLCEFQ9+rnbedU40kWqj7Z9lOVgy+CuuO9abb6kxc81fafANEbQPKJKI0/QOZRnwtW3AI6M1z/LpLCiH1HAdqMYDRxJv61+/9YUbaCEVEjSLYkf//j/UT8GOtuhYWFkZOTw4ABA5g1axZz5ny1p2bmzJm8+OKL9O3bl8zMTEaPHv2dj3UqjzzyCNdeey1Lly5lzJgxREdHExR04tIMRqORffv28fjjjxMZGck777wDwOuvv348cUhqaiqvvfbaGR/7kksuYd68eaxatYrFixfzzDPPUFZWhiRJTJkyhUGDBp32/WfSu3nKMirlFw+HvtSbdrZ6TGU/vl6dgn/dv9+gvsxEe8hhtljyGCsd5u5DdjrzLPhdSoKygjBOH8i7uVYCosC1dy8kOCEd9CGgMYJKxz+KqniysguF10/ArAWVAkUgQFptKVmVRSTUl2F09eBTaWiOzyAQOZQp1iiGeBUIwBGVwNN9nVQHHWCctIVrjZWo/RD8vpJDtfE81+/nONV65tZt4D7fWj7tM4IVTCVT1Y6aAKmlZQzLz6NwUgxh86ppPXwlCY0jSFZGs9+4njvHXcn1MeE8lZXw4594mexHdKGmuO6t3OVdtL9yFPO0JMxT5EWuTyXniU9oOEkAFhesZ+cDk5FEiaq/7+CabjutonjK/QhA1ROf3YA+M+DYEMevsyTAfSemIr+QOQ634tzTjKemG0GpIOTWbFqtHuIyQ1BrTnz4KEkSbocdd083lshoFMqTPKBc+xvY/wrbkn9NuzmbOKuZuFIt4bdmUxvaylUfXsU1mdfw4KgHz7ieF2r79G3TuV+Ic5U8Hg9KpRKVSsXu3bu54447jicy+TKTyYTdbj/7FfyaL39n09+bTpOj6YQyMcYYNszbcPoyPj8b6hsBAR61Ht9+JvuU9R7nbQr+9Iit/Eu1nQa1mkc9iQzZ3IfWw9VoszKJe+gh1P378/Yjv8ftszH/T49jNAbhrGvG21xBYUMzG4or8YgiN0sSap8Xs99NiK8bncKDRi3iNWlxJ+pwunRgdRNfUwjVBZSYQqgwZ5OtHky2X8erR/Rs107gr8NnUOiyM8e/lnHXvE+fgjqWvPU0L/aby/LEi1mrGs5d1iW8oniEvwctpEERjZCZQWN0DHM2rqe+M5rIW1ZQ6zMQ06FjlGMoc8t28wZjuTwqmHEh8qKcMpnszOjSQ9Bnh9OzpQ7DsEhUwXK22JO5f0bmV+aaAejVSu6fkQlA+4FqVhT9g/7GdLrME/CdYhZAbLD+ix+mPPzVOWkAav2x7T8RDfYGlu1fyvtVHxChDOX/Rj5A8EEFtf/MZ4vNhyFUx7j5GaQMCkcQBGytzex+721K9+7E5z523jR6PXGZ/Rhw0TQyRuUgCAK+gjWo97/CLoaxq1mLrquWrNZ+tAo2qhqO8L/y/2FSm7hj0B3n+Aycn+akzjnvg7Kvq62tZf78+YiiiEaj4eWXXz7XVTpjZ9K7edIyosi9XdZjP1jiv/U+ZeeHXt2T9rvN97C3NZ/nXVeg++ebSJJE5H2/wnz55biPHCXvP//CW1pKXFAwtLQieb0n35EAIIF04iRRQSWitfjRh3kRQ0UO6aIptUXiF5WognQI4YMZKQ4nXmHEGhB5M1zB68NNREstXM3/GNFzgNCXFXTqr+A3aePoUUhM1FRzvedZ9OpQnpYW0k/ViuALcOm6tdhjFfjvttKZ9wtGd49EUO7g8vHjUFoi+HRkFgY526PsPHWhPqnuzfxdbpqfPoAhO4LQqzPPdXV6rdNlbXz9dw/TXpOLpBQpMfZha9h4vGj57BcHcCyo++vc7BOTh5zH2R3dpV1463pAktAkmtH1OXlGvJOptFZy9Zqr8fq9TPL1gfAKYlVuUpyx9G3PQacax4HmIDqbnIyZm4qjYysHPlyJQqEka9wkwuIT0BqNtFSUU304F1tLM7F9+nLRdddhXnE5PX4V+/s9wZj4kSi9XuwfN1OecYT3VJ+ylWLmxQ3gYqWSQeP/g0p1ZklELtT2SV4Y+fzz9e/sjLM77vkrzV4r0f4A93ZZmeNwHns4dMnzJ00ecqH1mF6oTtc29eogzdZST9sjj+LbshNtnz7osrNxFxbiKSmBz4aliCHBBA0eQrElhKPYiVM2MNxXQKLQjFItIipVdPgT6XaG4tIoKNK2UyMqsDv1BHeLRHf5iO9wE9ruR+kHCQnCJRrjTBQKkQQkgehwOwbLdPoFxqFFwVGfn78P0VEcb2CAdIgFgVfp92Yz3rpBPD/kJnarFMyRVMxRl5ElvMYfAzeSqu5GEEVmr18H4R6cd7oJ5N5Hf2c/GvRvctmE27k9IYJH0+Vsj7Lz04V6E9Tb2T6uomdLPZH3DEETZzrX1TmvuJtt/Ov316G3eEjJqadzVQQOr4bNfWdTqsjC6uGbU/Gfh9zlXbS/ehQ+//WvgKhfDj2jrIl+0c9N626itqOK33emo+u3B4VKxOEXcEkQrj72QDQx+C6Kd06gKvcdfK5C+k+cyrhrbsQU+tVMd6IY4Oinm9j35mvoG5sZqGhGVAchiCKS5EbjSUahDMaaeYBVWiVN4XB5tgKnJojBMc/St9+oM/rMF2r7JAdp55/v9Z2d5w+HZCc6b4O0qnlX4S4oAEEAUUTQaNAPGYIzOpJ9hw8QO2MGnmF9sRauZFrHVqK8nfhQUuLvQ5trGEcD/Slya6gy26nUhOHxB3OqhJYKMUCGtZ7hLSWMaS4gzdaAW6WkNDWSer0Bk8rD6JgORNWviCCFDr/I+wYv/80JIaAWuZo3mLvhY2x79bw88iZyhSyGSkoeE3SIqq0sFRUo1AIayc/M9R+jCXfQ9XM1sbkPEOZT8nJ6Mf9Jm8PGEZn0M+lPWkeZrDe7UG+CejvR7af5yf2oo4yE35otp+T/Fj76618oytvJOH8V5iIRJAGfQsHe+XEcFKfz2xsuI71Pxrmu5g8qYPPQ8nweCqOayDsHIflFWv5xEHX0qa8f+86d9GzciCY5mY1BtfzNvpzfa1RERPVAYxb2wqm02l0sG/ARA1wqrguPwBGVS8Onw2gvd5IwYDZX/emOk+67c/uHtC99Gf/OMoQAiIDHpEARogSFGb3VgFPsRmPvRvHZ/YooCLRHRDHyzaXoE+JP2OfJXKjtU1FREVlZWfK/+/OEJEkUFxfLgbXsuPN2TpquXz8C3d0ETZuKadw49EOH0tnSxJqH7iNtbCiJ3rfJ3FyJV1BRIqawxHMVla6xVKi01Kn8+NQK0IFC04peU0eGPo/BEY3oVQ7yvC5qXSILmqPo6LiKDkUQZfEJrM9IYpV/DsHNTVxUfYCZ1XtJVHaSnxTFprpY+poXExrZD7P0M250a0lZ38hrg0N5I+Fm8qYP59cRz/PbVUv5w7RR5Nsv5i5RZLFvIr8Q3Gzx7aVUrWbdjFlcvG4toW/2UDfvZYIOPcDtVT2si2/n9yVGVg1NRyE3uDKZ7AwodCrMU5OwrqrAXdyJvu+p1+SRfcFrd1JcvItwvRPzXolAdAaa6FFw6C3Sd3axcYqP195Zz58funCCNCkg0bGsGMknEnZDXxS6Y7cA5unJWD8ox3W4HcOgiGOFvU5YcQs9u/Oo3yQgKBRIfpGBSPz2ASWJ6jgiD/4MXUfUsfIGmFGZwwZTLqV1sbSp47DXNBMzQs+n4kD6NveQHWM+Vg8pQPPR5XQ88RzKgzYkpYRSJSGpJQ5HxtMYYsAjGhkfOhhzyEh2p73DErGAyE4lEw6Pwa21EdfQTm1zDzf+xHNu6XQ6Ojo6CAsLkwO1Xk6SJDo6OtDp5PnDsjPTq3vSpEAA4UuZn9wt5Rx99iYydVUESU4KDakcEPvRslfPe2lX0Ko8Nu0sROhGGXQIh7mSBEUTA1RGpidXoABWdavY4VAy1OnnmvJLqFZPxGfqQS06UPhceAUfXvxIEtjQUe8Lwlxfw0Wl25H0LsqjQjAo/FyS0IFX8TBqgjnicfNerIMNwxIIEmz8puYfDF9Syd8nzWS3bxJhIvxDspCqVHJUkc+nahsa0c9laz+EoT3Yxowjs2wBnYZ/MX3cg/yjbyLXxcg3WrLzy4X6pPp8IAVEmp8+iEKvIvLuwfLN2hnI++htPnn9DUYrqgk5BNrZj/JiuhZTWy3z3vwnDbeqeLrjV7z4ixmkJJ1Zb01v5zzcRueyYkKu6oNxWNTx7ZIo0frPPES7j+j7hyMoRHj7euzbtlC/IxxtpI7EMZX8NWsCI48WE9ZvElHFN6IwqimxeWgM11IpejHbvFwqaHAJ8BuLnyMhStSGAIJJgVMXRKxRIsVbxPCq/QxYXkxyQwMqUUQ0qAmy9LBL0x+3KRKf1kmFxYjF5aGPZKdppJWtETDW5CbSJ1DrjqPLYaF/8nQWTL76jD77hdo++Xw+6uvrT7pAtKz30el0xMfHo1b/AEtVyC4I5+1wx+M6q7Cvewxd2SoEJNaFj2eVagzifheVoWko1BAqeIhUOjBpqvEICvQBNWpR99ngxmP/DwgBAkIAvSigkPQECCAKxz6/QgKdX0AVODae3q1S49EoUfu9QIB2tGjqbIwp30tThAaXWsVIcxcp4dcDA6ny+FhjrmTN6EysWh13Nr3AJf/exYdDBrPEcA1m0c8iXzhDdSoqhArWa+pQ+7zM/XAV7jkutBG/IKY9kpf61vBW6uXsGtWXYHWv7uiUyb7iQr0JOl849jXTtbKM8J/1R5cZeq6r0+s9+dS9KPeWM728mtL7I/lX9M8oEAYCcPmOT7h5w7u8e+loRGcGTz9y5zmu7Q+j9d+HCNi9RP9mOILiq4G8q7iTjv8WELagH/qiPxA4+A4V61NRxSWS9N/X6Fx/O3dIh/mDcwqRZVfjNheT2y+Pfx8eSpUzBp3gJ8aiojE9FK9Fi0t17PeuyudD9EpIkoCgBtQKRMWxh68qvx+Nz4Na6cel0BKlbKY/R0mnlHhqiaEJFadZsFr5R6ZMvPmMPrvcPslkst7ovB3uGGgtpfuDB7E0bsaHkaXBV7FHNZDgTjfBfjfGBAUJVAHHEn64lS7cCpFQuxONIZzIhMPoNA7sAQUOlYtwSYdGEQCFiABIkoJAQInPr8XrNeBzG2kUEsk3ZeD2i6hcDnpMFrrNIQRUGtRD/XziGsfkzdvo13iQfUIoZbY1zExtJEU7k/n2dCxbj7JmbAqLY++l455wFrywGu1YD//mZzyuqONXzlhy9KlM96n5RF3O2hkzuXT1Grp+/hpm3f9xZ2klKyJbeao6hMczLoyntzLZT4HH6aSprJjm8lI6Gupw23twO+xI4rEHQUFh4USnZRASm47OlIDHJaLRqdAaVYREG9Hqv19zbBgaSffmWro/qUPbJ0TuTTudw8v5efc7BPdz4U1X8rowlzIpixzrLoKD2/hg3GWIYoBL3at50jOEjw+WM3NY+rmu9ffirevBW9ON5ZLUEwI0AF1aMKgUBPavgsq36XTPJGA/TMi0aVjf/4D/6RX82jeSyLKrsUXu5V3bIXZtHoZXJzI/cw2NKQl8IswAYEB7CZc2RDC6U2C3kIvD0ES7FIy5xUGsrY3ysDg+Gj2B9uBQvDo1TuFYwpJ2KYImYtEFfPhc4di7RBQ9FiRHCKLbBB49kleDGNAgBdRkTpWvcdkFRk4MIvuSXt2TtuWxS+gSdRQqMvCJGgBECbolHaJXQ5g/FD8BOpKW0BhuZazfyxCbgJiuRqX5ate/KAr4/Rokvx4pICF53UgaBQqNEp3KDUr/l8oqsPeE0eaMpUzqQ1lwEpJBRESJCz2tRBFoV3LbW//Br3ah94pclJaJSTWXzoDEZkUJ60ZbOBKSySVtq7nrhTdZO6M/r1oXEuNu4WZ/DBeZgihWVbNPXUVkQyMT9m+n8xcxpNTcT0Pov7ly+CI+GdWXTKM8dll2fvgpPql22qwc3bKJytx9NJYWI32WddYSGYXebEFrMCJJAs5uD92tzXhdHZ+9U41CnYRSOwCFKhlBUGCJ0JPQL5R+ObFEJH63NRPtuxuxrqog/NbsYzfdshMdXn7CGmdOhZb/GebSbI+mT9Y2NkZMYp3iUn77wVtsNyeRoFLzz0duPYeV/v463irGXdxJzB9GotCe/IFA26uHCW5YgKAVKV8mHFvWRpLovNyHb0wkqXsW4fQ08GHzahQBLwIKnPGDeWfCNNrMQYztOspc/UuEK9opLx1NV3syAUFEFAQkUSKk20a30QQqJQZDFwlJR4iMqMEmWsi1TueofzQV+hjazFoABEnC5PBi7gmgcoPKK6H0SwgSKCSRJ0cnMHxkyhl9/p9i+yQ7z5ykbTpVin3ZheO87UnbYR6Hs8dLkzKYNoeONtFAVksZ2SQQHGOHtDUo4/IZp5VQffZATYxSEVC4ae62UN0RTZdHhy0ggGigR/QgdNfjU2lpjB5EsjeYNH84u0NNNIWGEqoSGSoVMFTIJVLfRkrQYdIUh5jqV9PdGofYlYbWEYVffQS3zk79jdF4dzlQ1LTySWUxmVEf0MdyGTPELPS7C9CP2s+HEZci/kLN3a+9RvfFy3in8Ube7SmBnhgmBSVjE9yUxEFZSwZpy0vouGIzGc0juLR9Gw+XmXl7UKr8RFwm62WszU3sXP4GpXt2Igb8RKWmM/KyeST0G0hUWjo6o4n6ki5yP66mvsSKJEoERWuJTtWi1rTQ01ZCY0kurp4PMFjCScyeDYpMinY2cXRrA9GpFsZdlUFUivlb1cs4PJruT+ro+bRODtJOZfNjX70JAgyih2vsH5HvfYojFQGuCn+Lvb4cPhwyinm293ij6RJG/XkTrT2e8zIlv9/mwXWkHdPY2FMGaAAmy17UdZXU7huG5GlCOygF2/U2pIp2kjfcjqgT+aR5PeFuiWGWyewaOIJnBpoI80j8e7+TEZ1JHJJu4oC+AR8i7SERmDSJtFgr+P3//s2+7GEcnTqYMUErSYk6SiCgoa5qCA3Naai8RvpQw7jqDegSJ7EywkO52YBTb8Zp1CMEqwlo1UiKLzI027vLgDML0mSyXu8kbRM+F9Y1D/HbvBQ6HF7+duVA+kR98RBPXg/twtarg7Q1wek0t2kR/BBjLOP+zg9QjTOgj1mBSutElKDJq6CyVkGtXUl+iJrGgIiIBvCBqu74J1SIAkoRRIsaUfCAkEeRIUARgB80rWAHcgWJWm8IIdbh+LviSTa0kBFXTmxsParIalxOI7bCWHoOmtCLBrQEoQsJxtNppbCtCKfNx+DEK5kg9ke1Nx/VmF2sjZ6FdIOCu1YvoWNCKJsa57Chay/Y3EywZNChsJM3ZBhRG9rQ5K3BmvooiwpeYWzIcDZ2hDM93HLOvgOZTHYiQSFQnX+QwdNnM3DaLMLivkgx19FgZ/3LedQXd2EM1jJ0RiJpQyMJjzd96YHLHAJ+P+X797B/9QqKt/+PhP4DufzXv6ClWkHu+hre+9sBssbGMP6qDDRnOBRSUCsw5cTS/XE13kY7mlh53bQT2OpPutkidaN29jDSP4ii+sNcnvguS5JuZ9f2kbQShNTjAaDB6uLBlUcAzptAzXmgBUQJ05iYUxcK+NHVvYCrO4Luwma6h4eivawAd5mamO1zUWWlsKPlfTym/kyPG8H/MoJ4KcNAZksrI6qX01mkZFV4FG1BCqLFYJJUfXkmMZQeZxP/eeEV2qJCWX35QRaEHcSg9mEtv4jmwhnkKZWUaDxkaiqJU3TSkxJBuX4zwd5aRtZYCXaoMTvUGF0q9G4lCjRIggJJEJBuueXsnUSZ7Md2irbJ7GmhvstFo9XFL9/K44O7ctCplaytXMujux7FHTg2cqzJ0cSjux4FkAO1C0SvDtL6dNsYGXKAoQkFxIc2ICglXD41h9xwuEdDqVuJSxJQixKRwQrCVCKWrgy0HjORvlCihFAq7DZSKorw6OPYnTqMo64EotItNCQa0AecTJHeYZS4gZZGDbUtcXTooF3fQk34PqSIfRQEIKZDR1pNOAODDUQmdhE/vAzfQA2dJSk48gJ0d/ccy00iKqj0VaAtWUbfzOsZExiMevdulOO28VHCDMwTXdx6eBnWzAj2MorQlo9RWv1MCR7IB7p9bJg8jbmr3qc98TkMvlt5rPxFHjP/gYtCzahPModAJpOdG5bIaG5/aSlK1RcZugI+kQMfV5O7rgaNQcW4qzLoPyEWlVp50n0oVSoyx4wjY9QYjmxez/Zlr7P80d8w7da7uH7ReA58VE3+pjqaK2zM/MUAws4w4DKNjKbnk1rs2xsIvTrzB/m8FxRLPNjqTtjsCgSxzvk2yR0JxBlmEJXwHB9457PPl8HXJwW4fAGeXF9yXgRpkiThzG9Fk2JBFXaaNTgL3kewVbKxaSyj+h6Bi7uxNugIWxaFesoMahyF+LUxXBU8mv+keHk5w8Dk/B088MqLxA3rZE3SdNqUCpR+Kzv6XsTwMiUv73NhrdqDWqXGPHcUd0StxmuPpHznVQz01jNAF4RGV0RJ+A7ytRX0NIeQ2t2HGH840aoYBK8HlaMd0WXDpbLRGOnGZuzGqxLxqSSGtjSdvRMpk/3YTtE29Wij+PhXE/i0uJWf/Xc/T64v4aGL+/Fc7nPHA7TPuQNunst9Tg7SLhC9OkibnPAfEiztdPkEPnUoOeJSUuNRIAIWRQzXHWkiq8CH5lY1bYFgSo5ORpIEBgQS2BdSS1dJOandnThDRrIsaDDBFjvaERbqNEamebdyg281ytpMlKULGEAsBqUejWBAo9DiUnko1lez31TIPnMR28Lb2SHaCa7PpG/1aCbFHyIquwRnhonm8hmomrNJdrfQVr+DQnUD6sI3SO93A0MDo1Hs+gTPxD28PeBygqwOftnzNo8aItgcMZnQxhXoUTA5dADrNHlsHT+Oyas+pe3aw1za4OL1uEMsbQzn5viIc/11yGSyL/lygNbZ6GDDqwV0NNjpMzKKcfMz0Js0Z7QfhULJoGmzSR06kjXP/Z2P/vk0A6cUMPnm24nvG8zGJYW8+9f9jL06mT7DY9BqtacdAq0wqDEOj8a+pwnLzGSUFu33/qwXlCkP411xOxohcHyTX1KzThnMfTEF7Oiy0V0bhtoaySzjGt7zTeFkZ7vR6jrJ1t7H1+jA3+YieNzpA0px30s0KyPJUtZgu1ykTaUn4lUdmtFXIgoCzd52JoVMYHl4Gy9npDCzdRuvdD5MVUgEH6hmUqdMpMOo4oNB12EUXXzQsZ6rc6MJTZlJ8dRGFGmrcDQNoL2pL68kv0mI5KF/VxtHVSUMrDCS3ByPUoKAuh2/yYffHIqoM+CLiAPi0ADhgFHpos5QQ7OpAZO5/WycQpns7Jjy8InzZSUN4uSHALgoK5IFY5J4dUcVF2VG0uxoPuluTrVddv7p1UFaUUMYH3W58XUOItgZSWfsZowKLxrLTdy/Yy2Je/20/06kor0P9fXZWEQD/cR43gg9QN/cGiSFCl/YJdiyjzA2+RBbFRczp6WHazt3Ed2Rjsb7KAABbQCHrwu/0I6krqERI5ViHB2eaDL8wYztGodX1cMhUyGbLfvYqSqkujOK8a2j6RdfytgBK6hO2MriiqloNbOZVbuJQzSiLVxGYr/rGeC/CPWOD3FP0vJKzrWErejk15kv8wfPg6yPmIGpaSUG5VUMCk3iUBTURicRs309LcMe5Omi57k6pC/zokMxq07+RF4mk50bkiRRsL2RHe+WodEpmX1HNimDvtsDFVNoGHP/sIiP/vNPDm/+mKMH92MLj0eh0WN2DWDbG5V8tOpjlJF2kpKSSE1NZcCAASddGNU0Lg777kbsuxqxzJLn7HzFwPms/N9/uMRQhF7hpE0VTHv3LAabl+NwRzAzuIIl9iSiGwcytf9HrNBOBc+JCbZig0/TK9WLOPNbQSmgHxB+6kLNR1DU7+OwYgwDx+VSFBeE5ukI1MFhaMNGUGMvZETwePaoWvjH4GSGdhfy9JG/8En5JWyfNBylqosGYxwfDh9BfGMdcz99lzuFjTTuCabi3nQUaYWoq6YQXng1IRf9gd8pelhSGk2gro5ZLRH4FCq8lkhizanUa3TsIgibZCAk4KQvLQQpvMerqg/o6dOdSR9rOlaHC2afhZMok50NnycH2fwYkq2eJsLYEPMLFo6+4XiRB2f35ZOSVp7dVEp0RDRNjhN7k6ON0WerxrIfWa8O0kbtGUaC6TfYdfWszH6WUMlLe/jvufroFpL2tNL6a4nD1ZOwWmNJC0QTjJFXDVsZubcRmyWaYPUUBma/wmbt7YwvjuOh1h40ogKPqg+V3iZ6OnfR6a5Hr2igLTaeLcYJNHgtJCs6iPW5ie5JQO2JpRaAaGLI4HbVHGojctkZ9Slvmw6TUZ/ETHUGScm5PDJ4Oas7DSyLGMBluQb2UY+6ZCWxWVfic8/mZzuW89xEC89ceSuP/ruDe2a8xF/Lf8WOkHGoOpYxQv1zIixd7Bs5lktWt2JLf4UU/1Bm1H3I87ER/Ckt9hx/IzKZ7HOBgMj2t0sp2N5IYr9QJi/oi/Ebeq0kSaKzoY6aI4doLCmkva6ano52fB4Poih+pcdGtHYQZD2WDTLAARSmSwjqycTXuo26/GXUKJR8qtUTFpfAyKkzyBw5GrX2WMCmCtWhHxCOfW8zQVMSUWjkBzyfa3N2UNeg59mJv2Bx5mUsOHyAjJ5DRDovpabrWobaX2V+/B4+KbkeZZZIRmwTpTXRCOIX+9Crldw/4xuGkvaCVNqSKOE81IauTwhK46kXz23d/gJmQcVo3QFy08zYP42kT6UV9aW/wBWwE21Ipy7QwR8nRhPp6+Dpood5s2cRDZlB6IVS6iwprB08iDFFNibmtoO1ncrSWLoXKAlkFhIonUKf6hsIqCQ277uJ/Z61TK4REAUFleHJhIcGEyqYsWpcXOUczCVSgD/oj1Dm7EthIJpkRQejxRJM3h4CWh0mlRe15CMqedLZO5ky2dkwcD4MnM/S3dU8vKqAlbPHfuVlnVrJwrEp/N+aQn4//OcsKXnyK0MedUod9w699xsPIyccOT/06iBNP2UGPUcLeaf/C6T7/FTE/pnhjSVMXrOTurv0HK6YjNtlYay/D12Ck+V8wqhDbTRH9SHJfxGjIo4gND/E3W4FbToH+1NL+dgcT6XNhjLgp2fQMJoiLkXwKdH5vOhFAZNbRYdXxOnxUIaPoICbi7r3Mth9mMhAKzrRhdsdxMXVFrYah7E2so5/amqZVjCK0fFVzA1vYKS6nNfNHibsiGOno5RJlRuJS52Gp+dyfnngTR4fsZC/3fZL/vCvx7li1lpWVF1KorMGZfN/GaH+GVuMh9h60VSmb/qQxiuCeahsORMjJnJLfDgx2jMbQiWTyUAQhCXAxUCrJEkDfqj9uh0+1r98lPriLobOSGT0ZWknXXvqcx6ng4Ktm8lfv4aupsbj2yVA1BlwBMfSqI7ErgnGpQ7Cp9QRYm9iYPNOXEoDRYZ0Iny5ZKkF1PoJJKSk4feX0VpXQ2dJAeuLj7BBqaT/hCmMmXct5vAITDmxuI6048xvxTTyNAkjfmK2FO7GIvnJizi2NtfwThPtlh2s0D3E8E4l+cZfoOwso8Pbhro9lXnJ77HI9CcMRR34/QrMOhWPXZZ9+vloX0+lbavDueIu/r66gMFzbjtrc9k8VTbEbi+GOZGnLON0WjEVrsCtVFPQV4fUpabPh1Y0fTLRKNKx+7qQlFp+O1qPU6vl5fzfsaH1dzhUkeg5TKspgo8GDeSGj97jmo0raAo3IAbM9MxWExjVhrXkIqLLoEu9h1BhDMndAtYmBZUhJjLGWNEYPkW359fMViei86r5IO1JhtbdyL+do3km9F2OdEZSFxhIoSKKm4xHmKo4QLDgQESgNWLIWTmPP5Yfq32Snf/ez2tgQJyZoYkhJ7w2f3g8z2wspbSyD4+OffRbB1snSzjywPYHeGLfEzww8gE5WOtFenWQtqH772zKrmKIU6Ap4kF0boG73vwvlT8L5UjVRQh+AzN92RQrGtnt2c3g2k46kkcxwzsWTbiSXaGT+TRKQWWwm1ZVOMdGtIMQJqLxeVBISsKsfkw+UKDCqfbQZhbxqlX4VUYCimNPn7eJlxLTOYKkphoSWuqJsHchaJRIHi1jW6IpCWpju6WA3A4dV3eOIDU1l/s1JtaNGIRyXz5bnQeY2hxJavQgfE2Xcn/xKzySdR8vLryTm99/mqx+WXwiTSGs4W0ON61gUNJUci2VVCWnkXDgfdxD5nFf1cs8lZDE01mJ5/AbkcnOO/8F/gn874fcaU+Hm9aaHqYs6EvWaTLmSZJE4bZP+PT1l/E47AifpQ/Xmy3oBuawuUtHidNIB0akz/rRQn1Ogt1uPMo4vBETGd66hThPE6uiL2YjAtd225GqYhg2I5H5f5hAW0sLH771Bq3FRzm6ZSNF2z9l5OXzGD33GtTRRhy7mzCOiJaX8vjMkfx80oUomk0mzAEbRmcXgsZIbugjHBqp5rq8h8i3Xk/f4C10VqeRHvUxifpO2keHM3B3ATEYvznIOlmaf8HLz71vMG3lGODsZIZ0HWpD0CjQ9Q09ZZktm/7DbMlDVaoJt06B+Q0jeFz4B1yJ4PdgUofwu/RGqsIy+XvpU5Q3zsIbSMYbdIAenY41A4dj6nwJq2obRjfsSXcxS1Tjmd5GZ81IWg5dTZP5EF1iA0PtOxhkGUd1ioJdGiOTI54gW+emcsKz7Nv6KBPU4aTVX8UfY5/jyaLbub/zCmyeVwk2vEic2olLUrNRHM6mwDDypHQWmwdyng/s+i8/QvskO7/5AiIFjd0sGJN00teDdGrmDYvnzb01PDhrChvmfbug6mQJRwCsHqucHbKX6dVBmsHjZlyPEkE/n2JLBm8/dzvl86IpaByHQTQw3TuEA8pSjtoPkNXmoXvkz+kOi+X+CBVNhmM3Q2bJSj93K6OaBIq9tUza8zGBsESMrqEEe0PwKtyUhe6lw+AjtrWbhNZqpACIgkCPyUJLWCzN0fHUxqawu/8YdmUrCLa107/0EAOLDhDkszExxskUQcH2EAev+MuYUziWkRm5XJr1HhXOq+g8XMyn3euYpg8l3RyPomwM9wa/yJMx97I25zpm1r7Fq5p72RE+i5kt72FvLiEyPoy8IaOIW9VAW9oRrq2vZWb5AcoSIsmQF7iWyc6IJEnbBEFI/qH3G5EYxE1/HoPWcOohZK6ebj78x1+pKzwCnwVIacNGYRg5nX8faCe34dj4uUxrLbOadjDE3kD/CD06gw4XAh6HHZpb6HD3kJcU4JeNy6ke+zNWN/i4vAt2rvey7eiL3HPvddz8q99w+PBh1qx4D117I7vfe4uOhnomjrye7tVVeGu60SbLS3kA9DS3oyKJRnUU0e5WqnSHqdZaiHJHUxcax9a0d5hVdDMO97u0liRjGKZhtLift41z0VkCVFmhyeYixnKaOWmnSKUdK3Tg8p6dzJCSKOEq6ECXFXrK4a61Lg/9Cl6jLUxDc7QOy24FQYUOAv1HYhSTkQSR94Pq2JKSyRUtmwiuFij35OA0FxJQ+lnXfyzRjW/jEvbQmq7FaXFxcbsRx+0dOFvSObpfwp5YQEhbDbqmKvYYC2hRhzPD158un52nD/6KG+LfIyWhHMWMP1F66CayO8dyy76hOLTPEGVuJl7nxBWI431hOCuDFeQauvH3dOF3duCy2n/Uc/hj+7HaJ9n5rbzVjtcvMiDu1G32wrHJvL67mjf21PDr6d8ui+/pEovI2SF7l14dpM3tMLMueCD/6jeDZ5Y+Sv24SIo6RxEimbjIM5ityiMc0HRjz57Hhwnx2NUK1AEJpQRRUiN38wwDS7JQN1zB71KbuWzTKrSWiWDLwivYKDe8hdrVQ1qZnTRAqxIJmEz06CPo0RhpDFHTqgynuSscW4sCjbqFQISOnlgjO4dPZtewi4iprmFc7iaSdtfQXxCITHezNS2fxpL+zEyqIX3423RqLqJmTys7Wt5lku4XxKuHoM+rpDroPd7NmEdcbT1zI1/ndd9d1KgGoHIcIst6Ce0hPey9aDrjt6ymfubVPFb+T/6SOJDXBqaf669GJvvJO12AZm1t5q0//RanzQoI9B03iaRpl/OPndVs/qgVveDisuBtjIvaR2S0HUGrwadSUSLpaBKDaZQiqKE/VeIl+FqMTN+6jiBbA+PffZRRESnkX3oXQTudtDenc+kj7/D0whwGDRpEREQEb731FgGtntLd23F1WsnRXYJ9d5McpH0m0BMgEGqggXhyHEfQaMvYY/JyR/M4PtIOpl63gtqQEsT6EUQa/Hjbkhkfvo73/JdSnJKMkNvDh58UctsVw059kFOk0m6Uwo79eRYyQ3qruxEdvtMmDFm+azW/DDSzJz0ETSPEH3TT5TNB0iwCkh+74Oc/A+OI8HVxY9kKdjr+jFfXhqRp52BSFsNKdmH37GNcUCdzgrw4gyLoWeglYA+jeKsBRUgywS2l6JpraQ51s62PhXnOo4i+PlwtGSlwJLCm5kqSAh8wKq6chGEv4ahcztW6DjRYaekKp0AxjzTNlUT7A/j4AEXIFq7YU4egLMNpk38Xyi48RxpsAKcN0pLDjUzOjOSt/XX8ckoGKqXilGW/Ltp48oQjn5OzQ/YeZ/6tngPSoPEsGzGTGzetREoQKPKMJkoyk6EawR8y3TyfM5b14y8nPyGBES1+xld04VMKZCry+Kv4W/rkZhBdcxV/zpC4eFs+muCbEaVIWliK37qE+IYmzG4ID1egTo2nJi2HbVHjWG4ZzTvKiWzvHkuHJ4wIk4MrfPt51ruY+3uWMLBiOcFF/0PddYDGpDiWX/lzXrj0NvbEjMBcYWbmxlgaPXW81RBJS0sqoQM/pc8UBTaNl9yapWgQMUhzuWX3YbL9h/lw8uWoc4MYHf0p6+PG4hJ1lLV8RKY3huZgA62RSThK1zGiI4C/dAOHepzn+quRyS4YgiDcJgjCAUEQDrS1tX3v/VXm7ue1+27HabMSlZ7KJQ9fy74IJVe8fpjt5d1cmrqOJ0c+wrX98+kzaCCOqGnsU41mnz2TZlswYT1WRnn3ciP/5WHFwzwc/kf6TmtCkxJFZWQImo56Lv/HPdREtZIQUBIjJnDNG8UsX7+X2NhYbr75ZpTxKYipfakrPUqLsg7XkXYCPd5vrvxPQFh3K83JevyCmnhrAKdCIqO2ixzVf1lYvpSOyBs5HL0V1FnohGa8NbEEqzsZ2lhIe0gkscpuCg6Unv4gUx4G9Vd72pyShr/7jyUOORuZIV0F7aAS0GWefKjjoR4nsw/+hdI0Iz6VgqzDPVhLjbjSx2HWJKAUVDyeYafdZOHvJU+zq/NhVAEvPZZi2k0WojwaMo7sIN4lcXdXNwlHvLTeZEHQeBDXZkB4BqoeK4bmWurDvWwe6OfyioUYm8dyRHEsgH0UHWp3IqaqeaypEUjdZyeroQK3yU5uzDBW6//IR0zgdeEIYaLEIs9ljLdPJXaQmosuFxk7edKPfh7PtR+6fZL1fkcbbJi0KlLCjKctN39EAm09HraVfbvr4t6h96JTnnpElpwdsvfo1T1pz/pCiC9vYaCvmAL9cLoi0tkR1YejISqUooWcdj9jyrqw1PjZnKhg+6AwhvoPcg9P4tkxlIGea3k5VmDizmYE9VC6PR+gddZhViioSupHlqKLCJWCfQyj0B9OlTcCEOgbWsKwyCKUjmCu+HA7Q5WHqNaEUSAaMAm1XKEU8QlaerRH6A7awb7BUylM78+eOfH0VEwg9shBRhzeT0t0M8swMtfTn6S0I2Sq0ijZYCWs8l0y06+hxnUXT+5fxFWj/soHV1/H3Lf/RUlyNutSrmRO41J6GvZhTs5g36jxzFnxFpXxo3i0/AUeShnPsmHZ5/rrkckuCJIkvQS8BDB8+PATc62fjL0NilaD23bsP5+TgNvJjkMdHCi2ozF7GTixB2toI/euTaaoM5PBhkJ+Uf0eCaUK0q+7DmtMMv+s8dHa0E2U1YbSH0mLUoEQbUEVYYSAG7WvAIFCwoKLCZtSQOmaVCoVJhoy05m1YwlViVcyigw6FT387tN2Stq38qfrJnDjjTfy2muvoUpIY3/xGuYk3IZjfzPmyT/tOa2iJBEuKqiOOvY1x7dDlVZNcquFjd19UKpURHhcxLim0BLqR2zwYqgMxjxSyXBVLvuUA5EitRxqUtDcaic68hQLjH+WxdG57mF0zmYapTD+7p/PanHcmWWG/J4kScJ1tANdRggK7cmHOq7c9QH36Oo4FGUhKjcAFRokvwBJE5EkiZ2GLrakJHFD44c01c9C79KSl7aTWAfYwjIZseE13JHdLFJVo0VkW8RI1PHl9GweR0FEHBpHG7q2JmpDBT4d2oao6c903Ur22m9kq8NLlg4EhZ8n0bBRKuEvTS3YlQKPx8ygjzmW8NBNpGb8mZjOJDoaRrHEpGeabh/zInYgqTzUSKnUedroYwr+Uc/lufad2ifZee1og41+sWYUp0lGBTA5K5Iwo4Z3D9QzOSvqjPf/+VDGv+79Kzav7SuvnWl2SNnZ0auDNF+Jg1liHksHXkNpdDIutZoIh597il3MqHewXd+A0mZgW2wkmwdZGOY5wN3KJ2ndlE6OdAvblRJhRzvwuQ8heQpRKiQO9s/GEZnBlfXbOajI4qA/ngYxBJ3SwfWWDxjWXoG420h6eR1a37Enz1aMGNUuhmqdBBQqENUo/SJaTwMKqYEbt+ynJTSUF66+iW0DR9EaO5CR5V6CS1MwHcnn/X4BLg0MIjXlEJkzY8j/uJqQxj0kxY6mvPV2Xix7iOszn+fgjFlMzXuLdxX30KwagtJ/lBRrH4pC/RSMn0K/3E8IN6aQULyCvWkpjAo+xQ2CTCb7Ufmt5fTs+B0KERQosXqC2VSWhEMNSVPaCEnrocSawgu778HpN7Cgfj1XH9iIt58S5naxz/MmR3eMRGVNJkHpIzy8hvCIGoKDm1HgJ6XWRUKjG7X/2D2ZXwEtkVpUY6o59HEakr+OIzPSMJQfRiVGMd1jIBCo4tUjKbjf2MHjN4zjuuuu47UlS9BG+2l2VSPtFAialHDaLJQXuiaXFY03muZgFUrJT2RPD59E+ogxWVAY03nfkYC10oo/YShe6U3CmxMx4sfTkcDgkC0YXPMpT0xE29jOjuX7mHf35FMfbOB8DAPn80FeA0+uL6HR6iIuWM/9MzJ/9PlovgY7AZsH8/STJx7Y2d7BLYceojjbhNKmJLOrnbKyeFyRfYkKSsIvwF8HWQj3Wplbkktezz0cTDpCgiNAbUQi04oqaMXBneYSdEo/W9pHIVxagaskiyOaWHRtXSjammgx6dgyooTM6mCK0w7xSvpArijejuQexzaNj8k40SglrhDHsD1QykOxVrrV9QyoGcWigr9Rl/gJnvitxGcvJx6QJAj4gjB1JpHuCsVmbICwjB/1XMpkZ5M/IFLY1M11I0/+b/fL1EoFlw2OY+mearocXkKMZ579e07qHOakzpFT8fdyvTpIC6Qq+VvqHSgkiUmtfmbU2pncJVHdc4R/xbsY4VGRH5bKx8OCGOTO5W7lU9RvSGeY6wYOItFq34XXvQfwUZSoYkfObUwvO8qAplJeFydT6Q8jzlPP//W8QXZZLdqWYzdEklEgOM6BPtKDLtiPxuRHqTnxAZYkgt+lxNWlRt/m45G3nufgp/15+oZbeTx7Olc7P+CG5ho2FPdhXbqL6YGhZKTnkj41wLYNO5hlTybZmExb2Wh+E/pPno6+m5TgUsZIK1jLFdxdmEe9byfxQZMpjVaQlmehplHDb42vc1fRdN4ZPUbO2CaTnYYgCG8Bk4BwQRDqgUckSXr1++7XadSROygYSYKOwhBaCkOJHtFOQp9jTyW3N45maeF8QnVd/LZsDePz82ifpsF3hURF/UQaKtNRCBJZad0MSnQQ5AugtmnRFLiwdPWg4Fh6fm9wLPlR01jd04fDLQqqa0MZlbyPrKJSwhxHUOUE0VBYhsk6nBx9MEp7MW8WZOF/cxdPXD+W6TNm8PFHH1HbUUq0IxlnUTvG/t9tse0LQUljOQp/GE16C9GBFgJCGwn1HbQYruZ11xBEQUJh92APEckuj8en9+D0lqCvicEyvJrRZUf4JGMkSZoqdja6uTIgInzDXJDLh8SdtZT7n3Md7QAF6E+S1VGSJIo3P0dYrAuPRseAfDvWiiAEr4g762IkSeKf8T20WOL4z5H/Y5/1djqDetCpvbhFLbN7Uqmte5IBQa1YtQpKbAPwTbYiOC2UVqThVAkYWuqwaQxsGlVORJeZS/cpkIIEdkSVcFtoPs3NWQR7W4kLfga/ZKbF/wRG/734GkuQUv7FQV0ZGz19GKNyI2q6CYgK2rqMSN4YzEoBSeNAE9pKqPv06xL2dj9W+yQ7f1W0OXD7RLLjzWdU/qrh8SzZWcWq/AYW5qR86+N9HqzJeqdeHaRFWWqZXhfGvZURRHkEukQ7W1o+5OO0GEZo3JT4ZvLhCBN9PUe5V/V3mjZnk9UwmP0GHw7n/5ACndRHOtmdmUpb2kKuz91EuSuc9b5MBrWVcU/jq2TWtCJI4ItWEzGsA0usC6U+wCGNmX0mNW1qMwPCfEQaRFSlKhrLEmlyD0aljsesVWJROYgKriI6spT4wUVkehsZt+YID2ffw1tjr6SwtC/Xr36HILufLf2dKBRDSEvNI/6iANu2rGKq7mb0whzm5i1i+7gDrB51Nbes+AelEdWs6n8N0xqXYm4oREiK4+BFsxi37k0CESMYXfQW2zMHMCH0zP4hy2Q/RZIkXftj7NcQlE7ftBfZ/r9VeJUH6Ht1NQgB/NYMdkq3sbRAy8hEBfPyd5Gdn4dw6UzCf/M7Xnp7BZaudlQJydxz1VwsZvPnFYVP/wxHDhz7OaIv221RPNY5lmqXG7XhIJqQbowxEnUGPSaPAopCSE2pJTtnKWXbwgm1JTImvAplVwHvHO1P3PoC7pkxipqaGor37yXbb8ez9jBp/af8GKfkvFB4ZDdGhZkGZSwpjnrcmibi7Epe9WaTGQb/uXk8aklk9lsbsZtHUymuIqPMChV9MA8TGK7N5RNhFP5YA7tqBDq2FxM+qd+5/lhfIUkSroJ2tKnBKE6S3GZHXTlzGl+mYJCBkFqIdDs4UpKOaDITH5JKnUHg7awoZrTtxFkzAYVPxf6BVYyqdxCjHUCgcz+IAoEgFblCNGKfKExBh3C+O4C28FAMVUV4VFo+Gm5HUMI91Q4qzbHc9V47v7od7k6KYJ33D5iUVvxSKG2+O2gY+jyRB+/naU8m/+qYiCVpE/F9d9ClcqNrHMtRRwvLvG3csrGJuHozjZnzqQ3pw4jf965z/239WO2T7Px19LOkIdmnSRryZX1jzPSPNfNebv13CtJkvVuvThxyRUkafymKJMIDm731bK79D9tizcTGuGiyTmXFWCOJ/hp+rforrVtHElGSzkGVE3vPchxKK5uGtbJ2+Hh6km7gun072NCTibrGxvPbnuL/di2hb0szof0cpF/SQtg0Fy6Vllq/hrHxWSyID6Y0ycjwhADao2ZK3p/InsLfU88fsZguJdPQj0HaNPrrxhKhWkBA/DPNnrewCn8iKqEPS7sf5sn9f6MoJZ2/3/JLIq3BzNmhZ3tzgOrqgYT06cA4spTDTWsIVilocv2O5/P/gVfS8OlllzCneTU1YjA2xUBaaCPOoaFJ76cteTCt5e3cXreCFw/vRJLkIeoy2dnWUdvCuudewpCxhdjRbTiaLVR+NIq3Kx5k6UEtF4WbubY4n+xt2xFHj6H6hp/z+qv/xdDdRea0mfzx5gVfBGguK/zvctj2JCiUtF36IteFz+fuYBFj8FEm+Txc1jSM2Y2jGVvbh9gaOJzQiNXoo3BLDE7BTebEZ5BUbkKtWYzSqch09fCPLTW8uLKQObMvRhMVQ7W/HE2Hmp7a1nN56s6p2tpm3NECXUIYMT1OrLp2OlXZiAj07clj4wfvoFX4+b22hYIkPYLSDMpQ1D4N3q4Y0sL2Y7bZqEpIwCap2LPpSK9rg/2tTvxtLvQDwk54TZIkPB//gap0LTp3gP41XbQWB6N2OWkbfB0CsCgzgEryc0fBVjod2XycXUR2iwu/JpjUQDSOps14g40UD46j2jyJoLR8xL3JFBnSMNeXoPe7+CgjFk9oHb860EO4V0AUFLSHRrFwo8R1XZVYVO3YA2Gs6XwaQepHoCeesn7vEAs82jOJa416GkUFG3N/TUrBrTTW3Ed2fn9Glnkwp4ylK7gZa9dinIqus35+ZbIf05EGGwaNkpTwM5/OctWweI42dFPY2P0j1kx2LvTqIK2fN4AbJw+5q2htfIvq6HgaBkUSWj2Cd8ZZCBXbeUC9iO5dOQglSZTqqgl4DlEcBysm1lISdQ1m41hG7jlKVaXEY5+8yB/2v0Gq2ELMyC5SL+7gk6k53Jv2II2rgjgaCXMHxqDQO7lb8HDpp0ZaV42mvPl+ArqF9A9KYU5QgAlBKlINWkK1TegUuxCVW+lS7KRYUchGycgy/2zW+H7HuG4/Hx76NTqNl/vv+S1uo45ffuRlT52axsY+RA3uoCtzD41t+STrjNS23sMr5Q+QrxmBd0IKF7GUVdHjCe5sx9p4AJOoJXfQIJSlrbS2TmRGyTI+7ZB/SclkZ5ugbyZx1mH0YQK1W0dTvjaaVcxjS5edHFHDxKO1pG9+h+6gJNYHT2b3ivdQimpmXnwd1+aM/mKYclc1/HssVG3Bpzbyn+xfMfvAS2jKmlhQeBvTS3/GkMZJZDWYSW9IJK1lCsNqbuGqvMdI7x6Kzqkmf10W7biJHboMyR9GiNLNQMFDok/Bk/uqee7/DtAvYiKHdZ0AVLy9/dyduHPM2eGiOf5YIo1EK7QqPWwVpjIsVsfCeXNobW3ltddeY/S48QieJiKdI+gJMmJ1d+CpScBktDGu7hBeg47IICerAgrcB4vO7Yf6GteRdhBA3//E1Pv7j2wiVbUdp1FJcqkHjRigvjIRj8ZAWlgmG6JVHIoK5reVS8lrv4mqMBsajQmDz8McRwZB1t1YvSrq0+PYU3MRmelb8LVF4N6jQWXrQOPqYUvUYGwp2xlZJzJgt44bL12MSevFFS6xQNnI3VYba4wm3Op2rKKXjkAAS+1M1HEbaRr+d/ReC5Zdj7GqLpy3svxsDVFwo6hjT+S1PDj9fjbHhtDWlc/+QeMo88rD/WUXlqMNNvrFmFF+i7nDlw2OQ6NU8O7BE5f9kJ3fenWQtjcilWt9rfRt/QCrOZRPJ0xgXqHIf8ckolI4+YPqYVx7R2EtMtGuyEMtKPl4mJfd2Q1Y1bcTrcwge1M+l3y6lof2/o8kmokd00nyxZ3sy5jDkJwVvGCYzy2vLqNwSg+/628kTunlN43JhOdlccj+c3yaWxhqimaGWUGmTkOQpgCT4lXUii04pBgKpLE8TT9u0Bm53dTDQ+ZmFlsa+ZtByR2qGTzUeQ83HlhDX1clD9/+azYNyuBX75ZyoDyK9vYE4nNaOBr+Pk6XlVhtf+IrYrihfQXLY25imNlGBAVsHHQtHUFOzB1ddCvdVI+ZQU9hOdc0bOR/+Zt63ZNcmexC57am0V0zhqqP76Sj2Eb+gOso1Gr59bQ+PHxNGP2OPouoU5F36wK6g8tRSCFENwzk8H9qWPboHnatLKcxtxjfKxcjdTdSqA3msvC+fFhdyFWH72NE/SyixEoG5z/LxG2/Ia1jIyZdEy5jD6JWQlII2CwZCKoEQtolXG/koJTy0IeVITkGERy6iyTPHgwBFytVTor39GASR9Hsb0TfqsVhs57rU3hOhDjstIYe+7UX2wYtaGlXhXD71AEMHDiQm266CbvdzqGySkY0l1KYFEKnRUMg0ER7+bF5ZWN0+0CScCQEs0dS0b66d/WmuY52oEkyowz6ahIBKeAnaPsDVCcaiGr1EGt10nQ0HENPO41DFuBRCzyVqSKlu47Uoii8ko71Q31kN9QQRwxOQzBHOnYjqgS2to/imrSPUSi9hCwRaYtKA3s7JaY+1PY9iA4J0XAVOrefYSWF1CemMCaihtA0J9WVJh4MD+fPYdHMsPyDKnU93YP/iSCATdvEH3QdqHxBPFv9IBfV5WKt+S96SeIhTwtF+gie1adzIHEkXX0Hkx158uUFZLLzkShKFDZ1n3Z9tJMJMWqY1j+KD/Ia8PgDP1LtZOdCr56T9kirjctbPsKvUrFq+lU8XPwBfx30C5w6kUcUi/DvzqbtqBNRrMcS1J+Xhx3EoevEzh30b9dwybplTKzPR9JB9Agr+j4uamKSWF79GC9NiCemvYmn/vVndk118VKWjrHhmcz0jKGzpAqvahb9g/RkaBUoBDCq1qES9uESL6VLvIn3g/LZoHwLs7OMEI+TyQ4QJHBqodsAtZECDUYBpajkE3c8k8uVmJICPDd/IZ5gLbe+vZql145l9CAX8VPqOLj2LXKEX9Dl/wX3H7mLzWPHsXrUNVz54VJe0N3FKEc4LapqQkKGciReTWK+iur6i7iiZBmbBk5kWuSZp1+VyWTfT3xmNN1t/0de+T/YFDOJvQ4zd0xK44YhYey/6T7inU523/drmhtK6IhLZtGN16J2SlTmt1F1qJ1Dm2o5JPq4NFTH+xEhvGIJZlzlDPq2DwddB3G1HxJfX8bumEHsGrYAvTKIuICC8O5G/O6deHzlCHzxy7hbaqd7UwrJ41fi6rgfi3sgxsTd9KlRkKccyuEBZkYVC9ShYaTJQtF7Gxl+y1Xn8AyeG2EekTKDgEbyYPB2o5K6iQ3WMTkrEoC4uDjGjh3Lzp07mZScyKIQJQPKhyAJtYhuM96uGKKiiglp76QxJoqgonq2eE1cvP0AIRNGnONPB/52F75mB5aLU094rXTHKzhj2xACatLL7fglgbr6dEzUkR49iMXpGmxaFU/lr6TKfSMrRzUwtNGBAgVD/GkInkJsTi/55kEsiMklOKoI1ep4upShOO0tWNXB7E7RgaGWzpAFbI4bz23Gj7j5w6X0H1pDotlGvd2MqyCZ6cEeNgwTuTqtGlPi/+ETdViO3oSUuhoh+DC/cpr4k6RhUe3PyNdvpt66g+GhE7mj+T2Whg5nt2Yo/hYt9Qol5/esNJnsC212D05vgPRTLe1xGvOHJ7D2cBObi1qZnR3zI9Tu/CdJEs3dbrpdfpQKgVCjhtBvkRHzXOjVQdrt7jexB7y8M/tnLGx8m38l3kVziJJfi0+g2BRPS0UbCCr0ibN4NeN9HOpOnJ7buGlvEZft/wSd6CO0Xw8h2R5qU1SU+vtzqOhRXp9sweKw8o/nHmfvhB5eydIwJGwao3MbaahSEmm4kkF6MCpV6IQtmNRv4QjModp/N9sc7yI0v8aIah+zek5ff4dWQVmskr196nlnQDUe51b6dd7Fi9OvRbQouP71VbynzGHU0D0ET82jbP1mMk3TKOp6kNeL72f6wNcZM2Ub0z99gxWp87mm7AUUTcG4E2IpnnAxfXcvZ05MK3cfXMPUmTfLmR5lsrNEoRAgUMzHHQb2hvXlpjFJ3Dc5lfcfXcTA8goOXn0N9Q11tCWm8bcbr8WkVoEOBk1OoG+aHt/r9+LwtfH3aA+bDMFMK7iXZHsiLiT07jAaYq+lIfbYUIdxAUBy4fFtxt9TilcFFYk91EQ76dFomVAygai2wwjGVKx7CzCm7MHZOoI0Uw11GYfoV6ZiS/1gJl7Sh/a14BN9eA534XU50egN5/pUnjWiJKHym7Fq9YSKnXjVbQQ73Vw3IfErQ4smTZpEUVER9R1dhPnLcJqSkUxGBGcz3poETIP3MblkHysiZhES4WNFm5sJ69oJGjMYlfrERB1nk6ugHQB9/6/NR3PbUJb+DWuamsziHnR+iaqyGIzdjdQPugaFRcV7iRom1O6htf5iqsKd2M0RpNRUMNyXhl2vY0tzCSYgPFbHoKzleBtjCf2kkwMj++K3N7Mu+iKUca/g1mQS6UljyJoloHAzPqsKg8nL+sYM3KKKkUPCuXF7ERGTBdxmPUFdATr2/5EMYuiO3sOg0GJ2NI7lT4EeFujbmc00OsK78Pu9TLCMwNO4gtcSboQq8HV5wfTTuYZlF7b6LicA8SHffrH7cenhxFh0LD9QJwdpXyKKEltL23j3YB0Hqrto7fF85fWMSBM56eEsGJtMSvjpFw8/F3p1kJY7cDZF/QwkBYo5oLuekjgd17v/i3Gtkq62NpSKKAIZo3k77j161B3EVF3OfZveJaWzEXW0n4RhHdgSY9mb6aClNoGaww/x5hQDfmWAvy9+guJhnbySrUXjm8Clm8tp6bmWgZYYUrVKBF8j4frn8eGmrvsOChrWEVu2hslucGgUVCaF4Rrv4LCYidAVQOPoQRBBFRAJKD0YvB5CHR6y6jwMrpJYuFkgL0XDOxNeIERl56VRV6PVebhs6Ses145i+OBt2HPep2tPPxL1yThrhvDLiP+yJPoWHurzAEWVRVSnTcNkLSTBlUCx+f/ZO+/4Kqq8Dz9ze783yU3vPSGBhNCrFAUBAXvva9eF1VXXruu7ll1dd1lde+8ioqgovfdOEkJ67+3e5PY28/6BXVBUFHY3zx+QTM45M3Pmfs493/m1EBnqJMrrsjg36l1WDzuVk6N+2zTPAwzwv4rP7eK5D9axOWIsswbH8sDsPJYt+Yi05cspGz6MakGiIz6Fhy8+/5BAA6SASN+yOpQ7bkdQFHN3vJUdahNzDtxOjDOaelUDM3Z/gkdpYln+SJJzrIwuyKaqfSNtH3+GIiBQmt6PsyicibFTmFhZRmd3G6b0dfgcifgdrRhjRhJXu5T9+hFESWZGuVJZmrOdqNoY/rFFxksX5tPybinx6nRKVixn2Nwzju9E/oa0e93I/BZsShNhITsOVQf0RzE199teCEqlkjlz5vDqq68yWKFmb1oGw+3R4Kigp3oQhsIdjDLu5gPxVGzJkXR39uMimtLnX6XwxquP090dwl3agzLBgCJM863jLSvupiUJZL1K4jt9eOQyWupyiJAqiEuewPxcDTqPi4tKW6kjk0Vj/cwuLUGFhihFIi6nE1lvAy5jGBPT9iPI/US/7GB1QQGCo5n11kmoUlbglYlMc8RSsOTf5Hd0kDa+G73Jz/aaZNpkw+jztzBp8CY6TrYywuRnRZ+CKTV9CO5mQtoYtPuuJn3sE+gCHm7a8wb3jLqQNQlPMq/9LCJkYURrU5gSNRezVMNCBqFw9QCW4zLXAwxwrGm2eQBICPvpLx7kMoGzhyXw77XVtPV5iDX/dKH334QoSize28KTa6po6HFjNaiZkGmlIMFMpFFDSJJosXnYVtvDOzsaeX1rPacXxnPr9GziLCfO3J3QIs2mFvHp1OS16nghP4bpXUtJ+qwZj8eLlky08am8Hr8Ep9DO+Z8P4oyS95DUED+2F2VigBIhmr7BHmzVcbTtuYtFJynoNWn465N/xRNTz4JRGiziaObt7sQhXcskix6zQo7a9wlW08v0OSdTWikitD6NN1LgrQl6DsTGY01qxxUIInarUPrrUYQJ+FQiRhWkiwJZARkh0Uy1FMvyQBSqLifjaw8wsrqT4TWwMfd1/nWhgicLLsUod3PSor3s1o4ib9AWKjP/zfDGv+AVLuPag9fwseVkFmVcyDnN7/JU4Fpu6NqA11mNlJzGgTGTGLr8FcYm9XHnjg+ZOuvGAWvaAAP8BqzfV8NS/WiKYrU8cV4BVVWVeF97HbvFQnFGBp3R8TxwyQWEqQ5ZVgIdLnreKUfdtRBBtZrrY6LYp1Ixs+oaYpzRbFd18IfV/6RHr+VvZ3bRa9196DybdEwotuLWKVk7JYXsiGRigyo+tMVTn3gqvpRDdaLCkzu4cuHTtPZCdf7ZZBzYQlfzeLLHLMBRncyaxGW4Oi/h5eoOTk/Uo+wSaFpezNDZc5DJ5MdtHn9LqjqrkAfN9MrDifdW0K3so0dWSOZhXItSUlLIz8+npOwgKzJCTBPHARW43TEE7LGY4+oJa+3EFh+FQdXPO4F2rmzQUr93NylDh/32NwcE7T4CTQ5Mp6Z867jUXkq3dwkBnZrh5d0IQH1rEnpHE93pJ7M7WUuZRc6F21fS5JzMR6N6SbPJiXC7mOAfTFCj4GNXOQkhD8aUZCyJH+LflI7D0YsU6KNKn0FfbB8OYzUzXQZmv7eJiG4PlukuIoxumreH4XeGk1c0lr2qV9gz3Ihc8KF4xcieIhkl4QKv9L1MmX8QqVjpaM3lttK3GNxexcVuP2858rg24y/MrLmCa30FxGrTmS1kMBvQqU+8N98DDPBz+Vqk/TyRcM6wRJ5aW807O5q45ZSsY3lp/1HsabRx70elHGjtZ0iCmScvGMr0vBhUiu+n4bh+UjqdDi8vbqzjja0NrC7v5K9nDebU/BPDGnlCJw75x8GHub1uMS/nTmRSxSoKPtxB0AvWQA5Z1gxezdlIeFc9f3tRw1nF+zCmekib0QWJQVb7E+ib6MdWZ6V5/59YV6ikLiaM6z54iyTvXv48TU2CvIjrtoggv4ZJJgNGyYsp8H8oTC/ymr2Iu2QHeWBqBdfNU/DQBXLWDPfRFV9Ltc9Lj8dHjzFAc3SA6iQP9XFuSqxuPopy8a9oJx8bu2kWK8nxbGeQuRzbGBUrzsjnQGoakw74eOP/XiC5aTsP519H1ZmZpK1upaU5B8ugVipMbxCjUlLcey8vl9/JbtkofOPDOTmwiFV5s2gNcxDuClKjduKNG05l1XDOrXqPNR31x/uRDTDA/wQThudxxfhUXr12AgGvh1Wvv05kdxebx43DZgrj1osuIFqjxu61s2XVSpoX7MTTsxal6nmujYlkn1rFGW0zSOjNYYfKyzUb/kHIpGP/VVPJDw3hpMRLibedyqR9kbRGp/Dm2X+iJuUKPjNO4QPLOCp0KfhlCuSIqMQQfeYodueNJOgvQ1ubxIbkJGRiEF/TeLKTOhhplxFr2sjnpR34J6XgDPlIVKZTuW378Z7K34yS0p0E1SYcgolwn4cWWYBQ0igU3ylG/dHeFsY9uobbdmn5wJNPWHUrFcmReDRa/IFmAnUpGAw2zmheBYKAIUXOcmQoZclUvPwRLvvxybjrKe4CQJf/jayOkkTD2qvptqpwVcRgCQZwqWV0lGSjCboJFc7lySw1qS0NDKpLpsnqpiYunpF1xURIFkR1FJI7gNW5DdEUQ9LQ1Xjt0cS938S+1HgccgPFUfl44leSFJC4cmEn4d0ewk51Emfqp7zPSkV/LFa7HXnaLtJObcLrUjJ6j41i8wwuX+WjSalkTbiNkL8ahSCgPXgOWVHt7Mg/hTj7auLbwgh5kliZvJA3tfsQBIHluk4WZNppjThx3ngPMMAvpdl2yOKjUR7hxVnxQvhHPjxgOfR/8cJv/TkpQsfk7Cje3t74P5lARBQlnl1fwznPbsXm8rPg/EI+umEcswviDivQviTKqOGumbl8Pn8CKRE6rntzDw98fABRPP4JoU5okbYmMoN7cn7PKds+YcTadSBYSe2LJT8unycGb2PWhgM8+GaI2JCDpEndBEaoCSmCLA9loDnZRVuXkeqSP1Ado2dLVjiTd21m1p5PufVMNfFCFheu02HVXcxovRqfp57d4bdwW3I9k1Li+XtRG7syoV8ZhrfjVPJ9Q7lJJ+eyjfHM2VvE1K6pXNSXy7X1Fq7YFMkFKxKZtTmGMQfCSOzW0awLsSrFwcu5Nj4Ld1LVLiHWeGgxwPqJCTTEhvHM3/5NXnUJdw6+GWm8msBGLX19UTBiPd2ygyQbUqF+MDe0vs1zinmMH9RIX38fMV4NPX1NyBHYX1iIvLqGIa0trN7+/vF+ZAMM8D+BViXn3tn5GNUKlixZQurevWweNw63Rsvcs2awrWUJV35+BS889TeSVmloVe8jQv0Yt8fEsF+t5uqeHCIaT6VKEeS0fc8SoZDQ3Xc/PR1aNuaNZVtbBlO2V9AeE05Kbh+vVNxLuqsSgHTvZ1zv/xM3+m4iveUSohuv5YqS5zjF1UhArkQmLGFk0m4sxg04moYTE95Bqi6SuOBudGobj3y8A3eKkmhtMjveWXqcZ/K3o7ayCUfUoSDxME+A/mCI3LRvF3/9aG8Ldy4uocXuQQKckoruNjVbzBIqRS5SsJKOqjQkUUZebBmCO0BnQhQd6NlCLTnaUSx/6l/HJduju7gLZbwBhfVr4eLb/zIN4e30+SKYWl8FQHl3CkpnM87YoTw9xExQkDht2ypc8kTeGadkVF0JmqDERH8WxhAs19ehcXtIGedAoXZifFPgYEwUfkFkQ9QkzAmfExSc3LLWTafTiGmKm1ijg232TJa15WBJn4L9Qhe2IZ/R1xBFxeJByF0appt24tIPJbcJnrVYSDe8SndQJEWp5mD8VXg0Ig5fN5rYRXh6zsSv8PDGoGo2RsoZ74lkVbVAe3vrbz7PAwzwa9Fs8xB/JCta8UL4ZB70NQHSof8/mfc9oXbZ2BS6nT4+K2n79S/4BMLhDXDNG7t49PNypg2KZtnNE5lbGH8ofvwoSbHqef+6sVwxLoVXt9Rzy8J9BELir3jVP84JLdLe1t3CzNVvMbhkB3JVPnltEnkZY/ggYg03v7GL2TskTOle4qf3sjkmnzipnc8C2VgmddPoUlC++wZCsig+G6Mlsb2FW995jrvOVWFSJnPBxnhSjOdhNvfwjPEprhj6GPclyKlExbQ9IgW1cqS2i+hsuoOzI7uZrSqld8Mw+uKGEhbtIrZzH/49fThq1ETq3JwcV8etkWU8HWNjUXQUmyJP4zH51Qx3TqA5Aj4f08GmSW3483oICTIaTCbW5ydwxQevktrSxPUF95OV1krjzhxElLQU/RuZzI9D/jt+X/kB5oCXdxPO5lz9aj61jsGn7sTY56JRaceRPZnqinzOqf6A9e21x/uxDTDA/ww7d+7EvmkTdSkpeDRq2rLquWX9OTy2/W+cdmA0F3TPwJsnMTZqEc+EmdmoUfCH3hDe+svpl0konTvJ764h4q+PcH/zBl4fNQq/P5Izlr2KQu3l/0yfMsW5l+vy76FLmcy5bcsYXF/GgTotW1qUDNeGuNoMuyM30TRqI/EFrQRtdkzazVgmrUCQB+gtn0FO3hYKXdkY9Eto9WnZ7NiEJElE+Y00VzQc72n8TRBsLuzhh76wLa4gYW4nhUnfTuH+2PIKPIFvv4EWkeFucxLU5wHg8scS6kgnPKaOxJqDiEoFyhgFryEil5kxt6jZ/dnn37+AH3kL/ksI9ngINDvRFUR+dUxy9VBW+xBBuYyWrdno9V48ahlduwYR7rWxc8bv2BClZMrurRg9RXwywoYhqGZQeytZoQRa9SaCArR6qzEPSiI8aRcdBwuQmry0hBvZZykgPvogLcZKprcJDNJ7MU/wkBjRx77eODa3xZCTcBK+03fgGS3CuhSqt80iFAiwrz+NLNUuyscXcMZmOb0KGautHdhD9ehlMsJcaYRUepS6qYzuuY7o6Fz8vRPReDexyL4EtQTXKZwkW0/oiI0BBvhJNNs8R3Z1XP0gBDzfPhbwHDr+DSZkWEmz6nl1y09Y13/Ftem3oKnXzdnPbGVtRRf3zx7E0xcVYdL8vCROKoWM+04bxG3Ts/loXyvXv7nnuAq1E1qknbLlXRJb61DoplDQ0ERm+jgOdC/iwoU7ifVA4qQeWoZF86FyLFOkPSxzZWGe0kN7QMbe3dcR7chg6ckegiEFf3n27zw/LYQrPIbfbU5CHT2Ct9Je4pq0P/N5fBnDm0I88GaQqz8XqUyJpDp0I12ewVyV/zrpjg4qq6ajCpeI6tyFv9SN5JOTNFRF+Mx82sZMYfngObyVNpclmixKutuR7fs3p1bfy1P2RTzXl8hpvafSLtfxdrKLPUO6yChoQJ/op9OiYebKtzH3O7i88BFOUu2l6uBwNOFOKlKfJF6jZl/HH3mm4n52KaegGSUyyL0JmTGBllAbSlFGcVYqyvpm0prtrN/29vF+bAMM8D9BZ2cny5ctQ+dx0xUVxd6IXXQJ9VybezUfB15gZPcgTKckkx6zmnfddbxpUHNxXz/+rivQBnTs0jq5YtubtJ8znmkdL7EpbS7yUJDzP/sXZtHLlXH7seVfwtKo13hxm4o1a/3cXjyOexqv44mGW3m++iGu2vMP0squ4U5pCOOMAWRxRlDKqVidy/adp+HTNeNoHIlSVBGV1ck5vX6U+iqecBTgVDSQahzMsufeOd5T+ZsQ5vTTZzm0yTE7/IT7JAoSLN9q02r3HKYnSD6RTfmJhBR68Jbgq0xHpfJxaWAZQjCIP91MOVb2BHeQZRrNvnc/onxL1dcDHOVb8J+Lu/iLrI5DvnZ1bF53Cb0WgTXemVziXYMA7OlJwe/rpjt5GE8NCSOzz0/+/m10xeooTUpjYvlmZIKSomAaKV6Jt+L85HV1kjhiA257LLkvlVOcGEWvwoIsSk9T5BoskpY3hj9PXUwCBeZ2drXGs7p7ApmZp6Cf+j5eYzOKj6OxLGln0fCFSEBf0E9/KJz59rdZMf5ShlWLvGw2EaN+BrcYItPoQa6aTChlF8Mo4c8HVnFWRxaiP5zyxO28q2xgRiCOGHvk4SdkgAH+wxDFQ4ksjijS+pqP6rhMJnDZ2BT2N9nZ12T/8RP/ymvTr01Jcx9nPL2Z1j4Pr10xkivGpf7i3AyCIHDj5Az+PCePVQc7+NMHxcetFuYJLdIMliGoLaeT0VVPQmQ6vQdfJXfvQfRJPlKm9/Cc9XR2iRlcLqxmhTMD2Sl2nEi0d/6RnI4Ctk9op1abwK1vvUBFYju7cy2cs9/K5wV2/pL1GPs0pVza5uOl131c/w7sT5OxcGY6Pb2X0x6M49KcheiajbR2DSHSvR/KOwkG5FROGsxfzn+IW0fczVvKkyhpiqavVEPvPj0lZam813Iyf+BW7jNdz8fhE0l17+CRvud5ug0mNE5kv0bBfXEC7qhaRg1pISqihzkr3iIgqLkq/8+M6qygpSUHRWYp3ZatxJgLsdSYObtjJX+X3cnUrEo2iylEBDvR2fppVdixFc6gtjyD06s/YmtnzfF+dAMM8F9NRVcF/3z1n+g7W2lISSVEN3eefS+fzvqYc/ZORFbrw3J6BqaMZnbvfpa/WsOZ4AkwpTuboG0Y+1RBLt39Ao2JCm7KrKcz6kZkITuXr3sMYz/MjGsikPEC3v1nc8kBD/EWLaZpyUgnJ7HFJ9IkQpAQblMP6cFI0kqvJ37dEyRXn0+SpRCF24m5MxyfJCIh0br/TJKSSlDGRHGWYhlSSOKfxmj0ChOa3i466o5PHNVvidEvo08vIZNCaN0+1ER/b0N0pKxeRqXE/jQtcmU2wVAjzU3phHx6ohJbUDY68es1+E0qXlCbCMqcjLBO5fOnn2TbkppDcQ1H+Rb85+LZ34Uq2YTCciiro6PsZarU5fS5o9CtEzDrnHiVMppLhpPU38qTl96AQykwd91SlNpBvD7OSE5bFdGuABP8GZRY1AQEyD64ndSTOpApfWgXS1REReBTyKmJGUIw5hP65BKdmol8tPIGxsoqWCaOYInpr2QVpGE46RlEScIRMrLVrEbnEzlncxC7SUOjJ4K9juEki3WEJTs5qSYCh1zG8thWuoJdhItGwlU+4rqmMlP/AtMtf+cR7T2c0WlBpu5hU8RCkD9DW8uuYzJ/AwxwvOly+vCHxCNndjQnHPXxs4YlYFAreGHDUXhW/cpr06/Jpqpuzn9+K2qFnA9vGMv4TOuPd/oJXDY2hZtPzmLxnhYeXVZ+TMc+Wk5okRbutxDusZHiaMdfvhi1s5P4cb04Rxn5veyPKIIiNyg+Yb07FfvJDhQKkcjwRzDsSKcjo4XVMTlM27ae3PqNvDZFQ1a3jBcLD1Ctr+H84iQW7XQz5z2Qd6v469kyanMKcLWdQXMokjOSP0fVGIvfJmCsL8bXDp4iI4tnz8PYbuGpv/+ZT+dfwT9eXsB1u9dyUt1+kuv3EdlSSmTzflLLtmDeVkLLOhfP1IzjZaZjVvbwdOhN7m/JIL17KC9F6XnUIjHaWkZhSgNnrn6blvBE/px5FeaD4HJa6BjyKmqNk1Zu4b6KZ0DQsyRuFLMVK6iPyaVa14VKlFGcbEXd3kt8o4cNm18/3o9ugAH+q/H2epG75bgsVkz9/dxzywOMckHvv9bhq7URnrAMw+4z6HpjNrdFRhDjF3m0vYs13fNxCBI+9y6Se2v561w93qjbgCDn73kEc72OiVFG1MJD+CrDWBGtYLtxBT1dz7Gl9APeW76CXnMr3ap6Po76iN6iB9k19CFeiXqffsFPqi8Le5wcv1og6N6FwZGB3tmIp7WIoDuMqOg68hNFko3bWGP345KFSDVksfal/4y3pj+HLxOB/EN/CjsPRmNs7ULCgzIy/3tvXG+bno32O0H7WuWh+MNUZyNVqdkAKDw+hKY8wiNaOLlnCYIYQsg3UylFscG1kgh1HOnaMHYsWcmnT+5DOsq34D+HQKebQLvrKytawNlMScPDyIMyHhbu5mrtYgRgV18RnSEPmyafxYY4HVdUOhHaivl4ggVBFsGY2goMgoUIWSzDbSJKdz+6+GaMsWXYdmTjrYPWMCNVYblER++i1ODArZ/KU6XbGa2rZbc9m/Le6ynK/gTdiBeQORJRNhlo6IujN70VUSYxW/Qw0VKNwyVnuGENAPfWP88np17GuPIQb5qMmDTPEJREcmPa6AmmsKrvJhZKJ3Gx9x7S7LnE9+TREFbPwzol8XnRPzAzAwxw4rO0dinTFk3j5A9Hok9/lLbg5sM3nHofKL/zEkmpPXT8OxjUCi4fm8LSkjbK2/t/+AJ+xbXp12RpcRtXvLqDxHAdi28YS0aU8Vc5z7ypGVw0Konn1tfy7o7GX+UcP8QvdugWBCEReB2IBiTgeUmSFvzScQFGtG3GU1GGzGtHFucndUQvLypPY0VoHKNDB7hB/QEHQ1ZKJ7rIVokkRN3Ottck/Fon7+YlE2nr4colL3PnZQpCshDl4U7O6Z7GzLV2Eo3bsZdCv0rF/RdDsjCazp5hVInRTIjYjbnNgtZWDp1elNYAbdl5DF7RwJnv3IU3JZlarcSaQYMQlZEoNNGIsnCCSiWSEmRaUGhAoRJQaeRY1TLUiiB7vSMpDu5kLJs5uU/iQfdlrIldzeWxUdzZWcm54X3077Ty2cg5rOmpJfdABOkjtlKV/U+ySu7mYMPFPBr1OH/Mup2Zw65n52Yno0JdBNxWOiJEuoafhrdiE7MTP2Zv92UMtaYdi8cwwAADfAeXSo1KDCAPCZwd2ory7wV0+R8kIKUSoXkCrbyHgKuPWyPDcSqU/LulnU8d12EQtXyk83Dn9qW8O10DKfNwKSxMO3Anqfs1FFlHEKufQp+/l/kTdBRu/oiJny4CQK9YT1SORHFRAaWaBArzVhBCIqTwoE2o5T2TyOi2Eczon8xGi5LWjs3UmbcRoRmG2SvRtO9cMiY8zYHSSdyU/zl/2j6Uz1RazjBks6/hM/orSjBlDz7OM3ts+TIRiCcQAkEg4JMjlAXZrdRTmDbye+1PH3qo1uRjyytotXuIs2i5bXo2pw+Np2dTA4+NiCfzoBbJvQFn2QiM6Ts5KaqSFS1u/AkGJJOOV8wjGWLbz5Cwk7C1L6KxLBFnVDhGec/3zteOlTF3LCXOomVyTiRry7u+d94jUrwQVj+Ioq+ZGLUVmeJBRPFcSjefjlcp8o73d5y8cwORcgc+uYzOnjB+N2w5Gu2nnLPlLapa8/gsKY3SpBGcUrIWlSgw3ZdDo87PEHeI7aFPiS9Yi6MjhfoSK5oYP340WGJF1lrLMXjVPFu2iXHaKnY501gWPolBgx/DZO7C69Uj0zejyvKTTxOjnUGUcUrkVXIGx3dRQgL7FVFEpdjJqHcwObALgQi2CjY+j6lhUr2dmL4c1EmrqWmcxHLZCA4aW7he9RR/7RzMFXorG6Pq+Gy7nXNmHLOPywAD/KYsrV3KA1sewBvyAiBT2VlY9wR5cWZmpc36duMh5x76f/WDhwSUOeGQQPvy+He4akIqr22p558rq3j2kh8oC2JO+MLV8TsIskMxauYEyJwGVSuO6rxf3teCPQtod7UTo49hftH879/PL+izcGcTdywupigpjJcuH4FZ+/Piz44GQRB4cG4+jb1u7ltygKwYI0VJYb/a+b7LsbCkBYE/SpI0CBgN3CgIwqBjMC4H+1zIAv1EDu/DOMHPpfK7WM04iuTN3KB4D7tCywdFcnJ1IpnuTA4s7MbtCmfFWAGHysC5nz/Krb8L4dQJDOsv5Pma+zhrTZAwaSe24iA2vZLbLoPB0hS89nx2B5PI1jWQbvNibC2GTi+mPBeZLR7O+7gMmT6aVUPOYbP1TDqi5yFFn48/toC+GA22uE4cUS04w1ro17Rgl9ro9rbT0tdETVcdZW1NlNic7BfzWGK+jXLraB4KPcVd9YOJdKbzYGwYn6r7udf/CoX1e1k49Gx8PomGugJkcTXYYzegi5jJyMpahjiqeUTxR2Yl7GVnRD4V4Z2oQwIHYrRoul1ENIRYt+mVY/EIBhhggMNgK9+ELCRj3L5NNFk9lIuP4SWNVYM3c/+kTN4wW3hS4WaPRsOcXjWxbiNd7knUKIKkt24hmBIkPXUoB/WDSG5fxJl7fIyKPJdk4xSafZWccXIUdqmP0YZIOq+YSuftRtoeD7J7egGNwSyyB21gT1c+zxb/jns2PcxTe65ncfUMbndZ+YvQz0jtaNQKC1pbJc9aoSRCgaejEJfLSkJCGU5bPLOTVvO5148COVaDiV0vvA39vyxbniSJtLYuoqLyzxSXXE9Hx/HNHnm4RCCSKLAhkEdWdtFh+5w+NJ7Nd0yh7tFZbL5jyldC6aqxJ6GXO3Ba0nGp5fS2q5C1DyYmrpoJbZ8il4LIhuhpcxt5hw5COBkdNZOI4Ca2OS8gIKm+dR63pOJh/zlIQIvdw5vbGr/KKtli93Dn4hI+2tty+Bv7RhyJgIRC6EK26hY6Fp9Cr9KGq28oq+RTuFH5Fn5ByafquZwWvxad1o8MiehAJ6Mi1uMYoiapu5F0m4tcMYU+pZIhLjUlfWuInrKXUEDLY/5rMDubCcpk9KdkUhK9E78gcG9j4AuBlklNZiyjxy7GbD5UBkAd8tPVn4itLJmMzQpG7bETFunF36fkbcU8JJmGnfVTaV4/mFrCua75PRyjshjXGeI9oxGF/lkESWCwUaBO6edkt4bTBCd/yvg321r8xNdPwOA3k5Xy/Rp3Awzwn8KCPQu+Emhf4hN9LNhzBDvHkHPh5lJ4wH7o/x8QShadiivGp7LsQDulLX1HvojDWegApBBfxajteumoY9a+FJ5trjYkJNpcbTyw5QGW1h75u+Cn9Hl5Ux23f1DMuAwrb/xu1K8q0L5ELhN48oKhRJvVXP/mbjod3h/vdIz4xZY0SZLagLYvfnYIgnAQiAfKfunY2XndJOW1scaYw5+88xik6GGQ1sEV/a+j0gV5Js3IOHOI+BYvNV1WOrrG0Dash73GcHLL7uC9CZ1ogkpur7qaycHBdFUsA+daAl1+bGFy/ngxTHJPwdMfy8ZAGtEKG6OddRjbDiKTQiQM7cG0u4A6cyFV0WkIghpB7iNo7sIh340o9yEgEBMVR3z6UHxaK32iCrtfwBeS8AdE1AiogyJKpxulrQdnRyvtXd18rBjEXiGMubo15LSl8LDzZD6JX0WTIsQ/Wh/i/LB/8+Swq7ln+1P0WaMI5b5Fpq2Aspa7ePzg/3HKyBfZlWQieccBouUK3K5+OsMkOkfMxlO+hmnJn1LeexU54cm/9DEMMMAA3yHBF0fCx//i2SFnc6ZrIrHIuAsXu6pSSWuoY7JiH3+LDiPSk8Yd9g285nwYEFir9fJY3TqM0W7+L+MyNN46ntqxlraEOygJj+bFCDcbE4fSjwydTsn9E/KQCVlIzEb0yZFHylBF9/GKfQqBfgFVyIsmIojWLCMQrkKrcvGZLoqWbjl/cI/B1/k54/rK2CXkMFjUsK3kaqaOfoSGxnym5axjbcs4qoMaYq3DKW4+wJi3rkV79QegUP3oHByOltZ32b/9WWSCAaXWjc22C6t1MnL5EeIsfmWOlAjEJeoZkhTxk8ZSygR+p3fy/qjhnLmslNjm1UilE1GcUszkqBI2Nc7El2JGNGt5P2IKaSWvc6rsErIN+bRm+NnS8XuKxNcxyLtpk8J5NHAeH4vjj3g+TyDEYx9t5fSDi8DbB34HBP0Q8oO98YtN1DcIeLBU7SM6OZxpMXdxRun7HDQN5pzUG1iy4/eo5MHv3I/In5oXscBvQImWEYEUugN2GgUPvsllGHU9vF53LZNXrsSpVyJTWmiKbKRJZ+PSVoGZygb2hRKxTbNhVdgQQgqkutFU1GhIszUyPmovaYKHDoWetwxn0B0XxrS9y4ivrKTKkoCqr4reThdlviwuzD3AaZUHKfEMZwt7+SzqILPqHUS1noQ8dzHigRlkdBayqsBE8agpHGgaRPrBMAxnDHiLDPCfS7ur/Scd/6n8bnwqr2yu44mVlbx8+YjDN/quhU6QfX9t+S5fxqwdRiQeTnh6Q14W7FlwRMvY0fSRJIkn11TzxMpKTs2LYcEFhagVR6gn9ytg0al4/pLhnPn0Fua/s483rxqF/Cek9/+5HNP8tYIgpABDgWNSIfUDkwO7eAbveOcyQVlPnC7IuV1vk2jqY0eYlhHREha7iEt/EhXbLkKwdvN2eB0RrY9i1/qwuDU8VH4XadpI6pq2E97wEXJvCEeYwC0XC5zkPQl1XzifBDNRCkFO8ezF1FaOShcgfpBIe+U9dEYYkCuCJOSq6Qo10dJTA4KESRlF9JACaiUTH9fbKVvXjyR97cOrUshQy2U4/UG+mRQmxpTCmIRCElxeehrLeVGMZLb6c/7uWstD1eeyNu0DblHKeLz6Pq4seJIX0s/i0gOfYBi1g/qcZ0j03IGzMpffxX3Im9Zb+NPgO/i0fAo6ayeZfhMHouRM3e3HWC/w0cYXyJn7l2PxKAYYYIBvUHD6TJxREdy7S0Go3UPNuCiyxAD+RgNX2f7Fn61mZJ5o5rc5afXn4PNms1PtpbB1L5GOPi6+ZR5BhZEsdzdnn/YMvi8LKktaQEAf6CdaUYkWL8EQNDssiMFoehUagnIjUrwCEgWCgFuSICiCBHZlOAgCO60Sjw3JY+66LUzt3seMibto2HEhYU0p2PMjSE4u4WDVeM7L+ZhlJVdzU0DPbnU/ZTVWhi2/E2b9/ajnQpREltYuZX3jSqztB9FtuBe5dOjL05K+luaUt0lOuurYP4SjIM6ipeUwQk0tOIgwqPlob8thXRuPxMWDhvGEt4mQykhrmA99vQdrdxZJcfVM2P0Z6xPPRjNYiX+rh6dHno9h+0omaWcSKK9iqbGX3c6/ovaH8ZjZDUeRgazVpzm0cdKYwZQACjXIlWCrO2x7jU/kz+4/oPD7aUvK5FLz+Qxbu5NImf2w7eN9negIMMtXyF6tn0xJRVnaB0TFllGxdwydjSoKpTaM3iD7B5sotm5iWL/EH32NHNCF0VPkQSYDbXce9aVTMYXWMlO+jZTodlrlcp5WZ7NHdj5Lh04iIc7GiPVbie6opip+MIF+gdroMERNHmsN4zij7+98HijA0pvEBxGNnKZ4EaV0C2cJOg6Of4bezTdy8Qo77xiGIMolOrVZOF02wPyj8zjAACciMfoY2lzfr2cWo48Bfp7b4Dcxa5XcNDmDRz4vZ1lpO6fmxxy+4ZBzvxZcD1iObvAjxKz9HOH5Y30kSeLhzw7ywsY6zipK4K9nDUYh/+1TauTGmvjz3DxuX1TMv9dWM29q5q9+zmMm0gRBMAAfAH+QJOl7kYqCIFwDXAOQlJR0VGNuDLuP0tYQk5S1WHUBzrGVMthUi0shw5upRSHqUCfNYuuiXPo1nbyZuRi9s5aMVjWagMA13fNJ00VSaWsgZs9LyGTgNUvMu1hBUWAYSb2xvBtKwSmpOcezlrCOCrQRXiIHW2nddxkRsSHyT0mgqq2MfSVbQQIdiYjZQ1ja6qRmsx2lvI/hyeHMn5pJYaKFVKueOIsW5RcfoJAo0ecJUNvl5EBrP9tqe1he2YXbHyLBksrU6AI+r82mSP4u94tvYy6/mk+z3uZhmZt5dc/w98z5bG2vRlbnJS1jL974zfS5r+P6g1fywaRTeE6YxHnq3bjFaHzOPrrMEu0j5+CoWM7klE+p67ueVPMPxDUMMMAAPxnRF8K1X02ozcHKLD3vVLRR1enkcvknvJpsxyvoKWqezLDQZ6x0XIdDIbIpRUPq4DGcdvlMAgoFgiQRIpE5jV7qQjtxCfG4o7VkipXMkxYgINLqVvNJcxFtrrOw+fwI2hAxWW5mudfS3BDDGsUoNKYQsmg1dr0ZBAFDwEWYx0ZJSjQpQyaQuedTcsunoC16n849l7Gv5CImjfkXoUYlMcputmibCHky0CQOZW9TNkN33IgsfjgUXvCj83Cw5yB/3vpnDvQcQC3I8EkihmEPcn/Ow9jXquitn0Bdzf+REH8RcvkRUkv/itw2PfvrmLQvkAsh8uQb+WjvxG/97UsXQ+CIQs0aHsdZ7s/Yk1vAiH2byCtfi1B+Jq7xLzIxbj9bqk/BkW0laVA7bY44/jl8LI6tpczW5zPTIbFO/ASbcSQmMYV++Y+ndI6z6OD6Td//Q+O2w8aROEQNG9MnIEgiZbJMrtz9DqsDE2kzRhHv7/xe+z6M5JJBUGUksq+RfSlbSMjYTHvlEF7smM55rYtRhkI44uLYGbuDWH+IJ3tbqIyw0J6rQhZSEV16KZb2NAoUr6JXbqRf0PBQeBgrAuNJbB9LGm2cfHAXq3KHs7mgiBlb1qHxBwBwW+I42zyNdU6BzebVXN+/mE+VRSDBwsT9XFTvJLxhOorYtWRPfYj6NXdwiUfB52ovjwhLiJTyf3QOBxjgRGV+0fxvxaQBaOQa5hfN/1682pcugMBPEmpXjk/lo32t3LeklLEZET9eP+xIMWqHa3cYfkx4/tQ+gZDIHR+U8MGeZi4bk8z9s/N+UoHqY805wxLYUt3NP1dVMio1nFFpP80j46ciHIvc/4IgKIFPgeWSJD3xY+2HDx8u7dr146lzR/zlfQb7monQ+JgVMjEheBd9opJdI60IWpEY+Wz275OzwaFiW/KnhGQqChpzGHFgJ0lx1zBKOYxqdx9RK25DUAqImiA3XqohWp7GOW2nsEiCbcEUTnOtJ7WzDEO8k4hcE0L9dKbOv4DSyjLWr9tAIBBA4YmnNyGH1TY3fZ4AhYkWzhuRyIz8GCy6n+Ya5A2EWFPeyetb69lW24tFq+SM5HCGVT/PeGEdT7t/z4e5b6KU3CSYr2Fz+BiuXPsGQ4dvx6jtJ33z32it2YRz9H7+lH4zZzlupmFfEYpwkeT+LCwyI1OWL0c/zMbyU6dx1ZwBa9oAvz6CIOyWJGn48b6OX8LRrk0l2xuI/fhR7g5NY71Sw+hkMwW+/ewJfkqNxsXpJX9AH9RTF6VmX6qasgQVokJA7w2iCIoYRB9vb9hMWOAA3kAJRp0Ts64L2RG8N7ySklpVHEFLCGMX3O+4EGOzizmtO4nvaUMuhvCo1OzIK2DD0JFsKhiBX6Uiua2Z05e/RZxkQsyYStDhxuaPZvC0W/H6jTy392pyk3Ywuvo8suQCH/UXc6HxAFm6JQhXrYaYI2+Cmx3NXLj0QuQhGec7BpFeWkFPg5ooh4vqvPPwh3IQCBJZuIhRs8aQlHjFz30sv4iP9rZw93vbcKFG1CiYqSsnzv0xyzX3HNbKFm/RsvmOKUccr3nPIk6r0XDJomfJae1BzJyB7pTdiJFlbCgt4pXMmzFo3Fgqy2lIHkGSvY2bttQz2TCUDk8DJd2fsjx2BDvlOQS/udeQgG/8rpDgtJCScUY9sUlmkrLDiUoxoTSqkNV8CB/PQxC/3twFkTEv+w4WR0/j/MpPGL+hjjXRF7BzdBijQ2v5Z+XjyPF91d6PgmXCHIZ4rmCFvgyZvoKUIZ9gb8vinv2XM71rHUmeBtLtHp4+14ZNHuCtlnakaDPN6aDtzqXj4GC0wRqmyNYgIPCRLpnHozxM7juJue3nsEPeTbXQSn0gFqO1B31/D7e8/xZ7E6NojokEuQJF0lB65H2sK8xnxf4/UCzXMi86HJ8iwGtl2UTK/sBa01r6wiqJD3PSuf0SQgEtJ0U/TvZVz6OIzTiqz8H/0vo0wH8OX1rLWp1t6OVW7ht3K7PSZjFt0bTDCpdYfSwrzl7xk86xv8nOGU9v5oKRSTx0xo8kh/oy3vW7afm/iVILs/91WHfH74pLOCQ8Hxj7wBHF5ZH63DnyXpZuiWV1eSc3n5zFvKkZv7gG2rHA6Qsy+8lNeAMhls2fiFn3y+LifmhtOhbZHQXgJeDg0Qi0n0KRvoEwyUeiNo9RtptwSko2TxiKTlmDsXMiu8Ri3lZqaU+pxacqxCydyhWfP0LJ1DMZ6Sui1e8jbPU9CGo5gszPPRdokasjuL7hfBbLG9gRGMRJ/dtI7SnDlOQgJs3JMONViNdP4u1F79LZ2YnSG06PPJstBoGe1j5Ozo3m+knpDEv++dldNEo5MwfHMnNwLCXNfTy2ooJXyjtYE34BfmUO10rPIC+Zx+L812hyvkmEIZulBacSdsDJ4NEbaM1+HaP7erJKPyAnvoHl3pu4Iu5FGh2Z+D19dBol2kechu7gMkanLKVj6h+I1h/b+hEDDPC/TJqlGq3yXZ4I20z/tCf5YM1uKu2d7Ett5LQDt3EgNYKSrBCtBhNRPTbmrNzGtPK1RPbVEm4PIfOJiMCX+f5cKGknDr9RAUYlPZoYtidG0GBOxWpyMiLsIGODuzB3hVAR4nXj3/BEKWn1R/N+/hQCgorRsmIGibXot7u44PMl7B5UyJJJJ7Nh+EmcvOlTIoMhqtVhxDnUtNSfQmruJ0y07OOF6lkEVb2M80fTnxjO3qazyVCuRHjtAoTfb0TQWb53/06/k5tW30TA62d+48V8Kn+OFwohNxas/lmkdaYwXL+IYvdp9JbNoTH/8eMm0k4fGs/BdzZRNqiQlckFjN65FrfRQmvX4TchR4pj+5KEgrmcX/EQ7ZFxaAMiQw6sIDL2D9RPuJ+hKbWsqThIzdChjIiTGLK/jIbwLD7NMqOu8yIG4wiYrmG8UyJcGWKjJki/TMIkCqQFBGqV0le/T/QqyAwo6HT66GzrZP/2Q5YwBaBXhJNunc0Q2WfoRBcujDxtuR5FTQGPfrYNryqfdtN4qvN0NEUpuXb/eOx+L5L6JcKlPvowskYYzxDPxbwfZ8cilZKStwxnbwoPlF3JEFcZSd5GMjrsLJnupFMR4p8d3fgyNXSZdHTsKkBo7WKW6WVMci+rQ7k8HiunWecA+QVEdVmJ7qnlrIgsRCy8Ex2k0lZKbsVuAjIZCpWZgNGCpqedPqmfkAAd/WYeSL2Bx2r+wb1dGTwa3c7Lyfv4fW0/I3sn8BB7iK6/FnviDka1pbKu9Q4MHb0kxx7rT8wAA/x2zEqbxQjrVEY+vJo/nZ7PrLRDeQSOZbxaQaKFy8em8vLmOiZnR3HyoB8oXXG4LJI/Ibvjl0Lsp7hpHq7P5bnX88rycA60dvKX0/O5ePSJk1/BoFaw4PxCznx6C3d9WMJTFw791cTjsXB3HAdcApQIgrDvi2N3SZL02S8dOMtop0E/nMuankAlc7Ipfzg6ZQ26jiF8ptrJkj4VMp0cn3QpjqgpPPz4n9k2cRCX+E7BHhLxbnsck0ICMci/zlXRbFHxRP01rFTUst6fSWF/MUN69mJO7Sc9rY1c7Z2URESz+cUXUQoagvY8NoeFUeXxMSwyjOdn5jAsOfyX3ta3GJxg5vUrR7Kxqou7Pyzllo5sbk/6PVe0/Bux9Pd8mP8Sqt4XaYm7g301gwlr7CYpZTfWtjIOdN/Cwwef4Kyif7LdoSTc6cST1EpMt5ny8BCTXSHUdTpWrPsXl8w68QsTDjDAfwqOMC2rMjOZVleN5YNzMfguZGPOPjSaa3hv0iAymqu4/JP1FBZXE2k/lKFPkEtowvwoExSgjqNFtKBWpCBP8fGB3kDQBaOKV6PrkxHZ1sDptXX45ftoyzdhLminvsyKZreAyhzCP8hAeHwf6RHNXC//gNdjZvPHxDvoVH/teqEMioyqa2dQiwuPWssO9w4aRl6AeUMfwaaRyNI/JStpLzmuApa5YrkGkYn2MA5K3TSH/5Wk3mvxL7gI2RXvooz5ugaNJEncteFOau21jHPm8+ek59D4JYY2KNmTWYDDmMrYik7krdOI0RfT5hxJ447R+EZ0oFYfn7pWKr+cPr0Mk2RH8ktEpKYTFzh8vNqRClp/hVzJTckxXNFmIqarFYXfwfu2Lj7a8H90iypMin5U5b2syRrJ3SkvMnRLBGJARxeHzKQCoBMEJolwsqMXQbIR0ChQFcTjjlbTr5bRbO+mrbuL7YIKvSIMi12LoUeOvl+JXOHEq+5nf+9s9vgv/Oqy9O2QDTgMKVSZ1GxKVdGaruGK0g6mt2v50JTBX4re48y96zAE/Mzyj2C30Y1F/gmp2WtxdGdy//6ryeo7yKjeHUT2u2iPt7MzXsZ9vTb0GRoqmxNRbXUzQ7+SMIuXOreZR7TxLE13ofXKGVeeSYF3H6ayWjyNHgxnxlDtmIhxVyWDgg5Suvpoi4wivrODDydPY3jPMhROByFjBGN6m3hj8Fxmt7/Jac5iGm2JPGeVcaHxDRK9N3LFwVN4RV5Oh5DE3w13c2DMv0gqOOUYfkoGGOD40GQ7tA4lhH299vwct8HD8c24Nkt2GDd/Op0lkfNIi/yBzKjfjFH7GcxKm/WTXDK/26estZ+rXtuJ3ePkhUuHMzX3xKuHOCTBwi3Tsvjbsgom74ni7GFHKDb+CzkW2R038S0njWNHfnkmV6nXYlDuZ6M8G7mlGbc9jGeFCsqdchIcaQQ959AyMovT162gN6Kb84L/h18QaGn6kGR7ExIin80R2RQv4/6myymR2dkdiCK2v5FxPVsxJTlIH9RKtO1KFge9dNZsxhBM4IArgY06EQMifztrCGcPS/hV/WAnZEay/A8TeXxFBX/bBM0RV3ND8CWCZdewJO8ZIuzLWDF6JkmftWCNaqQ59yXiux8lVBrJ6UlrWR3+J07X3Utbez4ebx/teon2EXNQly2jsOxT7FNvxaIx/WrXP8AA/0uUtUQwv+R+VJKIVRDoLmhCrj2VU7dt48y1N2Pt60YSBNRWCfOQfhSRMpo0Y3DpphIZyGafs5+moIFohcAIuZzJCjn3FX7KOxFzCfYNR6v0k2no4fqql0ne3oOwX4UElESk8FnSaFRyWD52GlO6DnJ9w0JubH6PG5rf54B9FMXtQ2nSydmam8Lu3Fw2ZU5lygY/w8o2s7uoiy154ZyyX05H61AiU/YwVl2C0ypjaYOK80UTn1jrOaAbS0zsHajLHqb/33/ENeYOjBMSkBtVLC5fzNqWdeT449lkLOGkUokRddk8df6ttEQc2mSsGC4hK7YxrKaQpPCVNFVNwm4rJjrmN95Uf1FL7BZzExdVhfN08Cx8gp/chJHcNuj78WpapZzbpmf/6LCGYRcxZ/88mpQqFuaO41N9LH7xkMtLf9CMqrEft07JP6Iv4IE5d6Hq1bOmdTa7owZjMyso6PNjliy0a8w06YN0avRfjS0PBTHJBaxaCbPLjsfVRLckERHfzciRO0g2NSK6dKh2j6C8dxp+fyQyBELAhjwNWw0qBFeAYLaBU4sPcENbEm6ZyD9zojiteDN6v4/RUiHt8l7E+A9IS9qPrT2PvxRfRmH3doa4DqINBEi1dzD/LBnXO/qxKfPoXWtihukgSZZm7IKF581xvJDixyf4KRAFJldr8DY5cKPCZ4ymONGFu1iOXb8bfUBiTH0LMZlnY1d50e78gPawKIJyBaaudmzmcJLsncglkb/G3sDYyie5zGHnA4uRf8fs5cGGXqJj8rl+w+MEunpoGDaC6FAOki+EoDmm+c8GGOA34ZviyayMRGGaTIxpwld//6F4tZ9yjm+OEZL1QuQiLnlPxbKr5mP8sfi048DCXU3c+1EpYToVC68dQ378iZsY6NqJ6ayr6OL+JaWMSAkjOUL/451+Iif06qYNL8Pke51ydyTiBC97nfCe00tQVDKh7iyi+4fz3KQIwvt7OWP9B0SNug+VoOSAt4a0/csBqJvk4dVcI+e3nUqYN5ZV8lo8/Wpmdq/FEO8idUwLYvkcFosiCrkDtWMwnysN1KiDnJwdzaNnDcZqUP8296uSc+9pgxibHsHN7ylwaU/jRt9CfOXX8Mmg59Hp8lk8YSZhB3opHLEOZ+YneOzzmFc8j88nj6dhQzZx6nZ6U0OY2/KosASY6AqgqjewYv0/OXf69yvTDzDAAD+dpgMe9BJ4EwwYZa1c9OlOJu79NwoxhBihJ2Z0P6Z4Fy1CPO/6LkThmEKhpCMhIKPD20yhPpahyOgKSmwTgrS4/PSXjiOEhC5GwJaXxKTut0ha1Y0QkNMXpsLnUzOkp44MZxsLT7mIS9Z7iLMns0v6I7VCA8OMHzLYsol000E2Oa4gdp+P2z58jAMpJt6cPof86l3MWvcZFRMuw6sU2Fl3DaMS7iEzuZiufWDPrkNRMY0kbzav1hxg/B2/RylvxFTyJj2bE2nbPBlhkIGVto8I1xooV7cwsUTNkKpYHrzqVgJKJXP2OEntcPPixC4+G5qHV+7E7NGgDHbRUuP4bUXaN2IrBAFi/L3cVfUqK4UCklNuYHTykQtX/yhqIxdnpXFXi52VnhH45d/e7AQlJZaqdnoTM3jIdi9/DbuVM6z/YoRfYIsnkm3qfEIhC9b+ABmtNgo9NuR+B1LAj1wSUSkk1AoJnSqE2RwgPNyLyRhELYKmI0SCo5M6wzZUYgWKoJJefTyb8sbQ5VFg9ivozRtOdmMJ9zdFg0JiXq6fk2pKCXc7yZHn06vYhz5rNdFhLdRXTOONlhFcFv4Sip4gIUnOiOo2nporcIUtwMjN0SSmdRBt3Y5DNPKakM1T8R68yiBxvVFM6IkiPMVPzIRqFJpuurZF0FEeQWv4oZeCMf1OhtZ18NE4NYlpOiZ0F+FhMTM27aI+Pp34rk6m7a5nT6KOOHs3NZYRrBIvZJrwHDf0hPFgtIoG45tk9s+jctgNZKz/E0J9JQf334O16J+Y0hOP+UdngKNDkiT6PUE6HV7sngAOb4BgSEKUQKOUYVArsBrUxFo0v2m69BOd74one6ATTexi9tvyyY09Hfh5boPf5XCp7ZEFsGuWcPFLY3jtihE/OafCr4XTF+T+JQf4YE8z4zIiWHD+0N9s7/1zkcsE/nFeIaf+cwM3v7ePhdeOOeZZJ49J4pCfytEGv7bcPR6tVM3WQVbeVYXY51GQJJcxdvethPtjeDhfRSDHzIPP/p3spEmkyTLZ53eQtux2ZJJIIN/LpacZyLXn8n/t1/Kiehs7+8OY1rYcg9VF5sx6evZPoMKXTKQlnuaaBD4zgFcO980exIUjk45bkGJTr5urXttFUc8nnN7RxfvWQpYOXoU95s9MKN7J6VGLiIpqIGnzX7DtX0rFKSFeDL+Qqc130OvMxuRPQK60MLU7Gln5SgynNpE5fyM6pea43M8A//38LwXmP/DUkxzw+Dl/9ToG1VfjUsvpSJczIrmLKLOLan8+5Y7p/F5bxC3OEIP1CjLkJvrEEGaZHEmS6InazfreXJaEJGoRScCDKlmkLDuTm5a8xZzVnyOXh+g6RcbWlmxUoQARbjk57Q7Mzjb6TIn4Bl+IxhpBt8JOs6wHUV7KaawjkS7qfEPZ0Hc93QoviNvpFMDa1YQm/wqUHiuBniCvTVNwgXkBPTtT6FSouMRVhMETxbk4iVSG+PfloyhafyW07MSZ/Dhd5Qm8EPYen0ZtIa86HKlrIpunzSBkUnHzFjv6VhkfmPzUxZcRyoxAJh/ELUvspIxfgNw5mlnX3PMbPMUv+Ef+YbOU2QQN5rubkSl+4Vtkj43OBdMYabv/COn0JaaO2MnS8DNQ1XYzR/Y6cxK3IJcd+s71ieASha/yhagFCbUMFD/zK0cCPuEM3hMupkjayaO7RSy2dJ4evIdAvYTB7yYrcyei2kOspYmQz8D+knNwRVcyNnYL9Z8m4OzUMaK2jYMpHkyJCiYqJeK1TfSj5g2jmdfCVbhlarz6caQEM/lr7Rs82TOd7uxBTNi7A0V/DQQl1GYf2sR+Elf5SOzwsT8hnA1DTmWXsgiVIOOp9U+ilURemj6N6PI1dCUMw9zzPq0J5/H+1LlcuG05E3y7mctyzoxNwi0P8XzDvXi98az0VJFWs4j4llaSP15CWErKUc3P/9L69GvRYvewsbKL/c19HGjto67LhcMX/NF+gnAoIU9BgoWhSRam5ET9sLvdfznHMinIDzHktSFIHG6PL+Cr/CtpkXre+N0oIo3HVwztbujl5vf202xzc9PkDOafnPWb1CA7VizZ18L8d/dxyylZPyst/6+aOOTXZHefgYMZiXwseXB5FMwwhEjafAcyTwwvxYUIZegZVbKHdFMc6fIsyjx+4rY+jkwSUcbL+P2pWky+MO7uvJIPNAeodumY0r4KpT5IxoxG2mqGUu9PITViCFuqdKzSB4mzaHn7kmHkxR1fE2tiuI6F143h+jdVbJOeY1JjHy71cJbrPmFDwemkr63npIgWWge9grp7PnP2/Y53Zs7C3jmTpPC12GJEFC0WKsNCjHW6UDQYWbnxSeZOue243tcAA/w3INk6efCtRXRZtJRP0DAptpHhsiCbtBrm67PZ2XcaqlAuYaKERWMkQ65kh1pE8Ek0Sz52adrZZY/HFQoRI/g5Q2ajJ9rPtoRBPLngYfIrSnHHC3RfFWR1zekkGSfxSbyZk/f62ZEQILL5PXLrd2Lc8jcqBiXz8Ul6So21+GQBnpU0XNkVwXXSfs633sSavnnU+E8lyrEYJAl32RsMT7uJCgTGF3t5fOLdnJK7Ct3WXZRmmZlbGcMEQWRbIMRZL+wi23oDZ6tWEV7+Lq/pAtRFtaPvyGG39wLcJ1kIWTTMOdCJqk1JpTKEM6INoTMFVdhmnIkFVMeqsNSNRxnyI0kigvAb1bc5Qh0fi+RFOAqB9qM11LRhRJ33dyxPt2GXf3/DaVH2c37YW/T5LWxKm8xHlVeydP1s4qwlDLNuI8/cgEUZQimTUAJf7klCEgRFAVtQRbtXTadHpMvnpR9wCQqcgkBIpiGojAJFGGpBROPw0Gs5jRbzcE7qX8s9m6sxy85jWUQxyio34ZZ2zGkNREVUIwA91SdxsDOXCOs+zA191K5LxOXRktLTiQIPBXl9jMZFq1zO38wW3tdbcIkJBH0paNwm8qu7iHBt5W1XIjmOfSib9xGQQXW4gvIoI3rBwB+W7Se2x8dbgybh13tJb9lOmLYVV4wFha0eEYnzeq2sA/amxVM1/hzG7t0BzKXVbKWiIZWNwnjutu3kythodhveZVTgVlJkadRmnc/e7HAuUIbx81N4DXA02Fx+3t/dxOI9LZS3OwAwahQMjjdzRlE8iWE6os0awnRKDGrFV+WHfMEQTl+Izn4vLXYPVR1O9jfbWVrSxl+WHiQjysA5wxI4b0TiCWPN+a04JklBvnDl/qFkHkeKa4vVx3Dv5cO55vXdnPbkRv5xbiFjM3775HJ97gCPrSjnre2NxFu0LLx2DMNTjm3eh9+CuYXxrCnvZMHqKiZkWhmadOxWpRNapO0cEcFHtBAjg6sifLD9etzuWDaHBWnN1KMQQ8zfsI2sjEto8osEKxej629HYVLzrzlOeuR67m6+kjq5nRa/g7zWUuRykZw5NfTakmh3DiPNUMSSGolduiATMq08ecHQE2bBMGuVvHrFSG55T0GaeA9ja86kR7ubzYXNLBo9jfjaZnKzt2JMK2Hfpsu4q+JZ7hl2GykrP8cdE0Qh9NIkh55hpyOWryNx7yICE29GqTihH/sAA5zwdKs7WTM7hbm6YiYKTiQJPnb+gXW6LjrU29AmvI2qP5sprZcxWa7kM/w87PvC7UQAs6ggUd3NabIVeLHQobbiC1p5/cHbMTkdNOTpUF5vx7spGqWop93fzfRdOtwGOS9NsnBbSwZLqtsYvaWH3AP1RDSpWDs5nzB9EkJTC4H+Xl5TeZiWdJAZYY+zX3Uq22SXI3qW4PI2c7DhNZLCr0BqlzO1aRsrkqaRNDwH/eaPcBmHcKZfT4m6nIKgRE1vOA+JJ6Mwh6GNe59A/2Cc7XOxpARxxIST11SDUGsCCRIGvcP/NdbQKIZTW2HlzZg+dmSryFk3FEvqWlyuWgyGo0uZ/os5Qr2fXlT8WGWbj/a2HF0NtdSJ3Jrydx5oSCco+1r4qSWJoR4VlWUTuTz9JUKSgq1ZExgWXYKqXsGu2nNZ4bcgqBQo9CGUuhAypYRSLmIKekjwdVHorKDIVY1KClJiKOCjiCnUqhNREkSDjzBXH2m9jei9LjYMHk+LOY4xtdspqLThiEpgj+VZzKZWEs2dqJQ+QgENtqqTaWwowiPvYZDMhr2nhK52CxqPEY3YSV6zk7hJ3dTJ1DwkFrLLnYWmS0+hG0wBB+ZAJ/pQw9dzqQzjoC6TJm0iDdpEQjIFQxqruX332+gCXl4dPgvXSBVpkQeIb9bCnhbCG1voNGmJ7Xfzkb6NWLme0ZVV7B90Ed1J8Zj6bfQaE/GpGzjYkcDchhJOMbl5JLKaRc5KclWptDjikRl9mF29DBSz/nWwufz8Y1Ul7+1swhcUGZ4cxl0zc5iUHUVmlOFnexm12D2sPNDO0pI2Hvm8nH+squS84YncOCWDKOOv6+nT5wkgihJh+uO7x/vFSUG+mya/r+nQ7/AtofZDcW0T0iJZdP0Yfv/OXi56aTtXjktl3pTMX5xO/mjwBkK8s6ORp9ZUY3P7uXxsCrecknVCxsgdLQ/OzWdXvY0/vLePpfMmYFAfm332Ce3u+Ld3Z9CsaGCmxYdz73l01J1Mu0LktUTwD7fyx48/4WzVOFwhOTvbDzJ61wIEhZw9Zzl4JM3E7OZZXOaYypvKTQQaGgjz20id1YjGLNBccwE6zyje6nFRpRS5fGwK98zKPS5VzH+MYEjkT+9u5/ztf2Kn+2beHfE5lZnXMaJyB7+LfQm9Moh17cNENs/j7jPnoaxRMcj/NPboFBQtQ0mWohixcgmykdBw7mymj7/peN/SAP+F/C+5E2156FzGBpbTLEYQJ+thpTUPWVYvMkUAh1/L+h41dBdyc9ulVMk7eF9oQo0Gi6RCL4JMX4ozaACUOMU2MivtTNxXjM8Uh3HM2dTPfJIWu5WqjUNJsCcTNBTSr7Pz9IxULE3NyLzPIeobSLenc90mC/EHdiIJsC8pih6TnjytlazIQnbpu1Bo3uV0bzdNgUxWdN+I3b4YszIZd8o4cpzljDa9jlHWSwgZMkRcQhh+35VcIo5EI65miEJJrdnG3ujNWB0RTCkfQmd8FItGTUXn7kWzS8a1HUoMxp3UyNv5iIm4UKHHjzEmRKM1jvDiPpwykSgd3DV76NHFff1SDlPvxy8o+ESI46z7Sn6w67hH1xx9DbWgj//70yMsJAeHwkBkwM31qgisnoN8EptBinM/TSYXq13D8PsUKDUhHo5awOy+PWh8Ih6VnOK4KBrCIpAkGZIkIPDNbFzSV//u7c5ledMk7H4TFlU/KWlt7EkahwyRa8V/M1K27VuX5nFG4OvKxtlSiKM3nIBlFTJDIw1aOwcEGLovBmufCr3YzaSSftwpMvZYY+kPfGOzLEjIdAJBkwKH2USfLgxPIByj04hDEYaUZadYn4wq6OL377zH4PIa+o0agpnjSUg4HVHhpTTzSdTJDQT6oXx1InQoOam8ngMpBkpTdUR1GaiedgdLkvWEe/w4lEouX7MeudqOqa2Z7hiJ1SnbmGtP5NKOuzkYENkmSEy8KJqThuYe1cfhf2l9+iVIksSb2xp4fEUlTl+Qs4sSuGJ8Cjkxxz7x2MG2fl7ZXMcHe1pQyWVcPSGVGyZnoFHKv20p0n5hmfDYfjQF/OGwufzcsfw1Nve+Dgo7ermVm4fN5/xBp38rgcfPifv6ORyuLpggqXhk4oNHd+4juHJjToSbS793rh+6P7c/yCdvLGBc49PECT145UY0KgWynzrXR2HZ63MHeH93Ey9tqqOtz8uo1HDumz3ouHuuHSt21PVy/vNbObMogcfPKTjqfv+x7o5JQS3Donz0VcxiX/MkokSJpboAwiAjmW1tzCEPUZKzw2ln5J6nAfBMVPBYqpGcnnQud81gkWozgZY2In3dSCNlWGJcdFVchNI2mpc8TpqVIvfPHsQV41KP890eGYVcxl/PH8X/he5kzsqn8RRfxXORa9iZfTL5e6s5ufBDAtlLqWq+kXuLn+Z3hY8y5RUtHYUeVOou6oKQOXQuvootROx8F2ncjSdEQcABBvhPpVebQ33/ZoIqOVsKrShMHfQ3FdHfnkdPfCXnICOx7VJKtTX8OeEZzmyficzlwq8Q8MiDyLwG5BJAAKM8ms6MSN7NTEcZCBIdvwNTTyK+ygvplsUSY1CwT+1nTYoBndPBE68+TKulD5clAbU8jGazRFd2LFn1XQyva6cyJpzyyCD9fe8T63IS5tBQaw0nubCa8yPv5w33NJzeOmYWrydtaDsKwQ+AAhEAo2RDVD7Fg9KVnOubgCz0OlVRlcQ49JzUUkTIomNpYSFIEDygYEQfyCWJXnkt73IaoS9SzbtQ424XUXbYccoABDrdHN4i9WvwxQbBseR2DCEbzepo9hgH0xns/9GuR6qVdtjjCjV/+vOtWK/7HSF3H5PLGhBOugWtOYd9/Xt5LWU0wdp+RGQIwEz/Vk7rKEYrHJpvnT/E8IYO5E4rLaaob6izb1e33mVPZXHreALSobfNdr+ZvZUWoqQ2rlAtRh9wUBcaiuAJQ7Kn0GOLo0PTRaupmuq4hfiS3V+NldOpYnJxJIqAnNzmTlJ7nPQny2g8XUmEqotoQYNS0CJTKAipg4SUPgSVG43a+VX4XaOUQLnfSJWjk0H7fFy+MkCUXaIjO5fY7CvRyoysM+3i1agldMlsGFrkzDaHGD63hraSMLpa9QytdrArXYssJCHVPsvljqt4fZAJUSZgz8gmoW07/bEJFPvjOb2+mLfTWphjW0c2E6j3ejD7ehjg2NHvDXDb+/tZfqCDcRkR3HdaHtnfKL9xrMmNNfG3swu4flIGf19Rwb/WVPPx/laeL6wla8fdX79g8fR+3ekIVqMjUdrSx0XvPkMofCGCMgCAW+zmoe0PcqBnP8saPv1KLLW52nhgywMAv6pQ+25SEIIW8rXnH/05j+DKfbjjP5YOX1e+mPPaHwPh0FzrQv3w5TLX14T0ybxDq9APzfUPWPZ8g85iU1U3S0va+KykDW9AZERKGI+fU8DY9Ij/qr3oyNRwbpycwZNrqpmUHclpQ+J+8ZgntEiLYTwHa6L4sHoGc30KNppDdKarCWn1/GNZDVpdKpudfvL3LkAuBlDlJfHHogaMfhNn+m9gp7wSX28zkc5W6hOSOH3oclwVk7E3T+Z10Um3QmLB+UOZU/DLJ/LXRiGXcc9F0/lnfw3569ZzzrahvHJKFwtzppLbXkJcynKiMyfg229gfNYuPpv2B8ZX/oXWQSoUHZHURcgp2NuOUG9h085XmTDy+BSWHWCA/wYctnI8S0wIOhFVn4DXkktb5zVIyLH5DMS6R1CvL6fGuoFJbRNxBwVQiQiiiNHhQB5wY3R6UfsCtIeFU5WYQkjmwBcew07FELxBNYEMOZIQpEIK0qjR4HGpUPSFeODiP3J6xQbyfJWkyncQre3GEOtHkSfRtsNMdiMMVbTiGSSj1W9ikyMW0a8iur6fKUlVzI1dwdsNQ4jN6/hKoH0XmeCjUFpEQaRAubWSczr8zHc0Y1aX0aGMoKNBzdKmIgRRYo8SEuVVLGb6VwLtSyRkCN9x1vAEQjy2vOK3saYNOZd/fVxGsymbD4fmcmflmyRbOn60W5zlp9VQ+6yqj1fSL6PTK/Jicj9Xl69l5qAEzg5m8nZdLyJfu1fdrliI7jvzrpBEMrvrWNo7GgiBICEhfTF3MkDGB56xXwm0LxFECU+FRLcmAWOoiCHBNA4aPqHJ+CoyU4BoJBIkGNOvRh0KJ801ko42kU57HUgwqKWLpH4HoXAFvpmDMfcn4OjLwO+OIxDSEBTl+ETwS4di5VB4UZubUcWWY4w+yGmtFRjXyFBXyMAShmbc5SRHJdGmLGVH5zbS9lTwaKGOVF0v4o3vYu+N4pNPniI3fhmaWXKUrwkUVcjoMUJuXSKKLg8Xte/jjakTeT8tlkGGmaSWbmGYqoWW2HuxCA9zb/ynPFk3ktmacmTyvB99lgMcHXXdLq54ZQfNNg/3zMrld+NTf7MNdKpVz1MXFnHhyG7u/LAE3caHQfYDReUDnkNWmyHnft+C843Cyz59HG84z0RK2oAgC3x7DFmAJbWLkb54OfUl3pCXBXsW/OrWtC/FkyRJZN3zOQUT0o6+8xFcuTEfoVbXD1m5Vj/4lbhaqtexIMxCu0JOTDDEfJudWS433Uvu5vWOQvLiTCRH6Ii3aDGoFV9/Pr4xxlcEPHQtuZuJ75vwBEKYNArOGBrPxaOT/2ssZ4dj3tRM9jbaCYnHxkvxhBZpj9TGUO/M5iqPgm4NbNOEEFJMPLC5lhh9GiXuEMaWJRj7WpFFR/HypBpaFFom2C4nud/Fat8BjF2NVBtSmTR5C8GWBOprLuENuYt+Jbx06XAmZUcd79s8apRyGTdecx1LO64lu8bHuJJqNg4dwwetM7hBfIbeQW9D443M23MfF074BxGrsug0dKGytFHtEUgrOB1X5W5MW1+BAZE2wAA/m0ZzCjMmrqe9zYhhlQKjWIlF9xB9Q04lwRfDO6rN+EN+6ExDY+igmUZ6Qx0ofCHsqanYLKn0mVJw6RIIKSLhO8k0BNGPIhREKUrIJAFJAIVJICRTUSPP4O+ZX8d1qXxeYrtaiO9qJG1oA5OVxaTVtKHyi5w0oY4pMbW0eyPYa0vlnfrhnJ5YRqq+F4PK94P3KBe6me9pYUh9O2GSD+GLb4uYYA+Pty9AwVUggwfUrxOGkwe/6GfDwAOBS/lYHP+t8ebINnG7YiFxQjetbisUP/KLCqYeLTKXB1fkoQ2a3ucnJT3nR/vcNv3oa6h9Hb8mgSBgV5tZkD8ToWolp2XPwSc6v1VJNE7oPuw5TbjYmj4Ci7cfXcgLCLhVGmwaE82maNwbnIctSOpGxXXuGAKyQlosn5OmqmVujxOT4KZVsvKv4BkEyeLM/gD7etbgE30IIgzvbCbK4UOSK+gZPImWqmH0BpO/GlclOFHJ+xFkEkq5BYXSSL9aj9ETR9yaJsz1bjRuBX6dht45It5TOvC4FmOtspLg2MFW/ygyG4PI4lVEJjupqi8jNrsApzOC8pXhTAz2E1CApOxBELSI/mJcwTYiajtJLcjHo7fQ1WunMZDGDEMVps5iDNEXUad5jnWWJZxkPxdJd+IVuf1PpLrTwYUvbCcoSrx7zejjlrxhbIaV5X+YiPqh71tIvy8gepn12hyoW/91m2APC9o/pz1MTowxlvk2GxMML/GZPILDlfOVJPGwVX7bXG0srV36qws1OBQnFwhJRP6UdPNT7/ueKzdK7aHj3+XH4te+sL4t1et4wBqOV3bou6hNqeAB66HPwQxXF0+tqeKbukMuEzBqFMgFgZ2hZg4XKBQR6uK8EYlMyo5kbLoVlULG0tql3Pz2I7T77Yeeo0/OrAk/zX31REYpl/HG70YesxccJ7RImxEfhW83aEQZ7yu8WPK9ZHZbmOmMpMkfpM1Rzejy1aBRUTMlwMcmLUO6i7jKkc0n4irUrXV0qawYRnmIEFyU7vsLbyrdOBXwyuUjjks2m1+KTqVgym1PUv37ObjLbqYsuYztqWMZ37CfopQNROZMp2ZDHnNzV7Jo2kWctfp+SifXI/fE0hSpIXdfA1J9BHv2L6ao4MzjfTsDDPAfyQixnLdNCcSmddA4VUmNbSRqRTS6kAeBejo0HTQYmmkIU+LVphFUFRFUZRBSfrHmSCLKgA3EPuJdxUT4m7AqG9G296GuVtIbkYFf0YsgA4MsgMFrIcITjyiIVJjrKYvoJKiKQCAeuSyJHnMGjXEnsUUm4+1pIVKb65i2fQtF20sxpcsYElHBjNhdeILhlPnzSAjr+44z3fexSTrGBj9HJfi/11An+Llf8TpGwYtK+HYK7nCcPK58HgJ8JdTmyDbxqPLFryxICUL3T3JZ+iWo/BIeHSglPwp/gMykET/a50sr39HUUHtsecW3xByAX67i5eQiTilZSNSQ0+j4RhrsVsl66P6/Q4cikoPWTPyqr7c7gihh9onk2/yUywWcoe+/nY0KiQTkRTyUq8YimXigbj9q2aFnkiB084DyNe72X8nrbh/ZIS/KUIgonwG9TYVbUrG8cD6iPJxIqZ0w9U5Mqg6sqipiFfVECR1oRB++fgWtrRHY2yxoO90QCuFJltF9EmgnPMKGrkiEpqUUxnyIs6iaXbVjEPrG0mfqwdjbB8ngri3FONyIQRkOurksVWjJSH6B3HaJypl9dJeZUTo7QRSIayxly9AJxDT3kCX2YbJ1oVQoGV3XQmeqksdjNhPJTqZZX/vRZznAD1PV4eCCF7YBAu9eM5qs6F/PvfFo0Cjl37MUHVFAdO5k1g+0uTcyAkmSjlAigx9cAH8Lt0eALsehl2U/KQ3+N61gPxAD9lWbw1i5vrJEfjHXC8IsX83dl3hlMhaEWZiliKDkhulUdzppsrlpsXno9wbo9wSRkOg/EIUl8H0PBZk5gQfmfG3tXlq7lAc23YtXCoAgHHqOchFW3XboOf6XCLVjaYE+oUXaUH0SpWIz2/QhnIkB1PoUHl5voz8E+9x+Ru99GQEJafwIHkrcSrLLxMXWm9hoW4OqpYoACnYmF3F76pNUb7qVt5TgUgq8fuVIRqb+56X5/JIIkw7bPU+R9ce/cP7mS3h6lsgr4aeS49lDZ+6bqOvnc+7Om/lsxkn0h88gvHotoaQGKhwykgfPxVZ1kPD1T8GASBtggJ9FQ6SZncnVxAVSifOFU2jyE5LX06Dro0KdQqdyDPWqLHyyQwkYrMFOMqQKYoOfYg3VkB5qIKSJRCd6iFB0IdOJBD1yHNFh6KMUyEM7UYu9SCrwBxUEQnIkZEgKLUWCHCQ5AcmFW6jBJfPjxIvDqaJZnkWzbDBtMUN55pxLAchpqmRIYzO/s/eQo/6EYbqN+APWHxRobkkFgnBIoB2BcMF5xL2PSghyu2IhH/sPibTDufh9a6PwKyILKnBplZjoIyBK6KJ+3JIGh4Ta0bhkHil+rVtjobdtC1eGJfFE4mC+tFv+LXjutwQrHJrvvo4JvLN4G0G5DLdagVwCvT9w6DtODLFBqeUVXTT+b1hd1RJcKddxW6GGDpmHD/cvQK38tmjWCX7+qFzEjLCHUARC4Dcx6eASujUWHhh9BY2mMEBCF7CQ7ZUxUm5hmCKFsFAPOysqMFUcRO0/dK1mcy/GLC/edDXuwXKSJj5GcuqpRLo8jNohZ1RoAiPcHzAqbTmD4sooD78EsSmOzr7d9O6N5UD5DrRt+YQIsDHrETxBJcNq/EQ0pNCNnZgx3ciCIbJsJWyWnUS3NYrx+zcS7mnEY0wiFB9Bbt9gWhJ2cXesSKzXz5CjepoDHI5up4/LX9mJIBwSaOknSu2yqffB4qu/+vXwAkI4JCBc7iO2CQjCkQXaj/BbuT1+KdJ+cuHmIece3dr5Y/FrX1jl2o9QbLxdIYep96FXKyhItFCQaPl+o7S/HJVlb8GeBYcE2jfwymQsMOmY9Rt8F/wnckKLtNZ+L70q2Kr0ok+GJ3Y5kEsCO92Q1fAuGq8dhg1lQd4WfIKCEQn349pejKujFIXfyycxs7mg8EMczSN51Z+MQyHx2hUj/qMF2pdkZObgunAUmYsOMK4sm0352Sytn8M5yW+jyyulfOkkrmj6gEXDLuLad1eyPrYROUm0RptILzlIoC6W8vKV5OSccrxvZYAB/uOQaw2cEamgimhKyaaSbKrJxCccilmKC7UwNrCVglA96YFaorsP0hATiUHdSVAm0B4SEP09xKjcSD5w9OrwBQ0ohET8gki0cJDegAZvSIlcEDGIPlQKCCr1iCoFLqUHQR7EIijQCiokuYqg3IOkKEaQ7QVep1OKZhtj2ZwwkYWJU1gkBUkLppPq2k6kbSv3NNoIJ/S9ewtKMu4IXMU/lU//ojmK/4a16EgufvQ1wQOWn5Wx7bAcLvYipMalVmPBhiMURDDG/rJzfIcjxa+FST62pscx8uB73Bz08krKSDoE6ZB1McAXrp89tEoRPOmbQ1RHJTLpU2SSdEhACwKSHFCCoJQw+ENMc2ex0TKefoWBKEHGRZJEt3clg5c3M8zdhynH+73rAIgTenAoDFxWug+TpxuPUoek1PB/O99EFfSj9btQh77t/upUqLGZY2nIHEtEUiptciNuZQ9D9JsYHCwjqa4bZ8M8GhJ20JdwEWOr3eR4JZKMZ/FiRBEzzG+QOOFJeuvGcXDv+UgeNToxgCVNYpHyGTrNPQQVasCPxWEHmZK6fbmEJ/dwnXo5rwavRxsuJ0s5jfC8bUQP/YCOzlSqKsdypq6YHSovsdoTLxvzfwreQIhrXt9Fj8vHwmvHnDgCDQ6tA5//6auEIT8oIA7z87GizdXGtEXTjlnGx8NlWgw6C4GfaEn7KfxY/NoXa27MrgdpO8wUxqgsP74uH6Vl74j14RTyI4vJ/3FOaJH2vtlJhcZDRvoeZjZPJ9MdYJs7gMx9gNj6HYTijOwp6GaLTsEE/0ROKvOzuX8nGoeNLeGjiEnpIkPfykP75mGTS7x8+QhGpf1YhZz/HArO/z3BNXOZuj+D4pRuPo2fzET7BsTMj9Bn38+wXTfz3ukzKR51EekH3qBveA0HbUriB82hs6Ye6+onYECkDTDAT6a9IZvbo68FQJAkonu6mCjbwKk9u5jWtRPcFg54R5KhPJ8DzctRVtn58HdDqVetIdNwPds0Msydz2L0RjCqfDhZXQ2IxsuQi15iQ8+xxZGCqFLSbgkSY6tlVLUCa18IQTrkUhJUKCkePpL9KQmYAl4KnZ3IlQrs1i7aleUUGwPU6+3oFZ8x2fMpeR2JbE4dz8aI8VRbitCaLyVe+yI3lH+K9jsWnTsCV/GxOJ7bpYWHdcv7sp0XFeE4jzhHEofcHD8Wxx/Rxe+rlj8xY9thOULsRbZyGg7lKKKkZvolL8iPbS2eI8Wv3TdnJEmr3OxULCWrfimvN+1k06hr+Ztazsfi+K+sjAoxwEznavQWH6IIkigghgQQBQQRpIAMvGBUxHCeJYtb5VEIyNjjLWVPoAyTywl+N4LGhDOoxaj8vmBslSKI8tgwerrxKWS41SFQ9ONSqrGrjAQU8YQU0UiKWDwaK03aMPYZDVSoRFwysIQEhvkUDHFmUWobS7HMS6xxFcM0K0htfApfw4vc5T6V/a65BDThzPEpWJN6M5Yh6zg15WPUcWVIOybRZZ+DvVZgnOJKhtWUYOmrpS6uBUtnP7LEAtSeVgqcOv4t3oHQ60cKN5IVU483ay0f107H5Jco1O6nrbGI2dlbwD+Q3fHncveHpexptPP0RUUMSbAc78v5PjP+CouvASRigiHalN/frsYEQ9/6+XBtfinHKuPjd9PufznuSeE3AFG/nkg7mvi1Iecy36A/fE210Xce3XmOwrJ3xPpwwdCRk578j3NCi7SkFatwxClIU0zhzJoA5e5+OgIS43e/CUpwjzyNJyPfI9+l56b0q/ik8l3Unc206uMptuTxl8yHeffA1bSK8PylRYz7D4xB+zEK/v4StvN+zxnbr+O1qWZe853D7ZZ/wOBVNC2ew42Vb/F0+jzm74hkTWoDgiKNztgk4g9+jL82kca6bSSljj7etzHAAP9RaNnCtMYY6oR1nLxrBLruNSD2Ix/TSo02mWxPF5OM7xGSlmFQSLhzhxEe2ECkEM4GYx4J/j4iNGfSKS5ha94mcoqvwN9XjM+3m0rM7B4yBrfSz4SKDZhiVdw7WYld5mGIzcAkdx+FoQ7Gyj4kUpbMDk5hQ3g0FRGbKTXaAAXxHhMJzRlE2IcR7koh0C9y7XtPcpNvEQunj2PPsKH8O/oqauzp3NX+CnEcsuj8LXjuV3FkfxPP41HZi+j42sIiSdArGfhz8JAr5ePK578Xk/YlMgH+pHiPj/3jD+vi9z1+qfvjEWIvxuvX4VRcTYbopF9w/byxf4Afil+Thl9MdsnJlL/8Ia0HljN6xd3cUngRLycMplOACEFgtMVIjKEId6cedW8DAhIqQYFGbsCkCceijiFKn45ZbsIvSHwap2JxgpLRrZkMrYM4UyyRohmdoMYv5eCXnvyWm6pbUvEP/5mc3L6Muy5V0hkmQ9KG8Ms8+CUPYAdagIPIURJFNHFSNEWqTC425VDvcfB5rYzVtgj2WXq4JtPK+TMnIzAZl/su1qx/i6jqNynSf8Rgw1LUwy8ntONF7PbZJD1ex2fnnsXotLVYxn+MoFexdnsrqe2FpHYXIunHgHIpltbPUSbFIIp1bLdfyCdhGmK6vLTmaZErIvDY0qmwZWDrzWBM3COIYgRbt55DYcHRua4O8G0+3NvMB3uamTc1k5mDj61l+Zgx5Fxo3Aa7Xma+zf6teDMApSQwz2b/6vfDteGH4tF+AsfC9XHBngXfEkBfjrux53VU8tsxaX6l7fhRWrm+Wxbg16gZN79o/tcxaV+gEUXm97vh5MeO2Xn+mzihRdq90/r4vTOJW6qgPdBHhV9HXtWLKAMOgtMv4amU91BIArdPeYr1r69E1lpJQKnlY+upzEhbhcMTy7qeNP55XgFTcv47s0ApjFaG3jiNnpd3sSNjGPsTR1HaNZxByWswDXkA+Z5laM9pZP1JZzJ099M0nVpOWbeGyKxTaa3tQlr2CEnXLznetzHAAP9ROG3x5Ba/jjvLhjk4l8aENGIb99CyJZZOg4FdymsZnNJJofMzjLE7sKjX8mLXF51b5n41TnVIz8KO03H0rQP8HEzJZvfICTjFFczuWs51KSFqQtcR2xTFQX0VKy1b+WeEC/gyK20AXWAd4zvGkdU9iUzNHiJCCvo68xBDCmRiO0GhiR6dgk3DZzBq32ou+mwDheUd1JuW0pKQxBXxt1JvjyPg/9LXRUKllJDF+dnsGMQwVyUWXLRKVp4Knsvi4Dj8ggCCBAF4QHkou+Ph9kJxsh5MQpCPQ+MA+JNiIXGy7iPHw/0Sl5cj9DXK+3DI9Bh9buTikS1/v4Qjxa8JgoBhSCzD/3kDzq2TsX+whgnblzNxz1so4ocjSz8JmZiEUsgAQwYcxuPMI4OdEXK2WBVUGGRMbw/w9C43hpCOoCKfLrqpDhXT3VeC11bLUJmFrHQHRpWHVsnKM+7TkDU5iBD6OHt9OMPleoznTsQ/UkOHYzPNtr30hqAzIKNL0tDg62a/t4Xdgd3IeyTS1SJjB+k4Q30JH63J5JEDflY49/LQGfnkJFqJvXg+TU1n8sRbTzPFu4HCXS8jEyTmyjbTGGFlxtuf45+UTf0ILRnCe4zPULPLPJis8vtJsBn54OQL+WPDZwzx7manDBoVW/HIJnNxZw1P5g1nZ5iKNEckcYZ2el3RSDl9WENVfGKbzoUqH/+d3+y/Hg09Lu75sJQRKWHMm5Lx4x2OJ6c9AUmjD8UrdfeyICKcdrlAjD72kIAoWw27XwUpxCyXBxQuFhi1hzJAyrW0hX4gjT9gUVuw++xIEugUWtQKNXaf/bBtj+Sqd7Qcqb9b7CbSqP51yx0cZfzaj9VU+6V8JQS3fSe748mPDcSjHYETWqQ9o5Yzr3wYPsnPHpcas2s/0a178RdlszWhmL1aiZt1k9j1zm762/YiDwVZHXcyBq2LUxLXc8uGB3lwbj5zC3+DejzHkYhZV5C9cA6zduVSHa/jJc1ZPM5ePIM/hLLzmF/8Kg8n3cPofQV4KmrxRmVhj88hcd3neKvT6WwpISp+8PG+jQFOMER/CEEhQ5D99xSbPFbEpSXjcI5mSnctkqimNayH9alert6ZhsvVjSS9Q1MgC6W/CG1PF6UTh7M1DixCDKdsX0uTKhK7002gT4maRvr1VtYMLcVlbEZyrGKIz8ewigRuco/GL/QTkDswGg5wR9dlhKnC2SZt44BnB5pQHCZhImZvHB7rdnzNwzEkFZM78gPcHWlUdCbjcYUTQIkXL6sjRzJ28xbya8uRcrOROjtIbKpHApQWPTEFOsLTtyJTBsBpJK2zHRV+BDdEhvRcHTqJm2R6euS9bElYyAttMynyPc8m1bzDujN6lAoWjL4H1l7OBaecR+uB0ZyuWcpFjs0IhxNVv8Tl5QixF/1iOJIgwxjwEqk+NrVrfg6GMbkYxuQi+a+mff0qNr30NzJ3HUTtduA3xiJowxENkXi0elwKGW6ZiDfoJBT0EB4McU4ggOBzEQwFaAiGEEMiyoCXMJ+L1KCX1C/OE5CpWdmUzo64dLJdlViNVcgEGSOHjWHYZVehivla1qQyn0DATl/fHhyOAzhdVYSCDjwBJ3UBFQfdIfb321jc2wq8SGJaLFMDc9jZKWPWvzZx1YRU5k/NJDExkbZxZ3Jf1RCmNu5mPNspFA6QkN2DI1HOW6oAz3XImGYxM8XkIjHpbT654kymb9/L7zQvoNAFie8pY0d0HgGvhzyhjHRVK5HeIvZFGMhoiiWU6uHi9HdQKAM8J1zP3OAuEgxnHJdn+Z9KMCQy7919yGUC/zx/KAr5f0BM3xcCYxbwPfmQNuuQkPuC77aZtmjaYd3rAGL1saw4ewWL9zRzy8L9LPrDBHJiTEfsE6OP+UW3cSRXP6UUgfXXcnU8Afm1heB/Gye0SMurnEqMV2JjXx9+ScGovW8impTYU2fxovVfjPMocLam4+rei8rtoCE6j2pVCldnvc6iqtO4fnI+l4xO/vET/Rcw+O/P0HbxfZxUciWrhmaxquM0pscuwVA0DeceL7F5FawbOomTV+2n7LxSDgSNjE+dSlujB+XSvxB1zXvH+xYGOIGQAiG6XylFYVYTfv6AS9H3iLSwKi+S9B4bac0Q6Y2iTLuJd0YFOWPv7/HISrHZStkqesEYj6uiB0udmTBXMXsCFiCAJGhRqAtAEvncmkqsO5l+44eIgkSdwsgHUXoGVx/E4JGQSRL+fhXrdWvJM49htnwGk+RTqQnKsTmbyC75JwZHC9tHj6SRIYi9qSTnL2V4YgWSJNDmjMbhMRHuc9OSBrJPDQw+WEFCdgRVwxTYazQE7S6a17to3pJHWI6ByKw2atMc1KbpkXxK/C4zAd8zaE0tyLR9ZMlEZisUvFl71mHdGT2SkhYshGRB9MPWY3KPpC1chbxfhmf0PHRr7j+6Oj9Hy2FiL0IyNSu85wNg9PuIsuh+/vjHCEGlIvaUmZx18qm8t+NNmp5dSnR7F3qhi9RwAwqXF6nThjzgRhcMIAQDIIqEJImgTE5QJicgVxFSaQlptEhGLV3GMDZFZ7NMlUKv3sis9pUkumqxm9WkZmRzyi13Yow4vLu/UmnBap2C1TrlW8fHfOPnNmcba5vW8tnmD9mlfx5Ro8VgO4vn1ku8v7uG22cmEadT81ZqLr/Pz2TTMhmLZENRK4vZGttJu0bOBLeHexpaQK/kQLaXSwwvE5PvRdeipyQnk+TiZspT08hwVeGJsbAyIhqLX2JzjI59kRO4SfFXcqQy3u+8kEFlBxkh24vWXgeRmb/i0/rv4qVNdexvsvPkBUOJP0Jh9v8m5hfN597N9xIQv51RUCEomF80H4BhyWEA7G6wkRNjOuSSd7jYrC/a/5JrOdy42v7ZP61G2gD/U5zQIi2n8zO2+kfQL8aRX/4cypCb9kl380Liv1BLEoP6J+Dt7kDZ3YrXFM4afRGpxgaSjfU4tXdz88n/O4u33BrPiDNT6FhXxp70PN43z2RiYCVS/kIUJRdy5e7XeTjn/xiWeSryXWtxZQ7CmZRP8sbncZVnY2uvICzm+4VaB/jfQwqK9Lx5EH99P4bzBz4ThyPktHLKfmi05uJUhyAQx4zu01lrXomScPyppzDbMJG6bQ+xfehIGvUi+kA/I3s62RsZi0mYjCaUiyDVEnAtp1MYxTiHgEo2Ar1JQbW6hqqEJqoSZKjk8ejkyYRLJmLanKiLdyLqYxmsC2eoTsCrj8Q+fQ6BvmbG9amw+lPY46xHWn46iWY3nfEiJmMj8cpWMLuQlAFCN0nYl8mwfNpDpkPG2zM0RJVGogooUJGEp0rJPtsphKHCEl2GNqIGpb4bjaWBUEeQVlku7kY97dI4pjs1rNSPhgDcqXqfGLoRTPHsc1jZ6UkhtbwfIb+YhM5umixRuNujaNEkkjn7X0dX5+doOUzsxWZxHFu+SNBh9PuJP4JQOR7IBBkXjLqUytjRvPf0syjbGmnwdhKwKkmaO4pTpl+CRjDR8/lKHO+9RmdnNy3mGNblT2GvNpb+b3x9y6QQg9yVjPLsIra7CUmA8Ph4Jt14M/E5eT9wFUdHrCGWC3MvZNq2IXQ7ujl4qo21TWvZUrOX3qZp3LFQQGnaS1jcBh5QepCSHbi+yBwa6bRwfVMY1wc30aLLIaFwBsm9dkraV9CeDN5IOaWaGDL31CH3yVBKQUrzimiMT//q/NcGnyFHKuOF0kvwdESTKnewShpHjmT+yvF3gB+mvtvFEysrOWVQNKcNOUHj0I4xX1psHt3x6FdujGaVmTtH3fnV35LCdUToVexpsHPRqORfLTbrSOPe/7aayBjVLxp7gP9eTmiRtsugoa8tGrNjL9EdxdRPO5ta6xZKtR7+n73zDo+zuvL/5y3Tu2bUuyzJXa7gig0YbMDUEFoSQrIpm01Zkk2v65T9JdnsJiF9E5YlhRrTMWDABhvb4N67LcvqZTS9z1t+f4xMi2SMLbnO53l4jGZG9z331cyde+4553s+1esmGi7F2LUBzWRiS+FFxDQ7nxv9J7ZGvspP75gwsjm+ZyHeT32HUc8uYtGWRh661MfDfR/h474/YrnoKvpfNdEwaTvraibwwedeZUvTZvZkvUyvmE13u8zBZ/8fF38y3xj0QkfXdAKP7ie1P4j7pnqsk/JboMEoLq2k3ReiLKCSMgpcrTRQ3z+GsZEK4kC5qoOSor3Qze+u+yCq2sk9u7/M2I1WjpTdgTHjxereQ6J9HRGnBQQBOZtl/uE76Hce5jAL+YS4l97y59ljPMphcxshoNkHb1wqYlL2kZXSmBFxKnZMuglTmYFcd9bteBI+dCo5aFBoyxxGDYJGMZqgkRIzxKUk4fExpphUPvesxif/nGDzxWbCKQ2LMYVqupbKrMIv53soTbu5s90A6Tfw3C+wasKVqGYr1l6ZcXI9fY4ktvHL+EzVtyid/+M379H0Z7/G/1tbwV19T2IFxqmt7LHU0pOuoK9lCw03fWf46xDeVXux5fvfI27PCZ/Y0hmqKs++g7vGqkY+efdX+fOf7ycV6CIVOUzXc2v4y3NrSDlF5Aov5utGURitxtXawx2HH+FDoQR9JhcRswnNoJMyiwi6hiiKjJ4ynSm3fIjS+sZht1VymXB2mLmp4SZuargJ7TKNPf4D/GblIZZvm0z20Hh8Ffu4tGArU1rXsCb8YQpUmT6DgQ1EsWfNVFyxBIPfz6r/DnH7X95g57/IHNZ8xGUzC6I7abMI3Lb5LziCQUpKq/i09yt0COXUxdzs9Y9lgXQUlxhnVWYUnzOd2cbL5wqapvP1x3ZglEV+dOOFtTd6r/Q6QRCYUuVha2vwhH9nuGxRNZ0vxJ/LR9LyDMlZnZDcnZ4NeopJOx4kXl6OyT6G/yt8jUviGaKZ+chdOxE1jWDpaHbqFUwr2gaijx/eeuO5kWs9zAiCwMX/8UMu2/Q89R0JXim4lO5kGeGxSzF77uT6TQ9xpNrKoYtvwLOmi7Cpl0zNRKq61hLc4yLuP3Kmp5DnDKLrOuFnm0nu8OO6uhb7jAvjtPVk6JKteM0iEZ9MVhI4EtFZnVUQuzQAqtNZ/lKa5Duf+iqOTAJ3z08p6pnEq/U/xJBxIxa+QsncX5NSIrRZCyiw9FI243eYCwP4Ig1clwoghmRKN0/jklfG8KFX53Hdzn/ikuZbmNR5OdXB8ThTPmJimi5DgH49jaiasGpmslkTHXKELc4WLFkrFYFGUikLyYyVTMqJKVpOaf9EprUvxGG4i+cX3k3APYbZ6/ZT15sikWyjW/gbsbTEF1aFiQg21odkav/QwQ7PKBS7C3tAwyTNp9eZ5cXGe/nT/ltonPzO94th/HV8VHqJrCgixgoZZT2Yu3fY6evrPC1/JyWVJTHgpNnTGcqLTj2qNBKUlpbyiU98EnNxNaaKWZTdfiNcWk/GJaEc7kFZdYCuLc0c8cfZbbOxq7yQHp+RpBOSHjuKx8fFd36SL/x5Kdd8c8mIOGgAktOIFsuiK7n3uSiITCgcwx9uu5aln5uD5rDT1tLE1qN34Q2PQkxZufr55RiJ8bxwOauyY/H7/RQUFIC1CK1f5oH1N7Kicz7NNWWMa2/BXpLAnIpTN64Dp2U/FZkIe8PXEAqWcrnhIG4pTrMxQnXCS1dndETmeb6xdHM7648E+NY1Yyl2ms+0OWcd06o9NPvjBOLHUZ8dAQLxDJo+gj3S8pzznNWRtCsue4bst5qR9RSHJ32Cv1f9AaOuMS81jebOAHI8SrK4nB2mCtSsxA31z3HlJY9jNZ7V0xpRTBNnUF31Q67dMItf3VDJn1N38XXPjzFcHCLyjJfJTW+wwTuNO7cWEtbeYL+xnIlFk+jt8rDv6Z8w7Z/+50xPIc8ZIramg9i6TuxzynDMz/csOR7zJpay+IU93B6zEC6z0F5sYPyRNDFDIx0+mRVlRjodVUzf38IkfxAx9hl2JsswZY7SW9KHuesoa1fW4gH2Mo5KuRXHBifBvr9j1BdgoxEYhW5MYDZbMQNFcSgOdbBRLGWbrZwCXWCCvZ32yhe4KF7Lx/puYHn5VpKFsOJQGVvjFqqNh/ARZFpkAjFnOV22QlptPkyaiBEZJRnkb32beOpDdhbt9XLj2hgZMafyaI3/F6N7svzxxW5iZpk1jVWEqutAFTFpC+jwqLxc8wf+GPoc5RWFyK53bTSqZ3OTYx/fD1+No6efotodAIRNImHp+Kprw4WoQNymY9TTyBkNm2dknJfhoLCwkE9/+tM89thj7N/ewvjxc5h9/VcpLy8nEY/S3dWCqIKsCUQTSXbt28/uAwcpLCri5ptvpqTk1IQNTgTJmfsbq9EMsuedm/1pFR6Y6qahM0ywXeWu7DcokCJUFTYj925lltfBOmkCv//977l4xgxS5gY+s+DLdFmKUKpsvG64nImH7kVv85CSM2z/02iunPhhZlWYebpMomX/JNxahk1KLcGS+xk9RmFsw6IRn/O5TiiR4Scv7GN6tYfbpleeaXPOSqZWuQHY2hpkwdjTpxfaF80dIPnykbQ8Q3BWezOOX3aQjXXx4sIPIRftYqclwNdDEhv7fJT6m5GdRfhd1ezNVHBZ1RrG1t5MqScvyDvhJ3+j9+bPMH3c59nYOJW98Yk0Nj6DpfITXLTpl9w7azrbEldRuep+dixoRa29mKpN99GxYxLj+1swe2vO9BTynGaSu/yElx3BMtGHa3HdmTbnrEfMqnhTfrx6BTVBldm2AD+u7MWtjKamT6Gm91jvMC86HmK2ZmYlf886gwNVruKVcS2UdoNTdNAplzE9upVU0ERIMmEOrGN8ZBV9ddOJWUtR5W6KxShjRRcljGJStpsu/3L+LnhZLjQy/ehH+ajmYYdlG+s8f+RQ99UcjY9iivEIxRctQ1JLSe+qwhQ7RJftYVTFQkgR6dJ7kIwxqguKaQyOwui9ghXXily+YjWm3iyHCw28UScj6HXoQNpXgWa2YojV88qYXRy2rOJjk75H4ZMxrLMLB7lJEvLYq6nf0EV3p4VOSzmmQ12sTtnZHrwa59aOQWXrhxVVImmVcREiqwoI9tOQvrvj0ZOutXM4HNx5552sWrWKN954A3H3Uq4U38ChhSg1+thRdCNblQa6u7uRZZlZs2dz+eWXYzAMb4PuoRBdudoZNfKPThqAS1PRvRKv3DKTx/7fR/ix8iF+PvV2RF3hJaUPnxrEb6znryuTZCjDY4rwsZa/8L+XfYpXi2byicf+QmkwzaFCAXSRdvEgjpCRdFUDPbZCXOb97Dp6MaMTVXSlmjHJ0j/YkOed/Ofy/YSTWX544wTEvFLvoEwJvcRa07cpe6R/eOpjT5C+WM5JO12RtGXNy4at1m44x8ozNGe1kybecjubn1vOBGsD3yj+MXMTSY5kZlDS2obRYCdc4GW37MakZ7iufj3Txr94pk0+K5BcbhpuKOe6tbvZWTOF+/WP8hPLVxEvbkZ+tJKZE19hm+1Kxkvj8AXXcMhSR6OrAX+fh91P/Zxp//SrMz2FPKeRTEeMwCP7MVY5KLh1dF5y/wQwHdjB/7z0a9Zc8nMqFdDbDjEp9grGgrtxl5iYHNXo3fA7+hov5tcznuTaZDtlB1UOTL8cG2mSBo3xvWUkHaAJEg0TjjKmrJlGvYVkby3pvkpenCAz1SowKRjlyKEDbBQTWM0v4TJksJjjXOWOc0NyDZUbv0zGdhTzxb/FeuRKjvZcyhiphw80PEuZ7TBwmMRkJ7t2LuDS7osZ1bgWuSBIJmFHTVaRFh0IDoXSDBwqO8wDxX18+g8qxXo5fROmssm9hj6lgEJzEX5jgF2V/0lB6gqm1n2Nu4Ju4kIMy8QhBDnGXc/MTXdzT/ASXt6zCEHTAIFw1sY3H98JMLKOmioTM5twESKR1cHiGblrQc5Be7vCZLgt9zOc8KZPkiQuv/xy5rq6kJb9EknLbeQsGT9T2/9M2nc7E6+8gylTpmC1Wk/JKXy/SPack6bFBk8LK0AjKEgYrXaulzeg6gLaITcrLT6ipTVEMaPLEtdMKCLTuY+CWAuMHs1N2zfR7Syjt6iWKv9R9pfUoBuNbEjpoBxE0OuJFJTQaH4ZjoI5VkdLwQ6yahaDdHoc1HOR7W0hHtrQysdn1zK21HmmzTk72fEoxue/SLlw8p/Zk8UfPX1O2rLmZe9Ql+yKd7Fk3RKA9+1cva+xTuP6dD5yVhdufa9pBtaK67m/6m9IKNyQKsGwT0BUFMSSavpsLg4mq7m65mVmTvo6opgPGR+j+nM/o773IebtTNLuqGNN7AqSo17EMPo26ra8Sm9Dks1TZtH4WoRe6170+jlU96zhyDY36eDRM21+ntOEGsnQ/5fdiFYD3jvHIRjO6iXhrGHf3r0cHJXr0eQWBGKpowiiE1GX8CDgTPbhIgrOGBFjmDGZDJmYkYLMaNxhldu1/wfJJCG7DQGNhBQgkTWx8dCVyKYU3gmv8ll+xczEd7CYfsO48S8yZuwaqmo34CjbTdbiJ9VZTvmGr5DRVVbZ3uCPb3yKZ5qvolHqZYbcwtGjk9iw/iY2b7qWgwdnYrcHkKQsB/fNo79tAm5LhPKK/dQ3bGDU+FewTvkrTcVruGFsjPCdaVzdrYw90McdyU9Rap6JMZ3hypWv8sv1H+TScR/np/Mmk3ijC/M475ub93+gZh715gjrTJeQ0d75mmRW5WfL94/sH0o1ETdacBMioGYYtOP2cLLiB+9sKwC5n1f84H0PZVz94zcdtGMYyDIv+ypz5sx5y0F75l8H+sPpb20wdzx6CpMYGsmRc4jUaHbQ5wslgbBkQNd1UkYvlaKfSrPAx/c+y5edL/OM6Tv8ovo1fvmRmXzt1kvxtq5i7J69SHqWxp4Wmuu8mDMpjLIJKZVASvfw4cQ0GiMKLY4yii25XnxishynUoA/+Y+9+fLk0DSd7z21C5/dxJeuPPsEc84ahvEz+345Fkk7HemO92y55x3y/wApNcU9W+4ZubFO8/p0PnJWR9JufmENvUW9bLMd5Vv9cbYevhRj7CjV3ovYZcywnUJcxjA3jeuhuOjqM23uWYUgioz78oe54dcvs6nhah423sos4yto07fg+Vs98ycuY6f5NsaVX4Lv6DpafROpNJUQDJrY9fhvmPaJn53pKeQZYXRFo/+BvWgJhcJ/mYTkyMsAnyhjp03locOvY42AVRRoHteNuC8nnFGWVtEi7fTbzYScOYGFsZkMh+TRIKp40irZ1iPo6PRZC/FIYbwugY5YGa1tV+Le+kEEKU3FBJWJl1lxF9sQBAmDwYPRWIgsO0i3RvDfuxNN0wjpUXbGruONuMrFhTpjI0eZP/9SKioqEAQBURQRRRGDwYAoiry2ajV79wtY+mYzO1lPYkyU5KwsSgcceS2KIBiY94F5mJVH6Hz0UV7LWtE0N5eueYPy8jvov+0m7r5uDKFlzaQzKq6Fx+lFKRsRx1xNaINr0Kc7QyNYm7bjUT7p+T1fXB+h3+RkRebk6iyf3NrBz5bvpzOUpMxt4auLRg8d/RusQffxHj8eJzLW8TaYI3BaLdpyTtpQkbQSo0xclIglEgj2EspT7ey2zWZUBHYV2pndDtmuVgCKi4vJGA00vbGLpy4rZdW0u/i32E5UcQNlnZ20eZ0I/V3YvAYu7ld5sMaOGBcxiCpysooPb/seJZ8Y+Tq8c5Wlm9vZ3h7mF7dNwmHORxuHZDg/syfKQHTpn8PtXGfyYtv/45P6vL6flMPuePf7evx4nPBYp3l9Oh85q4/NXVE79xUvZUYyhbntEgz9rTis5XRbsgRcIkcTFdxQ/xwTx3/ngpKUPVGKF34Kn/E5rtwSJWTx8kz0FrI1qxGabsCzdRuRxhBbGsYwbmOGHssmpIbLqe5bz/6tHrLB1jNtfp4RJvRsM5mjETy3NGIss59pc84pXKNHo4s2AGwS+ANhRF8jEuBTRbRIB23WFF32MLIuUJfKstnaAKJKzO7BNvBldtRQg1cOUWxI0BUv5dKkijEdZPaNY+k95OS5X8Kq+w30HarEIFVjMDhJHwjSf+8uJIcJ7xemcH+5hydjKtchMTGyjWpbCdOlBipVL9XWUipEHyVJJ65mMK+JMmdvJTOyDbTrfh53bKbD5qLlkWp2PlqEyzGND3zhdmom1KF97C5WfehDRFweLmsNMPWXv6Xq91/iohvGoITSxF7vxDq1GEOx7bj3SqiZS4EQGfS5spFqqDtwguuUwojoFKbDfEDf+75PcJ/c2sE3H99JRyiJDnSEknzz8Z08ubVj8F9wDeEIDvX48TiRsU7zBlOQRESbjBod3Ekrt5jQBZGWYBjZW0OZ4KdbsiHpcNCUixpI8TAAFosFzV4AgLu/DVWS6PL4CBSMZVRPAB0wJEGV08zs11BFgb1qEyW2AGETqIpGLJge1I4LnXAyy08HxEJunDzCdZ/nOsP5mT0R3hZdEtApF/wnFV06lnLYFe9CR38z5XBZ87JBX19iG/xAY6jHj8cJj3UmHODzjLPaSXtq7ho0IcPnOo0c9CcQJAONhTPx2xQ2pGopsfZwY5MTt2vamTb1rGXCD/6Dq9Y9RlV3hGWWa0lJRpRp66g8MoFZHY9zyFyNf+JVePesp8Oexio4iUR1tv3992fa9DwjSHxTN/E3urDPq8DaNIjoQ57j4nA4SNo9SIKGIqWI9Ikotmp0u4goCGixTpKylRZLF3UpET0m0VBQBsCjYh1tmV5Eo4m2dBluKYRZSiAZa4nFLBTSx+Qra7jzh7OYcUMdEX+KF+/dzf/+22us/sF6+v5vN4pFpmduKR/++zae6gjyubm1zKsPoQsqM7MNRJ5vwX//brp/tYWuP2yn6/7ddD7TTPdOP/1FNrxNFzHWswA9YWHT7jUc0l7GPrUb5+QQm3es509/+hN//OMfUQS4ZczV1JXdhp5yIblN6FmN8HPNoIPziqr3vlmVM/k38VEk/Z0pcgZB4auLRqhZ+iAnuEY0eP7r8IsJsMSd+/c9NkY/W76fZFZ9x2PHTdNc8D0wvMvxNFhyj79fTmSs073BBES7ETU2eLpjld0KQHM4gqFoFFYhQ4+Y22YE+oOkNStm5a2/i6UwpzboCvQCcNTlpKfoIqxZFYOmI2VVREeGSSEVWdXYI0yg2NpBUNZxFJixufLR/8H4xUsHCCYyfP+G8fkD7PdiOD+zJ8Lxoks7Hj3h9en9pi/ePfVuzNI7xX7Mkpm7p979vqdwwmOdgfXpfOOsTnf84AG4QfGzqnsuYibFzJKbWU0rAY9Gd08xn510H2Ma/+tMm3lWUzD+Kpw1X+f6NxbymxvreTh6Fx+v/APatLtxbvs14cW9bE1VsHi5kddHv0JpwxVUNz/F7m3zmBpqRXKfwCYszzlFpjNG8MlDmOrduBbVnGlzzkm0tEoq48Qs6fi1KGpaQksYMVhFUCCp9WIz1nDYvJt5kQTZmIzsdAMhGkQH8ayfpNmKohlwGPoA8NkayAgWSopzmyqT1cD0q2uYtqiajvVdpFa2YY5m6FN1HuyMsOxJP1kBFicMyMv3s9u7D0u8gleiAjD4JpqoAn1pIICz0MLs8VdhKc3QFWpm7769HOk8AOTk4BctWsSkSZMwS0YCyn5CzzSTOhgi2xVDDWdwXFY5qMLfP+Br4BbzRlZEfGyxLCSUsWERVa4o3sqNU2445b/FoAx1UpsM5P6DExIIGCodc8g0zWPjDEeh/ImMteB77xQqgZHdYAKSw4g2RCSt1uWA7hhHo3FMZWMBiIm596La1UfU6MGqJdAyKUSjmbKaCWjCs7hCuX5nfocZv3ciWVGiMBKny22nTTxMnVZAfSjGAVsD82zPsLlHJRxNDWrDhY6m6fRF03xoRhXjywZPM87zNgY+T8pL30eMdJC0lGC7ZgTT8YaMLrW9L9Gh95u+eCwNcjgUGU94rDOwPp1vnNVOWsTbTWZ7HWo4RWHBeEIWI6ozwprQFGqdLVw/dSJWa+2ZNvOsZ+z3f0vywz/n1abPsbp6PtfzdzxTX6H+3inMPPoweyxf4NDMxRRtfoz+CVfiyhhIxKNseuheZvzLyBfP5jl9aCmFwAN7Ea0GCm4fjSANfcra09ODzWbDbs+nQr6b1qPt2OMSLkEjk40DIGUk7DbQ1SxhQwLVbiIsxxinJMhEZfY7ZYyayI+ydpZmQnR5c3Lwh5Oj6IiVUBjy0QtUNL2VMqL4k0RWtsLWXqwWmdDCSn7b2sfL+6LUuC185+JRFArw0obHsGh25k2dhyS8tawLooAki0gGEaNZxmSVcRSYcRVZMJrfvvw3cSM3omkaqqoiy/I7TuC9d44jurKVyMutGKsceG5pxDTKfWI3SxDQyy9iWmo3t9Wm+FjNV5i+dx+jvS0nefdPAFfFQLH6e/Ae9RFlbgsdgzhkx03TbLp1+DZ47zXWcDqFJ4hoN5BpHdxBGuV2AV10JNOIVbkDPsWYc9JcoSyxYgduPUj00GZc4+bQUD+OoB1cMQVzOkPIKqJJRvzeIhq6+uhy2djXvYs6w0VMCaR5yFuEyxFFBwJ6Lt3R6RuhlNlzFFEU+O2Hp6Ko2pk25dyh6VaECbcw5rsv8PGmGr7ZNHbkrjXU2iRI76t+q8RWQle8a9DHh2Jx3eJhk8k/obHOwPp0vnFWO2lS3Yc5/Pz/oVutzHNexQPKcnqcGoF2D59sepS62vvOtInnBJ7yuTgu/lduXHuYn1RP46/JT/Gl0h+Tnfl5nFv/QPymDnYkC7hpcwFbJz2Ft/EaqtqWs2PbZUwLtCAX1JzpKeQZBnRdJ/j4QZRgisJPNQ2tyAeEw2H+9re/4fV6+djHPnb6jDxH6Iq9jiteiN0kkTXuQxfNmBWBQk1Di3YRMsgEvbk0r3o1QyrjJmXMYE2meELtBVQcVhto0JWo43vrvkUjOk2mOAczJaQe3IPaHSfZm6BfAn+jixe0NK++tBuLQeIbV4/hn+bUYpRFVqxYQSwZ4SMf+Qj19fWnNK9jIiPvRhAFnFdUY5tVhmiV33cKlbH+EjxdTyCETdj1CBGXxIhKGSz4HuoTn0PS34r46MCgVh+nPuKri0bzzcd3viPl0WKQRi5N82QYTqfwBJDsQ0fSiiwmJE2jO6uAK+ekueUImtNOYSROtNJKZfYQ7QfW4xo3h8raWtbZJXwRDV/CT8Sa22BGS6oo7evCqKhE+vrRS3Vm9sNDDRBz5qJDk/9pTN5BOw6ydFZXs5x1SKJAlddKS398ZC80VHTp3Q7aMYZYn+6eevc7ZPDh5NMXR5TTvD6db5zVn+IdDy5DFwUWeG/hNfUo5op+XumZyXjvXq6euhCjcYjePHn+gfqv/pbxRx5m+t4+ttimckSrIz1pBY19M5hy6AG67aXsnrOI0rX7iThlHHGVTLqb1//25zNtep5hIr6hm+QOP86FNZhqh06DSafTPPjgg6TTaa6++txXTRUE4SpBEPYLgnBIEIRvDMeYjaWLdu0MKwAA64BJREFUEBCwiQL+ZBsWT644v1TR0KKdBJCI2HMNrasUhbBehCInMAkSlkwu3a7FbMIpx/mj3c9nRJEkAkstIh/f5+eKHUdY1NvLjcT4hBrj6/s72N0d5QuX1fPKVy7lM/NHYZRFOjs7Wbt2LZMmTTplB+1EkGyGk6pxEatn0WgN0Jt0UEw3szKb+Nj+ZbDElfvvp7XDK8vcdCvrLdfhx4uGQFI8Tu3SceojbpxSzo8/MJFytwUBKHdb+PEHJg6p7vjk1g7m/GQltd9YxpyfrBxaYOQcRnIY0LMaWlr9h+cEQcCpZOhVNbAWkMFAmeCH4lJ8YfDbrUiCQqRlHwAFBQVE7Aa8ER1Ppo+EEXRZJe2tImGQKQ7HEdIq4WwfkyMSJkWhw5hTE22LjKAy6GliJNamPCdPjddGbedzLPvtBBbeO5am+yew8MG5Q4pxnBRNt8J1v0J3VaDpAknZBfJxDhuGWJ8W1y1myewllNpKERAotZWyZPaSIaNby5qXsXDpQpr+3MTCpQuHd055RoyzOpJ2oCLOxZ5JODUvHayhzWgnlrVz69g1VFU9eKbNO6coKJyF48oIH3htG9sbLuMv6qdYUvwNMnM+g2/zRrbfdoSdYRe3qrXsyT5IXePNVPS8yq5dC5jRexhj0agzPYU8p0C2O07omWZMDW4c84belGqaxtKlS+nt7eUDd3yIwqKi02jl8CMIggT8FrgSaAc2CoLwtK7re05pXN1IoVHEIUFvTxjJPQZZA6dgIB3pJGIyETYlMGgCxYrKfrUMXVQICxZGKQFiCLSJ5RQYAwSn/56xhrkUP3YzRcoOjJ+/jc6B/jmSKFDoMFHsNDO+zInhbafjqVSKpUuXYrPZWLRo0alMZ+Qpm8KYeDcvKBI397zI51ufwKgrbz2fDMCTn839/zCdum6JlPOr4v/AU9jOr/f/ePAo2gnUR9w4pfyEGm4fU4I8FnU7pgR5bIzzBfFYQ+toBtH0j5tLj64SQARBICF5KFX7yXprKD7cTJvVCCHIhntyY4kiSZsFb3MKm9KHIgpErQJFcRedHjujeoO0+Vy0JvYw0Tif2lCYvQUT8VlDHO4b4YjHCDNSa1Oek2cxr4HwJ5ZYnaTE3Pa4KxtmyZrv5p4fplRBmm6lr+Z6fvST7/Nz6T5IDlFf+R7r04mmLw5nI+s8p5ezOpJ2RdNNXKNdyTp1N476TlZ0zGVa8VaumHIbkmQ90+adc9R86r+pDD3O3B09HLQ2sFWZRrrpJerj8xi37yH8BT62zphH9Zp2Uh4jrnAMVTnMqvsfOtOm5zkF9KxK/0P7EM0SBbeORhCHjoS8/PLLHDx4kCuuvoZ/jwv8695zvhXDxcAhXdebdV3PAA8Dp6xW4SmyMNsq4bSmyWY0kmkbjoH6vlSim4wsEZHjlGYkBBU6LXUAHNTcqGk/ktVIR6oUlxjGaYxh1apJaFBfpnNlUyl3za7hrtk1fGRmNYvGlzC50v0OB03XdZ599lmCwSAf/OAHc42Nz2YMFhJCFf1KL5869Mw7HbRjaNlhbSCbVTRSNoFvH/kjsv6PUR8ECa771bA5he9bCfIc5Vg/RXWIXmk+SSA0sMFVLD5KhQBhqwtvRGefeUDQJptE13UAdLsbowq22FEQBLrtRjL46PA4sGZVjKpOR/IQAgINwSB+sRCPJ8zhvtjIT3ZkGZG1Kc/Jc3X7L/l9gZ3Uu1K+U3r2pJo+H49AIsPX5EeRtSEcNFflsK1Pw9nIOs/p5ax20ny7KgmSpce+k22ZKjKqkTsm7KS09JYzbdo5idc3D+d1OjetXos7GuNB9WPIvmbSc6qo2pRGqdjHXs2DXDCF7sh9iPWLKI91cOBAKan2fWfa/DwnSei5Iyg9CQpuaTxuw+odO3awbt06pl10EfdZfawLxbiswHEaLR0RyoG3V2m3Dzx2Sij+XKpVyuwHIGPyYjLlnLSo6keTDQQMUSozKtmYTMiVi0gGhWIimT7SNo2kYsUs5VTtxF4XkpLCN/bETNu4cSO7du3isssuo7r6OM2kzyLEiouYzHbs6nFU+Yazf44ikDJLlKX7Bn9e14a1VuJ9K0Geo4j2XDWhGh1cQbRYlogZTWQyGWRnGaVCgF6DDVNaY1c293kxiBpKZycAJm8xANaB3pxBm0RCLyJpMeC3mykPhImk+olnw4z153qs4dU43Bt709E7RxmRtSnPSbLjUUzZEN2yNOjTJ9P0+XgE4plcKvCgCPClXcO2Pg1nI+s8p5ez2kmb84WpvKG9jKfhKK+2z2FO+XrmT/4EonhWZ2metQiCQNVt/4FHeI7LtnTSaS5jtXI56QkvUaFdSf2+pQRK7GxtmkT92n40r4Sz34+m7eOl/33yTJuf5yRI7g8Qf70L+5wyzKMLhnxdV1cXTz/9NFXV1bw2aiLL+sL8oL6Mm0uG/p3zBUEQPi0IwiZBEDb19Q2xoX/375glECAq5NS1sgYPFqOIrqSIShEEu41uYz+VSppMVCZhNyKpOuWYiCkhEtbcGmaQcxGlwFEzjuhRLA3vXVe2b98+nn/+eRoaGpg7d+5Jzvr0Y5+wgBvEjsHTDo8xnP1zVImU2UCPaYj38DD36hlK8XHEGnafIY4d9GhDRNLKLEZUUaItFEb2VlNEkA4x16pBCcZIag7MQpbU3r0A+KobATBHcr3SwjaJrGaiwKzT4nNTNeCYtScO0BAVcWSjxJxu4hmVnsj538z6ZNanPCfBih8gACXKIFF3Tq7p8/EIxrN06kPoKgzz2jScjazznF7Oaidt9+oXyJQeZVX/VNAFPjy5HZ/vyjNt1jmNr/AKXDeaWLx2FaV+P0u5A6Ggi+ycAsa/oaP7NnE4U0Ri1Dy6uu9Dql9EWdJPy9ECwvu3nmnz87wP1FiG4N8PIBdbcV01dKuKZDLJI488gtVqJTL3Cv7SFeBzVUV8uvLcrkcboAOofNvPFQOPvYmu63/UdX26ruvTCwtPrLG3ntFAh2CyFUnTMOgWnGho0W7CsoFEqYOUmKZaTZBMmMgYs5iyOvXZ3IYzZs61NTCZc05af3cBrkgLpvcQ/2hra2Pp0qWUlpZyyy23DKrEeLZirp6GWxgkzfEYomF4++eoBuJGE/fXXE2Wd52Oj0Cvnq8uGo3F8M7rnHVKkMOAaDOAAOoQCo+VtpxTejgYxlBcjyToBMhtfL0RnajgxKInSO7NlV41NM0CwB6JY8zqhG2593SBSabbaUPSdWyKztHYHopwUx3ppMdaxh9uM+O2jqhG6EjznmsTnNz6lOckGIji3x0MYdbe2b7ALBiGXTUxkMjwn8qt6O8WDRmBtWk4G1nnOb2c1d/wR3vasVR2srZzBpdWrmHWxM+flLJYnrcQBJGya/8du3MFV2zqImjw8IJyHenxL+G2Xk3V3hforTOwqbGOxk0pRG8WZ28XgrCb5+9beabNz3OC5OT2D6ElFQpuH4NgGPyjrmkaTzzxBJFIhMKrb+Cn7f1cX+Tm23Wlp9niEWMj0CAIQq0gCEbgduDpUx1UkAQsF3vo6+7EklawpwTcuo4W6yFsMBOz5jal1WqGkGona4iiKlCihwCIWtyIgkqhvR9Nt6JmbHiEAJLTOeQ1d+7cyV/+8hecTicf+tCHMBqPo1h4FiIU1BEThsiCEES48XfDmn6oa0YSBjObiht5Rhidq/FAGNZaj7fzfpUgz1UEUUC0GdBig6c7VtltALTFEhiLcocOCTnn0PkiEJXs2PUIsZbtAJRPnExGAndMwRNJEbLm1iqLwYIoQFuBg8qeAMFMN5a0Sll/PwnBjmjvx2wYPDXtHGFE1qY8J8lA9GpxPMESf4DSrIKg65QqGkvm/nDYBTaC8QxPa3NRr71nxNem96sEmefs4azOG3RX7eXhnZdhEBXunJ7C7Z5+pk06LyguuobOG77Dgj+vYO0ED8+U3MQC1wuoc4zMfE6itXEVnYnZdE9eSKz5r/hG3UVRYg9dvTK9m16naPqsMz2FPO9BYksvqT39uK6pxVhqG/J1a9eu5cCBA4xZtJhv9saZ7LByz5gqREFg39pV2D1eKsZNOI2WDy+6riuCIHweWA5IwH26ru8+1XFlrwXp8hSBByOYcSLr4EQiG+8jZjYSM+bqkKqyCt0UgqgRN4lk4x2IokRALsBtiFJoCYCWi1gWlQweFchkMrz00kts3LiRqqoqPvjBD56bDcZFiUNWH+Pjfoxvj6gZLMO3Mdnx6JuNUz/pcdLS/xnCxRr7ZRd86fVTH/89OFElyOPx5NYOfrZ8P52hJGVuC19dNPqsc/Qku3HISFqN2wn005lIIVTkNr66nAFRpDAqECw2U60eocV/AACr00XQIeKN6LjivXQW5YJLBskOxGkrcDL7YAf7yry0x/ZT1SdDI6yNZFl4OiY7QozU2pTnJHlb/7LF8QSL44m31qZhcGaWNS/jni330B3vpsRWQoV+Mw5zDfLk22DybcMwgeMzbI2s37bG5ptTjzxndSTNWHQ1G7uncWX1q0wfnw/LDheCIFF8xbewFq9l4cZ2ErKVJ5VbyY5ZgaHweip2r6FrvMimymJG75ORCvpwd7Uhy4dZ9tct6O9KBchzdqGEUoSePoyxxol97tCbu9bWVlauXEn1hIn8l27FbZD488RaLJLI4c3ree43/82Gp5eeRstHBl3Xn9N1vVHX9VG6rv/HcI3rP7qDjCiTKG7AKoIoCCjZPhRJJC6nEHWBMkUhKA+kMEoCnekWNJOZsOrCLsXwWQPoyULMqQCO+n+sQ2hpaeEPf/gDGzduZNasWdx11104jxNtO9tJCV7+Kk6ly+RFAyKydXgdtGf+FcJtgI5TCvOTQ79kfvc2Cj2D15mcbRyT8e8IJdF5S8b/bOu3JjqGjqRVOnIHCN3pLDjLACgQw0hFRVQlbXQaDchChrSURQkGEQSBqN2AL6LjzPqJGQUUWUAz5daulNFAX1ERhbEUR2O78GR0KtR21ifOeVGjEVub8pwEA/3LQoZitGGOah2TwO+Kd6Gj0xXvYnPij9gKtg+D4aeRd62xhNtyPw9nj8s87+CsdtL+usWJTU5w1wwXNtvIN2q9kCgtuRHbtUZm73yVCYcO8pK0iIRDRZ+VYf4bZizaCwTjxRyadTWh3U8j1l1JQSpOOBTkwAsvnmnz8wyBrukE/34AdCi4pXFIuf1EIsHSpUtxut08WzeRvqzCfRNqKTIZaNu9g2d+8RPG1Tm49s6bT/MMzh0O/eUFdEEgUzcF28B9TmgBRKNEWspSnDViAHpNOfXFnakaLBkV1SjRn/JgF9NIcRvhHg+22GH0mloCgQAtLS2sXbuWP/3pT9x///3ous5dd93FokWLkKRzOr0Ls3E0KwQjn5z6fabNfZAHqxcN3ynsih9A9p1KilYtzU1H11HmOzc29OeKjP/xImkWWcKsZOnLKmB2kcZEmdCP6iuiJCZzwDBwyOeykN6XUw1O2ax4I2DUe0EUiNhEksZqjFIu4rq7oYyyQJiEGsWUSNCYbma3UkpSzR8Y5hlGmm7lwTnPUZd6gMTntg3b2jSYBL5GhrTjHGsoPcgaSzY5rK1T8ryTs9pJ+9jEp/nclL/SNObzZ9qU8w5RNFE49ytYajaycGM7GhKPKHeiNK5Eq7me8l3baJ2ss6XARU23B92zH3dPOyaLn5VPdaBmBz9FzXNmia/vIn04jGtxLbJ3cFU5Xdd56qmniMVi9Fx6NWvDCX7SWMEUp5Xelmae/NkPGV0mssj6CsaXvnmaZ3BuoGkqye05CfGkvRzLQI+0sBZC9zqJSQkq0qBmBELWnIKX0+hBySZQnAlCaRcOIcuh/TPZ3VHMvglJ/ufAfn71q19x//3389JLL6FpGldccQX/8i//Qm3t0MIv5xKu+tmYtX48mRRh0Y2eNL/3L50oQ8j3uzNxit3Fw3edEeRckfEXHQbUWHZICXynphDQyDW0lgsoFQIk3V48YYVtcq6/mWQxkNqTEw+RnAUUxEBXczL8AYtIVCmkxJRrUdHlVPGay5BUDTHYzajIEZr0bfRnjtPOIU+ek6DEmVuTusPD994aSupeEQLDdo3TwlAtUoazdUqed3BWO2mTx3yWm+d+GpPp3PiCPdcoL78N6yKZSYdWM233btbKc/HbbOgXh1iw0YE98RjJdCE75i5C3bQWQ81l2JNRkol9vP6XJ860+XnehdKfJPz8EUwNbmwXDy2tu3HjRvbv34/78kXcH0jw0TIvd5R6ifh7efwnS6h1xbnKuYa0XMSR+v93Gmdw7tC+fStSJhfxSMbAaAQ9myKsZ4i6LfgNYSrTCtmERMokIWg6ky0COjpps4amSyR0jclTnsMnGhi9t5WF8+dzww03cOedd/LFL36Rf/7nf2bu3LnnnEDI8SietgCXquBJpUkINmIZB7pyHMXH98MQstURg5XCgsbhucYIc67I+Et2IygaenrwNFK3rhEcaLagWgspFfoJmh2YAwkOmhIAGIwiqd25Eix7cRmiDoZ4zkkL20QiKSul5ig6kFXjhMbMoTQcIx3tosTfx1fEe/ASHPnJ5rmgKHENOGmR4XPShpK6N4veYbvGaWGo1gDD3DIgz1uc1U6a1VpLcfG1Z9qM8xZJsuK5+As4GraxYEsHJkXhQeXj6PWvkh59PTU7DnNgmsI2k40CpZKEYy2e7nZsbpFtr0dJBqJnegp5BtA1ncDSgyAIeG5uHFIFtbe3lxdffJGC0WP5nW5lot3CD+rLScVjPP7jJZQKHSz2bSRlrubBo99jd76MfVC8ikbSaMBoFJEjCjZBR4v3EhFN+M1x4lKSSiVJJm1EMWQR0hqVWu7zolhMuUFkcDj6saRKmNTdxuzLLmPKlCmMGjUKt9t95iY3gtiKa3ELIp6BeqaEZiLUfHB4Bl/wvVyh/9tIiCY2FI6lsGDS8FxjhDlXZPzFgV5pQ6U8eiWBqJQTwjG4KygT+umWrYhZBTktkNJtmMmQHFhgCupz8zNH/ciKTtgqkkmJFJgVBEBOZwn4fNSqHjRBJ7rPQp3jCSyWs0tQJc+5z0hE0gaTwNc1A5NtdwzbNU4Lg6yxI9EyIM9bnNVOWp6Rp7Lyo5iulBjTtpaZWzez3TCZZksl2rQuLtvmw+t/CE0oYMusS3GvPYRx1GzM4W6yyQ08/7vHz7T5eQaIr+8icySM+9o6ZLdp0NcoisJjjz2GZDLx3KgmVF3nTxNqMOgaz/ziJ9hCu7mudAdp6ygeOPxtkokYRzfmC4IHQ5xQRmiMjLPcizOu4QK0eB8Jk4HoQKSgWk2QUuxoUpJsVseczJ36p825+iiHLee0yVED9lGVg17nvEMQcJklnNHcBihpkNm8ZZhaewwU/uOqRAf8gpcvN36VTksJZk/d8FxjhDlXZPwle84BG0o8pFCWiBmMZDIZDL4aCoUwHUJuXfJGIIoTq5og03oUNRqltHEyAPZ4EldCIzTQK81odgNgTmrEhRTFjbfiiqew9nYR7PSP7CTzXJCMRCTt3RL4JdZSUl0fYIp3wbBd47TwtjV2JFsG5HmLs1qCP8/IYzA4sTd9EmXcH5i/fSrbJiZ40PAxvjPq+yQm3EHDtr+yemEUfZOFCe4JBMWX8PQ6SY+ZTvvhCH0H2ilszIe6zyRKIJVLc2z0YJ0+dGrwypUr6enpIbb4g2yLpfnj+BpqLCZW3Pd7sodWc3vdPhR7NQ8c+gbZRIT5G35GcN7QaZMXMooaIx234q2vJrZPx2GRUOK9JIwySWMuulCrJ0lqpahSkqhuQo31I0lG4nJOnXFUQS+6asDS049x8oUjjOSymwjH0gAkrDKH/M1cMVyDN90KTbfyy+/9O2u9E1hT3MBlRzYi2M6dJsDDIeM/0kjvEUkrMRvQUiLt4QhVxbn3dkjMpUaOSjkJiWm8WpiwC1K79+AeO5YI4I6peMMpwrbc+IprPNCJJS0SF/1I7olUdxSxQ4zQuWEVk6/Lt4PJM7xYjTJOszyskTR4pwR+ZyjJ7M0r8VjPwVT2gTU2z+khH0nLQ03NJxHni9T2rWf2xrU0y6PYYZ6ANrWFOfsrKOl6ENXuZePUqdSu6cc8eiyG4EFQtvD0718esng8z8iTa1o9kOb4gfoh0xxbWlpYt24d1otn80BM4UOlBVxf5Gbbi8/R9sqj3FJ3EM1WxgNHvo0STzJ343+hGbN4O+OneUbnBkaxkmwCFO8kLCJIgkg23QdGAxkxpzhXpihE9EJ0UaNfspOI+zFYbMR0B1YpQY0rSCbuxR5uxVQ36gzP6PRRoNtJJnNCGAmrkZCUHvZrCBmNlBWsegxBEcE4dK/APO8f8VgkbQgnrdSSi0YcDUeRvTUApKRc1K0+48Yvm3AIAdI+mdTu3VhLSkkYBXwRHUe8j7A1l/KZto3HImUxKiIBYxsARXXXYlBU+na+lv/uyTMilLjMw+6kvZ1APPe5OSedtDynlbyTlgeT0Yd13IfxTtzPzN1+SiMhHtI+ilC7jkTT5UzaHGbP6E6OJK0E62fTF34Zd18cc8koov1H2b18y5mewgVLfGM36UMhXNfUIrsHV8pLpVI88cQTmH2FPOAqY5TVxA8bymnfu4tNf7uH20YdQDI7eLj9m6RjGhdt+TmKI42iC/xkQX5zOxjBzlzfql7Zg31Afj+pBLAXFYEg4FBNWHWdPjEXiRQLSommAigWiZDiwCHH8RqDZBMFOGLtGM8T9cYTwWWehF+IY9JTRM1mssMo8HgMPSuQsso4iKIq+a+54Ua0GkAEdcheabl1oy0af1NUQJQSCCYTFQkzR2URg5hCrS0ntWfP23qlgTndR9QioImQkKpxG1IICHTKbWhoqAYZi8GO3wj+zZtO25zzXDiUuCz0DGO647sJJnJOWoEt76TlOT75b688AIyq+xeYCxWRTcx+/VV6pBLWGeegTj7A5PZGyjoeIVpZyKax9YzbrGGY6EHu3ohRaufVx3eRTuQl+U83SjhNeNkRTHWu46o5Ll++nHAkwq4ZlxHIqvxuXDVaKMjyX/6Qm6v3YDaKPOb/NtGIlWnb7kH1RTBGBP775iLc4/JN5AejoLyCD377R/TjfLNHWlQLo7ptqCgUZXL1N72GUgBq3AUklDApc5JAyoNZSGOR/ChxL/ZYO8aamjM1ldNOwbiriBHCrUWIGa3IlhFYOzSJpNmAgwj5pWn4EUQB8Ti90qqduYbWnYkUOHOpm4ViGKmoGF9MYJ8hp+gpFHveVHjM2K14ozqi2gWCQMwqElV8eAdqPANqnDhpdE0jWz0Fa0EdrgkTR3qqeS5ASpwmuk5DJK3AZhixa+Q5P8g7aXkAMJvLMI66meLJzUw5FKHR381j+u1QvYVU0yxmvpGitWQXfQEbhy++gviBTTijMmJRDdn4el6+94UzPYULCl3XCT1xCDQdz80NQ6Y5HjhwgK1btyLOvZyXYxm+WlvCOLOBZ3/+Qxa6N+A2JHgu+U16QyVM2vV7MtU92LtE/m9hAb6JTdwU+9Npntm5gdFipbppMuGwik0EXckQ1FJELZAS0xRnc38PvyFXC1Uvgo5O1hwnkPIgoyKLYbSkG7OUQS46d2qmTpW6yZNR9D48Spyw7MChD79KrK7KJE0mHERJZIdJ4j/PO5AcxiHTHWvcubrL7lQaTHaSWCgR+lELi3AGMxwy5VJcJaNApqUFNRZDdHooiEBGyvVcClhFIgkTReaBvmoxnbiQQhINOIweYkVliPk2aXlGgBKXhb5YmuwINUsP5tMd85wgeSctz5s0NHwBbYZGSWorM9a8TFh085JhEdmmHdRFp1DS+gwdk4vZVFpIQ6sNZXwcQ+dqHE4rh7e203sk37PmdJHc3kdqXwDnwuohm1YnEgmefvppTGUV/M3g4iKnjc9VFbHqL39iYvx5Ki0B1slfoqV3NOP33k9m9GEK9omsmGTDclkdC5KtCP3nmPrUaUYNZzDLOWXHmCzTb0wQkRIUZRXUjEDMZAJFoyib22hqFoWkYmGghRSGmBFTdfWQTvb5iN3hwEQMTzpNWHBjTGmw41H4xQRY4s79u+PUVEU1TSZuMOMgQkYZ3JF43wyzjec6ksM4ZLqjw2DAqCr0Zgd6CRoKKBMCxJ0FGPxhjpgHnDQ1929qzx5MvhLcCcgInYi6TsgqEg5mcPtyUbmCmIGkGMUkWTHpBpJi5s1WAHnyDCclTjO6Dn3RNMual7Fw6UKa/tzEwqULWda87JTHDyayCAK4LMMYScuvT+clw+KkCYJwlSAI+wVBOCQIwjeGY8w8px+rtQax6hrKJx9hTEeG6R1HeFa/CaXyAEyYxJVrdUKmVWRDbrbNXYRzXSsu3UHU5UBLreapXy1HG6GTpzxvocYyhJ45jKHSgX3O0CpwL7zwAvFEgo2TZ5PV4dfjqjiwdhXSpj8ywd3DXtfH2NY6m1HNT6KO345rq8iBcgOR2yqZlgjQsvZfWHOw4DTO7NzDFFexi6DFe0kYDfRIfuJyipJsmmzahCqnUTMgR3Jy4bol51CbLLnNq7E3jbGm+ozZf6aw6xk8yQxBCqgL96A/868QbgP03L/P/OspbTJ0zUhczjlpRn0YnLQdj+ZsGkYbz3VEuwE1MvS9dahZ/GpO2EOzFlMq9BMwO9D7+lFkE1ndhDGbS2VM7d6DuybXJsGQDuBI64RtIqlwBlPZGEDHFTOQFANYBSuKrqChE0/khY3yDD+lAzL8jx94hiXrltAV70JHpyvexZJ1S07ZUQsmMrgsBmRpmOIk+fXpvOWU3yGCIEjAb4GrgXHAHYIgjDvVcfOcGUaP/iLKdI2i7HamrnmRjGDgafkDJCdsxCPNoeToarbN8bHdasOtlhOsOIrz6Mu4SsYR79/Lpud2nukpnPeEnm1GS6kU3NyAIA4egdm3bx87duxAuWQB6+IZvjuqFEeglwN/XcK8ohZ6PZezcv91lHS/gXnMStghkDSKHPxEKQ1KhJa1nyUpxZl0Rb69wlBouo49qWEXRPREHwmTTJfcB0CpmiCt2NHEBCkMJEO9yJKJjDHXI63cmducmo/0YKy+AJ00UcIdz6IIBi6O7EPIJt/5gmwSVvzgpMbWVA1FM6OIBhx6FLd7GBQAV/wgZ9Mw2Xg+IDmMaPEMujb4/XXrGqGBkLHBXU6JEKBbtoKmMZ5SIriwKDGk0hJSO3fibhgDgC0Zxx1V31R4xHcxkqBhS8nE5S4kREQlw8LMJIxivqYnz/BTPNDQ+pFD/0NKfWdObUpNcc+We05p/EA8Q8Fwpjrm16fzluFw4y8GDum63qzregZ4GLhhGMbNcwaw20ejlV5G1eQ2Kv0Clx3Zy0quJFbei2HsKK5dLWFK/B1J87Fx9jxGr4xhL/TQaQ5h1JpZ/9R2ooF8ocBIkdwXILmtD8ellRhKBldeTCQSPPvss5jLK3lIcjDHbefDhQ5W3/NtrireSdLZyBN7Po4rfITCskdobjdQHNTY+vECKk0xulZ/GVGTiauPs23tfad5hucOHeksvpSGLAgo6X4USSIm5yILZVqcZNaJKqXRrS7CoV7MFicJIZe6Ve8MAWDv7LmgREOOYTFJOKK5VDeHlhj8ReH2kxo7GcuSNuSEW2xqkpISz0mNc0K2nKSN5wOS0wgaaEMosxSIEBFzrVgNvhp8QoQuIbcxHacUExKt2LQIxumNJHfswDU656S5YgreUIbwQENr1T4Wi6RgUEX8xqMAaEoKXdKR1XzFRp7h51hD61C2b9Dnu+PdpzR+MJHBM5zKjvn16bxlOFa4cqDtbT+3Dzz2DgRB+LQgCJsEQdjU1zf4Gz/P2cGYsf9GZopCkbaTcWtewqhl+bt0B4nxryF7L6fs8B5Wz7BwMGMkWTKR/sxhSo+sw1QxCSX+Kk//+sV8/5oRQEsphJ44iFxsxXlZ5ZCvW758ObF4nPWTZqEBPx9Tydr/+y2XSC8hmmwsPfQvSJkstZb7eE6yMmtvmq2LHZRWpgmu+i6SYuaw5zFc/WEOeYdujn2hs78/jkfLRQrSWhiTw4E8sAktJ0lI94II1sISoskAgtVMVLUjCQplpn6UlANbrBfTheak7XiUf1YOsCT0TTa+cStxwTT461wnF8WNh8OkjDnnwKqmKS2sOllL39uWk7TxfEC0DzS0HiLlsdAgETMYURQF47GG1kLOoatNu+mVTNjFINqESrLt7ZhdLgC8MXDF+gkNOGlRoRKHIefQd6khAARB5CVpB2k5LwqTZ3hZ1ryM25+/FvuYbyAweKZKiW1oNeUTIRDP4rEOYxQ4vz6dt5y2Yyhd1/+o6/p0XdenFxZeOEpm5yIu5yQyRTOomdKJL2pm8f4dbBJm0lOiYRlTyrVvOCjp+z8yRZVsaGpi+hsCwgQDLezE4/TiP3KAPWtaz/Q0zjvCL7SgRjI5NUd58I/ugQMH2L59O/olC3g9nuE7daUkt7xB+YHf4TUleabn0yTUMhoy/8t/j3Xz4RUhjkwwUTBPIfrqf6BljWwveYHyIx0cLc4ScbcNep08sKszjHXgzxDXYxgLnBi1nHNQrCj4hZyDW1pURCIbJm2GiJrrkWYXA+hpJ6KuYbiQ0h0HaiecegYBqEz3YCaL8u7NkMECC753UpfoCPSTNOf+DrZsGp9n7CkaTc4Ww7sEek7BxvMByTHQ0HoI8ZBiowFFkumNxpB9NQAkByLNpXEjHbKIRYyQKsgpQaYPHyZlFPFGdIyZPiIWER2IJow4TLkaTn86l6VhMLqY5XJdUII7eUaeZc3L3qxBEwTQ+ccae7Nk5u6pp9aaJpTI4B7OdMf8+nTeMhxOWgfw9mP9ioHH8pzDjB37FdJNWUrEXVS9/ireTJAHxbuIj34ZrWoB9Xu72NAYoydkpHnyPNjWT0PPAUJFXoTUelb+bR3xcPpMT+O8Id0SJv5GF/bZZZiqnIO+JpVK8eyzz2IpKeNhg5MZLhs3GVT6Hvkqo51+1qZuoSszm7rQw3zjCg93L20h7pIw3aERfe0nxFMSuws3Uti2jYyssXFMDzd25ZtZD8XR7hjWgZrAiJYg6zAi6QJuxYIR6JeKAKiWBXR0onKccMaBVUxhFAIIKRuSy4XsGYZ0vHOFQWonZF0jIxjBVQkIuX+v+xU03XpSl2jr7CFpytUzWbNZXJ7Rp2p1zpbrfjVsNp4PSI7jR9LKrLmUsSOhMDhzJ/pGIY7ocFAQ0Wg25DbAWTUBokhqxw5SdgveKKh6G5okkLCKRPtTGAeibEpURSWLVbBQ3NeJxTK4sm2ePCfDPVvu+YcaNABREBEQKLWVsmT2EhbXLT6l6wQTmeGNpOXXp/MWeRjG2Ag0CIJQS845ux340DCMm+cMUuCZQbpgMrWT99K1ZSw379rCH6cu4EBxMU0NVua9UsahxnvpnPwtthxVuPl5G2tvSRLwv8LYsgX09qzm6d94uP1bi/KnnaeIntUIPnYQyW3CubBmyNe99NJLRKNR9l9yFalElp81lLPxPz/NFZ4DHJEuYnvodopDq/nGzXa+9LcVFMQgeLdCdPN/0R+ViUjbKG59GlvSw4bR3fxofR0O9xCpaHkI9CaxiqBl4oS0DCGLCrpGsZLbnPYbCoEMhWqWvUBSDhFOOzEJCrIhhNxbiuFCU3YcokbCrKfhS7uG5RLd7W0kjAM1adksBnf9sIxL0635Tc/bOCZ/r8YGd9Iq7FYIhWmLxqG8BgAvIaTiYgz9cQ4XZyEKaqAXU0MDyR070e0uCiJxknI7gg7BASfN46uEox0Uho2krGHsupm2QJDJp2mueS4Mhqo103WNHXcNjyhaKquSymrDG0mD/Pp0nnLKkTRd1xXg88ByYC/wqK7ru0913DxnnrFjv0xyQoYSeS/uTWupi7fyMB8hPnoFct2lTNuaoM2+i0zExuZLrqDhhQxjpDC73P24TCK9hw6y67V82uOpEn6pBaUviecDDYgDEYJ3c+TIETZv3oxx9nxWxjJ8uaaE4DN/YZa2nJhcxCttn8EWb+E/b8pw+dqVXHRQJ369SqLj3+kIWCnqeQ1X919xp+zYLHFmHShiWyrDfv+B0zzbcwctnMEiCugJPwlZwi+FyYhZCrO5ZTUs2UHVESMhAERrinDGiSwKSKYIsj914dWjDVEj0aV7eXLr8CRgxAOdJMwCgq5hzipIFu+wjJvnnYhGCcEkDdnQutqRE8npiCfBaCWBlVKhH8VXhNbdQ8Kd26QKQT+WpiaSO3di9BbhjULE3ItV0wlaRcL9STy14wFwJAykhCB2TaZbGI4z5jx53mKoWrMSRR02OftgIt/IOs+JMyw1abquP6freqOu66N0Xf+P4Rgzz5nH651H0jWGuil+zIqLO7ZsoU8oZn3BZJSGJOO7x1Dc+3denz+avQY7ZqmSFjWKPbICrbQekqtY9cAGIv7ke18sz6CkW8LEXuvANqMEc+PgaXGZTIann34am6+Qh60+xtnMXB/vpXjLT7AaNFa0fYKMauCvV3Xia3ueu1ZoJMdpJKU7OdxTjKf3FfpsL5KRS8jqBtSIkYreCBcf7sTcNXi9yYVORtMwx9VcJC3RT9JooFvsJyonKc4oqIpIUhIQNIFIXy8AkkkjqViwyCKCqGNs67+w6tEAFnyPJO+MziZ0Iz/N3sbPlu8flkvoiSQps4iVOKIiQT6SP2JIDiPqEE5ajSeXotiVyj2fNBRQKvSTcHnJdndj95Sj6SKGRBhz00S0cBi7qwBXHJJyEEdSJWwTSYQylIydAYCAQJQQVt2E3+VGTQyhDJonz0lw99S7Mb9L9MysadwdCA6bnH0wnvtOHdZ0xzznLXn92jxDIggCY8d8hfi4FKXGg6h7tjErsIUn+SDxxtdxVM9mwTowR59EsZexccYc5q0ScNWobLJvorT4IrKxlTz+85fRhuilk2dotLRK4NEDSB4zrmtqh3zdq6++SjAY5MjMy+jNKPy4ppDe//sMNfYgG3uvpkOYxoqLD9KfeYkvPZVBsOpE6ho52GLC5P85XYatpNMuSgJxprZ2Y0mleX1Mlv/6YIZ7PpA/7RuMo8kMzqSOVRTQEn5SBpkuQ4CklKUkmyGbNaELCSSDmUigD4vsQJBykQWXnHMaTP7khRdJa7qVb2Q+QbvmQ9MF2jUf38h+kqe1uXSGhucwR0xmSVklbul5gYVt62CJG34xId/YdQQQHYYhnTSP0YCkqfRmcptS1VJIqRAgYHagBgLUWWuI4cCciWKe2ASA0WxABKypGJ5olpBNRNd0DAWNb44bUUNYBSsZkwV/R778Pc/wsbhuMUv6ApRmFQRdpzSrsMQfYHE8MWxy9qGBSNr+2CoWLl1I05+bWLh04Sk3yM5zfpLPF8hzXIqKrmCPYxSjpnbRub6OD27Zw/oFk1juuJLrGlop7p2Ou2cNL027ngUv9VDbcDHa6xuZ0rCTvd5RVIch3NXM2ke2cckdU870dM4pIstbUIMpCj/VhGga/KPa0dHB66+/jvuiWfxPNMMnK3xoD/yQGdZdHI03sln7ODvqD7LTuZZ/fjZAeZ/G0SlOWpuzxAyrMatZxoRDBBxO/nJxOe2j9qNL/SjpOiTrDUzoD53eSZ8jyIJAcVpDNsiksyF0i0i/JedklGSTZLJWNGsai7OIaPduTGY72sCRWMGADLkU5oLskbbJeSVzQ3P/4fEyt3l4LqCIzEuv5+st92LRBhyIcBs886+5/8/XbQwbksNItjM+6HOCIOBQsvSruQM6g6ec0vBBtkgWyoExWjkhwY5ViyHVeBGsVqRkTrTBGcuCMU2nxwpAKi4gSzqaphPOxhANIt7SrRQ3/PtpmWeeC4fFcgGL2wdRNR4mOftQMovs3MpfDz1JRhtoLRHvYsm6Jbnrn6IoSZ7zi3wkLc9xEQSBMaO/TGx0gnLzIfoOH+TGzpdZwUKC9YfwVl7EdWttjOr8PT0TxrO1ro7pBy00uxQ6LSsQy8YiJNawbeVh2vfm++OdKOnWCLHXO7HNLMVU5xr0NYqi8NRTT2GxO3jSV0WpycAtnTsZ73+QuObk5fA3OVzSx8raXczauZ+LDsmsHV3OHq0IXdMYp/Swo8HOl6+v5T+v76ajYQ8utZRQ5odEar6Dv3wqrY1Np3nm5wY1FiNFA/v/tBrBXODhmIp8qRonrjhQZQ13cTHReADJbCEt5JTovAQAkMIChqph6OF1jvHVRaOxGN5ZWykLCl+6bOho8ftB1SU+3fvoWw7aMbLJYUtZypPjeOmOAC5dJTiQRGH01lAgxOgaOBuuyxbjl0zYxQCxeBeW8eNRBiJj3phOQShC2JZ7n0QDKYxmIyZRIT6Q4pjM5LMz8owAIyxnH0xkMBUuf9NBO0ZKTXHPlnuG5Rp5zh/yTlqe96Sk5GpSthpqpoWRNTvXbGvDoiZYavkgffUbcbhnU9h6hF1FUWJJFxvnXs7Fz8F0T5hXPVupKp2FEnuWp36zhtQQPXXyvIWuDKg5Oo24rqoZ8nVr166lt7eX+PyF7Euk+W6JE+uyL2KTM7za/RkO+Sw8P6GZTy5bzeXbillfU4EiizSJSVZMq+Lfrihm3fgDmC0HuFqtpVL6KAfLvk+2vgZNkjCpSRbtW3v6Jn4OkYhlOOY6J7QYksuKSc+lhpbpcSJ6rn6wvLSQZCaCYpZICrmoQLHRDzoYZA+S3X4mzD+j3DilnB9/YCIOMQLoaGaJBcWbmV8wPGuDpsmUZPsHf3KYUpby5BAdRvS0ipZRB33eI0BYyDlahqJRAITI/Z2L4ka6ZAm72E+gqx3L1KlkmpsB8EZByvYQHmhEGO1PYnJ5EAUdLZaLtmmKA7R/7GOVJ88pMSBnrzkr0HSBqLl0WOXsQ4ksgiE06HNDqUvmuXDJO2l53hNBEGls/BKx+jiV9mYOtbfx8ZbH2CVMpr0ujat8DFdsL2VU1z28Nm8yBwwujMZRHNppYLRpPdsLgpRYfWSj21n6H8+i5+vTjkt0dTtKTwL3DfVDpjn29vayatUqSpom85e4yiKvk6oH7qbe2s3e3kvY4pxBNvs0P/rDsxhjlQRsZprMcXaNmcaX5svsq1qPZOxj0t4iPhFewIvFn2FTxQJ8Any8vY2l2zayck0312V8p3n25wYH2iNv9kgLq1ESZh2zZkTQBUpIERELACg2i+joxA1ZYroFSVDxWf0IKTPGigsvinaMG6eU87XS57jT2UxmfglVvn4irUeHZ3DNSKepcPDnhillKU8OyZ47mBhK4dEni8RkI7quv+mkpaSBPlQ9frpMAqKgEW9rxjp9GmgaWVmkIKKTko6gSJAwC0T7UziKK1A1kZQSBUDUvJDwj/wk81x4NN2K8KVdjFEe4jeTnhjWFOlgPAOKe9DnhlKXzHPhknfS8pwQ5WXXk7ZUUjYlhqhZmLkrTmm8nUcMd9BVv5KCkkuYuDOFKfYq4aJaNk+dztUboccqsL94JenSGszKIQK9YVb9bsWZns5ZS7YnTmRFK5aJPizjBpcO1zSNp59+GqPJxKqacQiCwKePvMrE7Cv0R31sDl3KzM3fo+5gMy3eAmqFAHKNia/NMrG68Vl0OY6WKuKD68eSqLyZBxpv48YOB8+uaeeF1Uk+t9uNt7+K3QTZks23UBiM/YkEEQ9omQRhNUm/lMSkihQodgxAWMpF0sRork4tJMaIqVasUhKjNYQc0jFWVJ7BGZx5KssvQtMiAMTNZjpbD53ymJqmo2gy/1H7adLiuw44hjFlKU8OyTnQK20IJ63IKJM2GAnGYggDDrJJiyB5vShd3UQduShbtrcdy5QpIIqoJiO+KIQtnRh1nZBVJBpIUVQ1irQmk9XSKHoai+ol8+6/cZ48w4QgCBQ6TPRF0+/94vdBMJHFHLsWs/TOGlyzZObuqXcP67XynPvknbQ8J4QgiIxu/DLJ+hi1zqPs7unhC80P0CWUs72qAr3Mw/juRjzBv/PKxEpaUw72N82l7iWBy5z9vFTwGlXl89Cjy9i5I8Ghl4anMeT5hK7pBJceRDRJuG8YNeTrNmzYQHt7O87Lr+KVcIK7PTJ1679LJiJzaH0V5r6n2FVcgGhRKecov5ot8ocJh8lISQiPR5Ii3BqcwaSGafy4u5Cla5N88ghkkwrr6GJ5IsKKgIm27hoM/nzkYTBqSuKUZfrQE36SBgN9YgSDBj4lV8twzEnLDgivZOQokYwDq5jBaI8g+rMYqi5sJ61x6hVo6SAAMZOZ/X2nHklLx7NkRDNPFF/JEw0XkTJYAAFclcOaspQnh2jPyYir0cFTVUvNuXYLR0MRcJYBUDDQ0Drb3Y3gc+ZeGPAj2e2YRo9G1gUKIjphsx9rOkvIJhH2p3AXFqEjYJAyJPQwJRkf3cm8BH+ekcNnN+Ifoln7yRJKZCgSZrNk9hJKbaUICJTaSlkye0leNCTPP5A/hspzwpSXX8/+Az+ncFqE5ldNVB6yM6lwE08W38zoxl/QELiUK9e1Ihh/x65Zn8axJcU1h8t4dFeQpjHbeTlVysLkLPYGnub5x67njjIXvvEXbsrXu4mt6SDTFqXg9tFvphG9m2AwyIoVK6hqHM1vsjLjbBLzHvkn5AOw9WglOyuMJI0ywQo/67xpDpSDloWqtkVcLm5krt5DXc9tZNRZCBjoJcGhZJrujEhStyMbevEIIZyySEI1YlcaB7XjQkc12qjIagM90mT8hjBZQaUwm9uUhkUboi4Q7/UjICCYEoTTTsyChsEcQgqBccKF7aSVVI0hmYki6ipxo4UOteuUx/SHE6QNuc/OIW8JrQ130zj9m6c8bp7BkRwD6Y5DbGTL7FaIxWiNxJhSWU4c20BD6xLobMVdWA+sR4qFAbBOm0Z6/368IsSNIRyxNCGrTKwrhc2TSyH2GZPEs1Gm6FMoNBadlnnmuTDx2U10hVPDOmYomcVtNbC4bnHeKcvznuQjaXlOmFxt2pdJ14Wp97Syq7eXf219kKxuZGXJLPpKA5SKU7H076THEKbPUcWGi2dx07oshzMmgtWvsseXpsLiQ0luYelv15HsCZzpaZ0VZPsShF88inmcF8ukwetpdF3nmWeeQRAEDk6aQWc6yzde+T32F3t5rb+WDXVlJJ0yz83s4qmJcTqK4IaOapY26yxN7+Yj0Y9SGf0BcWUOzWmBlZEsqxNhuoQtuDO7cab9mHCCwYrBEsXnasdoGKY6ofOMGQUVSEIB+oCT1m+JEZMzFA4EFGJImI0mwv09WCQ7JmOaUNqFSQPBEEEKCxgv8EiaKIrE9SgONUFUtpE0Kqc8ZnsoSNKYi+5Y1TTegvwhw0gi2gwgghoZ3EmrstsA6Ijn0n6TsodSIUDCVYDS1U21bxxJ3YI5E0XX9Tfr0twxUIQ43liGsE1EU3QMplx02imnSWRimAUdiyPfxzHPyFHoMNEXG+50xwwea/59m+fEyEfS8rwvKsqvY/++/8Y1LY7wsgGto5FFtmd4bvxNXDT2v5kRWMjCjYdQPP/Jqun3IK/op7h+FlVrX8N9bYZXy1/kluwduI6uJ5au4NHvP86Hf3I7svPCU7k7hq7pBB89gGgU8dxUjyAIg75u69atNDc3M+6qxXyts597n/gtBWs3s6qmhrDZzMFaO2807GWskuKzHRauSXeg6VX0af9GUCsmqqkcSakcxI/BupESdxvGsgQGRxzJFKPAmESSMkiSgiiqCAIEeyuAT5/eG3IOIAT7QTSjZIJoFpGgNYUmgS+bRdchLoq4XS6iXXuxGF1YxV5iWTs2OXcqK4bBUHlhO2kAdkI4lSQRkwOb4eTUHZ/c2sHPlu+nM5TEZZGoknO1HrZsGrO7fjjNzfMuBFFAtA0tw1/tdgI9dA30P1MthZRl+ukwOTDH4zSY6gkJDmxqDEUJY5k6FcidHtsTWYqVNM0lAymRQu47wiwpJJUoelxFVzQEOX/WnGdk8NlNBOIZVE1HEgf/Xn5Pdjyaa/0RbgdXBTNjNyFY82nXeU6MvJOW530hCCJjx36dg/oXaPSZ2N+T4U7fJl5PXcbjzhspKFtNVWgOdXufpd/6HHumz6dga4IrN1bw5x0hrp/SxlPxl/mkcj37W5cREW/lyW/cx03/9Ukkq/VMT++MEHut/a00xyFOhiORCMuXL6eyuppVHd089oslhBSBtaMrUCSJl6dmGGPbyH1dWaZkI0SVS+hUfohJcBNXNfalMhy0bqGmfgUTxxxEH/jkK4oBNeVASTvoClfSmbZwVDMQUswkMzYMUoQPnsZ7ca6gHm0Bcj3SRLMJbaDtV1EmSSZrJiupFJWW0LtxDW5LCci597Zbz0mGy3EDclE+Vcsmh3Fm00RMblyG2Pv+/Se3dvDNx3eSzOYk4ENJlQg2xM44NksWg618uE3O8y4kh2FIdccymxV0nZ5MzgE3eMopiRxkg2SlHHDErLRLZkrFAOFQK76iJqTCQtS+Pnwx8GVDbK0rBiCdFBElmawoksxE0NFQoxlkzzA1Qc+T510UOkyomk4wkcFnN73/AXY8Cs/8a65HI0C4je/of2Bl3AdMHFZb85yf5J20PO+bsrJr2LXzP7FOjSG8JOPvn8kd6/6X313+ZfaMWUuFv4am5gYOhZaytfgKWgrq2Dwtxe2vP8v9jhJm1W/j8ZSP27NXs6XzEbpdH+PFr/6KRf/9RUTzhfWFm+2JE37xKJYJx09zXLZsGaqiMProDmb8/Xn2l/to8bhJ2LOkxh3mN8kQo+Jp2pVZHE5/HLNURlrT2ZRJcNi5gkljX2SMx0g6Wkb4wGKC4dEcipexVVVoF5NEcYD+TgdR1rJMkDtOx20451Aqawht+yIRNUjW5Hjz8SI1QTJrQ7Pp+LweWlIRPAU1ZKWck1Yk576sjeYSBDEfAbBKCs5Uli67G6f2/p20ny3f/6aDdgwNAflgFOuYLLLBPUyW5hkKyWFEHaL/pSwKWJUsfjV3OGHw1uBojdGp5d77gj9L0CjSmO3hSGcnvsImLBMnElu5koKIjmLpIGQdC0AskMZe4KUrEyab2cxr2aPc4bjk9EwyzwXJMcfMH0ufnJO24gdvOWgDWIUM89t/D+SVHPO8N3knLc/7RhAEJkz8Nvvlz9BQaGF/t8Kl7lZWdR/gyeIPUFXzF6bFFnDJhk7Mhp/wxqQlmF8L4mqcz5R9y+l3O9FHreblrIfLlcvZ1P8wh+138uoX/4P5//UNpIE6hvMdXdEIPLIf0SzjvnHoNMedO3fSsWMTt25fQ6wtzvrRFYQMZhLl/dxRcIj6aIZdhklsET9KkTIaXdBZn0ywx/0cY8o2U5Kcjf/gt+jW3WzQNXagkh24lCBnMBr7adQOUhmJYA+kcCoxfAX9+Mqj+HyFwOdO3005R4jqOnrbDuIVRcRly5uPl6gx4nquzbVJ0AGdtFkgKeYOH0o9cQAsrrxgDoBZlnElFSK4MJIhm0pheB8HNZ2h5KCPCykVWREQ8xLtI45oN5Ltig/5vEtXCA70nDYUNwAQIlfno3b3ErGKGJJpwh0tMAlsc+YQW7kSXxTa3B2okk7KONArzeulu91Pg7mLwz0yaiyL7D6JzXOePCeAb0DAyx/NwMm0MAu3D/qwPZVvWp3nxMh/g+U5KcrKrmT75grMF8URnpM4HL6UD6/8Dd+94+e8VjuB4o4ooyLT2NW9ijL3JrZeNAXPhhiX7prAQz2HuKEgw8ujluNTbmOyMoWNyafYY7oe6d++x5yffgfZ4znTUxxxIitbyXbG8d45bkg1x3A4zNF7f8T1r+2gTzazYXw1iqgxufIgl9u62e4p543srZR2X4qui+xKp1nnfJHRls04knexMbWYdYJKOxqQxSIEkJz7kBxHGCO0MbdbQz7oRFSt+BwWqkt0yq1g04sgVUWyK3h6b8o5ghiJIKsqMXRiRgWTKpKWNEq0GH3kUuzEdC4FLCalSBxz0nxhUMFcWHfGbD+bMJhkbHEFRTCQlq0kIiFc5hPfDZW5LXQM4qiJZkAxDKOleYbiWCRN13SEQep23OiEBjTKTCU5Jy0jxMFgINvZhV5sgX5IdBwBwHH5ZXT98Id4IzrbzT2YlQxBm0ikP4m9wId69Agl1ij7IkWk9Dh28k5anpGh0JF7b/XFTlLh0VUB4bZ/eDhlLcUyyMvz5Hk3eSctz0khCAKj679FS9dnGVXs4EBXliljk1y3aTVPXnQ5E8bdy8LEfGbvO0LK+yc2FPyGXbUT8GpxPrSuk3ssLr4y5ih/q30Gj3YHTb0lbNVeYad0FfqXv8HsJd/GWHX+RhvSrRGir7RhnVaMZfzgTavVUA/dn7mOUdsiHKlwsdNbiMmY4ra6PfTWGXhDXkDRnk9gUZy0ZVRetLxBmf1ZEslP8T/qZbSKGpKexU2WGuEVgtWbwRTixj4PMw82YcpOx20sxlPmxSC+LXqZhGN6VprhwMjfjHMQeyKBH4iLELVk8SgyAUHHLSU4LLoB0CK59L2QGCOuWQEdn7sXMQqmquozZvvZhN3sxZoYcGbNdmJ9fbiKTtxJ++qi0e+oSQMQBB1HvYKayH+9nQ5EhwE0HS2pINn+0TH2SgJtA0Wwgju3ptuVIIaSErKdnTiaiuHQbgj2A2AoLUWQJLwRjZipH1sqPdArLUllgw8yWersAVpsAsYLLD0+z+nFN+Ck+YeouXxPFnzvnTVpQEI30j39a+SP6fKcCPlvsTwnzahxV7FrVzXmmWHkp9zsisxn8e7/Zc2kyTzlu5pC31omxhfQvf1RTPIveGXM17EHxmCbkGXxzmf5XWYMn56ynweyj/NJ7U4m9bawlQ3sMn2Q7A++y5zP3o11QO3rfEJLKwQe2Y/kMuG+bvClWtnyLG1f+jKZPomtkyrpw0SlO0D9Je3s9xbh2/lJqgOTiKo6z9BGvPBeQskr+HPs62gCNAKNWhqn9L8creukPjWa6/2LGR0dh00oACuoZMgIbWTTmwgmQvRJLnpNdeiam1TagqpDS3E1Pz29t+ecwDRmDO4//I7Ab/6TsC2FVRERBCuioBMWcumOmWCu91NMiBNVvdikFEbZj94nYKjOKzsC+MqaMB7OObNxi5VwSzPl40+8oP7GKbmo5TF1R7uWQh9loagsTHbPSaqx5XlfvL1X2mBOWqFBJiHIJFMpLI5SNF3AJwQQS0rJdnZSVDIOWIk5+VZNouj24Iv4SRijFKQyBG12IodT2C/2gqrQbxSpM/dh1JLAhSk4lWfkcZhkTLJ48jL8TQMqjgPqjglLCd8I38QXJ94yfEbmOa/JO2l5TokK88cJ2b9PVUWc5rZ9SBOdfOqxZ/nxHR9l8wQbtWEHYzuaONy3nnHuNWybNAfnxjDzwvPwplbw5JZGbp58gPuUv/N5/SNM6d3LJvMW9vMRMvf/kpl7r6TgQx8Zsl7rXCT0TDNqIEXhp5sQze/6CCpp4vd/ifbfv0xEM7JxWinJjJG6cV045oTItC+gatWdyLrMrkySV7wPU6SFuDf8ecyYuV6X6dWyaOJ9OMoE5iQuZe6RSZg1C1ktQ2+qhb7YWpyHtpGNRTlYNpauirnIwnQExUBajxNwZ9jWmCHuSOOhDbjijNynsxnRZCLptKNIEiFbEqMg4FNym8WoaMEkycT8fsySDcQw4bQTq5gBwY8Y4YLvkQY5ZcYf759JT1zFuKqbnRV1zO7b/77HuXFK+ZvO2n/e/V3+Ur4AO1GSijbcJucZhGOp2mo0g6H4H+uJi01GNA3awxEaiouICE7KhX4y3tFI2zZjcy0koxuxZZPouo4gCBhra/Ht8ZORkozJCgRsIrqiY7Dmsg52aD7mKx0gSqd1rnkuHJY1L+OeLfdgrO/iiT4vk5q/enLNp5tufdNZe3jNEZ5+dg/fz/dJy3OC5J20PKdE08IPseyxR7DOakVur2NT8FIu9j/GVP9MXvQupKbmIa7NXE7/nnY22B6ixzmWLRMnUZgNc83eJn4/Zy9b99Zx9Zh9/FZ7iC/yEWb697PGuhkh9TGS+//Oxd/eTPm3foRkP/d7qSV2+kls6sFxWSWm2lzERdMUotGdBNufJvLww8hP6PT7rGwrK0ED6q5pw+G24VnzI4pTFQQUjWeN2/CU/JX9oQ+xUR/DZzUjflXlsLSai90ZLkl9mOJuLylSdEYP0BHbh6l9B5WBBPHay1gzYSEHS3y0FTnp89iI2G0kTRY06W2pl1qKwnB+iRiKcF8PACFrChsytZncF29MN+K02Yh2dWGVnBjEIOG0CysqGiGMYQFDRcWZNP2M85Z0vgYIiCmVN5onUCTvY94pjKvrRhJGE3aiaKo+XObmOQ6iIxc906KDKzyW28yQTNEaidFQXETK4KVM9RN1zcHe24vJUEJEtGPTomQy/ZhMPmxTJ+PYtBFBU6nPCLxoz9W0iUKuZ9q+bBkfkFpJp4KYLO7TMs88Fw7LmpexZN0SUmoKBEjRz5J1SwBOzlEbIJTIIAjgtOTrZfOcGPkdWJ5TwmCWMR65FHnW/1BclSFzdDfRqWV85k9P8qWvf5bldbMp7TjEZO+V9O1+HLPxf3hx7NdY0zgdp5Lk42t7+fX8GMVt5Sys3c0veIgv82EuDx7heftr0HsLqypfZtIXr6b+s7/COnXKmZ7ySaMEUwQfO4hcYUOanaWt7c8EgmsJBt9ATcVx/V3CtkaitdHGbmsxRnuWmgU9GNo+QN2e+YhIbM7EWFf8J8pS8HLwu9yh2xGy8Jyhi2stPXxcvRxD1EC72Mza7rV0pg6gIXCorok98z5DV2EJMZsT7W0n0JKq4kjFKfN3UhALIWQPERF3EpJbKcqUQr5T2qD0tLaiAwmTiqrpFCZy9zQmGHAXeIju24Xd4MIiKoQzDipEUOQEVs1+wbWaeDeDSeermsTyTO1Jj6lpOppiICmbcRDDJOWjLKeDY+mOQzW0rrDbwJ+iLZpLZ9SsRZSlj7DH7MSuaRjCRoKyCafYT2f3AWqrfZiqqxGBghg4jL2EvO7cNdSc3EJrupp/rg7wfVE6KdG9PHmOxz1b7sk5aG8jpaa4Z8s9p+akJbM4zYaTb4yd54Ij76TlOWWm3XgzGzZtwjN3O71tjWzon88C+8Nct207D0+dw4am/dRvrmJ8oomezvUscjzEM9V3srLmIq5RVK7btZwHxpj4l74irqzdwU9Fla/wYT4QCfCoezmj2hbxRlkJ4ac+Rt3yGyj5wtfOuahaJh3i6LMPEW7YRKpqH+mNOQlei6mc4lYD8v8KZLsl9k9zclgpxFaSwF5fTtmWL1AqePCrGk+ZNlNV8H9I4Tuo1WYyOyvyhJ5ijrGHH1FLSi3mqGENff7dPFM4hkNXXkxv4Q3EDG/dK0HXKEiHaAi2UdnfizOYwKDpaCjEDHGyooJZNWFRxiHShDXRe6Zu2VmPv7MdxSiBAGlJozCbiySEJSMVXi99sQBeVxk2WSASc1DoTIKgYzQMLhRzITGUdH7iFDTPgtE0imhCFwTsehRfoeO9fynPKSOYJJBF1NjgTlq1ywH005XIbXoNngq8oU28KJioBaQAJEwiZek+trXspbZ6NnJxzvXyRqHPfYiwdTQA6aSEIIh4khWsCt9GSb6VRZ4RoDs+uET+UI+fKMFEFo81H0XLc+LknbQ8p0zR+FqUexdiXLwNT51K4vAOei6u46bHXmDH2AJedF9BafEybs0uwH+0nZ22jcyzVLO6eh6rUxO44ohKQ/A5fq9U86+yzvU1u/mx4X7+rfkjfDwxlfsKl1LbdyM7rN8kOuoP9H7nOWov/w6ua68/axsC67pKNLqb/v7V9AdWEw5thXINSbBR4J5DQcHn8B49iv7wr2lfbSelGdg0v5BAyImlWsVluoGZrU0gSGxIR3mt+F4uz3ZD8PtconnZklFoN8X4rOAkKhbzN+dWnvZW0Vsyn5jtOjhWw6fpiNEMtv4IY3uOUpfqxUUaAdA5lg4mICLjSJuxJmL4Av2YkxkkRUTIp84PScTfR8b81vuvMJMiqxpIyUZsJiOqmgWzCcFgRtMlSpy5L2eTtfRMmXzWMJR0vl0cut/We9ERSpKScm9YBxFKR40/6bHynDiCICA5DEOmO1Y5codE3amcE2fw1WBqUejVFAC0ngiqXcQcixPqaM29pnTASYvo9Bh3IHMVUXOuV5rF6KBASNAZShFNZXGY85vePMNLia2ErnjXoI+fCqFEBne+Hi3P+yDvpOU5ZQRBoKLWQufRGZRcso7gkXGs656Fr+Jhrlneyu9uqOLlsZOo6D/EzMLrCe/7G5JhDWOkCnaNbsCRTTCveQE9nuX8umciXxAkPlSxn58Z/pePH/oAn01ey2O+JxHCV9D8+reITlpKOPJlvN/8LbU3LME2a/ZZISySSnURCKyhP7CaQGAdihICwGYYS8GRxfh88ym/ZiHi7ifgwX8nuD1G9xYXca/ExrGlJMIm5IoSpiiXUilW069pPG7aTL33f/hA7ApqMnfTkdHZLSrMNEskRRP/W9bH3+rKiFoGKnl0HXsiQ2F/nJL2PjwJP04xhktMIgig6zn/TUcnKUQxRTsY1aZRFHQTdlTR426g1WFFc6XR9RhxTea2M3dLz2pSkRDZAhFJB1WAYiVOUrWDBAY9l8qXMQtkDLnUxjJv7j1qdudP/weTzkfUudS2AU7yHdcViZE25jZANi1OYdWJq0TmOTVyvdIGj6TZDTIGVaFv4G9tLG4EIKrl0h+zXZ0YC63QDaI/J8N/LJLmi8COwnbcukrIJhLxp7BKDiQhycdm15BWNPLx0jzDzd1T736rJm0Ak2Tm7ql3n9K4wUSGQnu+r1+eEyfvpOUZFib+002El9jJVGzGOTpD5b7tHJ4xlpl/f4WWyTpLa67itYmtNGw1MCkxh+jRV5jhfIKE/DE2jJ2IS4lz675LuW/SSn7VOYN/ytr459JD3Gf4C0cPXcXt8VvZaVvBGt2HsO12Ir5ppObeS6Dlo7hfrqZ67ldwzV+EcBrrULLZIMHgBoLB1wkE15JINANgNBZR6LucgoJLcIrTCP2hFYM9gq9mA8IvvoQWC9Kx1U3skJve8Qa22ctQYgaKSyczQ5iDSbayO5Xm2aK/8HF9PcXB7xJXq2hWNMqMAiXIPFop8Kf6AsJGH6KqUtrTxsSWbsb22jBokDWGSZv8YFBBh1zoTCQpQUAGhVKC7gq6G+2E5knELUYU+R+Xg7qWg6ftfp5LJJMJtFSKlMOIU9MJSgJFSpS4lhM2ELO5DWtczpCSck5akSW3AbUU1p8Zo88i3i6d3xFKYDAAow3M6Nt9UuM9ubWDf396N2GpFOOqbo7UVmCdcWGLs5xORLsRNTB4CiuAU1Xo13KRe1PZGACkbBDJ5yPb2Yk0phTYjzWWyD1nt4HZii+SJGSOUylByC7R3xvHKdjIqiGWXJ+PlOYZGY7Vnd2z5R664t1oGRefnnr3ydej7XgUVvyAp8PthMJFsONHb8nz58lzHPJOWp5hweywkEp109Mxl6qZLxM5MIHNbTOoqnuUSStTHP7QFl4puISSopf4J/ViejuOsv/wIW6w/B+PSP/CynEXY1GzfHxHinunvM69vbO5LeXg86O28IC8lG919vHd7huo1/zcX7Gc0s5LObT8R5SPfZHs7KfpT38By+9sFLmvpHTep7FWjx7W+em6TjLZQjiynXB4C6HQRuLxXKNnUbTgcV9EedntFBTMxWZrRBAE9KxK8Dd/xaP+HXNkHeoaaFN8xNeWInUJNM+zsC9ahqCaaSyezWTjdOIaPK12kCz/Bd+OeVHSv6UjKyObBUaJEqsKJX452kybFXx9/Vy7fQWF7X28UXAZXWYrFlsXpVL0zYhZUjJw0FtO2Oalx+nB736rPs2ajOEO91PWFcScTGJKJrFm4qDrRGUH/YKbsMUzrPfxfOHowYMI6MRsWRyqQlAyUKxG6SPnGGjx3GYzKiVIiLmT0wLaALCVjz0zRp9lHJPO/+P3Z7Om6t9YUVaMMZBCVbJI8omnsL2lFKlyTCly+f75zNurc+vFI2d/nreQHAYyRyNDPu9GI6jnIslSQa6Ru0Ptx1BWitLZBZ5a4FUcqQyariEKInJhEYXhNmIWnSt7e9htKyLVmqJIctKVaHlTrj9PnpFgcd1iFtctZmNLgFv+8Dpj5p/kYrLj0TcbWotAgdKT+xnyjlqe9yTvpOUZNiYursf2ahHBok24mmLUbd/OjhmTuPyhlczdNI+WOTW8NH4KVYF9LCy+mVjHvbSaYtyu3s8DJZ9k2YTZSJrKx3Yp3D9hHQ/6L6Fz03V8/OJnWG16mU+4evnS4YV8Lno1W4tfY3OiCGHnYuT2BYyduJrUqCdoMT9Jy4EnMb9mx2Eai6f2cjyjL8Vqq0YU3zvNQNMUMpleksk2Eolm4onDRKN7iMX2oii5TYgk2XC5plJctBiPZyZOZxOi+LY881QEffvDZJ7/DSklRrfZTRFO9GCKxCoJsrDpimJ6++wY7SXMcy7Ga/LRklZ53LGS6633MTH0UTabrkZxCDRFdY6YRT432shGZwTXwS4+seEJ3JkwB+wT6PJOYIa9GbOkoQFJ2ci+kiqO+CrxO5xoooAxk6Wsp5UxB16npLcDQzhFVhGxqElsQpKgp5SAt5SwuwLdIFOntnFdYjtqUARuHJH3y7mMw5z7e/cZI1gUEbtkwS51c1jLtVVIh8JIgkyCBAlykTSbcpRUCsxVjWfM7rMRyWTEHldQBQMpo5lEOIzD6zvh33+3UuT14hq+Jj9K2XP9sLYCFnwvvxkaYUS7ES2RRVc1BOkf64QLRDgoDmw3zC6SupFiAlBcSvbgAQzuxSjI2JU0R8NHqHWPwlhZTuGhDrKyzpSdm1lTfy2CDgapACWTJp2IY7adWwJSec49fAPpif6TbWi94geQfSvKvMxm5R6Pm+4tP6DkwL3cfSoRujznPXknLc+wUXX1ZRxY9jRbI/OYN/VpQrscrG2eSl3TIcr2qFxX/SJ/rbiVFyd3U7+pn1mFN5JoeZB2k8DN6UdYWnM7z0ycyw07dT6yX+Bvo19jZXAGHS//M5+57D5qTdv4k7mFRwKX8x9tV9IkJni2fC2hvnHsXL0QS9lCZs1PoIQeJixtp8+1kb7IRtj4U9BBVmwYZDcGsxfJbEeUjehaFk3LoCgRMtkg2Ww/uv7Whk8UzdjtYyguWozDMQGnazI2cx1aKILi96Ps6CXS+zTZ7h6UI3tI9Gwj4FVweJKMop0yWcUiJNjbXYp7RZJ0ocjaxnoyfRplhZOYaVuIpgusTkbZUvZHvpzeyXOWe1jtLufDrVkyos7PG0WeKthE0/4ubt+fpTR+gJjJybaxC6gUopj1MFlB4khBCTvLR9Hl8qGLAu5IlOnbX6eudQ9l3a34jQ7aTTVoiopPiIPLgWIvQQbmxppp7FlDeaAbjyOKJOVSk4LhojP0bjq7Ka6t57af/pwHXv4g9WkDBYoLSc4Qz1gwyzJxvx+r7CSoJohrBUiCikHpIBMTkQoKzrT5ZxWC3YNtQFQiZnERDwXfl5P2dqXI68U1/MRwL1ZhoD4q3JY/tT4NSA4j6KDFs0jOfzwMKzJIbBUkMpkMRqORqOCmTOgn6Z6A2LUKp7mcuGjFpkXZ2/1GzkmrKKdgi55L1d61gtCk6wAQDbnPT6zfn3fS8ow4voFm7SftpIXb3/zfZTYrS3wFpAYEz7riXcPSfy3P+UveScszbAiCgMnRwriDk+gyb6Xwom7Grt/G1pkTueHBlfTuvoqFBS+z3L2QxytW8/nWeppSl6A2v0q/s5YbDzzHE43X8GTTPK7bJXLnQZm/NqzjgJzgey9+nY9f/Fe+UnSUl8xPcpt7H/P7LuffuueTtvfyonErod4GVj5kRyy4k0sW/4T6USKBjY8Tbl1PInyAjBpAsydIWTvRJcAkI4oyIkZE3YxFseJQvBjSNgwJG8awBSkioccTaLFDpCJbiId+hRoOg6blJm2F8HgXhiqdGlcXpY4wo4B91lqWyfPwCxqTXj+EZ0eKrjFOdjhKMcTNzCy7gWpTJd1ZjeelAxRW/p5iz7Xc5fk2X9uX4equLKu8Kr8ufQBb6CAfWz8TMdGLUQvir5uAwWymQQ8RMVrYXVzJ7rJaEiYLtmSa6Ts3MfbAekr83Uhagk0lFXQ7JlJPLxNtSf4/e3cdZkd5Nn78O3Lc95yz7pLNbtxdIJDgwaVYnSqUtlQp1be/vqUtpa7UkJYixT1AiCck2chmk3X3Pe5nZn5/nGAvCVZI0jKf68p1JWfOTJ45Z3b2ued5nvsOOu1ktVFW9+0Am0JV3gBaiULcItFnsNAiF5GWRBRJIzlaxNnH86I6QckGA2m3TMagkUxLeDNWAGKaEYfdTrinA6vkQMkOE82U4ZBTZNQAsmLWp2j9H56SGZgO5LI6Ri02Iv29FNbUveX9X50p8kvy3a8EaC/JJHJPs/Ug7T0jHS5orUSOHKQVmoxkNYGhUJhyv4+k0Utxcoyw04crlcIYd5A0GHGIo/R0t8BkkAsLsCWzGLISrfYgSWMuG6To8MAIRCbG8ZVXHsvT1L0P2U0yJllk7CiJcd6UqzT3sAi41eN+OUB7ybtRf03330sP0nTvqjnXnAu/2M9v5bO5evJvGNlZSNOhuexZ1kNJR5BsXpxDc9t4ZtJcCie28WF1EcHhYcT9B8gsiHD+fjMPNpzEA9OXceZ+mavaLPytZh3xmgA/2/VBFnoOcMXsfzLX1sz9citnFMxncWgZn+ubh9kRZovhIBPhAp7/2yGekZP4a6azdM1lNDR6URMJUh0dpNvbyQwMkOkeIDsxgTIxgRqPoyYTaJk4aHFglKzRgGo0IlptiDYbclEhmkdi3J1EVbvJT7ZRmhoEBpiQnex2zqDDMpedvR4GEgpXuB9kwb1DSGMCe+ZW0q+KFBvrmOM9E1mQ2BXPcF/JOqylAn/x/4oruuAP25NERfifwkfZ4H6YuPUssqwhqz6E7HUQcZdjAoIWJ/tKKjlYUI4iSVT2DzBz7/3UdLfgjmdBHOPRRh8F4SksNruYlFeHXVuIxfokFtcG0u4BIvMlYlaJ/UIuwNA0ATJutLQbVAMCKpJTTxd/NP3RfgDCMtQmcx3TCEZcHg+RPeMUyOVItBJOO3EaVbJyDFNWH0X7v6rqFrG3aS8AUZOF4KEWWH7yW97/1Zkii4WxI7/pVU+zde8+8aWC1kfpyJZYzZBM0RXMBWmCLZ/i1C5eMNpxAXJAIGoVKUiMEB6eAMBQmLv35IWho1jAGxlGEVxkDbn7VWR89L0/Md37niAI+Oymdz6Stuqml9ekDclHTmz279Zf0/330oM03bvKVlVBOvIUVX0yze4ZlC1pZfpzNvbNrefCrc/RP34Olx58nFsnf4hHZ9dTueEgp+SfR3wgxNCOAL6F2zh3r8yjjUt4aNoSTjpo5sp2C3dXPk2y+jds6L+c3U9/lw9MuZ2PFbfQntzE48I2zvfMxqcu5rLR6SwRIG3ro01RiR8y8tDBJlLGIPY8qJs0idpZS8hbYcfrNB55VEPT0BJBgiOHGBs6RGRwL8aR/RSOPY0nE6QsABHRSpNhEg+aVrI9PZ0t0VJiUQmrOcFHyh/mys5NuH4nkTIb2LegiLGkjbn+M6i21jGWVbnLEWX9/HG6PecxOaRx29Yk1TGNHUT4UeX3iRhSCLZrmNeaYOrQ82SLK8kKAgGLg90Vk2jLL0VUVaYcamFu01P4AhOUTkSQtHHuXWSkKFHMDSERvyuEnNdM0vd3Qt4Mo7bcj7ycMWIPC5SOCpgTGooISYtG1BEi7gigHL4zeDP6L4+jeamOTtCg4I/mPrCIZCbP6WQ4FsLicWCWsoTSDrxWiaw5jUPRC1n/X/W1i5DSWwGIGS20DzQz723s/1KmyBvv2sKA5qP0SIGaS8/0+F6SDk8JUyNHDtLKnXaYSNETyaXdN3lK8QWep0cRmQwIo0nStiyWQBg5kEbTtFdqpUU0eouszDq4j5B1GWFVAEEgMj5+TM5Np/PZje98JO3wCH78sW9SmFUYNLy+2/3v1l/T/ffSgzTdu658usbS/gJunHQl307fiM8eZkf7XNafNZ2pG/pptpZwje92bvFfwz+nhShrGmJZ4aU81X8bg9vNlM3fwPlNAs/Wz+OZxnmELA7O7TSzpWATXRW/JTlyKr/Z+3EqWwf48LQ/8+n8MbpT29kQfZHf5fm5pXQ+DmEWs6PVNEYEvLEQzqgB87iVjhdG2PtCH1lLL0ZTH27jKAXGCfzyGBYi2JQIedlxrGoSFwKCbGPI4GOPqZY7XZdyQKqi3VDMqDEPxSAiZBSkQBopneBC/yZOK3oA/z8ymJslAmUOmsstONRprC49DVky8cc8kbsnaYy7ivGknXxtf5xz+iGpatzq2MXj5X8gY6zDIl/GGbtexGA0k3V4iBpEttXMoLWgAklRmLt3B3N3PYMjnqV+YBBXIsjfV4BUJPHbaDuyr53BQjND+SYSFglB1XCGNYq74ygJlZhRIuyQCRRICJbc9AtN1RDiGQxjCpaYgiOeZVSvE3tU/dF+REARNXyHlzGGJCslUi7wF00WHAaJcMpBvUdEs4FJ038Z/18WsxM1HkHQVCIGG63xkbd9jHNnldDy5x3c2ngV3+35OWb1VYWVDZbc02zde0a0vzLd8UgqXU5gnL54ru6U7KuGDhjN5Ka5ZodGUTw26JugICbSH+3HX3i4VlpIYFehwGkvttE6aQUT8Sw2t4foxFFGTXW6d5nPbmIwlHzzNx7N9Iu5N76AjnV/w13+AKlX1V8zvwv113T/vfQgTfeuq/nw5Yx85SkaJrrZHF7JvGXPMfvxF+kqL2O6+hSWWBGG/TbOWPowjxacxZ/LX+SGbgfLiy7j2YG/0ryzlMbpm1jdrFAQn8MzVZMZcXhYdcBAY6iPR0ufxOpopmvgUm7acSNV5l4+WHsXlxcPcL4yyJ7EQ+xOPMouzcYG3xQyJZPIGqtRZS9uxYwrrWLI5mHIzkRTQdUgI0BSzpKSVFIGkZRBIi3LaP9n/jiqhjiRQhpJYBxJIiRVlrnbuGDe3fi6h3H90IiYlIjMltlhrGCudTUu92T+Vizxz3ITIatEebyXD7a2sLazHqsmciiT5fuVf2LYuQvZeBqrh6w4gvtANiDax9hYtoS9vnoETWP2/h0s3PEUprSRht4BKsdHeXyuwMb5Ah9VVQpsAs01bqKuXKBgDYMw4WBcdhBzRDGVxhBFhZcHEDUIZYx0xZxExwykWyeIZyE5G+RRgUZDJSuO7eXzrhEE4SLgW0ADMF/TtB3v5vEHo4N4VJFxUcWfzv3SjQlWZDUXsWXNAiajRiRsxyfl1kyZXRXvZhP+8x2uH3Sjq5cPb/0X91UupkfIvqNDaZqRe4rXUG06xJWtT2FX07kRND2743tONEoIJumoI2kVDhsAg4nclDFjUS7DaSY1jmizkenrQ1tcAvTiTQk0jzdzSnHuzlMUlNhgSFEUCrDNJpGeyODz+oiM/+cGae/1vUn373uk4xFu3XkrQ7EhTGIeinoasOwdHy8QS5MNz+IbC2fwy90/Zyg2RKGtUM/uqHtDepCme9dJVita+gCL21x8b9FVzB5uotQ/zPbuubxwziJOvucAuxZO5bLnW+g5uYz19TPID2/msxONLCy8AGXwbpqM1cyofZGZnSoNgWn8ckYR98w9iZWHXuTK1kIeKnsStfoWDONL6Rg/hZv2fRlHS5xTvM+zatIzLPCnyKppulJbaE1voTcsMpARiCgOEkI+SdGDIHkQBTuCaEXSjJizMo60gDGmISkKggoJg5WIaCeSdBIPWRHGMwhZDQSNlZ4uzmp8iDx7G/Z/mHBsM6C5NZpmezFrJzG5/GT+VmHlkWIjaVmgKtTCj/bdzdShC5Czk0lqcL8S5E+N/4ssyJw6djbOiJyLGpPj7Js5jc3556IJAlPb9rF4y2PIGRslQ2kW9O2lrUjkax8UmVSkcH0qi1ikELaKyGmB4WAt/enZFCot5OV1kGcZACA54SQ0WsCEUoimAfY4ZnuAqY4epNos1IIxpGHcKWJqEvG424/vxfTv2QecD/z2vTh4f6wfl6IyLkJ+OkZKM5MVZYRMriMaNyhkLEbUkIRXiQBg8Ve/F035z/Sq+kGCACWpET7W+ggPG9960pCXRJNZFNVAwmBmb0EZ9w0v56rP3fMeNFp3NJLDeNQ1aQ6DjEFRGDlcKsFSNhUAa3oUQ1kZmb4+yKsGtuBMp9k+3szqytVIeV4KgwlUMY2xsoKAXUDOCJgdPiKj/9HrDN/Te5Pu3/NIxyN8a9O3SB4e8Upq42juu3mobSpn1571jo45EUvjMMusrV3D2lo9HZfurdGDNN17Yuol81EfD9KYbOHxiTM4c8HtzHt4B/v7G+gubcUeTrHVXstnWh/kG3WFPDJrFt4NO/igMIu5RWuh5352SnXMqmhCHVS5ZZPCTTP8PDRjKVP7OljRIZMWgzxW+hh+9w7MY8sZDC7m/uEzuH/4dKymFGXuAeYU7mKuby+rpSASKlk1RTAbIKoIhDWNqGYggouw6CMqFDCuljKWqCAQzScVNiEE04iJXMfCZIxR6+tjldhFRd4hPEXNGHfLOP9uxRjNojaoPO0/A3XSqTxRnc9uj4ysaJSNdnLT4P+ydKKUYPbTCBjpyaj8zbKfFyf9mXmRBopD5WiqgBwYo7+4gKcWXU7UbKW+p41lGx/ClLCSSPg5t/lZVEnlD2tE9sw28EVbEKtdIGMUscZUjGMqHVo+Zs8os+V/ktFkRoLFSF2LGA76CWdkXCkoaTuAqGTorKxi3NnIkDKPBnkfhUonWn6C6DKN6EkKmayT/9SxH03TDgDvWTbFweggxUoaDEbys1HiggNEUBO5QtYxOUXKmKuR5snkpvBZC9/dIuv/0f5P/SAAs5phtfD2HwwMhpNMNrWyfcvFlKaGiYuWXBCoj6AdM6LDcNTpjgBONcO4mivtIXnKyWoiXm0MqaSEdFcXJudJpDFiV6K0j+USyRhKiikMdAIQra1G06KATFZz/kePpL3X9ybdv+fWnbe+HKC9RBAz3Lrr1nccpFUPPsJTwu/gW2P6CL/uLdODNN17wr3yJAx3/IlpvePc2XgaK3fvoqaym+1jc2ldPpnVt29j5+JlSLsbuLb413zf9iXunj+DvA17Odc8A6XwLOh8mCZqmVG2l7aRLH/YMo1flcg811hNl6+IhR37uKzNS5etm83Fj+H3ricvOJNoaC4DqXwODldzcLiaO7gAZAHBJCCYQDQJqJKIgoSWFSCrIqRUhKSCkDmcWh8VqzFIsX2Yqe5WZgVVLNl8xLxteIv3IUyImH7mwnswjuRKcddpZ9FbfzIbqooJGkX8UYUl+4eYm/wtnw+/QCj7LYLKdBIa7IpnuLvsAcyGMU7vX4OoCZgjQ4xlZNavOIPuvFL84QnOfPZevENp9pimc1Xr49QF+9hVY+T3Z6ic5zay1hska5SQAwaUkIWoL4xoA782gaJBb6iEPyrX0OqdQr46wGndm1ikWeiwQPOUBsSMkTm7n8cViNJZU0lL+TT2GWbjGg9Q3b2LrFNkWDO8rSQO7xcpJcVoYpQqJRfA+7NhwgYnAOlwGLNkI0aUuJTL+uhI5zJBmqz6mrSXHSXjooO3n0Ut0/QPzrE/gjGVCxJsakKvj3aMSQ4jmcHYUbd70Ahoh4MSSSaEkzJhlKRvEtqGDTjMpcQMFlzSKKGRSC55SEkJvu5c0D5kSCBlgoCPRMpIOhEnFY9jslrf+5PTva8cLdviSHz4nR1wz91cMvQjTNrhe5tev1H3FulBmu49IQgC7sJ+lvaU8lTtCOvE+ZzeeC/zHtvB+pbFCCtSVA2G2Znv5JQH8/nMxbfwY+tX+Mu8WlwbWzjJMgWKNOh8hL1aFdMr9vDssMoHB+o4r+8AX19YztON89hXMsHcLjuXtlYzZhhlfemzqN7NTIqVkBerQonVMK64GVNsxGJGMjEJFRENkNAQBQ1ZULCQwSHEcRHFrqSxKwLOtA1H1I7fZ8dRvxmP/yG0pET2n3mUbowQtQr85tLL2DplBV0+F5KqMWs4yeSDKTThKT4p/Yni9FRGM3cAVnoyCpszIVrKHqcx6UNKuKhJtzMwkuG5OavZXT8bUybDyTufZ8rug6x3z2HFxFa+1f5H4mb46VoR8+w0NzqTYEoihmRSETdaXgBBCJMcrSUVLkJy9+H0dlJoH+CT2W/THFnC3far+dua89m/bxMzhnqZI9bSKY+zfd4iisfGmbFlCzN27aFjSgUHG+vY1X8yYo8Rsla49HhfTUcnCMLTwJEin69rmvbAWzzGx4GPA5SXl7+l//elX+KiIuDM2rCIQwxqZRgkidjYOFbZyUQ2SkLIjaTZMrmAxGjUszu+7FX1g14tLhiwqAqieOR01UdSsfNmjML/GcXR66MdU5LdSDIcOOp2ryjQIhnQNA1BEIhLeZRpIwTc/lyttJiDhFnCkRjGGatnIDaAobgYeyyFoEGb1kHcPhmAVEClbsFisunUCRukvRv3psPHedv3J92/p9BW+HL23lfzmPLf2QGf+c4rAdpL9PuT7i3QgzTde6b241cT/smLzBzfz8PTV7H8wQHqGzayY2A2YoVE/tbtRL2r6HDV0LCtjY8s+i2/z/sUv5ufwbSlg8XmqRhLjAjdD7I/VcLUup1sGdWozhbw6PMObvH28MjcKh6esYSCUIApA+2c1ZOHIS3TY+ulzXOIkH8z3pSb6rQHV9qDLWvDmrViUA0ImoiGgIKGhoKKiCCYMWh2HKYs3pJN+Er3YLOFSMeNBB/Kx/uixt7amfz4uhXsr65HFUWqowpXNY9T1iowIfZR5/szl6QOMJ74KuPqTOKaxu5EnL32ZgTnBCUJP5NpQRgL8HjeIp6/4HSSJjNTeltZumUrTdIUNpsnc+Om3+OLhXh2Bmw8Ey70JXGacynzMwmVtAsy6SyDA/MYHKigxdKIppRT0yZQIbbjnvwk+aU78EmbmBrZyT3qFWyYfiod5aMk1t9NpcXELGEW+7wST5x1Bla5hZlP7efspnbaa2bSNL0ObCf2mjRN0055F47xO+B3AHPnztXeyj4ZJcM0exWZ0CHysi4kuZ2YYsJptxNu78EuORnMBolrh4M0rR8hY0QUX1/o933rVfWDXhIXTeyyFjE7EsHqcr/lQ1kTRykVoddHO2ZEpxEtpaCmFUTj6wPsfKPEi8gkk0ksFguKNZ/SSAtbbN5crbRxkYhVJT88gi+5mKaRJhYWFyMpCs6YRI9xgGRFJaH9YbxBOO0zX8RoNB7z83yr3o170+HjvO37k+7fc93s616zJg1AUw2sKvjgOzvg0e5D+v1J9yb0IE33njGWlyMG/srcQ3ae9WXYWepmtrmWRa3bubfjbCYuymPhs/20V5QwaY+XacWHuLjidu4uuILfzskgbe1mgX0SptKLkfvv52CygIZZO+gcnMWwLcDHojP49H0t3FhrY9eMEtY1zGVzbZKK0SGqxywsHvNhSdlQVYG4nCYhJcmIGSYEBRkwqDIWxYJJMWNSZUyOIRzFe8nzd+FyjSAIGqNjPpq3rWAsU8rOaVM5cE4tmiBSGM/yge4s83qGSI+ojGEkWPgkn1buwBQ/hcHs19A0Iy1Kgiaxi0jeICIqJlMni5Vu7o3OYdPSqxgoKKUgNM7azesIjvr4u20pnzl4Pye1bmfcYeJnHxWYOTnNh60aUkaDjEbULDEQAWuPkz7hMi7pWkR7/ACitoFonoeR/BJ2O2opGPwMc5q7KWh4CH/5dq7J/InliW382v4J/nHWJ1iyfR3ZrgepKVxJVrHQhsD6k+op6UyxePdj1LbvJj21+HhfRiekWk8t3ys4i68M/hxv1okkpYkqJpweD8HAOPnWUrKpPqJqKQZRwWAKImj6KNprvPQE+ZnvoIV6CQh5fH3Sp5iR2MSkwMTbCtKCRj+e9BFS9+v10Y4Z6XBBazWcRvRZXre9yGQkq2gMBEPUWCwYXKXkR7fQo8nUAQwnSDtU5OEMRUkbu0d3s6x4EQD+EAwVjNPgtBNwRHFF3PRs3UrtsneebU+nO5qXsi2+lN0x31JAV9sKyiYteWcHPMqsAf3+pHszepCme09VnlJOtNnM9OReHpi1ijl/EaiZ8QRl7f1YBmP0O6JYsxo76nxMfSzJsou3EvfYebj0XH6vHELd1sV8RwWryq5iw8A9dG3Ko2ThHgJDdTxo3M50byk/HfcTvnMXPy2x8PyCatqKSmgprkRWs5TGRvBHxsmLhnHFwZ1RsCkJTMYQRlMcmzWE1RbA4IwSN5kZw8/+9GJ6R2roo5R+XyHZkw0ImkZZIMGH2pKcNKbhGemhJR1nVKlk2Lub88x3MS2bYCxzC0mtgrAW5Xmhg2HbAKqg0mXvpStTjxBfygbfUnYvmo9JyXDS/u0UtCR41DqDxepe/vTcn3BHQ+ycI9B5YZwLnAqCqiEqGiMZP+2HihnMptjp7SdkzTI9+QemOe4gbimjWeni1LZpdNZZyAvvIGU28URdBZbQp1nybDtlU+5mSv5Ovhv8Pn/JXM0LC06lv7Sc05+6l5oiPyvV5bwodTJYJfLThrlU7elFMDmYcbwvondIEITzgJ8DfuARQRB2a5q25t06fjrUz6hBZE4yN1oWES3YLWbGsmlsshNRiRJJ23HKaVQXmA16kPY60y+G6Rfz17uuo6NzGvcXzKVmeC/hvi7yK996Jsx7PedxxfCfMPOq7IJ6fbRjSnLlgjQlnEI+QpBWarNAPE53KExNUSGSvwb6YTQVAkEg2zeAUu4HwhQmJZ4e2Y1h0gVALg1/W0mcaU6JfXaJMtlN8K9/g//QIO29vjfp/n1nVp/5crCmqhp1Nz7G+DssaJ1ecSPZBz6LVdDvT7q3Rw/SdO8p3/kX4Hr2TqZ0j7Bz8mwO1gQoHb2IZerz/GH8CtYs2UzZQwcYqm1E9ZYhbfZyzsr7SVosPF2xht+JbWTWH2JB3iROKbmKF0cf5dALcUyzO7FG8tljFDiYHWBp4WS+rRSRfrCN3YkB/thQzqGGUkZcDnrsBajCK9NvBE3FSBqZDFlkMhhfsx0T2Fxx6vr7aBjuZWbayeqwCVtGoTd2kEOZGAeZSsAeY47rF3xK2Uow9VGGlFWoKGwR22gxdKNqEh2OLnbbjEQj5zAj087ehVOIWR00DHQyd18X6zI1DFgCfPPAn5nVup+4He79rMq0SVkWihqCCsRKaTt0If+cqOUQGiZUasJjrLX083j+v/hCaYrZyYN8ZCTLUJ1Mc9ZPNJ3g6kkPUzgwnYlkAetLipGGvsTKzp2UT/0717m/zcOj13BP0Sr+dumnWPvInUQS/2RB8XkMZ1OQhHCjnz0lwWN+zbxbNE27H7j/vTq+Euxnwqjii+YK+YYlK05ys5FMBjtGIU047cAlp1GdGiZr0XvVlP94JSVTGTiYm/YYNdsYbd1L7dKT3/L+OxIljDuu5PL0Q5SkRsBVirDqm/p6j2NIcuam8irhI3dky512GI3TE8llPzUWTYbdoEYHkAsKcmn4Z5QD7ThSGQ4FDpH1u3P7BsxAHI9xhAm7iIQRedsushMTyHl57/3Jvcve63uT7t0ligJ5NiNj0bef1AhgtHot/5tp4v8578eWHNKzO+reMj1I072nRJsNm/0Q8/vrebaul8cXreDLf21GbjAztbeFrqZ8RpdamdOZZnt+muW7h9mddyaXz/kLkqLyRNnp/H5lJ9lndjHLO5NF+edRHHuR7TueZ6I0QqU3RV+qkGfMB7ClD7DIU8t833Lmh7Ioj7QyFurhkJZkR76LrkIfUYeDhNWcSxqiqTjjUTzRMGXjQ/hSCv6sGbehlAJbOfnGXKc6kBqmPXaAblUGaRYRyxCTXXfxCfUR4qmz6FP+ioCRg2I/OwwdZLMmJgSVF8qexhudy9wRB/tqYUvxKfgiQVZve4Hu8Xw2Ggs5N/A8Z2x/DmsszoEVWSbOgUUWlWRW4snuZTzVdTLlaSP2wH4uM/Vht5bwBEaezeTTms1nUV4j1Qd+QnOjyLXlKqfENnHN2G7s0yI4U2lWxiLs2Oclr3I6IWcvDxV48bZ/mzXGRzhr0u+pz2zkVr7CXedew2lb7ye65y5m1M7gzNR8nqOFNcna43wFnbgSsX5UE3iVXMHzqGAl73Aha8UkYRcglHLiJzeSZnHri/6Pprx0Nk2pZwCIGq20t+9l0dvY3zs6wKN1y7izfDU/nPgBay5+7j1pp+7oJOdLI2lHDtIqXQ5ghP54Lhi3lOdqpVmSQxhLS0n39SJ6JqHxLPZsHFFTOJDuwelwUB4wAXEyyR4mHFUAHJw0i/psVu/E6I4J778RpAViaR5Ul3LW2dexeoqe4Vf31un3N917rvyDlxH+WzszR5t5uHANbYUP4uy+jGX23/Hb7Ie4iMdJRiJgmcRQwwwad+5hh2kVH5j+Z4zJNA+VrOUXZ1j4xL+eocp/MnW2ORSaq9g88iTto2NUz9jJ6MBiIuYsT9vaMKaaqVDtzHTVUJjfSCGwHFCDIbShEFo6AJqKJggoJgeaqQCTdQ6iLdfZzqppxlMD7B7fQU92mDQNyMaFxBwdzHbcw0nawwwpZ9GT/QtG7AyK42wV24imbYjxajZV3oc5Osa56wvYMmcSjy9diFHJsuzQblydKZpUB3PEds7d+STFHcOkvVmeuRYmlapYNUhkjMSyVoqj5SxMWtiWjTHumcdGwEKakzSRrwpGmtB4tEtDMH6ZyV39ZJx7eNa/kefLFT44pHJRX5rAcyH8mTj95YM4QjXMVmaSFcf4S/FqZu9ZyJLyP/L/8j7FDzPf5uHFFzLhqkd74W6KPIOc4z8HISsez0vnhBZLDoMJ/IcL9EaxIaQPFz81ahhMGuG0g0laAM0IJlvJ8WzuCa28uBEh8yCCphIxWOmJvr2ENbZkgqTFhIMwQlpPznI8CCYJwSiihI7ckS215bIwDqVyQZy5oIa0JpGnjiGWlJPcshmzfRFxyYJDHKNMcbF7ZDeriospCoVy+wYPEbLXAJBYfiYZs5nXT6zU6d59foeJsXc43XEiltsvz3biJrrRnZj0IE33nrPMmoXlh/9kWpuXdQUxNiyby8fv202vdTWzY7t5sGMlM9e0MePZMfa6RE5x1VLTFeeAYQWXTPkbjuQEd3mv5ieXnMyn7n+EwcwpzLK5WFl0KZWxA+x78XlSBXtYYknQNHYqMUuIVkeaVnUfpugW8lIiRaIDr+TAZrVjtFlAEACBtJIgrgSJhiJEMgGC6VHGSGOU6pEN08haZ2C1tbLUcBuq1EtUXUN79q/YsBASQuznAIdSFvzx6Uy49nOo+C+saXKzteYUbrvsJJImC42DXUxr66I1ZiFPDvDV8Reo29GOmoTm81S0kzQaZI3xbgvqXhtGh0JV9mSmxhsQBm9nnqMa/I2sk2IkM+U8Kyg8iopTS7FSMBNFZGu2DGm8hE+Hxzng38nv3S4esdn4ijdAZMJHp/tj7Gycj2SBZS37Wdi3E00z8k/10yyd2Mg3q7/En7Kf4PkpKxlylbH2qd8RaL8Dq+JkEucc70vohJTMBAA7/kyuNlQMC0oijiQaiEhxJKtGZMyOR+kAwGR8h+mb3wfMZgspJYxNTRKV7MS07Ns7gCoQN5spE/pRUob3ppG6NyQIApLThBI5ckfWLksYFYWRdO6hhiBKBFQXZcIICe9clOFh7EIhCZMBZ2KI6Uxl9+hu1hQU4tozCsCeod0Y/OcBYfLLGnE6ncfq9HTvcz67ic6xo9cBfCOBeO5nwqMHabq3SQ/SdO85QRDwLy9naq+H2dHdbLYvoM/8I6ToVSywbmWPNhXnjgg7qjxMGVc5UCIxeWcbg64GDklZzpj8CLbUCH+xXM//XnYRVz79KBOBahps5dRZ6yi3TqIt0sSBAy9iLX+MNeYABybOpcPoJGmTGXRqDGoaYmoUMdmNmIwhZDMIigqaEQkHsuAHQyWCYy6iKYxsCuCXtqHJI8S1MnqUs5iULsKDgRExwgZzL01hKzWxKlxEaLH/iaKRJIXCDH69dg1BVx6lEyMs2LsNJWjBZlC5zv4Pal/oJd1rIFKrsvdDUOFRCSZMtGyvJdCrQEzB0i/TSTOmzB48iTTuwH7S/fv4oLmQGvMQvd4mnikp4vnwMp5TDSholGgCiiDys+xVTN+7mI9M3Mvf18S5tkjmdEeMm4K/4Qd7FUbDk5gZqSRj8DHsPkRldB/bgyXsDl/PlXV/psTezZ0lV/HrSz/H+f+6D2vQfLwvnxNTOkZYSwF28tMRErIVRZRJR8JYZSdRIUzabERDxH243o7R5D++bT7BCVocRyZJyORCNrz1TOOapqEKRhJmM04hSCajj/4eL5LTiBI6+miDU80yrr7y75jkpkwdJeDKxwkYgiaSVhV3ZITSbDnPjj6F5D4JUyzXOe6J9VJVYyZsERgeemcdZp3unXhpuuNLdf7ejpdH0qx6kKZ7e/QgTXdM+C66kPwv3kVD5wQbpstsXdTIJRs205G8ggWZdTwqLucq54NkuyV6nFDZeArTdj3C8/JkujVY0bAeT/YL/CH7bf5w2loWtTShbV9Hp3k5Uy0KdY4Z1DlmMRBpY99QM2H3Rs637ceTstGcXEq7WMmYbCXhtJF1H2mheRYYOvwHJNWCUa2jNr2YPM2DhkpC3k+LYzf3J+ZROOSjNjlImK0Y4mMI1lr+ueY0hvMLyYtGOGPvJvJHhzDn9XNGyTZKNgaJNNlIGiR2f0LFO1WlWBMwHFrN/O6LETQZ3BBzR+ky9jOg9hAN9xEYDzCazRXp7VVH6Qn14u1PcOqmfs5VtnLQXsaT5fM5UFjOkDEfA9DsrWGv70uoXSrGvGd53L+OjRaFb4z/kOLwcp41nUef6sAamkTWtY9iKYoWidDVeQkLfNvwFf+IX5mv556LLmBOYPQYXSH/YcKDjBy+feZnQsQkGyaDgej4KDbJSViJkDTkpt15MrlrymQsOG7N/U9gFIM4MylCJjdeOfPmOxwWTGdRVZm40YyDCMns2+tA6d49ktNIqidy1O15gkpQeCWIVsx+ShP7ecGehxOQxiBlU7FLEzgiDkKmECGzjJhJYU1IxC0J6s1ZJuwS1pHEUf8fne7d5nOYSGZU4mkFm+ntdZ0nYmlEAZwWfZRf9/boQZrumJD9fszmDqaNTqUxs59tZcs4VfoFxuxc5sZN7DYH2bB3DkUrhmncmmKnpZu5RatY2NHCeqEcQ9MSps/YyJeEz/DnwA1sbpjFodJKrnr0Xp7LzMOXKGWqZYICWwkltjqy6hmMjvdyUOnBZm3hVOEOiqU+BBEi2AjjIIydlGYkgwOD5sOoFmDQqjBoNRjU3DSablua3a5OEsY99PU4kFpLqE3sRsn2kkZloKyBradeTn+hH3siwcqWnUwabmdq4Xbmlu3DvUNlYoeDcNxO1ykCkTPTFJo0BoeKMY+CXX2KoeRWMu0z8GetGJwl1LsraHSdjGCVUKwKncYBQsI4MbYz1hkkYLfQBqCBOamxtv9xPrUvRp+1kIcbz+Q5fw0aAoIm4RuZwYXs4ilnmhvyBdZYd/CZ0W28kDqXdqMbBO1wPkKBsWCQ0XAD9okgNzR8n59KX6TDbjtu18yJLJlJ0WLIw5UxYxTDhDQLTqeTcGczRXIlw9kQCTG3WsZtCQNg0kfS3pDPFMCRytBrd+EyKm95v95ggiwmVFHEqYVRVH0K3PEiukwo4bGjjjb4JJF9kgFVVRFFEYOrmLzkVnqRmQRogyGSNgsQxxpOgQ/apRC1QOm4lUOlCVzaIAMOI8WD7yyJg073TngPT1Uci6beUZDmthqRRP0Bku7t0YM03TFTeNm5VN8/wPSBQzRXTGFrfQVndzxHm3w2CxP/4nHXGpZtPcBBv4fqUJKJQg37viyNIQvNVKFuEilduIHPOP6H+8ZOZqvjQ9xy8YeZd2gP9W33EUuchBw3UGPqwW/LYDD7mSlWAysB6ElmyGgJsmQQRBEDEjYsSMIrT7dSSoLh1BD9Sit90jCxVJxMZwRrfAL34XUyEYOLQ41nsG/KdIa8VmzJFEtbm5g6cog53s0sdu7B3CQwssfJ8LiRSJ3CgSuzlPpUDEkjI9uXkFe7HdO0KClV4JHA5/lQYzmpTJimQ7/FMfgwlSkrZoMTyVdHcVEDVY5pSMJMIqVxBuRm1gfSdCeDTBaaabN4aSv0kpQsFCebuL5zKwOFK7nPUsKg5OeXo1/gwk3PsCRvHfcusbKjTOF7Y3cyc7SC3amlzLjqUqomN/K1+zdi6dkFEw6CnUv5UvEtmNMysOLYXywnuGF3Ldut5RRk04jSEFEKcDodjERCWN1OMqkB4odTGjjtIUTBhCTZj3OrT2wmWxJnXCHk9WMxZ8hmMsiGN3/y3BdMkhVz03IdhHHa9VIHx4vkMEJWQ41nkWyv/+7yjTJxVSISieByuRC9VTAM46EhBLOZTF8fyuwSYBxrLEa+xc9u4yC1QMWYk0OlCbRULwF7HcaESjqRxWjRuzG6957PkZsZMRZNUeF9ew8vA/E0Hqs+iqZ7+/S7m+6YsS9div1nn2eSu5yCskFenLKMUzr+jCEzxpzUVPaa+viHvJwPWe4nPlTAXnMvJ9ctx7D7r+QvWEivXEX2GRNVJz/DFZ5nKA6/SFvgs2yrm87umkbmH9hC/shGxMBc2ifKMQhx8h27SdksDIUMFGRV8jQFOxqapqJpKik1TiIbI5KdIJQeJZYNvabNsiCTlr2MWRpIOCvpr6lnT42TiFXEFY+x4uAupoy2Ms/0IiuVF9H2CQzudZMeMRDNE9n7uSwldQr5KoRbDPibJQxshhGNrNVEd3Qx56lBRoDdIw8QdhqoL17NiG8yu5I7mN83hm/Xj1AiBqT8RhK1M6nIm8HHbBbCthjphIn7nSYGLQlKI124I8MkBYG8sQe53jWVLvty7hZF7q4/FXt2Keese5Cds3bxycJ8LrOM8KnOvzDx+cfZKpcytaCIMa8fq92KMBAm2lPGXJvj+FwsJ7iJjIKkhclTCpGlGBHBgkXKTeOyyU6UZIyomhs5czrDGI2Fb3sdw/tNyizgiCskBQuKGeLBCZz+N58i2h9NkTTknnI7CJNfMu+9bqruKF4paJ0+YpBWarWQzaTpDQRxuVwYC+uhGZRgD8ayXBp+Tq0B9uDUJljhmccmx3NcCJRNWEGDYLidXl8DO2pMXJbKkqcHabpjwG/PBWmjR0mM80YmYmk9s6PuHdHvbrpjRpBlXEuqmTxayPyJXTzkO4Mtdh8nmR+jLXIlK4L3cFfB6ezet4jCRa3ktSg0WduomfRhpm/9E5sWz2bcVIb6yAXUrLmX01xBtkW/z8pQAw+kPsimqUsR1cXsG9hHWf/TnDzgYjgylWzYgpEsMcso4zaFQ6KBoViKRDKJJMjIshlRKkQyFiEJMhIWzIIVh+DGYnTQW2rmQKmRrvzcj0tFcIil7V1MmuhiCS8yX9tNtNdMe3M+0phG1CbQ9DGNgulJykTo6bURWV+MmpDoUP9vR32IQR5/+V8mFQYjB2hPtWCWbYzm9bGpZDmGrII4tpdF2/aTSf+VUPkMYo3zKCtdwceQGbX00l+qsD/iJxPMYghHiQRayQ8c5OfelfzRUc8O2cKdpZfgGjuTKcrD3FWwm22NFn7gHcPW42H6vm5ce3cgKCojfj/b589jZySI3uV9vVlOK7KcwJuwIUlpwtgwHZ44apWdEI4RyVZiEVPIfjCZ9fVobyZhBEciN1q9hVn89Nc7GIlDsdvCDWvqOXfWkUsYDEaTJIy5kTQnYbylFceszbrXeqWgdQqKXj/aUOmwQShNWyDE1Eowl+VqpZkTgxhKy8h092ByzCEhm3DL/TSqp/FPewxNNlAUFkGAQyN7CRVewK4SC2mLdCxPT/c+5rXngiz7ofvgqV9BqO8tF6UOxDJUeK3Hopm6/zL/VpAmCMLNwNlAGmgHPqRpWvBdaJfuv5T3kgsp+eKfqXJmsHpj7FuylJOfvRcp004lp1Cb3M8W2xQ+ua2f/uIMSiJCpXuc/uJzWLxrHc/OribucNL14NVUn/4XFjgV+lL7ucZyAyM9c3hMOJ/mogZay2awKR2ncPgg8/tGaYipOMJ2lPFKJmlWJh2hbZoAAbvIoEem3yeyqVBkxJnr/PliAeZ1DTBpuI/aVDcL2UV+aoSxznxa28uRIwkCLpW9HxUomp6iSobhsTK2xQRmyTYqrziAOmFGM2tIgszgxq8wO2llXG0mHHsYuzWBQ0sSzxoIZG0MZ9zEExG6IgaM9ACgkMf90+pxJFJMH+2i/MndBC1WuucvplRexszh06jTYjSpIQIGN7I3gK3+rxxs6uK8eB+n+FbyYxEimo0tE5diFOfS7v87HyiV+Yqli9PL4YICJ8t6CnB217Erv4pi/5GSrOgUVSEoxvFlc7+4I9gwHU7wIhiMWMU0wZQLlxBHzRP1zI5vQdrqwzGSQByI8cjoyWQPJ3jsDyb46n17AY4YqPXHI6TMr4yk+UqP9NOtOxZeKmitHqWgda3HBX0BuiK5zIz24joSqoEibQSleBbpTZuwmM4lZpFwxwdwBuwgCCS8dvJjuXWKnbFuJtvMCIJAoUmfQqY7Nrw2E+eIG1iw7zZQc/UwCfXCQ9fm/v4GgdpEPM2scvd730jdf51/dyTtKeCrmqZlBUH4X+CrwJf//Wbp/lsZS0uRbEM0xOcwP76d9dZlbIo9wbzyB+kavJ7zB8b5aWWaB4VJXJZ+lNF0FTsNnZzqm0prbBqL2vrYUOfC4DHS99hHqFn5O/x+EADB9yJfsOxgoHkq25MraCqtobtwCneX5ToOopLFEw+RnwxiVzOYtSxpyUBcMjNhsjFicZERcz8SBjVDWWiYqo4gFePDlMaGKdP6cKpBXCEjYguE+s0Y1SD9RXb2XQVl9VnqZY1AKJ+upgtIN/yT5aUBUCXU54oQ544iC04Sm25kpZpHmzDM7qHttFbMp6avjZMLzyPt3sgkYRdnsBlJ0GghjwcEO9mWybTYaylJDGKTw7QVumkrdGPKqhQe2EEotoF9M6vJL1rNYqGejEkhUHKIpoFLEY0FdLj3Ys5u5IfZOfyvwcKopiINlxANfA5X8V181wcbY3F+MzzOLwsu55cnn8WZHjtfnVJ5/C6WE9hEcgJVAN/hTIIR7BhTCUAgbtIwOARCKReubAzFlsVk0kfS3ozLV0+qJ4HcGiGrvfZXUyKjcPMTB48cpIXHsB0O0myZFFabvibteJEch6c7HqWgdaUjN7rWl8htl00mhlUXlcIQAV8R5lQKc9hJ0qbiC/WTGM5QZilk0Bun5HDK/RRpiqUAL0T1pEa6Y8coi3zFeDeGlwK0l2QS8Mx3jhqkaZpGQJ/uqHuH/q0gTdO0J1/1zy3Ahf9ec3TvB/mXnEPtfd1MahvihekaB1ctZeWLj5ERtmFyr2Jm4nG22k+lue8kaiY/TWxiCjvsXUzzlTPQO8isQYVdRWlkp4G+F65h6oxfsrPMSJFVI5qGwvp9nCHsY+a+yRhfKKDH4uVAZR1jTjcRs5Wg0cmYKJIVJWRFwahmsETjTBkfx5WI4Y8GyYsGsWZjGDNJktkgQqAb/5BASfc4KCpJi8b6xQKBlSqNBRNMk2AsWE733rUkBqcBAlKwml7rKJ6Og9guWIdJKUHe9HlqcLEn2UnL4D00T5lCXU8zc92rabcI7BXLUSnGRhKf9VnOCA/wZXmC2KRhHshkGBTLCEsVmNVxbMogwyM20qJAt9+NPB5F6rmdeyo9VBSfzLyBk1ipaexzDbDLmKK36iR+XuPj3PYEPR1hdksWJsdH6Ou8hFT+btblP8Z+k5n/Hfk5H5hIMHvFdxBEfTrRkYwkRgDwK7nhnig2XPEYZoOdkBTC4NAIpZzUJAdR5Swmoz6S9mZKCqYRTg8gcOTMjgPBI6dcl0f3EjcXY9DSmDICkqRPKzpeBFlEtBmOWtDab5QRNZXB1CslFuKSh0ptiGaHn2pAHhYIWSXMYox0IMFMtZ5W+3qqIzFERUSVVCzZbsYzkwhmsrgN+qoN3bFRyPiRN4T6jrpPJJUlq2p6kKZ7R97Nu9uHgX+8i8fT/ZdynHQSxl98ikr/DGand7LZO5dpA+uon/Ygw60zOGeolEOVwzzr8FJ14BSEsq2MKxUEfVFsiRkk29YxyVLNIXcGKauxr+laToreyiO1ZhwmDbusoWWgckYL8coWxvYXsGJvC3njCawRgYTNTspkImozkzVKaIKInE5jicWxRWM4I2HMyThyNoUr+krl1TGPwONzNEbmaRRWKTRYVAQgPDiFZ7LLmKy1UrboN2STTsZb1hDtmkM6WsKAuw6eOROnpFFikNmQaaF/7AGa5s5hTusuKphO1l3AXvkAKippMcteUz9XPOTiIXsB66ct5WLj81xieB5B0Oh25tEll3L9+Je4tu8uZvcN8NicqzCn2gnYOlAmMnSPPkpr/nqmeFczKzOZGqWE3xlNnDyY4aKEgV8BJwsi60z5zBdHGAs6GIx+mOGye/lwkci1PX+h+tbnkc7/Hc6KxuN2rZyoSu2l3LhtMdM8Gsi56Y7JUBCr5CBCCMmiEow68aZbADAa849zi0985fnTaFbawCZCUn3d9mK35Yj7lQ310VxRgV2NQsasJ2g5zt6ooLUkCLjULCPqK8XKNWshZfF2Hja6qAboj5KwGYEYxliE2fapbHE/i5DJUDZRRLdvFFO6i2vLl/L6q0Sne++MS378ysjrN7hKj7pP4HAha49eyFr3DrxpkCYIwtNA4RE2fV3TtAcOv+fr5KoB3/EGx/k48HGA8vLyd9RY3X8HwWDAfdIUGvq9tPfuZnvtfLpWLWRJyzp2eh5HE9dySe+d/LZyLc8Z05w+WkXAGqDJ1M2qgjr6sosxvfgE5Qtn0+NKUx5Ks77ti1wYu4UdDSoPqQ7mulMUoWFxwPTFw4i1w1gflVB6ZBKagJLWsIbBlNVwxcCcAUkBVYSYCYYdMOIWGPKIDJZqmCoVJrsUJtk0posQzUKgo5p0cD6JhgOcbPktaAK94yVkdnwU45DK7P4fEP3MGKa2awj3zWZMETmQVIEaKPgEZ3VuJp6eRn7hHJ6UmwAIGCNYD43yre172FZRyS8bPkBSsNJQ3IalsJjyLo268ABlBPjb+DcQAhJPLvwmdsnBgoKdWKZ307RuEcpgD2OjMVrGH6DNvYGp+efwxZZ8siaJb6WiTCnp5ivBH3Bj+tv8PZNPvaGYxVI7paOXcZ/zBX6at4+t8WE+9aeLmPmt/cf3gjkB2VMC84N15Nm3kZFkBJOTcH8rHslPVImQtcpkwwa8mQAAJpMepL2ZosIqUmoKY7UBpSWBqr5S9NhikLhhTf0R93MnEsQtRhxEENJ6R+h4k5zGo46kAfjQmBBeGaEX8qqREy8wHhlBdDjIdHejLK0AAtizEUqsC3jQIwIq1SMO+r0TDI3v4weLi9/7k9HpXuWx/I9x0eCPsPCq6bwGSy55yFGMHw7S9JE03TvxpkGapmmnvNF2QRA+CJwFrNI0TTva+zRN+x3wO4C5c+ce9X2694e8Sy4m/MlbyLf6aKjazwtlC6h9/AWmL1jHSGARBcaTqVG2s882n8bxA1QZOxiXbGyydrM0z0Fnegm+jc+gLFlEjytNFSIPDHydtemfMqV0lJtx063KLHVkmWpRkPMh+kEFFBXfkA25z4sw4CdktNPkS7PTP8CQeRizpFKqWagQzZQZIyw2R5HNuSfzUQXa4wIlEwKSOg13WStyzd9JplwIfZWs615C8cAKvGNNTAr8meA1WcoPfAtDuIyIRaFv+F4CWgxjdQMVIxZGlZPALLIjksCaqWDY0MHaJzdRPBFmw+Rafl91AXGDjc/P/QWulEZ67EwKQn/jA/JP+OzIH1nk2Y+yxkAs/iAmeRR/7QGe6f4oEeN89qzsxTd0gIUvrqc/mWZ38E/0O6qZ4jmN70kOTENZNpSs4PbaAmYcMHNgIArpSr57xVw+U3ARn7zjO2xxr+dAgY8XjvO1ciLKDA0hmJ2IjBPT7DhcLqJ7xilz1TGWmSBpzE2584q5IM2oB2lvyma1ImdjeL0KamOUxB6Iis43zO6oaBqSIhC3WCmgD9Km49By3atJLhPp/uhRtxcaJJoMZhKJBBaLBbmoEfpBHWvFWFlJqrMT+Zx6VPbglvpRbGnyaqcATZSPmckKCgcCLUctmK3TvVf6y87m670hfux9AOEtZnd8aSTNrddJ070D/252x9OALwErNE2LvztN0r0fGIqLkQuTNGRK6Rvay99KptC3chHzOjM8VnMP8zo/xSf3b+fr0yM87Szk8gk3Ts/TBOwNNHs08tVeYulF+DZtRlu8gE5Xkmo5xN3DN7Aq+w9uHttMc76Db6SKuEOM02BWWGDLUm1S0YqjZEqiQDcGYNbhP6/IPSVLZmFYFYkkBayKSrGoMcUO2DUyqXZ2CPPwHSjAHAvSO7iU4kQRFd2PUSI9RPiyKmqbvoCommjPBtg7eAf9TisLJw9gCHfTGSqhuMTJQS2BKenHFi2jWqigv6qa1im93GMuYNzk5erae0jvLaZx1komt9/IVdL38B3oIttbwe1TP8Ec599ZYL8XVRDYOHImw8PzeWSpQkvJDGoiU1lpns+prfcx2LafveUxnot0UOecxdS85VT2TuNaBGo2/5GkoYjvlCzl0jte5NPxQyyd6OfC866hYtWSY3xl/GeQbDY0sxtJCBDEht0ok9BUbLKLbKqXuJybmufNy629MenTHd+UIAhYxAjuVJqxYhvXvvhTPnbLujfcZzSeRtNMRC1WJgvjqCm9I3S8iQ4jaiyDpqgIkvi67cVmIxuzAoFgEIvFgrl8JuwAa7QXY2Ul8e3bsdpPJ2Yy4E4OMKCGmDvrdBShCV8oAwLEtQT90X5KHUefZqbTvdv8DhO/zS7mpmu+ifstTl8ci+b6Ez67/gBJ9/b9u2vSfgGYgKcOP9HaomnaJ/7tVuneF/xXXEz21xvwmk1UFHXyQt0Cyp/dxKqSZrqMTYila7iq6x5+V3UeG01NLA9fjFV9kD4X+PKm029+kKpkOXmbt2GYM5MOT5QqSeaZsYupzcxkefo27jUcotVQzTO+k9nniHDf+EHiqVHm2BQazAoFBg23pCEf4YGsWYYSNEBDighEJyYxEZhKk9zIPdWNfKP5QVrHbPgnVuBVk0zb83MspQdQZ15NddsSNA22xPbRM/oYXdWVLC1u54/2aazePY5UMY0mQxdoGtObHqBwKMDeaScR98xGzS7lrIxGNDOAa6uVM64+n4ptX+Sa7OeRu0Y5cyLGvikfZUDMYsrmUW2QSCp5LEs/jFY1xD2eL/CxthSXdkao++xqxqyn8a8v3MLl2/5B0jDGU9PCdPYdZIZ7OR/omYFSeAHWUwoZ3buZ3war+LG1jlur5jN/9ZyXs7XpXivpzUcyORClCBHB9XKNNLvsRknESQi5IM1doCGKJmTZeTyb+x/DYhvHlczQhh+rNYsWDyBYPUd9f08wgaAYiJkt5DGBktUT3RxvkssIGiiRDLL79R3TCpsFNa7SFQhRXFSEs7yeqGqiVBsgW3Iy2YcewimUkLBpeGL97I+kOLn6VA66foAzEXj5OM3jzXqQpjumCg6X5BkOp95ykDYSzgVpfocepOnevn83u2Ptu9UQ3fuPbckStB/+hkmZU1gyto078y9hZOlipnUn+XvD3Zy58xtUaTNpkFvZ5ZxG9cjzFKTOxRRdx247LLFexp9X/ZLT1/lQ97ZSV1dCaxEUFWoMj5ZyZ+KnzCu8jYbUNhr72kkNGEgqHkZsbjotIl2yQr8S5ZCWwiprOEQNhwBlapqirIIxbWGsI4+usbUMuJeTERT+ucxJwJPhQ9ufYmBiKkXJAjzx3TTu/gex2eAs/CmWiI2QlmDT8EOMJ3sZnF/H7lKB7jETq3ZkCJVXkxUioGksfeEFBCXAgY9raOPreXLAwaDdzlnpIHnRfJAuoulfffyZjxIKqFwSE+iqPJNmOU2l9hgXuB/idtcXuMO+ivnyY3y94/ds3P5BerIXUvyh75HMM/Hh32zGV+qgvmCCjXsbuGhrHy9WB3g0b4zGvt3MzT8daUOSRXE7FbOzfLfDyKeGA/zslm3M+8BUzLXu432pnHC6WgfwGO3IUoiwUIJBzWUktBncMBYnpuVGztyFKURjvj4t6y0yuMO4owpRwQFWCPc14Zq08qjv7wslSYs2EATc2gSZrD6Sdry9XNA6lDpikFbtcsJojI5gmMWA1eWmO+ugUhpiPK8QC2AcMxGzSpRJg4QnBIrtxezMt2MNB5BUCUVQ2D+6j9WVq4/tyene1/IPB1ojkST1hY63tM9IJIXLYsBs0B8g6d4+PXet7rgRRBHvBadSvynFgVYo8vfzwpR5FLywkYvLB1lX/hDz+y/i05vv4IsLinnGM4NLx7agiPMwGJrZZmzhisQX+J8Lf8yS7Rn8vU7mjg6yc1o9kQITdWGRF/o/yx5rP/VVf6NUbMUdGqUuPkLdESbnKoLAhNnJoUAFHS1eItpChgoWoLoEegoy3LU0n8bBYdY+O4wtvBhZClJ/6Hf4xpuILVxLuecM0GB38gDtw4/R6/DSsaqOdmUDK/qnUDLSQMBvwKSJaILK7J27GF06gG9JhtSGEp4aXsGuvJmcywv4R3ax9CPfIPniNl5oq6VILaVYyjLqk9gqx/Ckt/OFkj/z7bLvc0fBIpJGgaXtZ7FNdTNJvZtq+Q7Ujb3cEP8oltEefm3/KZ+c/V2eOGUmFzx1K9c8tI1JA4P8+dQJeocHmGVayFTPUooOifxjcSFX7url0/Ewv3i6g+W1s4/9xXGCKwyHSJNAFlNEsEEqgSCIGCULSjZOJGvBKKQxetJIeiHrtyxtSuM6XLQ44nIweGDrGwZpg9EUacPhUUsCpAX3MWil7o3InsNBWjAJFa8fQa522QHojuVKKgiCQFxwUyUO8aLdTx0gDqnELRKSoEAgg6ZqWCtrcKxvwpksIW4cp2lg5zE7J50OIP/wSNpLo2NvxWgkpY+i6d4xPUjTHVfu885j/I5PU1mwjOXBzfzDcyHhFSdRd/BR+qc9j9K3gIGKc/jy0Aa+nb+SF+xeTokOEMSP6AnRLOzn82Nf5tsrbsM1uovuLSdz5vpNNC1exG5XiukWA9mgjU37v0vCGqKg9ikqq57CmM6ijHsIBosZDhUzNOjEMKxQm4aYZwqhwhrQFATLGI8tNOJPZfjCs2MYJooQJR/FyQeo2fYcWt0kLLNuxm1wEVJCbBl5mJHUMPvqG2mregZSKlf3nU1Yy5I1SvhVG6NihPrwPmzX7McgSbQ82sj22BQ2+xZyOlup72/i5M/cRHV6K18aG6RP9XNSVkSRTCAIzM6amOme4KLJf2NjfjkNIYXP7Rxj1PIw+9QKJtf8HnXKTtKPfoUfKFvJWG1cOu1mdtpq8Ib/gVYzTsjuQMok+OxDKR6b003gyrNp392Cq91B4QaJv9oEbrQZ+J2YZvnxvkhOQHanm5DQDOTS7yvxKCbJSUiKIpkVQmknTmJkTUmsRr2Q9VuV1jJ44rkOUNThIdjSDGuP/n5vx/1cav8lP3z+/xEzGWhznXqMWqo7Gsmd68hmJ47ckS0x5zqsA8lXMkBq1gJKMm3cI1qoEwTU3lFSRQ4giksbY3xwkNKGeShPNuGMycRMcDDUqicP0R1TL42kDUeSb/LOnEc6HmFr9odk8yZYfU8R182+jjOrz3wvm6j7L6MHabrjSnK5sC2opjFspas1gX/eMM80zsTx/LNcVWPgDzPv4NJdN+AeL+SCaXHuZQplicdpiE8hSIBoXoKBRDNfG7qKr1dvZ8L9EE0tq/jgln0ok4ppKtDw+53MiBsYiRkZ3nsRe/eei9Hehat8F9bydkrs2yiTE2QTHjJxD/ZED6aMjWiqEDVYwpkv1KMpJmTzOA75PiZv2ord34C4+kuYzeVk1BSbxp+iN7yTVkcN3YtdDMuPsmJgMb5UIWGylKUcCAYzPdIYVYU7cS9uobt7ChPbbBxQS1jvX8YKdjNloInTvvBdKiyjfOkvgyQn5rFc8yBnxrjXEsKtZlltUdkfPp9FGwTm+yNUplvZW30nUvcKzrfPI/+yKdzynIkdieu5zfIT3JkJru67B7WkAnVkA8sfdbGtwo+/sISFJjunP/go7Tf9jKbrz+Gycz5K61/WURqu5mZRJlHy1p8Yvp+Y6ksYdYxQmIYIdoRAAIvkJCgEkG0qoZQLtxolI4Qw6iNpb1nUYMaZyg1zh20uhvsPHf3Ne+7m3IPfxyzkrlFHKs30sadgz91vmG1N994STVKuoHXgyB3ZPIOErKoMZV4pWi54KmFkI5GJbgxFRaS7ukgXlwKDeA099LW1UTNpJn2AMxqh258lrWUZjA1SbNdT8euODZtJxm6S39JI2iMdj/CtTd8iK+Z+DgZjg3xr07cA9EBN95bpQZruuPNedQWJz95MgXM6q8Lr+bvrIpKrz8S47Z9Y5vXRm/c0mngapz9yO7tXX8DT6kp8/feRL6whFNjFWJ6AKdjJr7qr+Wz9TQxZ7uGHhVbm7PSxdscu2mZMZZ0tzGRzCYtTBkYSKkOxWkab66D51S1RgddmI1MtQeJ5W3EM72bRHgG7dwbyyd9ClJ2klAQ7xp+mM7yLHnMhzY1Lyfgfp3F8CotT56IIGpZkhoWZCnpsCbqlMcrKm8hoBnZsOpu8kQlaFTfr/CuYpx1g7sgu1n7le5T6DHzjZ/dhnVhGFTY8gd38sjCfhM1AwQyFbxTMZHFPmjN3RUgOZBgy+DAdPJ8lxlKqPzyPe5oGuG/dZn6a/zjLG/7KB4ce5pPdf2P+sIEN7dMZMAjMWbicZZ+9Hkk2EDplDZmv3EDhTQ/ylytb+dRX/0xgZxsT9x9C6Nfn0R+JaJRIxYdBhrTBQ6pnkAJDJSE1iGSHUMpJmRJAUWOY9JG0t85egTmdmwYXNjsYTr1BZ+iZ72DWXrtdUtPwzHf0IO04k/LMZI8SpAmCQJ6mMPaqQjxiQQOMgDLSirGqilRHB+KMYpJGGa/cSVf3KA2LpgPgiAcBkdU9k/Bb9QcgumMr32Fi5C2MpN2681aSymvfl1SS3LrzVj1I071lepCmO+7MkyYhF2tMSXgZbe3AP2eYJ2oasK1zcUU0xM2Tn+CTz0+no+JcvrbncT5dtYZHC1dx4cDDOIQLiAQ20p8H4rjAnQeH+eOUWp6017DN/QIvtq1iTWsfU819tFRqHLQO0GAqYY5iQc6qjBJlTBYZMpgYNZoJGpNo2jC+aCdloQB1ATuFoUokz2KE+RYULcNYcpADY48zmOik01rJvvLVFOS3MDM+jnV4BZogUKzmYR5op8G5iG32AYakEHb7GF19k7FaQuQPj7E77eYp/8lM0zpYGdrDRd/8IX6vne/98I84xpbjUAVK+h/ke5PmEi33ozR6WC8Z+MTBJPN6u3jKv4mYp5tprZdhDU2mzWVkYusAP9mwle8W3sNVjd/GaHGSmbaMnzdv5GOmbi6u2MmodS0l13/p5c/ftXo1kxunsO8TV7P2Dwe4o+10zv7BXUz//nQyCX0k7WiE1ATIIDmLSMUO4nK7GcsGEdwiwbiTmfIwACZ9JO0ty3M1kFaTyFqWkMHOmCSBpsGRprSF+o58kKO9rjtmZI+JzBvUSvNLMCYZyGazyLKMuWwG7AVrtBu5spL4zl0YY6uI2gX8yXZ29mcwlJUBUHg4waMaz6LEUxjserIY3bGT7zS9pZG0odjQ23pdpzuS1xcx0emOA+/VV+A/9CLOSBmnhJ+jVfOgnncJ6Z1uajIpNky/A0U0MJxp5Dv2IcYNBTzvm0M6fi/2xBIME+P0SuPsHrfy8S1+fmb8CR8osuGba+ehlQX8sPA0OnqNWEaGaBZ7+KdpM08YdxOSojRqLs5Ku/hQ1MT1Ew4+H6jlqsypnGS9mJKCNcQ9HjpSB9g4fD//6v45j0w8zr9MXh6tXIta7WeVaZDGmA+HYqNeKeGcUB2eof1MzVvJC44ehqQQWSHNdnmYmuIItr3D7M84ecJ3CvVKF2dkWrjiuz/EW+Dnf77/IK7R+eSl40xq/QPfmbOY5OJaAjMLqIxJ/Gh9lOq+Jp52rWdf+fNMN0jYbGOsXFSAZpLofqibD6dUbir5Ck6Lg2/EDxL92Z/I9BazYUctquKhJHU/PP0tUF+ZbmQsLWHmvY+QPmslK5+bYPsHzuZg1w7MdtvxuyhOcDIhMpqM0Zj7jOwGN8lUGNVhIqWYybflhgpMZn061ltVWzSThJbGpUQJy060jAKxsSO/2XWU9OtHe113zMgeM9lgCk3Vjri9yGggarIQCoUAcJZWE1QslDNEJL8ELRHHOOIgYpNxi0PERgyIZjNyQQE1oy7QQKv2or7qHqbTHQv5DjMjkTcP0gpthW/rdZ3uSPSRNN0Jwb58OYM/vIXp6XlE2ropmD3IPb4SrjAWcuFEjB8U9jHXuBnVs5LqZx7gIxeW88eOqfjTI0wP34uNC4kFXqDXrZHMuFj09A0savgty8sfIm5zsc9zFk8NVfHCyFRsyTQL1RZUU4QJc4rtdGNIpbCkVMxZDSmrIGTTpLJRMkIUZDdx2Uev10fUWIFTTtMgxBCFfoSMSkFCpM5QR6VWwJjxaXrTIiW+NTxq3EdayNLpaKHDtZ9rE6fQ83Qrva4qHvKspibTwwecw1z0hZvJZkV+9PUn8MSrcYcOUtr7L2688ksM1eZhUeALzWMUN0tEvPs56Gtmg2cDHzLYSbTO57yKRRjOreb2X67j/KI9BCcWcvkzaczOHrp77kNxCKwYSuDO2pCvfwC2/AA23AJD++DCP4LZBYBoMjHjR7/m0MzfUvODnzL+gQ+z5Qc3svCkDxzfi+MElE5mMYthItgwi7lRHpvBRSYaJm3JJU7w56kAWMx60PBm/rWrn5ufOMhAUMEhTsPQFyNY4caoqiijLUj2I4xGrrqJ9L2fwCi8qqNusMCqm45dw3VHJOWZQdFQImlk1+sz25VaTMRTGmOBAF6vF6e/gN60lSrTID3uEkoBeUgjOklGJIEjEyQSiGIsK6OqfwCECAcMvchmy7E/Od37ziMdj3DrzlsZig1hEb2E1VPQtJVvmLTmutnXcdPGb5JWXwnozJKZ62ZfdyyarPsvoY+k6U4Igijiu+ISig7twRIu5bTw03RqTlKXXk1gt4tZqQwPzvkX1mAzHVVnseqO37GkxMYGz0o6rW4y0X9iiy3AGAwyRohnTb0UHPgiyUfPId1iZr7zPr4+/XvcuuLrnDP5CTrzfPxVWcy/UlNoyhYyaHYy7rQwkmdlMN/BQLGX8fIKwmVTCBeVkPWbKLKnqZPGqQ/2Mbmzl+XDGpenFnOmYTVOW4KnDQ+SDlZhcDfyuKmJjCnFE8VPkLY185n+k+nZ0MqQr4J/eU6jJtXNdXUaH/j6N+nvSPD7r2/AGndS2fMIiryPa7/8P7RO8rJqMMHvNz6Fda9IyreXgfIOHnO/wAVOlVDrStaY5+K5aAqf+usWTnU+wf8sOYWWhi5Q9pIM5SN5PshibSG2wTFKb7kF2V8IZ/8UzvopdDwLfzgVxttf811MuuIafH/+LbIgE/75r47D1XDiC48lsEnjRAQbwuF1UzbZjRKLkBJz0698/gwgYjLpT07fyL929fPV+/bSH0ygAWHBTKhVY2ggD4sRAgN7j7hfbMoF3JeYTb8xHxVIGAxw9s/09WgnANmTe1ChTBx57U61y4EmCLSNTeTebzAQx0W90Mu+w9OD5UiauCMXhHnlLvpaWzFWVeIJRpAUmUGGSSbfWpY9ne6deikByGBsEA2NuDqGVHAv9xx88A33O7P6TM4puQ417UZAoMhWxLcWf0tfj6Z7W/SRNN0Jw33uuYz+6o9Mz3yUZGsfFXM6+KtUwOdrZrCqK8yP6mOMzN2Mb6+f5urLuP7J3zC68hqeFM/g7KF7KYneg009i6jYRsym8rB5N8syiyjsW8FE80HGjfuRfQGW+4Y5tfhRQqUW2qOltEVLGE4WcDBjI5OVsJLEKsbJ0ybwJMcpmRihKtaHwyZjdTfisM7HYS1HRaVNGqRJbMI9EmOeaSU73L30S4OEbcM869vC+QELBa3T6Q+0M1hSyz3GU6lNdPC/Z9Uyfflq1v39EAc3DJDWFBp7/85d517I43XFFCZUbnxmF3XpAzSHT8NWvJPklAR3R59ilT2DsfNkZqVmUXvNAq5/cA+TxSf4Y+larn7ib+T1dJApdvN0yRNc0PtBDmlLGV8zn3xvDS8/d577IfDWwt1Xwh9WwaV3QsXil7+L4rnLsf3rEUT09NZHImXiOLUBevGTnAgjCgYk0UBSiZHAB4DTE8VkKkAU9TUzb+TmJw6SyLx22pqmCsTaBOwmjVjnDnxLXr9fRyDO7lQtn1t4M2dlHuQD489zsh6gnRCkw7XSshNJTFWu122vdjmAMdqC4ZdfS1lKcNHBwPggoiMfLTqA6GtEFcfwGboY6hygoK4OKXEPVeNltOUP0pPsZqpz2rE6Ld370JESgAhihl83/ZyLJr9BfRCgWF5CrD2Ppm+uxmXRfw/o3j49SNOdMESrlbyLz0Va38KuxmJODzzDb/I+xsjaS5B+3MJpZVH+4Wvi80IxEcMpHLIs43sH7uPTlWfzWNG5nD50DyXRB7CrSwgJRgTDEM9ZmpmULWKOexYV2mxMUQPxQIikGkfMxmjUUuQbggzYD9DjmiAtZ7FlbbiyTvKyLryGKoqssylQPbi03NqjoJZkqzZEi7UdazLJnEgxWWclj8nNZMQsTXk7mTC38cW+6Yw0x9GkEborZvGAsJwZ6Q5+8elTEbUCbv/2FuITKUa1cYylWT59wWdISgKLO+Kc+cjtuKpKaYudhqNyA57FpdzYcQsNFoXGYCPuidnMP3cZt+zpRY48TlOmjI/c/QtMkkTJuafw3dRtfFBdyMI/fYfgyg9ygAX88/vbmXlqGXPPrMJglKBqGXxsHdxxMfx1Laz9FUy/6OXvw1VYdrwuhROeOTqKLEWIUEV8IoRZcjEhhdDQiKq5DqrDPoLFqE91fDMDwcQRX9eSGoJDJtXTmkur/8x3cklBXKWw6iZa5GWoOEAQ8EqjkDIe45brjublkbSjZHissOR+Rjpjr3z3iq8exl5AG9qPaC8hO9aD3TWfmG0zvswhDnYnMS2tBWBhVxFWk5d81fsen4nu/e5oiT5GkyMv//3V0yELbYUv10MbjaYwyiJOs97V1r0z+pWjO6F4rric8dvPZeakT7GtbYjJ8/bzu0gNPzltLaaNf0VePM6LK7ax4h9p+ivXMtLdxY88m7nWvoDHCy9gxdh91AU34BipJuKdhzG1lUMujV5xjEWZekolDw4hDwQjaBbyVQdTBANCVoDxI7cprmoEsxqtWpy9jlaCjk4qQl7mBN14zZN50dXJkDRA3BRkg28by4Mp6lpmMTQWosIV4p+es9gqTGW1bZQfXn8FLz4+SMvmXcRFFSU/xWPzauixS9SNpki0BDlz/W0Ypy9hODYV96SnmXLmSXxi45fwGlXOFvKIdC/h5FlLeUBJ07v/H9i7BjhpfBsVs+Yy/bIL+PDmTzLdWMmZv2lBLClhwQ+uYbZgZuN9bex8ooe2naOcdMVkSus9kFcNH3kS/nEl3PdRCPXA0s8fOZue7mXGIi+SrBDBRjI0gdPgJMA4gqQSyDgxCykkpROzZf7xbuoJr9htof8IgZpmlojbHUiDzfDQtZA5/J5QLzx0LXL9jaQNuQcneeIYqaz5WDZb9wYEWUR0GskGjpxgodxiRNA0etPZl18zVsyDsT/gjbejuErQDu7GLtURsYIv2kug14KhJheklU5kqPNfTn6hnpRH994qtBUyGBt83esuQ25a7kvTIV8abXt1PbSRcDH5DpNecF33julBmu6EIufl4T7rFKT9LeypL+Kssaf5sa+B56fOp277RtaORfh7/gSnnmGg6JlNdFecTuPWP3PraheflupY7z+XccMLLBjtxDYyBPZTEKUW0kYj60z78KkO5qo1FOHBgZ02cw93e54hrkJNspS8jAdRM6BqIiE5zLgpSJ+1F5UEM6KTqIyWUDY0FZshj32OXrZIu0FUeNGzG0Xq4KPtkwh0ZsjKo8wpDXKj9AkG8PO5GWZOyl/FP3+wl3QyS8YlsG6um10+mdJQnLKdEfrGs3x9x+2o01YTjlfhnfIoi8//AFc/+ikUY4arnCJDTSdzgW8xeyoN7L7j/1Hd30fWauH0z32Z6nnzuPrxq1GzWW580o4a7Kb8H79FcjiQgFVXNVC/oJBnb2/hgVt20bi0mMUX1GKy5sGV98EDnz48WtEPZ9wMol4j7WgkIVdwOWPykk4EcDhKCKtBBJvKWCIPnxwnlR7CrCcNeVM3rKnnq/ftfc2URxmNeJ2DSNxDYTAEmexrd8okWHroVp40fQwADxPEtfJj2Wzdm5A9ZrJHWZNmEkV8gsaIIJNOpzEajXiqGghstVIv9jLsPIV8TcM8bCVglykejmFSEozHRHA4cYVDiLx+GqVO9267bvZ1rwnCADTVwHzX5cAb10PzRb5DvuP1iXN0urdKD9J0J5y8D36Q4NpLmFl9HZvaR1nmfZ47w8u568OfIfqTr1F2Uh+/cjzJF/OWEg+2cqDhSmY9+FNuPVfm+lQle10rGZZ6OHPkeeTwg5gSk4gWVeGOb2fCXsDjpggu1UKDUkpF2s/Xhj+EIiqM2kIc9HQRJQKqSm0qjxnJYoyh6ZiyGi7ByZAcYY+tnwmxGwSVZtcBBi2tXNjrQ+iqJZRJM8/bR6u1ho+Ln8QgifzPgiqUbWE2TLRitIhsmG/j2UoT3mici57dwKNKDZogcmPTP0g1rkVL+CiY9S9WXvBJPvjPawhYY3zcl2Gi5VRWavNp8/ax85ab8WezTExp4OvXfwObw8G3N3+b5vFm/tC3GnXboxR+59uYGxpe89mW1nu49Bvz2f5QJ7uf7qF73zgrL6+ncpoPzvsdOEtg408hMpTL/GjQs6cdUTpGSPaTlP2gTZBnyKcvPQI+E2MJL/mWNKBiMZcc75ae8M6dlfuMctkdE9ilECdpWe4uLiU84sYqZY+4nzc9QsxiBcBNALPp5GPWZt2bk/PMpDpDR91eZpTot9gYHx+nqKgIb2k5/SkbDZYeNrmLyQfEnhQRW66b4pW76NpfiL24CNf4GLGU/Ridie797KVEH6+eztjfsRK3byHwxvXQtEiKar9exkb3zulBmu6EYywvx7FqKWL7fuyTCzhpYBtbSxZya1TmmuVnkj5wB3dMj9N26giNv7yXfeaPsWf2Z5lzz//yh0vO59pMGQNaFXeW5HPJwN0Ysu14etrRLDOJOWV8gTai5gK2WBJsMbTiUi0UqB7ccStlsRJkJAQgRZa4kGJECjMihQhJuelWWTHKXk8rIamXswd8mHoqSKUU6hzDVOcH+J5yJVvkWdSbDZwTNTHx+AiiUWDLTAtPTTLjSiT45D23Q0LkT/nLMJpErm17kmTNeQhpKxVL/8GKs77OJ/76CbpdAS7PSyH0zqO8v5o92UcJ7u9hsKgSbfYkfnLZNcgGE/e33s89h+7hBm01ztsfw7X2HNwXXXTEz9dglFh8QS01c/JZ99cDPPLLPdQvLGTpRXWYT/02OIvhsS/D386Dy+4Ci+cYfvv/IYqm8wfLJ7EnNeAgToOXbLwdU6GRsVAeM4pynVOzHqS9JefOKnk5WPvfP11K8cGF3A2EbE5CqhG3lH7dPoMGD1GzBUHTcBHClT/rGLda90YkjwlldwpNURGk1yeSrrJaaDbbGBsbo6ioCKvLTURxME3o5k8eD0vtdtKtnagn1QA7ybfto+9QHUVuN66ODsYn1GN/Urr3pTOrz3xNVsaVNz/LSCQ3ena06ZCFtkKGu1IsrNbXTereOT0Fv+6E5Lvm46gtjzM7Xc5YVxVnKw+yUTWQOuVC8pKNLAzDb1ItFHzhbGbv/jmZbJZdC27AcOff+X1sF9WeNCHZze3lVzFucJExWCCxk/xD21FDfgaNBlKZTQjhLiLJYdroYZuhjXXGfTxpbOIJYxPPGfezzdBGpzBAUggQN0/Q6z5IihZOa5VZu74YWg0Uy2lWFzkJ2y/iI4YfsdU8iyVJmTOHJJSMyrrZVr6z1s2GUvj0v/7KXd+8lg6hgD/lr8DlkPjY2E4E9xokROpPvpNV5/4PN932Jfa4+lntzFDQW4uyzUx3/zoGwxM8eMolZJdP55ZLPoJsMNE83sz3tnyPVeaZLPztZky1NRR+85tvOg++oNLJxV+dx9wzKjm0bZi7vr2VzqZRWHANXHgb9L8Id191jL7x/yyZTIZIJEImEAXAacxDjUUQLBIpxUxJfu75lz7d8e2zOetASWFV44wZPTwX8KEKr32eqBks/MS7kKjFjE2JIaNQPHnKcWqx7khkjxk0UIJHXpc22e0gaTTRPZZbDCwIAmlHJUZBISX3Y5pcT6rlIOa8aSTNBoptLYz1GBk1mzFkMsR7Bo7l6eh0L3t1QevrZl+HWXrtelizZOaT0z9LKJHRpzvq/i36SJruhGSqq8O+YhFC64sUNBZT0LWZjTX9fK0jxX2fup6JH32BpuWD/HDi93z1oktYcN8tbJ77ZXYv+zqzHv0uv5gzwE8WzOfxzmIeKL+A2SPbmJ1pImovwhbroOZQGk1wEXJZ6M7vZSCvE0USMGFCFSSKlEKqE8XUxgvxRcyQSDCajDCaiqNqoEoytY5p1DpnkZLd3KImWSdlcSkCl8YN2PPM3DfHxMFiA0IwxeVP3cfVD92Plufm2hWfpsuQT7lH4YyxPqzqQoz2EWac9DjTV/ycW371RZ7xH2BuWqR2UxkTPSIGOUjrtEU8vGA1F4Q2c8tpVyKabASTQa5/9np8Rg+fuS+FkkpRcuvPEK3Wt/Q5SwaRBedUUz3TzzN/OcCjv95L/YJCll58NubLvWB2vsff9H+mYDAIQDoQQhSNmEQrsWyYjJT7hVzsSQACZnPR8Wvkf6hJhTPpFJvxZ0KMGv10BGwEa2rII/5ydsfgkq/Suf5+on4rTjWMpskUl+n16E4kUl6u45oNJJG9r582XWPPvXYwEOasl/bxTYPxdZgyHZjq6wnf/y/s1mUEHSL5gV6UlIEhbNQDQn8X2bSCbNTXzuqOrXynib39udkSR5oOed3s65juPgl4Fr8epOn+DXqQpjth+T75CSIXXca02q/x5MAkriq+nf+1fpnfBY2cfcoHGG/+FY9PSrKzajtTJhUys+kX7Jp5LTtXfoeZG7/PF/t7mXrZUn7VVs9m3yLabDWcM/wwqqhywL+C6tgw7nAf7mCCGfzfDl4UaGWIVl6acZ5nTFNrFzFK+WSFWkLGKn5iMPOCGiUtwmzFgLnAxkN1ZmIWkXRPhOkvtPDDp2/GOJblUMN0vlJ3CXGjmfmOERaPCBhjk7EV7mXhkp1ULfk1v7nlBh51vciqfV5K+2zEBYn68sXctmAGm7xFXDH8FDefeTWC1YOiKnxp/ZcYTYzyt0MnkWl6lJKf/BhTddXb/qz95Q4u+upcdjzWxc7HuultmWDl5VOoqvb9u1/jfyVRFJlcN4X+ticwmOykhDRpNUFUza2T8VsGMQkFiKKeFv7tqi2dRauwm4JkjE5jIW5JwxLpha91g5z7PB9vHsQV+ittFVZ82jhkbMhy7tfZv3b1v7y+rdht4YY19S9PpdQdO68UtD7ySFrV4TT8HfFXki7YPHNRx0TK1W4SZWtQ43GskXwCLpnC0QgOaYSQOXevzjeMk4xlsetBmu4YK/VYeWL/EIqqIYnC66ZDAuzsCQC5gO4lR0vVr9MdjR6k6U5Y5sZG7MsWIzSvo3rmLCYODrNs5rPcmVrOpSvXMm3vLjojz3GzrZV7P/IxlJvuobb59xyc8nF2Lv0Gs/f/mlN+dh+zPrKQH6dK2Dkykz+VX83MYBNzhjcyZC1ic+V5LPeYcQWiWEdGkbNxNHJZ5lTZhCYbQfYgyF7CmoVYWiAuaOwxZtllyhIji9ssY611Eqh1oY4mCe8bwx1P8P+6fk9NUyuaZOTnSy/jUe9sZJfEual26vvy0TI+fPUPs2J6HPeCX/LH715PW7yNc/YWI4oaQoGTZfmX8505XrabLHxo4GG+f+bVCI58AH6262dsHtzMT5QLEf/5dzxXXonzjDPe8ectySILzq6mesbhUbVf7WHKsmJWXj753fg6/6t4vV4mFyygP3s3JpufkBYgJUkEyY1gOuVOzAY9MHgnCgpKkcUkBdE0250+jA4j4ZiA5fkf5OqlhfpYY8onrvhYb7NTSxtiKve5/2tX/2syRfYHE3z1vr0AeqB2jEkuE0gCmfEj18Ert+QC7v6siqqqiKKIw1BIQithstBDi72QKkDuVQm6coWAy+xbiTAD0euloSKN3aOPUuiOvQqvlYyiMRBMUJZ3eNbK/6nlKNVfBxST78g9rHijVP16oKY7Gj1I053Q/Nd+luj5FzJp8lKeDJVw7shj7M6fw2f2tPHQ577CwHd66J7Xxrfaf81PvvkdhC/+D7HWv9A16Wq2T/4Us0NPkPfzB/h/i6p47qTnuHfoMnYIc9jlnsHkyEHmDa6nK+AnmFfJFWunkldWT/dggtGhKMloBiWeJatCTFUYRGFIyTCRyKAB+YU2Tp9XgksU2bpriH0PduIwCnw3+giLNz5FNiTRW1HD1yZfxojDS6k7xkWhIMaxGgRDhqq5t7Kkopo+wyX8/dNXoyRTlEoWbI0BRE8xNRMXcePcfJqMRj7bcxdfOf2jCO5cgeknu57ktn238WHHGsq/9yCmmTMpuOGL785n/qpRNatDHwk6mp79A6AlcBt8xDIhIjYnAdWFRUohqV1YzHOOdxP/I9nMRmRbisKwilYiESrIJxocIH/jrQhqLtNjXmqYKw1jvBjaSMYbR0rmOko3P3HwNan8ARIZhZufOKgHaceYIAkY/FayQ7EjbrdJEl5BI2CyEAqF8Hg8mJJmskoJDXIbv1I9VJvNZPa0kl1egmKIUSq9yIGhNZjq6ki1th7jM9Lpciq8uftN93g8F6Ttuft1tRyn7LiRc8QP43esAt44Vb8epOmORg/SdCc0c2MjjjWrYedDzF54Nrs7olzlvY1fmj/HLc0RPvqxG+m/63M8NyXEPzu+x/nf+jp8/dvETCa6Ky9hu201M6+cS94/vsuKvSIz1/yYffMbeGbsQ2ztmMx+5xQkNUteIsDPnxsgZQxS5TEyrbIAk8fKSDTF/oEwfeHczTffYWL1lAIKnGYODUe4/5FWFFWj1i3yQ8OTzF3/CKkhAzG7nR8tuJAXCqdjLpC4UBhi1oSL0GgNZl8r9f5fw8Qc7npxgujEj0kaFQ7URVg8ewxXshwOnskPFpfTbBC5qe23fHzt9Uj5dQAcChzixo03MtcxhbP/0IxqNlPy01sQjO9eQPXSqJruyFRVY+BQBwAlUjnxZAjB6mAi7cJrTpBKDeqZHf8NGdMoJQENgDFfAQXp2MsB2kuMgsJXu/7AbflLIJG79geOUBT7jV7XvbcMRTZS7cGjbi83GRg6nOHR4/GgjaaJKD5KDVvY2zOAZcYMEjtexLN2IUFnF/mhLjTFRMpditb0CJqqIoh6/jPdsVXhzaXV756IsRRfbgQt89p7jKwm+ZLhbry2/wHeOFW/Tnc0epCmO+H5r/0skbPPwRNbgkXy4mtvY+6kLfxFm8daVzUfWPAZBjt+yM/8aeZF/kjh9dex8JZbUawm9haeA715lF/1GxoO3Y7z3nUsWN9C48mf4wsXX8mDffNo3tLKYMZFUHQQ00zsDYjsDYyBpiEKIEsCFoNIOqsyEknxxP5hBAHq82SuKe1jzcG/497cRXzYRNRo5s4pp3BP7UrUIhtT5BCf8hXTv0kjmIpidd2GNNjLltZSYBhBlthXG2FXTYArvBmKNBeDrWdz76LptBjgBwdv5dLzvoacPwmAYDLIteuuxS7buPEZN+muvZTfdhuGQj1pwrE03hclFR8BwCsXMBg5hN8uMJbwUmDLomkKZoue2fGdSpqGqR3LdXpG8wqwDWeO+L6S1AilQi+pbK6wcbHbQv8RArJit17v73gwFNmI7xpBiWWQbIbXba+1WzloyQVpNeXVZMcThAwllALuiT0wbQbJ2/6A23QeAcdd1I6HsZoHGErbyU8kyPT3YywrO/YnpntfK3KaMcoiPePx3AuhviO+r1gYRzxcfuKNUvXrdEejB2m6E56ppgbX2WehPXsP8065lmeG4lxdeDsHnFP51L52nj71XD5weze3pG7nBqmXu1zryfvwh1hy25+wWo3c61nNynYY9VzGwpsuwXb/z5H+sQ/14Ts5d/59XHTOx1ifV4PlhT9gPdRPX9iOokkgi4xb8wlY8oianNgMWUrEcRqEblYEdiK2qIS6rGQTEmNmJ/c0ruRf01aSKnbiSsb4uEPDuL+Ptq070bR21EyMVBB83kIaZy+gZcsG1s8ao80b4AK7RKPBwP495/HIvMW0GTR+cuBmzjjnJkyF9QBk1Sw3rL+BkfgIf504n/Qzd5B/wxexLVxwfL+g9yFHnpnCuiy9ewSsspPx1CCeTIKxRB4zC3MLxi16+v13LC1nMWaDWLQ4o3YfQdWAR3p9oNZvyqeIflJaLQA3rKl/zZo0AItB4oY19ces7bpXGApzIw6ZoRhSjft122sdVuImC50DHcwujoEGMW8dakBgjthKV/EF5Ksqlh47Q4fXpVUVPsbBzkuZ9/SzGEoKjuXp6HQAiKJAmcdC1/jhqbyuUgj1vu5946If/+G/Xzf7utesSYNcqv7rZl93DFqs+0+lB2m6/wj+a68l/NjjqBM7qPFX0XVwNh+f80tucXyZzzzRwp8+ej1dt3Ty1/yN3BDcxq8mudGuuJxZt99B6RoL33AuYVVM49n1ApUnf4M5n0ySuPeXCOu3Izz7C1ZaRcRpk+mpWcOEEkAIdiGFohjCfeSHc/V4zFoGWyaDFlPYnClDUjQGS7wcLKhkKL8As5LmpMF1lPeGMSaCxNUscXI3dL8YZ3L+EDXnfoaOZBHP/u2PbFsYp80T4EyTlcXOEFv3XcyDM05lxKDwy/3/w+LTb8RR9krtp5u338yWwS38yHoV0m//jGP1avI+/OHj9I28v5ntBiKpHiSzhbSQJqQEKNEypFUTRY5cgGA2Fx/nVv7neSkzY3/wS3ikNI6+ccaKvDwb8HKeb4hXV/5LCkaed83hgq2PY07dBbds4NxVN8H5S/TsjicIQ9HhIG0whvkIQVqVNZdUYe/IGOcM5GoOmqtLGd1kZY6xlY2mIs4RRZR9PQQn+1GEMJWuQ+wXbPT0aUwufeNakDrdu+b/JAa5xHQF940vzm1bddNr16QBaSSsQgq+5QZXKWeuugkWf0vP7qh7W/QgTfcfwVBSQt7VV6H94U9w3pfojedT13WQ1dWP8qTvDH7zRCef/uyPGfn5R3ikcD8/6nmUr8w4D7TL4Y47+N0pMb4/5Xz2H0yg7Bmjaw80LPkqM76YR2TDzwhseBTp0D5KtzVTpr3y/yoChC0mAjYzYYuZgN3GRJ6MioagqYBGSbSTomgXyDIGyYKm+hBNRbg9o1S076LRGcc/OYR63m95+oUO9jz3e3YvFzhgG2G17OEU/wAvtF7IvQ1rSUgpbtv7TepOuQl/3byX23H3wbu5s+VOPuE7n6rv3ItcU03x//v+mxas1r13QoODeGQ/w9kBghYZp90AWShw/P/27js8yip74Pj3Tkky6b0TkkgNHSJFQJGiKCpFRcHdVSzoDxVE1r7WtaEuTV1dLLhiAbsCohRZC70ISCekkE4K6WUyM/f3R0BBggWSTDJzPs/jY/Jm5p1zZ3hO3pP33nOPYjB4ykbWf9LJnRkVR5Unap+m1hBMZpEP6QGdiDfvA6AAM6sDLuDKglVYtKP+BKWZsGQqYy6fx5j7xztvIOJnRj8PDL5m6nIbbh6ScLzDo11TlJ6P2dtERLcO5K72o7dXCv/KrWR8585UbdlKcVQ05b6HibBXYvYu4sDGbDr1l30IRTNooDHIDWoWB+3laD0Y1f1YvjlWxDm8AqG6HB976c+PZ8lURl0+j1FXrXDKEETrJEWaaDVCJk+m5KOPMR1cSr/2V/J9lpWJIYvZF9CFWR6xdNxcxON3vkHBf8bzXvBh4g5+wMSuV2CafhcFs+fweEkR+yffx5x1BUTn1OH4IYe9P+QQ1m4s3W+cgnf4FgoK3qM8fQvGEvAwhOBr6UhkaCLxEYl4RsWjzRb25pSwKTWVtKw0wutqiKoOwp6XhL0mBJNXOW3iDxL11Yf47LYRfe4RfNv5Uz7yXT57+zPy0lPYPsKTnaaDDFORXBqVysrDV/Nh4tVYHBW8u/0hQkY8Q1y3wT+Pe13OOp7Z+AxDQgdwyfwd1GlN7EsvYfDxcd6H4ebqamvQpdVEBUVTWp1LhacfBX4ecBSCPVPw8+uKwXDqGhxxeg11ZtQORU2Kwtth4IeCwWw5vz/7rWEcOvAd/6zegUVbTz5JXXX9hVJ3KdJaCnOUD3Wn6fAYf2yvtFKLLxkZh+kcew4hbePZYQujJ3lYc3dj7tmL8o8+pCC5G8XBJhIycgiL/R9Z+4KprrBi8ZUOtKKJNdAYxEPXMo1FFFQ8XN9mv/v4n/NO3fNJeKqjJ59DcpM4A1KkiVbD6OdH2NQ7sT/+BDvbdSbWHsbOvcOYnjyTf5hfYMbRI7y335MXJ7/P3/47jpnBEJzyGZfElmB+5glyH3+ahAduY/HMmawN6MTCNano1Ap6HCqhIKUUrXwxhN6JbwT4h6Rj8NhLoXEnqmo1OvUbHPt8qKsOxFoeQcjReHyKBmC3+mFVDsISKunQxY7/J0uofXUt3omBRF+YirlTf1IS/4+vXniVOuXgx8t8+cm+h5EkMjJ2F18cmcgnsWOJqSnk9Z/uRw+fTfuevxRou4t2M33NdBIDEpjxlZnqgwdp8+oreLRt68RPQqTvW4ECvAJryc8vwmYKosirvijzZgsB/lc7N8BW6LQdGGscVIVHU1Cazd2DXuGZjW8xyBpLdO2mhh9/mkX8wjnMkT5UrM9B2zXKePKdfz+TkUgPE2V+gWSnZdNrQG8MBiOO6N5Q9xM9OEh2mwH419ZCmhdHhnqQmFFFp8D1ePRLQnG+k0Yl3MpvNAbZWlT1815ox3lU5vyp8whxOlKkiVYl8OqrOfr+IjqsX03Z4DtYV1uG7UAUU5OeY6b/I9y5J4MF5kTemvQJE94ZwwOh4Hd4DQN9U/F6fTZZj75A9s030+OqKxkxYwZ5ePLljlx27SqgJr2C0OIqwgsMlBMFRAFDTw1CaQLCTST29CO+azSxCRYq3/8vRQ8twIomcrCJwOi92M+bxtcpfux6ZT5+HeL5ukMmGbY0RqsuDGmzmbfLbuPriBH0Kslg7q6HqLhkPr2Tz/v5ZTLLM5myagoBngH8K30A1SvfJPyee/A9Xy5MnK3SL5iY83Ox6LZk5R0hPC+E1K6BeJuq8TSU4e/f3dkhtjqn68yovYyU+USRbUlh64o1HA2vpM4zmmzPcNrU5p96ogCZZtqSmKN8wKaxFVVjDvc+5efd/LzZ6R9MnmE3nsfWrQV07E/l9vfoazzIV2os44Hwwhp0aAdqfPcSV1PNka6v4eE9uXkHI9zTaRqD5OgQMoqqODc++KTjZR4RBFgbaK0vuUn8SVKkiVZFmUxEPPQQtddfz67STxnkN57VhXWcl7WM62IXsDD6Jm7feIiX7Iks/MvHXLt4HHeEwwtHshm24joSHn6Kgu8KKH77bSpWriJ40iRumjgB45Bz0FpTUlVHXkkN+bkVOKpt2KtsBFrMBHp74OVjxifQE79gL8yeRmxHj1KyeDFZd7+LvbAQ/57RhLfZjikmhsPnPMXyTzZQVVpK7BVDebXuS0rqirneMoCkiO+YVfMQ2wJ6c1nuLh488E8KL3uHvsm/rEErrS1lyqop2LWdl5lI9SszCRh9BcE3TnLiuy+Oi43qxNG4QOqs+9gS4cvVKWmsq+lEuKUMAH//ns4NsBVqqDOjGQeV7QPJrYrEVLyBV4uX4+lfQon/QJ5OuIUX9z+FSZ+wiNRsqV/EL1qMnzs85laepkizsMrDi0JTLdYAhQcQ06kLuev9GRB4kEfTq7kkMJC2hYUEhl5IbvBu4jNz8SWZ2to8LBZpwS+aWAONQbTZwgtV44krOnUq7wf+k/hr4Sy8qP3loOQmcQZkF0jR6vj064vfJSPp87+9bPT5gSRbLOvTLuHy0hWM0Z+yLdGTv687RN6OGhZP+Ix4SxwzwoNYjAXDV9MIj91C4oK5eHXvTsGcOaRcOJTcRx6lcu06Aj0UnWP8GZIczdDBcYy4OJFzz29D++QI2nQOJsAPqr9dTfbdM0i5cCgFc+biFeVD/KhaYjpvo673lXxachEfvbMc3+BQwiaPZqb1ParqqpkeegFtIn7kYdtzbLP0Zuqhdfx9/0yOjPn4pALNarcybc00siuyeSngVuyPz8KS3IfIJ56QRiEtRKglFL+CzlgDMsgIiSQqspq00ra0D8rDbA6RjazPwJheMTwzrhsxgRYU4GMqY5ZaxqbDN/BS9hyetmQSFnQAc+1eigKC+DpwMLsTg6kxeQAKAtrA5fNkzUcLYw73BoM6bfOQ7r7eaKUo9vHncOZhAKLadSSnxp8Iey7G6iJ2RSXgk55BhGUkR0LNKK3p4z1RCjTRPLqPr88tAW04nmtUj4nc7/Eh09f1g9ld65uLHPNeTX/eC59x0uMlN4kzIXfSRKsUce+9VPzvW87duYeipA6E2YJYt/sKJvR6hypvP1Z0Gs5DW9O5ryiCt8e+z63Lb+Epwx52HG7LEwdW43FwFXGjr6fmpnkUfbKS0qVLKfngA5SXF57t2+PZrh1Gfz+UxYKjvAJbcRG1Bw9iPZQKWmMMDCSgfyJBIbvxMq/HGnUu31f1ZNPn+7H4VjBw0o18UruV5ZlziKyO575uPdhZt5eX9SxsyotXdiwh9ugySq/9nP6dE38el0M7eHjtw2zN38qs2Luw3DcPU9s42rz8MgZPTye+4+JE1cWl+BV2ozR+OT2MNRzo3YO6Mg86BKcQENBTiukzNKZXzM/t8j+e1ZtLSzMw1toA8Pew81TeDrwCAvkqIoigqnIKogzk1g5g5M1fODNs8RuUyYA53IL1WIv9X0ty1P+tuNg/mIyMDJKSkjB7eVEd0BlIY5BpL9/GJjNg74/Y16VgOmcA1fu+wWvP56hk2YJENJMTGoMc7/YYqX/p9siSqQBYk67icHEVxd3GwMX3OSdW4TKkSBOtkjkqirBpU9HPzuSHjku4kJv4vq6aHT9dxKRer+Dw9GRV0mCePHCEKQsr+c81b/DUj/9kKV9y4Eg7ZuSU0H/LArx4g+iuF6LHTaEy34eqvRnU7NtH5dq1OCorcVRXY/D1xRQUhEdsJP692uDtnY23dT1K76E6pCc/VJzHxm/yMXumc+7l41C92/Hghn9SYMilX+VwbunnxZulis/Vw0RVVPLmrg/Jsu7BeP1nnJsY+fOYtNY8u+lZvkz7kr8n3ET8o++CxULc/PkYAwKc+G6LXyvZm4nn0UTsDkUflcVuv+FQBucEbMPf/xZnh+cShlVkYVS2k45ZtIO7Ssp4t1MonUrTUQYNtXFOilD8UZ7nBFKxMRdHjQ2D18mXHcGHKwmwOqgKj2Lfvp8YMWIEJpMJzw4XUJO6glGG9dzpOw1TmzaUr1hJzJMTyQxZR/u079CVhSifUCeNSritBro9Hu/eeDjyEuwOTWKYdF8WZ0+KNNFqBf/1r5R9uZyxX6fz1MQ3mJp/KytqbBz8aTA3dp+Np0cdyzoMpSa9ipzndzL9hgfpGNyRedvmcX94MEN2xHBxbQE9HJvwTV2DH+DrG4kaHA+jEkAZQduhLAeOpkHFegBsOpDD3slsSjdzeK8D7wArA66aSPyQ85n53Yt8s3E2vrYA7o18lMBu27irpDdpqh39s4/w6oFP+NysufC2d+kQ6X/SeF7Z8Qrv73ufGxMncv7ctdSWlND2nYWYo2VT5JYmamBXbsj7NwNqPGkbmc/S7ADCLIUEeJbj79/D2eG5hABHbYPHw7SNWk8LUfrYJvM+vZszLHEGLN3DqFibQ/WeInx6R5z0M2tqKZ3NmuLwcEp/LGXjxo0MHDiQ6E5dObQvmvM8d2HTmryeAwhd/gmRHk+zKGoEVcZAJtbUES/XwqK5na5LY2kWhwrqp/WeE+bbjAEJVyVFmmi1lNFI1JP/JO3Kq5iy3Ys3e33IDblXsqJCY/6pluu6vYSfRyWL4i+nJNBO4Yvb6N9vEG8M7cXjWx7l0x5pZHt1p+deX/wOHSDOp4RI72qCS9PwNe2vn7KmFNX4UG4PJLcslJRCMwW1PnhYvGnbrRejbxhKaJeOvPrDAqYtvYpaVcPA2ouZPvw6XstdweKS0Zgddm7dncYdR5bxYmAnbr3ldmICLSeN5c1db/LKjlcYm3AFVy3KomL3bmJffglLly5OenfFb9Fas6fyJ4KsoZwTnkXKnjC6h+4HwN9POjs2hkqPQHytJaccL6b+4qetIQ1lM9Nl+Nhmjkz8WR5xfhgDPaneWXhSkabtmppDJXTp5s3bNgeJHTry7bff0qNHDyI6dGalqRNd1AouC8rk9aJ47rfZqPp2LasjriXLYmWGn+xFKJzgNN0eCYgl9ViRJnfSRGOQIk20al4dOhB2+xSYM5ek9kl8HrGKS/KHsKZco3+CMd0WEGvO5OWgKbw5Koicdfl03woPDnuBTTFf886BhWxNtDJi8DD8dBIq287+vFxKj+Rjs9Zir6vDw+KNl58/gYkRJF2YQMQ57Ylq35H9JSnM3/Ae3+yaSq2hmnZVPbi9x+1UxtiZkJ5DDhfRoewQd+yoo5d1FS+0vZR//O1y/LxOvrBYuGchs7fO5pK2I7n1K03Z6m+I+Mc/8BvaQPt/8YcppZ4HLgeswCFgkta6pDHOnV+VT7UuIS+nC7k+dVTavOkQvA9f3yTMZv/fP4H4XSX97sHz+0cx88uUxzqHgSfPuZXw0jJ6mn/EXB5MWGyQE6MUf4RSCkv3UCrW5uCoqsPgXZ8Dq7YfwVFmpWdUFG+UFxM/+ALSUw6yePFiioqKsJvaYderuDc+hUHFQ5kaGErx8uVsn/h/XBOQg0G1zo2smzI3iWbQQLfH490bD+2vINzP85Tf80KcCSnSRKsXcsstVHz/Axd/tJd/3lbKxshAhuT15NtyRd12T/p1W0m4Ryqvez/LosF+ZBZD4fJsgo09eDi5L5ujvmZl/nK+qltBlE8UfQf2pU/ECGL9Yon0jsRgMGBz2DhSdYT0sgw+TFvExi3rKdIFGB0mOlT24i8d/0Zscg8e3buZzenhhDmquPLAGv6aGUUBW/hi0J08PbI7RsPJDSUW7lnIc5ufY0TccKZvDqPkkwWETplC8F+uc9K76VJWAg9orW1KqZnAA0CjrOQurCrBUZlAYFY0KWH1bcU7h2q6d3ulMU4vgIghU/hy03eMql6H0VBOlmcEcyIm8H7cFVyzZR2+PYpw5LRzdpjiD/LuHkbFd9lU7y7C59xItN1B2erDmKN96NM5HDYVk2n0pG/fvmzYsIHExEQ6xvQkc/l7RGd8xbXnXs+SfT0Y//03RA25gmt6DcFsbrV3K5osN4lmcLyByOon0KVZ5OoQwkY9hbn7eA5+v1buoolGI0WaaPWU0Uj0zJmkjRnDwyv8uOmKVfiZfRma2ZVvgLJtAQzs+gUPqutY6f0Ii4K7sH1sMJcUKtqtLSaiehDX+w3kSPu9HPLYweq0b/j80OenfT0PmxcxZR0Y7H0ZVyWPpiw+nHlpB/l+ewY+2sJlpctI2mni4poY3jMdYfA1f2dG18hTzvPazteY9+M8RrQdwX27Eil+42UCJ1xL6J13NOG75T601itO+HYDcFVjnTt/VzWVh28lMaaCHeUaP3M5fTpMxGKRzUrP2s4PYPUTmEuzOA9fHrddxULHcAworFUWfFfnoB2ZdFlXQxTf17e/HvaItLdu4cwxvhhDvKjafgTvPhFUbs3HXlxD4PVJhHl74mc0sLO8iqdHjCA5OZnQ0FAcdjtrl8YRX7WTh/qZGLNjGFcc+p4bP/qQ9mNHOHtIZ6wpc5NoWstSlzF321zyKnOJDICpNm96lkPeT/8jfOUTfFqRTY3JH2aaoPpo/dRIyU/iDEmRJlyCR2wMUU88TvbdM3gx4QImdV3EHR3+xiUHerKKXaz88TouSvyES2Mfob/qwqd+D/ORNuMzJpiLDF70yq4jYa8PIflJnIuDUq9CKjyPUuFRAmgMGAnzDaFjVHuSOidi6xDINxWVTM45QsbOQ/jrcsbZVhJ3oJT4vO4k2s281DaGf1x75Snrz7TWzNk2hzd3vcmoxFHcvS+RopdmEzB2LJEPPyzt25vGjcDixjqZd6A/RrJ5ubB+fVTv8B1ER13fWKd3X8daWx+fRhRGOQ+Y36W0zsIXNYMwZVVzqeEHnjW/jjfW+uec0P5aLoRaLqUUPr3CKVt1mLznN6PrHHi08cOrUzBKKbr6WdhWVoXRaCQ0tL5jo8FoxKPnlZC2E489H/PcLXeydN/5XPnTaq55cBH/fnCcKzRoaNTcJJrOstRlPLbuMWrsNQDkGhWPhwbxGMVceuh9FIACb3sZHJ8JKflJnAWltW72F01OTtZbtmxp9tcVri//uecpfvNNsu8YzXS/ZUzzvpmBPyWxwrCDo1TQPnA78e23U2MxUmAezhq/ySwvMWHVmlCzifMCfEgwmIlxGPA1KLwNRhwWA9WeiozaOvZW1LC5tJI8ax0ASXoXg/S3xGYVU5rejX61SWwxGAm7tDfX9Y/H8KvpjXX2Oh5d9yhLUpcwvsN4btsVSeG/ZuE/ahTRz81EGY3OeNsahVJqq9Y6uZlfcxVw6m1KeEhr/fmxxzwEJAPjdAMJTyk1GZgMEBcX1ycjI+MPvXZ5TR1rUwp5b/X7DIhewW1XLZcC+2zN7trggvwsRyiDrPMA+MFjKrGGwlOfG9AGpu9q6gjFWdB2TdXOAqq25lObVkrojV3xOicQgJcy8nkyNZdN/TsTZ/llT8jinGwqZg8gwh823LaNyev38PHD08jq0peL3nn1lBx7Os2dnxojNx17zBnlJ9H4LvroInIrc085HlVnY0VWzm8/WfKTOI3fyk1yJ024lPAZd1O7fz8x//mSBx8aw9NVr1M7+CbGbh/EptI97CqBA5u7cX7MSqLiVjC+bhVXqjhSAyexRfVgW3kVX9TWnfb8MaYaztEHuVx/TzfHDmy5QaRndse36lw62qL5X4dIbruqK+H+Xqc8t7S2lL9/+3c25G7gjh63M+4HG4UvzcL/0kuJnvlsqy7QnEVrPfy3fq6UugG4DBh2uosgrfV8YD7U/wHpj762n5eZi5IiqDn0GRaLQQq0xnCa1tbRquiErxso0H7juaLlUMb6u2k+vcLRDo06ocC6PDyQJ1NzWVJQyu1x4T8fD46OITX6CuJKF3Jw+RysbcfjcelI4j77nLr0dDwTE5wxlN/VGLnp2HnOKD+JxpdXmdfwcdMf+N0t+UmcASnShEtRRiMxs/5F+rUT6D17BVMeuIJ/57zB0X7lTDk6gYSNe1nncZDvs0dCtpXkyI2ERh6ivX6c9sB12giGSI6a2lNt8KZamzHYCzDbswkmH6+6GhwVFjJzO3OgYCiRtVEMtSWwPSSEruM780hcw53mUo6mMHXNVPIq83hywBP0//QghQsWEDB2LFFP/lMKtCaglBoJ3AtcoLWuaorX2LBhA56eRfj6DmiK07uf07S2ztEhJ3wdSmxDhVqArAdsTdSv7oC1tXjS3c/CkiMlJxVpAL3vnMPRZ1cyJPczPnV05uv9PxKREE2E2YgnrU9z5CbR+CJ9Ihu8kxZps//+kyU/iTMgRZpwOcaAANq89hrpE65l+Nz1GP4xkZfS3qMsvpxHbrmX2GWxpOSksc0jnS15g9G5g/Eyl9ExdB/h3lkYvXKJ8MhGK4XWCpvVk+pqf3IrupFX0hab1UKiI5IRthjywsPxvawdt7UPOW08Sw4t4ckNT2IxWXhz6HzCZi+meOlSgiZOJOIfD6EMhmZ8d9zKS4AnsPLYXa4NWuvbGuvkR48eZfOWRXTtWkNC/MjGOq17G/YIts/vxHRszQdAlfbgOdvxtRya52zj69ekKesvzzvW/lq0bleE1d9NO1xde9KUR4PJxLqB9zHq2+lMzvyStrdNpfOgIXh6ezsx2rPSpLlJNI1pvafx2A8PU6N/mW3j5XAw7WjJbz9R8pM4Q1KkCZfkERtD3H/+Q8Zf/srwF77Hcv/NPJ/+OlkVWcyeNJs+2fF0+F8meWnZpBjzyFQl7MwLAPo2fD5tJsoRyAB7GIHGUOo6h9Px4kT6hZz+IqHcWs6zm57li0Nf0Du8N890f5C6h56lbMMGwqZPJ2TyLTJFrglprZusP7vWmqVLlxIWloLB4EV4uBRpjaL7eJ78Yjc3O94hWhWRo0N4zjaeLxyDMODggph1rC1K4n7rzdxnWkyUoZgcRwiv67/Q0z6QMc6OX5yV0015rLE7eNDch94+cYy2HIQLBoNnqy3QmjQ3iaYzKnEULL+PuZ528kxGIm12ph0tYVRlFXj4gCUYSrNYFhTGXF8P8oyKSAdMSxzLKGkaIs6AFGnCZXklJdHmtflk3jKZgU8vp83Tj3HfvplMWDaBJwc+yXmTzyOopCPxOwuoTS2l6nAJpdVlVKs6rNRhwohZm/Ax+WAK9cc7IYDQXhGYY3xPmapzIq01KzNW8uymZymqKeL/evwf11uGknvDndjy8oie+SwBo0c34zshGltaWhqpqQcYNDiT8PCRmEytvsNci/Hfir681cAfSzSK5/IPEmr8N/9x/IsLrHOxcewutBUsn/wEwJheMc0ZrmhEp5vy+HH+UfLrNIXDnyHqi7/Bh5NgwiIwyiWMaF6jCrIYRQNLA61V8GBOAx0g4bGsryC1f32RJ8SfIBlOuDTvPn1o8/rrZN5yC23ufYWFzz3NvZkvcuuqW7mm4zVM6z0Nv/Nj8Ts/Fq01sTV2HFV1OGrtGDyMKC8jBh/zH77jtb94P7O2zmJdzjo6BXdi3tB5xP6QQuYT12Hw8abtwrex9OzZtIMWTS4hIYExY+IpLKoiKnKcs8NxKdGBFrJLqk85HkYZYaaVHLGN4kUifinQjqmus/P81/ulSGvlxoUH8dihHF7KyOeOthGkV9cyJyOfbr4WuvYcBfZ/wdK7YPk9MGoWyGwE0ZxOs272+Jqzudvm/lygHVdjr2HutrlSpIk/TRbDCJfn3bsXcW+9hcNaC5PvZ0HAnVyfdD0f7P+ASz+5lHf2vIPVbkUphcFiwhRiwSPaF1OoBaOvxx8q0PYW7eX+7+/n6iVXs6twF/ck38M7588n+PmF5N7/AJakJBI++kgKNBehlEKzHk/PSIKC+js7HJdyz8UdsZhPbqRjxMFfKaXM3oeNtglU6oZ/deU0UNyJ1uXm2DDGHJv2OH3fYS7ecoBym52n2sfU5+LkSTDwLti2EAr2OTtc4W6GPVK/xuxEJ6w5O20HyNMcF+K3SJEm3IKlW1cSPvgAc1wc+VOm8rfvDCy6eCEdgzsyc/NMRnw0gjlb55BR9sf3oCmpKeGjAx8x6atJjF86njWH13BDlxtYNnYZYzLDOXzZaEqXLCX0jjuI++9bmCMimnCEojnVWgspLv6OyMgxKCWdORvTmF4xPDOuGzGBFhQQE2hhfKgFo3ckW8sfYWlgJqHmhn91Rf9q43jR+pgMipeT2nJVRBDv5xbTxsuDr5M70DfwhCnFwx6Fyf+D8M5Oi1O4qe7j4fJ59fueoer/f/m8nzeqjvRpaGu80x8X4rfIdEfhNsxRUcS/+w75zzxD0Wuv4bX2B+Y9/jg7ulbw3r73WLB7AW/seoNY31j6RfUjMSCROP84vE3eGA1Gyq3l5Ffmk1qayvaC7ewv3o9d24nzi+PuPndzZYcr8UjJIv//plO1fgNeSUnE/vvfWLp1dfbQRSOrsxYR4N+bqMixzg7FJY3pFXPStMWyfUXc9tnblLTbSnnWQO6/uAMPf3OQ6rpfWl9bzEbuubijM8IVjcyoFPM6xzEuIoj+gb54G39VlBsMECl5VThJ9/E/F2W/Nq33tJPWpAF4Gb2Y1ntac0UnXIj6jT0Um0xycrLesmVLs7+uEMeVr1pF7qOPYS8qwv+KywmbOpXiIBNrMtewLnsdW49spdxa3uBzLSYL3UK70TO8J8PjhtMpuBM1u3ZRvGABZV8uxxgYSOiUKQRNnIAyuc/fQZRSW7XWyc6O42xIbmqZ9PbFFH36IMEUUmsMxzLmKT6zD+T5r/eTU1JNdKCFey7uKOvRxGlJfhJNYucHsPqJ+s2qA2Jh2CMs8/Vh7ra55FXmEekTybTe02Q9mjit38pNjVKkKaVmAC8AYVrrBnYZPZkkGtES2MvLKZr/GsX//S+6rg7fIUMIvPpqfAb0R3l5UVJbQlZ5FjX2GmwOG75mXyJ8IgjxCsFoMFKXf4TyFSsoW7qU6h07MPj6EjRxIiG33IzRz8/Zw2t2chEkmsTOD2DJVKg7Yb2Z2XLSFCMhfo/kJ9HoJDeJRvBbuems/8yvlGoDXAQcPttzCdGcjH5+hM+4m6DrJnJ00SJKPviQijVrUJ6eePfpg2f79sQmJGDw80WZzTgq87EVbCA/LY3qHTuwpqYC4Nm+HREPPkDAuCsx+vo4eVRCuJjVT5x8EQT1369+Qi6EhBDOI7lJNLHGmIs1G7gX+LwRziVEszNHRhJ+112ETplC1abNVHz3LVWbNlO1aBG6tvaUxxuDg7H06EHA6NH4DR+G5znnOCFqIdxEadafOy6EEM1BcpNoYmdVpCmlRgPZWusdf3QfKSFaKoOHB76DBuI7aCAA2uHAlp+Po6oKbbVi8PbGFBaGwdvbyZEK4UZ+Z18iIYRwCslNoon9bpGmlFoFNNQ79CHgQeqnOv4updRkYDJAXFzcnwhRCOdQBgPmqChnhyGEexv2SMPrPo7tSySEEE4huUk0sd8t0rTWwxs6rpTqBiQAx++ixQLblFJ9tdan7NqntZ4PzIf6xa9nE7QQQgg3cXxtx686qMmaDyGEU0luEk3sjKc7aq1/AsKPf6+USgeS/0h3RyGEEOIP+419iYQQwmkkN4kmZPj9hwghhBBCCCGEaC6NttOu1jq+sc4lhBBCCCGEEO5K7qQJIYQQQgghRAsiRZoQQgghhBBCtCBSpAkhhBBCCCFECyJFmhBCCCGEEEK0IFKkCSGEEEIIIUQLIkWaEEIIIYQQQrQgSmvd/C+qVAGQ0cwvGwq4w0bbMk7X0prG2VZrHebsIM6G5KYmJeN0La1tnJKfzkxr+5zPlIzTtbSmcZ42NzmlSHMGpdQWrXWys+NoajJO1+Iu43Rn7vIZyzhdi7uM0925y+cs43QtrjJOme4ohBBCCCGEEC2IFGlCCCGEEEII0YK4U5E239kBNBMZp2txl3G6M3f5jGWcrsVdxunu3OVzlnG6FpcYp9usSRNCCCGEEEKI1sCd7qQJIYQQQgghRIvnVkWaUupqpdRupZRDKdXqu76cSCk1Uim1XymVopS639nxNBWl1JtKqSNKqV3OjqWpKKXaKKXWKKX2HPv3Os3ZMYmm5cq5CdwjP7lDbgLJT+7IlfOTO+QmcI/85Iq5ya2KNGAXMA74ztmBNCallBF4GbgESAImKKWSnBtVk3kLGOnsIJqYDZihtU4C+gO3u/DnKeq5ZG4Ct8pPb+H6uQkkP7kjl8xPbpSbwD3yk8vlJrcq0rTWe7XW+50dRxPoC6RorVO11lZgETDayTE1Ca31d0Cxs+NoSlrrXK31tmNflwN7gRjnRiWakgvnJnCT/OQOuQkkP7kjF85PbpGbwD3ykyvmJrcq0lxYDJB5wvdZtPJ/mKKeUioe6AVsdHIoQpwpyU8uSvKTaOUkN7koV8lNJmcH0NiUUquAyAZ+9JDW+vPmjkeIM6WU8gU+Bu7SWpc5Ox5xdiQ3CVci+cm1SH4SrsKVcpPLFWla6+HOjsEJsoE2J3wfe+yYaKWUUmbqk8y7WutPnB2POHtumptA8pPLkfzketw0P0lucjGulptkuqNr2Ay0V0olKKU8gGuBL5wckzhDSikFvAHs1VrPcnY8QpwlyU8uRPKTcCGSm1yIK+YmtyrSlFJjlVJZwABgmVLqa2fH1Bi01jbgDuBr6hdKfqC13u3cqJqGUup9YD3QUSmVpZS6ydkxNYGBwF+BoUqp7cf+u9TZQYmm46q5CdwnP7lJbgLJT27HVfOTu+QmcJv85HK5SWmtnR2DEEIIIYQQQohj3OpOmhBCCCGEEEK0dFKkCSGEEEIIIUQLIkWaEEIIIYQQQrQgUqQJIYQQQgghRAsiRZoQQgghhBBCtCBSpAkhhBBCCCFECyJFmhBCCCGEEEK0IFKkCSGEEEIIIUQL8v9gfsC0Vo1RiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print sampled lines\n",
    "fig, ax = plt.subplots(1, model.n_hidden_layers+1, figsize=((model.n_hidden_layers+1)*5, 5))\n",
    "ax = ax.flatten()\n",
    "for i in range(model.n_hidden_layers):\n",
    "    for model_line in lines[:]: # hidden outputs of each sampled model\n",
    "        line = model_line[i]\n",
    "        ax[i].plot(X_test[:,0], line.numpy()[:,0])\n",
    "    # for model_line in lines[690:701]: # hidden outputs of each sampled model\n",
    "    #     line = model_line[i]\n",
    "    #     ax[i].plot(X_test.numpy()[:,0], line.numpy()[:,0], 'b')\n",
    "for x, y in ds_train:\n",
    "    ax[-2].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "# for x, y in ds_test:\n",
    "    # ax[-1].plot(x[:,0], y[:,0], '*', label='ground truth')\n",
    "ax[-2].legend()\n",
    "\n",
    "# compute the mean of the sampled lines\n",
    "line_output = []\n",
    "for model_line in lines[:]:\n",
    "    line_output.append(model_line[-1]) #the final layer\n",
    "line_mean = tf.reduce_mean(tf.concat(line_output, axis=-1), axis=-1)\n",
    "ax[-1].plot(X_test[:,0], line_mean.numpy(), label='mean')\n",
    "for x, y in ds_train:\n",
    "    ax[-1].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "ax[-1].legend()\n",
    "# fig.savefig('2layer-sin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 70, X_test = 1.4218782186508179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6abc3e9970>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_index = 70\n",
    "print(f'index {input_index}, X_test = {X_test[input_index,0]}')\n",
    "points = []\n",
    "for model_line in lines[:]:\n",
    "    line = model_line[0]\n",
    "    point = line[input_index,0].numpy()\n",
    "    points.append(point)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(points, bins=90, density=True, label=f'point density at {X_test[input_index,0]}')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}