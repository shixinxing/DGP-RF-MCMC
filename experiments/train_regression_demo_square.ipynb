{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 11:07:34.400246: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-08-20 11:07:35.604610: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-20 11:07:35.658626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2022-08-20 11:07:35.658653: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-08-20 11:07:35.662111: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-20 11:07:35.662146: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-08-20 11:07:35.663101: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-20 11:07:35.663355: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-20 11:07:35.664254: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-08-20 11:07:35.665009: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-08-20 11:07:35.665200: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-08-20 11:07:35.666509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-08-20 11:07:35.667164: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-20 11:07:35.674345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2022-08-20 11:07:35.675284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-08-20 11:07:35.675355: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-08-20 11:07:36.127436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-20 11:07:36.127477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-08-20 11:07:36.127487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-08-20 11:07:36.129542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21313 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:25:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.regression_model import DemoRegressionDGP\n",
    "from likelihoods import Gaussian\n",
    "from utils_training import regression_train_demo\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_square_data(num_training, num_testing, std_noise=0.01):\n",
    "    num_low = num_training // 2\n",
    "    num_high = num_training - num_low\n",
    "    X_train = np.vstack((np.linspace(-1.5, -0.5, num_low//2)[:, np.newaxis],\n",
    "                         np.linspace(-0.45, 0.45, num_high)[:, np.newaxis], \n",
    "                         np.linspace(0.5, 1.5, num_low - num_low//2)[:, np.newaxis]))\n",
    "    y = np.vstack((np.zeros((num_low//2, 1)), np.ones((num_high,1)),\n",
    "                   np.zeros((num_low-num_low//2,1))))\n",
    "    scale = np.sqrt(y.var())\n",
    "    offset = y.mean()\n",
    "    Y_train = (y-offset)/scale\n",
    "\n",
    "    X_test = np.linspace(-3., 3., num_testing)[:, None]\n",
    "    Y_test = []\n",
    "    for x in X_test[:,0]:\n",
    "        if x > -0.5 and x < 0.5:\n",
    "            y = 1.\n",
    "        else:\n",
    "            y = 0.\n",
    "        Y_test.append(y)\n",
    "    Y_test = np.array(Y_test)[:, np.newaxis]\n",
    "    Y_test = (Y_test - offset)/scale\n",
    "    return np.float32(X_train), np.float32(Y_train), np.float32(X_test), np.float32(Y_test)\n",
    "\n",
    "def load_demo_data(num_training, num_testing, batch_size, std_noise=0.01):\n",
    "    X_train, Y_train, X_test, Y_test= get_square_data(num_training, num_testing, std_noise=std_noise)\n",
    "    ds_X_train = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "    ds_Y_train = tf.data.Dataset.from_tensor_slices(Y_train)\n",
    "    ds_train = tf.data.Dataset.zip((ds_X_train, ds_Y_train))\n",
    "    ds_X_test = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "    ds_Y_test = tf.data.Dataset.from_tensor_slices(Y_test)\n",
    "    ds_test = tf.data.Dataset.zip((ds_X_test, ds_Y_test))\n",
    "\n",
    "    ds_train = ds_train.shuffle(num_training)\n",
    "    # ds_test = ds_test.shuffle(num_testing)\n",
    "    ds_train = ds_train.batch(batch_size) # try not to use full data as one batch\n",
    "    ds_test = ds_test.batch(num_testing)\n",
    "    return ds_train, ds_test, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_training = 60\n",
    "batch_size = 20\n",
    "num_testing = 100\n",
    "std_noise = 0.1\n",
    "\n",
    "ds_train, ds_test, X_test = load_demo_data(num_training, num_testing, batch_size, std_noise=std_noise)\n",
    "for x, y in ds_train:\n",
    "    plt.plot(x[:,0], y[:,0], 'o',linewidth=0.5, label='training points')\n",
    "for x, y in ds_test:\n",
    "    plt.plot(x[:,0], y[:,0], label='ground truth')\n",
    "plt.legend()\n",
    "# plt.savefig('square.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-layer GPs (fixing kernel params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "d_in = 1\n",
    "d_out = 1\n",
    "model = DemoRegressionDGP(d_in, d_out, n_hidden_layers=1, n_rf=300, n_gp=1,\n",
    "                          likelihood=Gaussian(variance=0.01, trainable=False),\n",
    "                          kernel_type_list=['RBF'], kernel_trainable=False,\n",
    "                          random_fixed=True, input_cat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.4142137], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.kernel_list[0].length_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.kernel_list[0].amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training settings\n",
    "lr_0 = 0.01\n",
    "beta = 0.99\n",
    "total_epochs = 2000\n",
    "start_sampling_epoch = 0\n",
    "epochs_per_cycle = 50\n",
    "print_epoch_cycle = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 08:26:04.908282: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-08-20 08:26:04.928324: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-20 08:26:05.526450: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-08-20 08:26:05.526561: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Sampling at Epoch 49  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 49\n",
      "Mean Log Likelihood -- train: -19.41837501525879, -- test: -66.80551147460938 \n",
      "Root Mean Squared Error -- train: 0.6450119614601135, -- test: 1.1678111553192139 \n",
      " \n",
      "#################### Sampling at Epoch 99  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 99\n",
      "Mean Log Likelihood -- train: -9.708231925964355, -- test: -248.1070556640625 \n",
      "Root Mean Squared Error -- train: 0.47099635004997253, -- test: 2.2337892055511475 \n",
      " \n",
      "#################### Sampling at Epoch 149  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 149\n",
      "Mean Log Likelihood -- train: -7.464330196380615, -- test: -149.24615478515625 \n",
      "Root Mean Squared Error -- train: 0.42066556215286255, -- test: 1.7356832027435303 \n",
      " \n",
      "#################### Sampling at Epoch 199  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 199\n",
      "Mean Log Likelihood -- train: -7.77556037902832, -- test: -122.47209930419922 \n",
      "Root Mean Squared Error -- train: 0.42800015211105347, -- test: 1.573885202407837 \n",
      " \n",
      "#################### Sampling at Epoch 249  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 249\n",
      "Mean Log Likelihood -- train: -8.039461135864258, -- test: -127.46150207519531 \n",
      "Root Mean Squared Error -- train: 0.434122234582901, -- test: 1.6052734851837158 \n",
      " \n",
      "#################### Sampling at Epoch 299  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 299\n",
      "Mean Log Likelihood -- train: -7.288422584533691, -- test: -125.65029907226562 \n",
      "Root Mean Squared Error -- train: 0.4164629280567169, -- test: 1.5939507484436035 \n",
      " \n",
      "#################### Sampling at Epoch 349  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 349\n",
      "Mean Log Likelihood -- train: -7.776122570037842, -- test: -98.72213745117188 \n",
      "Root Mean Squared Error -- train: 0.42801326513290405, -- test: 1.414961338043213 \n",
      " \n",
      "#################### Sampling at Epoch 399  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 399\n",
      "Mean Log Likelihood -- train: -7.6435675621032715, -- test: -125.87609100341797 \n",
      "Root Mean Squared Error -- train: 0.42490503191947937, -- test: 1.5953665971755981 \n",
      " \n",
      "#################### Sampling at Epoch 449  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 449\n",
      "Mean Log Likelihood -- train: -7.741800785064697, -- test: -99.68843078613281 \n",
      "Root Mean Squared Error -- train: 0.42721065878868103, -- test: 1.421773910522461 \n",
      " \n",
      "#################### Sampling at Epoch 499  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 499\n",
      "Mean Log Likelihood -- train: -7.4802632331848145, -- test: -122.46780395507812 \n",
      "Root Mean Squared Error -- train: 0.42104417085647583, -- test: 1.5738579034805298 \n",
      " \n",
      "#################### Sampling at Epoch 549  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 549\n",
      "Mean Log Likelihood -- train: -7.440936088562012, -- test: -122.34026336669922 \n",
      "Root Mean Squared Error -- train: 0.4201090931892395, -- test: 1.573047399520874 \n",
      " \n",
      "#################### Sampling at Epoch 599  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 599\n",
      "Mean Log Likelihood -- train: -7.934455394744873, -- test: -77.31242370605469 \n",
      "Root Mean Squared Error -- train: 0.43169671297073364, -- test: 1.2545602321624756 \n",
      " \n",
      "#################### Sampling at Epoch 649  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 649\n",
      "Mean Log Likelihood -- train: -7.489511489868164, -- test: -104.79301452636719 \n",
      "Root Mean Squared Error -- train: 0.42126378417015076, -- test: 1.4572348594665527 \n",
      " \n",
      "#################### Sampling at Epoch 699  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 699\n",
      "Mean Log Likelihood -- train: -7.506882667541504, -- test: -136.83494567871094 \n",
      "Root Mean Squared Error -- train: 0.4216759204864502, -- test: 1.6626399755477905 \n",
      " \n",
      "#################### Sampling at Epoch 749  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 749\n",
      "Mean Log Likelihood -- train: -7.543203353881836, -- test: -95.78118896484375 \n",
      "Root Mean Squared Error -- train: 0.42253637313842773, -- test: 1.39402174949646 \n",
      " \n",
      "#################### Sampling at Epoch 799  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 799\n",
      "Mean Log Likelihood -- train: -7.421690940856934, -- test: -108.40906524658203 \n",
      "Root Mean Squared Error -- train: 0.41965073347091675, -- test: 1.4818415641784668 \n",
      " \n",
      "#################### Sampling at Epoch 849  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 849\n",
      "Mean Log Likelihood -- train: -7.230910778045654, -- test: -134.17002868652344 \n",
      "Root Mean Squared Error -- train: 0.41507968306541443, -- test: 1.646533727645874 \n",
      " \n",
      "#################### Sampling at Epoch 899  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 899\n",
      "Mean Log Likelihood -- train: -7.7636003494262695, -- test: -92.70458984375 \n",
      "Root Mean Squared Error -- train: 0.4277206361293793, -- test: 1.3717743158340454 \n",
      " \n",
      "#################### Sampling at Epoch 949  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 949\n",
      "Mean Log Likelihood -- train: -7.6172332763671875, -- test: -126.95023345947266 \n",
      "Root Mean Squared Error -- train: 0.42428481578826904, -- test: 1.6020854711532593 \n",
      " \n",
      "#################### Sampling at Epoch 999  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 999\n",
      "Mean Log Likelihood -- train: -7.432596683502197, -- test: -154.9005126953125 \n",
      "Root Mean Squared Error -- train: 0.4199105501174927, -- test: 1.7679599523544312 \n",
      " \n",
      "#################### Sampling at Epoch 1049  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1049\n",
      "Mean Log Likelihood -- train: -7.636972427368164, -- test: -130.24533081054688 \n",
      "Root Mean Squared Error -- train: 0.42474979162216187, -- test: 1.6225225925445557 \n",
      " \n",
      "#################### Sampling at Epoch 1099  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1099\n",
      "Mean Log Likelihood -- train: -7.61295747756958, -- test: -109.28643798828125 \n",
      "Root Mean Squared Error -- train: 0.42418399453163147, -- test: 1.48775053024292 \n",
      " \n",
      "#################### Sampling at Epoch 1149  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1149\n",
      "Mean Log Likelihood -- train: -7.482264041900635, -- test: -129.51722717285156 \n",
      "Root Mean Squared Error -- train: 0.4210917055606842, -- test: 1.618028998374939 \n",
      " \n",
      "#################### Sampling at Epoch 1199  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1199\n",
      "Mean Log Likelihood -- train: -7.501524448394775, -- test: -101.07864379882812 \n",
      "Root Mean Squared Error -- train: 0.4215488135814667, -- test: 1.4315186738967896 \n",
      " \n",
      "#################### Sampling at Epoch 1249  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1249\n",
      "Mean Log Likelihood -- train: -7.550761699676514, -- test: -125.99259948730469 \n",
      "Root Mean Squared Error -- train: 0.4227152466773987, -- test: 1.5960967540740967 \n",
      " \n",
      "#################### Sampling at Epoch 1299  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1299\n",
      "Mean Log Likelihood -- train: -7.540990352630615, -- test: -135.03546142578125 \n",
      "Root Mean Squared Error -- train: 0.42248401045799255, -- test: 1.651781439781189 \n",
      " \n",
      "#################### Sampling at Epoch 1349  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1349\n",
      "Mean Log Likelihood -- train: -7.334301948547363, -- test: -158.6240997314453 \n",
      "Root Mean Squared Error -- train: 0.4175631105899811, -- test: 1.7888976335525513 \n",
      " \n",
      "#################### Sampling at Epoch 1399  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1399\n",
      "Mean Log Likelihood -- train: -7.5599188804626465, -- test: -131.16343688964844 \n",
      "Root Mean Squared Error -- train: 0.42293182015419006, -- test: 1.6281710863113403 \n",
      " \n",
      "#################### Sampling at Epoch 1449  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1449\n",
      "Mean Log Likelihood -- train: -8.566908836364746, -- test: -113.66462707519531 \n",
      "Root Mean Squared Error -- train: 0.44610661268234253, -- test: 1.5168932676315308 \n",
      " \n",
      "#################### Sampling at Epoch 1499  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1499\n",
      "Mean Log Likelihood -- train: -8.462559700012207, -- test: -140.6240234375 \n",
      "Root Mean Squared Error -- train: 0.44376131892204285, -- test: 1.6852754354476929 \n",
      " \n",
      "#################### Sampling at Epoch 1549  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1549\n",
      "Mean Log Likelihood -- train: -7.37787389755249, -- test: -135.07656860351562 \n",
      "Root Mean Squared Error -- train: 0.41860532760620117, -- test: 1.652030348777771 \n",
      " \n",
      "#################### Sampling at Epoch 1599  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1599\n",
      "Mean Log Likelihood -- train: -7.462230205535889, -- test: -121.68760681152344 \n",
      "Root Mean Squared Error -- train: 0.42061567306518555, -- test: 1.5688929557800293 \n",
      " \n",
      "#################### Sampling at Epoch 1649  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1649\n",
      "Mean Log Likelihood -- train: -7.46007776260376, -- test: -124.5700912475586 \n",
      "Root Mean Squared Error -- train: 0.4205644726753235, -- test: 1.5871593952178955 \n",
      " \n",
      "#################### Sampling at Epoch 1699  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1699\n",
      "Mean Log Likelihood -- train: -7.4766011238098145, -- test: -121.81695556640625 \n",
      "Root Mean Squared Error -- train: 0.42095714807510376, -- test: 1.5697171688079834 \n",
      " \n",
      "#################### Sampling at Epoch 1749  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1749\n",
      "Mean Log Likelihood -- train: -7.561875820159912, -- test: -143.64739990234375 \n",
      "Root Mean Squared Error -- train: 0.42297807335853577, -- test: 1.7031208276748657 \n",
      " \n",
      "#################### Sampling at Epoch 1799  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1799\n",
      "Mean Log Likelihood -- train: -7.610730171203613, -- test: -131.3669891357422 \n",
      "Root Mean Squared Error -- train: 0.42413151264190674, -- test: 1.6294208765029907 \n",
      " \n",
      "#################### Sampling at Epoch 1849  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1849\n",
      "Mean Log Likelihood -- train: -7.700296401977539, -- test: -136.415771484375 \n",
      "Root Mean Squared Error -- train: 0.4262380003929138, -- test: 1.6601169109344482 \n",
      " \n",
      "#################### Sampling at Epoch 1899  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1899\n",
      "Mean Log Likelihood -- train: -7.485749244689941, -- test: -159.25863647460938 \n",
      "Root Mean Squared Error -- train: 0.42117443680763245, -- test: 1.7924412488937378 \n",
      " \n",
      "#################### Sampling at Epoch 1949  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1949\n",
      "Mean Log Likelihood -- train: -7.7395243644714355, -- test: -116.82575988769531 \n",
      "Root Mean Squared Error -- train: 0.42715737223625183, -- test: 1.5375916957855225 \n",
      " \n",
      "#################### Sampling at Epoch 1999  lr = 1.2021529605110715e-10 ####################\n",
      "Epoch: 1999\n",
      "Mean Log Likelihood -- train: -7.701108455657959, -- test: -112.19412231445312 \n",
      "Root Mean Squared Error -- train: 0.42625707387924194, -- test: 1.5071680545806885 \n",
      " \n",
      "Number of sampled models: 40 \n",
      "Test Log Likelihood of all sampled models: -47.30219650268555\n",
      "Test Root MSE of all sampled models: 1.5928168296813965\n"
     ]
    }
   ],
   "source": [
    "_, _, lines, W = regression_train_demo(model, ds_train, ds_test, num_training, batch_size, X_test,\n",
    "                                                              lr_0=lr_0, momentum_decay=beta,\n",
    "                                                              resample_in_cycle_head=False, total_epochs=total_epochs,\n",
    "                                                              start_sampling_epoch=start_sampling_epoch,\n",
    "                                                              epochs_per_cycle=epochs_per_cycle,\n",
    "                                                              print_epoch_cycle=print_epoch_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6e3828fd60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAEvCAYAAAByngQ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAADhzklEQVR4nOydd3xV5fnAv+fuJDd7703ITiDMsEFEFAVUwIXWbW2tttKqrajUX6vVFlctlWpdxYGKggtkyRZCSAIhO2TvcW/W3ff8/ghENgECGZzv55NPknPe877Pe27ynuc8z/M+jyCKIhISEhISEhISEpcGWX8LICEhISEhISExlJGULQkJCQkJCQmJS4ikbElISEhISEhIXEIkZUtCQkJCQkJC4hIiKVsSEhISEhISEpcQSdmSkJCQkJCQkLiEKPpbgLPh5eUlhoWF9bcYEhISl4n9+/c3iaLo3d9y9AXS+iUhceVxpjVsQCtbYWFhZGRk9LcYEhISlwlBEMr7W4a+Qlq/JCSuPM60hkluRAkJiSsaQRCCBUHYIgjCYUEQcgVB+M1p2giCILwmCEKxIAg5giCM6A9ZJSQkBicD2rIlISEhcRmwAr8TRTFTEARnYL8gCD+Ionj4uDbXANFHv8YA/zr6XUJCQuKcSJYtCQmJKxpRFGtFUcw8+nM7kAcEntTsBuB9sZs9gJsgCP6XWVQJCYlBimTZGsRYLBaqqqowGo39LYpEL9BoNAQFBaFUKvtbFIkzIAhCGJAK/HTSqUCg8rjfq44eq708kg09pPVrcCGtXxeHpGwNYqqqqnB2diYsLAxBEPpbHImzIIoizc3NVFVVER4e3t/iSJwGQRC0wOfAo6Iotl1gH/cD9wOEhIT0oXRDD2n9GjxI69fFc9FuxF4Gl04RBEEvCELW0a+lFzuuBBiNRjw9PaWFahAgCAKenp7SW/wARRAEJd2K1v9EUfziNE2qgeDjfg86euwERFF8SxTFNFEU07y9h0QGi0uGtH4NHqT16+LpC8tWb4JLAbaLonhdH4wncRzSQjV4kD6rgYnQ/cG8DeSJoviPMzRbC/xKEISP6Q6M14uiKLkQLxLpf2LwIH1WF8dFW7Z6GVwqMQTR6XS8+eabF3Tt7Nmz0el0Z22zdOlSNm7ceEH9Xyy9GXvr1q3s2rXrMkkkcQlJB+4Aph1nfZ8tCMKDgiA8eLTNt0ApUAysBH7ZT7JKSEgMQvo0ZusswaUA4wRByAZqgMdFUcw9Qx9SzMMg4Ziy9ctfnvrcsVqtKBRn/vP69ttvz9n/smXLLkq+i6E3Y2/duhWtVsv48eMvg0QSlwpRFHcAZ31tF0VRBB6+PBJJSEgMNfos9cM5gkszgVBRFJOB14Evz9SPFPNw6cjbvoW3Hv4Ff180h7ce/gV527dcVH9PPPEEJSUlpKSksGTJErZu3crEiRO5/vrriYuLA2Du3LmMHDmS+Ph43nrrrZ5rw8LCaGpqoqysjNjYWO677z7i4+OZOXMmBoMBgLvuuovPPvusp/0zzzzDiBEjSExMJD8/H4DGxkauuuoq4uPjuffeewkNDaWpqekUWbVaLY899hjx8fFMnz6dxsZGALKyshg7dixJSUnMmzeP1tbWXo1dVlbGihUrWL58OSkpKWzfvp3Vq1eTkJBAcnIykyZNuqh7O+ARRWg5AqVbIftjaMjvb4muCMxWO7tKmtiS34DJautvcQY9ZWVlDB8+nLvuuothw4Zx2223sXHjRtLT04mOjmbv3r10dnZy9913M3r0aFJTU/nqq696rp04cSIjRoxgxIgRPVburVu3MmXKFG666SaGDx/ObbfdRreuLnEl0yeWrXMFlx6vfImi+K0gCG8KguAliuKpT0WJS0Le9i1seOsNrGYTAO1NjWx46w0AYidOvaA+X3jhBQ4dOkRWVhbQvchkZmZy6NChnh0r77zzDh4eHhgMBkaNGsWNN96Ip6fnCf0UFRXx0UcfsXLlShYsWMDnn3/O7bfffsp4Xl5eZGZm8uabb/Lyyy/zn//8h+eee45p06bx5JNP8v333/P222+fVtbOzk7S0tJYvnw5y5Yt47nnnuONN95g8eLFvP7660yePJmlS5fy3HPP8corr/Rq7AcffBCtVsvjjz8OQGJiIuvXrycwMPCcLtLBSEZdBiuyV3BEV4SnsZOwjhYebtUTarV2N/BNgDEPQOodIMV39CkdJivPfJXL+tw6Okzd99tFo+DapACenD0cF420Hf9CKS4uZvXq1bzzzjuMGjWKVatWsWPHDtauXctf/vIX4uLimDZtGu+88w46nY7Ro0czY8YMfHx8+OGHH9BoNBQVFXHLLbf0lGc6cOAAubm5BAQEkJ6ezs6dO5kwYUI/z1SiP7loZas3waWCIPgB9aIoioIgjKbbotZ8sWNL9J7tH7/fo2gdw2o2sf3j9y9Y2Todo0ePPmFr8GuvvcaaNWsAqKyspKio6BRlKzw8nJSUFABGjhxJWVnZafueP39+T5svvujW6Xfs2NHT/6xZs3B3dz/ttTKZjIULFwJw++23M3/+fPR6PTqdjsmTJwNw5513cvPNN/d67JNJT0/nrrvuYsGCBT3thwJdli6WbFvCtqpteCucGKdvpkUuY4eLG1tc3Hg05jZusTkiy/kY1v6629o15zVQa/tb9CFBrd7A3e9mUFjfzoK0IKbG+KBUyFiXXcPqjEoK6tp4/54xaNWDN5PPc+tyOVxzQdk2zkhcgAvPzIk/Z7vw8HASExMBeizfgiCQmJhIWVkZVVVVrF27lpdffhno3kVZUVFBQEAAv/rVr8jKykIul1NYWNjT5+jRowkKCgIgJSWFsrIySdm6wumL/85jwaUHBUHIOnrsKSAEQBTFFcBNwEOCIFgBA7BIlOyql5X25tMbEc90/EJxcnLq+Xnr1q1s3LiR3bt34+joyJQpU067dVitVvf8LJfLe9yIZ2onl8uxHrOmXCDnu7OmN2OvWLGCn376iW+++YaRI0eyf//+UxTLwYbVbuX3237Pjuod/Db4Gm7ZvhJN+CS44Z/UK5Q8u/tZXsh7l/Lht/DUfVtg53LY/DzUHYI714Gzb39PYVBT0dzFgn/vpt1o4Z27RjF52M+hFVNjfJgZ58vDqw7wi//u5d1fjMZpECtc/cXx649MJuv5XSaTYbVakcvlfP7558TExJxw3bPPPouvry/Z2dnY7XY0Gs1p++yL9Upi8HPR/5m9DC59A3jjYseSuHCcPb1ob2o87fEL7tPZmfb29jOe1+v1uLu74+joSH5+Pnv27Lngsc5Eeno6n376KX/4wx/YsGFDT8zVydjtdj777DMWLVrEqlWrmDBhAq6urri7u7N9+3YmTpzIBx980GPl6g3Ozs60tf38Nl5SUsKYMWMYM2YM3333HZWVlYNa2RJFkRf2vsCPVT/yp+GLWbjxHxCQCrd8jF2uwdVg5c3pb/Jyxsu8f/h9otyiWDDxdxCYBh8tglUL4K5vJAvXBWKx2fn1xwfoNFtZ/eB44gJcTmkzK8GfVxeJPPLRAZ5bl8vfbkruB0kvnt5YoPqLq6++mtdff53XX38dQRA4cOAAqamp6PV6goKCkMlkvPfee9hsUgydxJmRaiNeIUxctBiFSn3CMYVKzcRFiy+4T09PT9LT00lISGDJkiWnnJ81axZWq5XY2FieeOIJxo4de8FjnYlnnnmGDRs2kJCQwOrVq/Hz88PZ2fmUdk5OTuzdu5eEhAQ2b97M0qXdeXXfe+89lixZQlJSEllZWT3He8OcOXNYs2ZNT4D8kiVLSExMJCEhgfHjx5OcPDgffMf4uvRrPin4hF/E3MLC7f9BdPQkL3w5ny/PZeVvfuTt323n6zeyma9ezMTAifz1p7+yt3YvREyGm/4LdTnw2S/AJr3VXwivbCwku1LHX+cnnlbROsZ1SQHcOzGC1furyKnSXT4BrxCefvppLBYLSUlJxMfH8/TTTwPwy1/+kvfee4/k5GTy8/NPsOpLSJyMMJC9eWlpaeKxgMOLwWCzs7quhfVNbbgp5firldzo606s1qEPpOw/8vLyiI2N7X377VvY/vH7tDc34ezpxcRFi/s0Xqs/MJlMyOVyFAoFu3fv5qGHHuoJ2D8erVZLR0fH5RfwJM73M+svDFYD1625Dh8HH/4nD0P46V9kBP2XvRmueIc4ExDlhlwlI39XLV1tZkLHuLDS/c90mDtYN28djkpHyHgHvn4Mpv4JJp+qjJ8OQRD2i6KYdomnd1m4mPVrT2kzt6zcw80jg3plrWo3Wpj68o+EeDjw+UPjB0UCysHyvyDxM9Jndm7OtIYNeQf/x7XN/LmklmaLlQgHNZYukTqThbcqG3kqwp/7g72RDYKFqS+InTh10CtXJ1NRUcGCBQuw2+2oVCpWrlzZ3yINCT44/AENXQ38LfkRhI/vplw1m70ZrqTNDmP0deEIsu7/mdHXhbP/uzL2fVPGnLG/4FXhad7KeYtHRz4KaXeDXA2xUuGI88Fqs/P0l4cI8XDstXvNWaPk97Ni+P1nOXyZVc281KBLLKWEhMT5MKSVrZWVjTxdXM1YVyfeCg9lvJsWQRBoNFt4vKCSZ0tq2KPv4O2EcORXiMI11IiOjubAgQPnbDcQrFqDhSZDE28ffJvpIdMZue9/WAUNm6tuYuodw4lLDzihrVwhY/ScCASZwN51RxiTPoX3Dr/H3Ki5hLmGQept/TOJQcwXmdUUNXSw4vYR5xXwftOIIP63p5yX1xdyfXIgcpm0pklIDBSGbMzWmxUNPF1czbXernyaEkm6u3OPad1bpeTdhHCWRgbwfVMbr5bX97O0EhIDh7dy3sJsM/Oo9zgoWs9e3U0Ep8Wcomgdz6hrw0meEUzM3ukoUfHivhelRI4XgNFi4x8/FJIS7MbV8X7nda1MJvDQlEiqdQY25zdcIgklJCQuhCGpbP3Y0s6ykhqu93FjRVwYKtmp0xQEgYeCvbnJ152XjtSxveXMu+okJK4UOswdfFn8JddFXkfogU8w4EGhfC4TFww757Vjb4ggwMOPMfWz2VG9g/31+y+DxEOLd3eVUddm5Ilrhl9Q3NWMWF98XdR8uKf8EkgnISFxoQw5ZUtnsfJofgXRjmpeHR6CUiZgtNmpNZmpNJpPaCsIAi/GBBHtqOGhw+W0WKRdUxJXNl+Xfo3BamCh7ziEkk3ktF/NpFsS0GjPnaFcoZQz9fYYokrHoMWFtw+dPpu/xOnpNFn519YSpg33YWzEhaUMUchlLBoVwraiRiqau/pYQgmJwYfNLvLqxiJmv7qdtOc3krJsA8t/KOypxHC5GHLK1lNF1TSaLbweG8KO1nauySgkbFsOqbsOM2r3YWbuK+C96ia6bHYAnORyVsSH0myx8maFZHqXuHIRRZFPCz8l1iOWuPxN2EQFTb43EpHa+xqlAdHuJE8IJ65iIjuqd1DQUnAJJR5arM6oRG+w8OtpURfVzy2jQ5AJAv/bK1m3JK5smjpMLH7nJ5ZvLMTFQcGMWB9GhXnw6qYipry0hW2Fp+aevFQMKWVrQ5OeL+pbuS/Im6eLarjj4BGaLFYeD/Pjb8OCeDYyAKso8ofCKuYfKKbJ3K3ZxmkdmOfrzttVTTSaLf08i8GDTqfjzTffvKBrZ8+efc76gUuXLmXjxo0X1P/F0puxt27d2lN8diiQ3ZhNUWsRCyOuhwMfUWicSNzVKefdz5jrw0lunYxadJCsW73EZhd5Z2cZI0PdSQ05fcmp3uLnquGqWF9WZ1RhtEiJNs+EtH4NrfXrZHRdZm54YycZZa387aYkPr5/HC/cmMTKxWl8+XA6Xlo1D3ywn+xK3WWRZ8goWzZR5PmSWoI1Sr6sb+Vwp4G/xwSza0wsj4f7sTjQiwdDfNg0KoZ3EsLI7zQwJ7OQckN3vcDfhfliFu28Xi5Zt3rL2Rarc5Wn+Pbbb3Fzcztrm2XLljFjxowLFe+i6M3YQ22x+rTgU7RKLbN0TchsnZQ53EhYYneFgZaWnRQULmPPT9ew56drKC7+G21tOaftx0GrYmR6NLG141l/ZD2VbZWXcxqDkh8O11HR0sW9E8LP3bgX3DImhJZOM9uL+rYc11BCWr+G1vp1Mku/yqW+zchH949lQVrwCedSgt14/57ReGpV3P3uPsqbOy+5PENG2fq0roXCLiONZisiAl+lRnFbgCfmdjNlB5soyqineH8DVrOd2d5urE6JQmexcVNWCW1WG5GOGm729eC9miZqTeZzDzgI6TzQQO0Le6l6Yju1L+yl88DFKZZPPPEEJSUlpKSksGTJErZu3crEiRO5/vrriYuLA2Du3LmMHDmS+Ph43nrrrZ5rw8LCaGpqoqysjNjYWO677z7i4+OZOXNmT23Eu+66i88++6yn/TPPPMOIESNITEwkPz8fgMbGRq666iri4+O59957CQ0Npanp1AeMVqvlscce6yk029jYbT7Oyspi7NixJCUlMW/evJ5yP+cau6ysjBUrVrB8+fKeDPKrV68mISGB5ORkJk2adFH39nLTYe5gfdl6ro24FuXeVdSZhxF61XQQRIqKX+BA1mJqaj5BrfZFpfKiovJt9mXMo7jkJUTxVOtJ6lUhpDRORUDGhvIN/TCjwcV/th8h2MOBmee5A/FMjI/0xEWj4PtDdX3S34Ag51NYngDPunV/z/n0orqT1q+hs36dzHcHa1mbXcMj06MZcQZLsY+zhvfuHo1dFLn//f1YjoYWXSqGhLJlsNl5obQWhQDeSgXfjIwmzCpn2yeFfPDH3Xzzzxw2/CeX9SsP8d6TO9m9pphEuYoPkiKoNpr5U1EVAL8N88Umivy78vL5cS8XnQca0H1RhE3Xbcmz6Uzovii6KIXrhRdeIDIykqysLF566SUAMjMzefXVVyksLATgnXfeYf/+/WRkZPDaa6/R3Nx8Sj9FRUU8/PDD5Obm4ubmxueff37a8by8vMjMzOShhx7i5ZdfBuC5555j2rRp5ObmctNNN1FRUXH6+Xd2kpaWRm5uLpMnT+a5554DYPHixbz44ovk5OSQmJjYc/xcY4eFhfHggw/y2GOPkZWVxcSJE1m2bBnr168nOzubtWvXnt/N7Gd+rPoRs93MdW7xqPQFHGE6USPdOXToESoqVhIYeBuTJ2WSmvIuI1I/YNLEDAIDbqG8fAXZOfdjtZ64m9fRRcXosbEszHqSm/xu6adZDQ4OVLSSUd7K3enhfZYbSymXMSPWl4159Zf8IXJZyPkU1j0C+kpA7P6+7pGLUrik9WvorF/H09xh4o9fHiIx0JWHpkSetW2kt5a/3ZRMQX077+4su6RyDQll69+VDdSbrSgFgQ+TI7GXdrDq2T3k/lhNzBhf5j8+gluWjmHuY6kExbhzYEMFX/w9k1gU/CbUl0/rWvm6QUeIg5qZnq6srmvFbB8CC9RxtK0vQ7ScOCfRYqdtfVmfjjN69GjCw392hbz22mskJyczduxYKisrKSoqOuWa8PBwUlJSABg5ciRlZaeXaf78+ae02bFjB4sWLQK6azG6u5/+LUYmk7Fw4UIAbr/9dnbs2IFer0en0/UUn77zzjvZtm1br8c+mfT0dO666y5Wrlw56IrSbqrYhLeDN7FHsrGLMpQp8zhS/iINjd8RHfUUMcOeQyb7ubamQuHM8OHPExPzZ1padnDo0COnWLhSrwrFzeJN8X7JNX82nDUK5o8I5OaTXB0Xy9UJfugNFvYeaenTfvuFTcvAYjjxmMXQfbwPkdavwbl+Hc9b20rRdZn5+4JklPJzqzhXxfkyfbgPr2wspE5vvGRyDQll64v6btPp2wnhcEjH129k4+LlwK3PjWXqHbH4R7nhEeBEYIw7sx5I5IZHU2lvMbLm75nc7+pGsrMDSwoqaTZbucXfg2aLlR+a2/p5Vn3LMYtWb49fKMcXY926dSsbN25k9+7dZGdnk5qaitF46h+zWv3zQ1wul58xXuJYu7O16S3nm8OoN2OvWLGC559/nsrKSkaOHHnat+CBiMFqYEf1DqaFTIOcz6k2J+KRYKGq+gOCg39BSMg9Z7xfQYG3MmzYMzS3bKP0yGsnnNO6q7nl6TGMuDr0ckxj0BLl48w/FqSgPY9s8b1hUrQ3GqVsaLgS9VXnd/wCkdavwbd+HU+70cKqnyqYnejPMF/nXl/3zJx4rHaR5785fMlkGxLK1t+Hh/DSsCCCSrrY+N/D+Ee5Mu/xEbh6O9DQbuStbSXMfXM7UX/8hunLN7D8YBEJt0djaDPz3evZ/CMqCJ3VxpuVDUz1cMFPpWRVzRB4GzwOuZv6vI73BmdnZ9rbz5wMVq/X4+7ujqOjI/n5+ezZs+eCxzoT6enpfPpptythw4YNPTELJ2O323tiGFatWsWECRNwdXXF3d2d7du3A/DBBx/0vCX2hpPnX1JSwpgxY1i2bBne3t5UVg6OwPBd1bswWA1cpQ1HbaigRj2VWt1TODiEERnxu3NeHxhwC/7+N1FW9gaNjSfugHLzdRwURZGHIg4qOVOG+bDhcB12+yDP5u96hlqPZzreC6T1a2isX8fz8d5K2k1W7p8UcV7XhXg68tCUSL7OqeVAxek/g4tlSChbo1ydmGVTs/mDfAKi3Zjz6xTUDgp2lzRz1fIt/OXbfA42FCC47KKsPY/P9ldzx5p9dE5ypLWui7YttczzdeedqiZ0VhsL/T3Y0tI2pALlXa4OQ1Ce+HELShkuV4ddcJ+enp6kp6eTkJDAkiVLTjk/a9YsrFYrsbGxPPHEE4wdO/aCxzoTzzzzDBs2bCAhIYHVq1fj5+eHs/OpbzROTk7s3buXhIQENm/ezNKlSwF47733WLJkCUlJSWRlZfUc7w1z5sxhzZo1PQGmS5YsITExkYSEBMaPH09ycnKfzfNSsrFiI65qVxKKsrCJCjrDPTEaa4iL+xtyucOZL7R1p0kRBIGYYctwdo4nL/9JLBb9ZZJc4lzMSvCjvs1EVpWuv0W5OKYvBeVJf4tKh+7jF4i0fg2N9esYFpudd3YeYWyEB0lBbud9/b0TI3B1UPLm1pK+Fw4QBnL9srS0NDEjI+Oc7QztZj796z4Q4eYnR+HoouL93WU8u/YQgrIJz/DPmRwxnBjnWLzbgygqbuO/5R10mr0ZrxWZUO3I6EcSub6umgeDfVgc6MnYPXk8Ee7Ho2F9szvoUpCXl0dsbGyv23ceaKBtfRk2nQm5mxqXq8NwSvW5hBJeekwmE3K5HIVCwe7du3nooYfIyso6pZ1Wqx0QxajP9zO71FhsFiZ/MpnpIdN4etunVLcFUzjBSEjUZGKH/+XUC6oy4MAHUPoj6CogZBzEXAOpt9NurWHvvhsIDLyV4TGnD9Q9F4Ig7BdFMe0ipzUg6O36dSnRGyyM/PMP3Dcpgj/MGt6vspzMef8v5HzaHaOlr+q2aE1fCkkLLp2AlwFp/eo7vsis4refZvPfu0YxdfiFPdf+8UMhr20qYsNjk87LDXk8Z1rD+jZIoJ/Y/EE+hnYL8x8fgaOLiq8OVLP0q1wU7jvwDtpOh7WN78vK+J7vkdnlaK1uJGmSaDZPZleHBh+tFffVpcyb58t/q5t4KMSb8W5aVte18ptQ3yHjBnFK9Rn0ytXJVFRUsGDBAux2OyqVipUrV/a3SIOKvXV7abe0M8M5EpW5njqH61E4fkVoyAOnNj7wv+4dYAoHCJsAMbOhdCts+CPs/y/Ot3xCUNDtVFV9QID/Tbi4JF72+UiciKuDkpRgN3YVD4F8W0kLBr1ydTLS+tV3rPqpgkhvJ6bE9L7ixcncNT6MldtKWfFjCf9YkNJ3wjFElK1x8yKJHeePT6gLh6r1PP5ZBprAj1G6HEIhd2dK5/XkmQ9Q71yJXWajTdPMocAtiAFb0ZT8lq/xwKdOxoImP9Zg5+2qJq73ceOJwiqKukwMc9L09xQlzkB0dDQHDhw4Z7uB8FY4ENlRvQO1XE1yVXegcbNvM2E+s3F0PCmofctf4McXIXwSLPgAHNx+Ple2Ez69A/4zjcgb/0298hsKCp8lbeRqBGFIRCoMasZHefHG5iL0BguuDueucSlx+ZDWr76hWmcgo7yVJVfHXJRxxMNJxaLRwXywu5zfXjWMIHfHPpNxSKyEHv5ORKR609JpZvG725D7f4jS5RALoxcyu/ouDgg/0Kyt4DctOr6rrOfjCj0hFgty7ChDV2ATrHylNVC6qZJp7s58XNvCdA8XAL5vkuJPJIYue2r3MMJnBMqCTTRYIpEH5hIaepJV69Dn3YpW8q2YF62m2qSmsqWL5o6jO1nD0uG+LeAcgGL1fcR4LaatLYuGxvWXf0ISp5Ae6YldhJ9KB9/uMgmJ3vBNTg0Ac5ICLrqv+yZ2B9e/t6vsovs6niGhbB3jD2v20OXyP5TO+fwm9TdElY5ijfuruAptvFQL9uaZvG19kE+7bmNc5SwizBoUig60Af+jXiZjb1sXNzQL1Jkt5HUaSHV25NtGSdmSGJo0djVSrCtmnHcyjm3ZVBODf3A8zs5xPzdqr4dvfoc9YAQf+j7OhJd3kP7CZib+bQtp/7eR+9/PILOiFdxD4fbPQK7EZ8v/0KpDOXLkNURxaOWrG4ykhLihUcrYVSIpWxJDk7XZNSQHuxHiefGWqAA3B2bE+vJ5ZjUma9/lGxsyytbukka2NXyE0iWXB5IeILFtHG8ZnsBJtDCtKoGdhnnU4odWpUU1bhEfcw0HK3+PGgeCHQ4jV5ezQ2Oi7ccqfJRyPqxp5hpvV7Lau6gxDp1diRISx9hT272VfZTBhoCdJlcVQUGLf24girDu14imDn5RcQ1/WptPqKmAv4Rk8NI1fvxySiQ/HWlh/pu7+NOXB7E5B8L8lQgNeSRWONHZWUhDw3f9NDuJY6gVckaFebBzKMRtSUicRGljB4eq25iT5N9nfR6rLboht77P+hwSypbZaudXa99B5bmDUb5juCPkLl44+AvaFWZmNSZgUqQiGA2EYyLWWUbMwc94dXgTNwwLorFqIZVKBXE+H9Iuk/GTzshtnSo2Nrcx0qVbS14/xBKcSkhAt7LlrnYnOD8To12LJcyIh8fEnxvsexsK1/Mv8zVk2iL5T9Q+Xg0qZ0rtVuZvnc0S2UfsWjKJeyeE8+GeCh76cD/GsKkw8Xc4FmwjoNOLI2Wvn7Z2osTlJT3Ki6KGDhraL12GbAmJ/uDrnFoEAa7rAxfiMSZGeRHo5sBHe09fPulCuGhlSxCEYEEQtgiCcFgQhFxBEH5zmjaCIAivCYJQLAhCjiAIIy523ON5fsMmTK6foRJc+deMf/LCqvspdjRwXUsE7cJEbNVlOFUU0FxaSGV+Jm3NlWR9+RGhP/yDO2wyzK2jKXdqx8l5P7s0ZjS7S7ED+3SdRDio+V5yJZ4WnU7Hm2++eUHXzp49G51Od9Y2S5cuZePGjWdtc6nozdhbt25l165dl0mivkUURXbX7GaM32g01T9SaUkkPCEBmezonhlDK7b1f6RC9OEt28380T+cI4emsiZzFmsan+adxvfY+I0d2ddP8KfZw3l2Thw/5NVzz3v7sE54HNzDiS5to6ujkPqGb/t3shKkR3oBsFtyJfYgrV+Dd/06nnXZNYwK88DPte82sslkAreMDmZXSTNlTZ1902cf9GEFfieKYhwwFnhYEIS4k9pcA0Qf/bof+FcfjNvDd/XLQbBxvd+fWPjyCn7Q5pDaIed/9b/AkJuNY0stbd6u+M6rJ+rGnwi9bjvDbqzEwUuO8+HNzK0Jxm7XEOX5HR0ygUMtMqYoHfi0vpVZXi7s1LWjt1xceYWhyNkWq3OVo/j2229xc3M7a5tly5YxY8aMCxXvoujN2IN5sSrVl9JoaGSsUxBqWwt1Gh8Cg27oPmmzwnvXI7cZecN0K7+SedJaoCdqpA+z7k/gmgcSiRwTSrF5Mqt/HEPzZ3/lrvFhvHhjEjuLm3nhhyNw9f+haK0htmMYatXQSjcyGIkLcMFFo5BcicchrV+Dd/06RnlzJ0UNHVyT0Pf5MG9OC0YuE/h4X99k0r9oZUsUxVpRFDOP/twO5AGBJzW7AXhf7GYP4CYIQp85WOeF/AZZ4518uNmIxvU/KEWRWRHPcWfz5/ib6igdFsaH2oUsPbCUb7e/SNnmx8GSRNjs/XgM68SnPIPYqihKHTpwczxItspG4sEKSg3daR+sIuzUDf6ttzk5OSxfvpxnn32W5cuXk5OTc1H9PfHEE5SUlJCSksKSJUvYunUrEydO5Prrrycurlvfnjt3LiNHjiQ+Pp633nqr59qwsDCampooKysjNjaW++67j/j4eGbOnInB0F1w9q677uopUREWFsYzzzzDiBEjSExMJD8/H4DGxkauuuoq4uPjuffeewkNDaWp6dQHilar5bHHHiM+Pp7p06fT2NgIQFZWFmPHjiUpKYl58+b1lMs419hlZWWsWLGC5cuX92RgXr16NQkJCSQnJzNp0qSLureXmt01uwFIreueryFIi7Pz0bxYG5+ho7aQPHM8wYapiF025jySwtQ7Yokc4UNEqjfT7ohl3pJR2BSufL4lmZp1H7IgLZg7x4Xynx1HWGtMgfBJ+Ofn466O7qdZ9g5BEN4RBKFBEIRDZzg/RRAEvSAIWUe/LjxteT8hlwmMjfBkT+ngLUP2Tek3zPxsJknvJTHzs5l8U/rNRfUnrV+Dd/06xrbC7vswediF59Y6E74uGqYN92FrQQN9kfy9T2O2BEEIA1KBn046FQgcrx5WcapCdsHYDcFEO4/iZq8PyHWEhfLptP7wBZoOPUHpDTz/2zt5Z0oU9zt9wYiw5SSMfAEf1S60Ld6ETqrHPdpAaoEehVWFl89GGhQi+nw9gihSYTDjIJOxvXVwK1s5OTmsW7cOvb7bJarX61m3bt1FKVwvvPACkZGRZGVl8dJLLwGQmZnJq6++SmFhIQDvvPMO+/fvJyMjg9dee+20xU2Liop4+OGHyc3Nxc3Njc8///y043l5eZGZmclDDz3Eyy+/DMBzzz3HtGnTyM3N5aabbqKi4vQ+9s7OTtLS0sjNzWXy5Mk891x3hvPFixfz4osvkpOTQ2JiYs/xc40dFhbGgw8+yGOPPUZWVhYTJ05k2bJlrF+/nuzsbNauXXt+N/My81PtT4Q4h+BZsocWayBBaUnd+WmairHtXoEjZn7o+B0OchnzHx+BT6iGqsOH2P/NV+Rs/B5Dexu+4a7cvHQKTmoT33/vRGdFMX+8No60UHf+8PlBasYuBaMe9g74RI3vArPO0Wa7KIopR7+WXQaZ+py0MHcqWrpo6ujb4vOXg29Kv+HZXc9S21mLiEhtZy3P7nr2ohQuaf0avOvXMX4sbCLI3YFwL6dzN74A/m9eAmt/NaFPEpv3mbIlCIIW+Bx4VBTFC44oFwThfkEQMgRByDimvZ+L388azjVBBjLdDhNuVDJcHo6xuhnv5BbGXfUizT/WIFTewPzAb5lXdZgx2TrG5DYxOu8wifmNRI0tw8XJRkKZG/UO9SjUVRTKtEzQdfF9k56xbk7saD1zwdLBwKZNm7BYLCccs1gsbNq0qU/HGT16NOHh4T2/v/baayQnJzN27FgqKyspKio65Zrw8HBSUlIAGDlyJGVlZafte/78+ae02bFjB4sWLQK6a5m5u7uf9lqZTMbChQsBuP3229mxYwd6vR6dTtdTvPXOO+9k27ZtvR77ZNLT07nrrrtYuXIlNtvADQq3i3YONB5gpE8qjros6uxRhEVf031y4zPUiJ7s6rwJudmdiQuH0ViRxZv33sEnzz3B1vdX8sPKN/jX/Xew9u9/QaYwM+uhFCyiAz+8sROFAK/fmopcJvCHHXbE29fAxN/274TPgSiK24DBa/LpJSNCuv83MssvTaHdS8mrma9itJ0Y3G+0GXk189U+HUdavwb++nUMs9XO7pImJg/zvmRVXnycNagUfaMm9UkvgiAo6Va0/ieK4henaVINBB/3e9DRY6cgiuJboiimiaKY5u3dO9Ngfl0bNflPU61UMN9pEXnf/4CjnwFXxymYv/meesOjpLQ2E1XWhVIZxVd+v+Od2pk0V/vj2WxmdE4LaVMLiCtTobQq8PH6nsMqGyH7D3G400i81oGiLtOgLkx9zKLV2+MXipPTz28YW7duZePGjezevZvs7GxSU1MxGk/dDaVWq3t+lsvlZ4yXONbubG16y/n+c/Zm7BUrVvD8889TWVnJyJEjT/sWPBAo05ehN+lJVXmhxIjO2ac7Y3z5Lox53+NolZPdeTOhiR6UZa9l3Rt/x+AWjBg8A8eY21F6LkKuSqE4Yx//+9PjyFw0TJ7YTnVbMPv+8yX+rg78flYM24ua+KotGuRDImv5OEEQsgVB+E4QhPj+FuZCSAh0RSkXyKzQ9bco501dZ915Hb9QpPVr4K9fx8isaKXTbGPSJXAhXgr6YjeiALwN5Imi+I8zNFsLLD66K3EsoBdFsfZixz7Gt+veY7OHjmEdrliytgNgVroQ3wVNAZ+QekSHtt2Obc5/UP5+HyOn38LqyHuY4fECxaUToEtgdGEr48aWElarocupDLPcRFtnAILNjsne7a8dzK5EV1fX8zreG5ydnWlvP7PFT6/X4+7ujqOjI/n5+ezZs+eCxzoT6enpfPrppwBs2LChJ2bhZOx2e08Mw6pVq5gwYQKurq64u7uzfXv338wHH3zQ85bYG06ef0lJCWPGjGHZsmV4e3tTWdk3gZV9zYGG7vIgw+qO5pCJiuvOqbXhafLkMexqvxu5UoHFuJeM3Gw6o5IwebnSodVRL8unPaAc33GjUWrn09HSxqo/PY772BHEeB0m84AWXWUDt40JJSXYjT9/fRhd1+B9STlKJhAqimIy8Drw5ZkaXohl/nKhUcqJC3DtTkI7yPBzOn0A9JmO9wZp/Rqc69cxthU2opAJjI/07G9RekVfWLbSgTuAaccFkM4WBOFBQRAePNrmW6AUKAZWAr/sg3F7cNF8RbNCzkxzFG2VIspQB+KrZDQ6fUxyhR6VQYZ425d0hkxm7d//wvplf+Waw99hsdm4y20++RlJmEUZY9oaGNkFNrkVV5efyFcoGFWRy359Bx5KOdtaBq8rcfr06SiVJ1oYlEol06dPv+A+PT09SU9PJyEhgSVLlpxyftasWVitVmJjY3niiScYO3bsBY91Jp555hk2bNhAQkICq1evxs/PD2fnU6u1Ozk5sXfvXhISEti8eTNLl3bHOL/33nssWbKEpKQksrKyeo73hjlz5rBmzZqeANMlS5aQmJhIQkIC48ePJzk5uc/m2ZdkNmTiofHAr+QndFZ/gkeMh4rd2Kv2g8mFCvNIQuOUHGwoxOLmRXLSCB555BGefPJJ7r//foJDgsmv24c6xYLc6WasZhnrlr/AyAUjkAtmdr67HblM4K/zE9EbLLy/u7y/p3xRiKLYJopix9GfvwWUgiB4naHteVvmLycjQtzIqdJhsQ2uzP6/GfEbNPITt/Zr5Bp+M+KUTEO9Rlq/Buf6dYxtRY2MCHHHWTM4LOdCX0TZXyrS0tLEjIyMc7Z74v1llLXuY3yOGRQy1K0aUv0PERyjx6/ehOXad6lSBLHrn+8T5zIOH3W3R3MzFpZi4GZdNneXvEtMej317moWKAKxCF7UlT/KDco8Ppk+g5meLuS0GzgwPu6S+YfPl7y8PGJjY3vdPicnh02bNqHX63F1dWX69OkkJSVdQgkvPSaTCblcjkKhYPfu3Tz00ENkZWWd0k6r1Q6IYq7n+5ldCq794loiXSN4eftqSsyjGPbnL5CveZCfcovQt06n1DKOZofNWJzUzJxyLeOnjj7hervdzk8//cT69esJ8Y2kY7+IpeMzYsZNwN8ksqd0FNc/EEFwahj7y1tJCXZDLuvd/4wgCPtFUUy7FPM+x7hhwNeiKCac5pwfUC+KoigIwmjgM7otXWddPHu7fl1O1mXX8OuPDrDuVxNIDLpwq3ZfcL7/C9+UfsOrma9S11mHn5MfvxnxG66NuPYSSnjpkdavC6Opw0Ta8xt5fOYwfjVtYO12PtMapugPYfqa+xLvZ9/mvVR3KBFDghh/ZCeO13fhX2yizeN6OtxiKVz+JVO8FyA4ynGZGorSx4H57WY+/yqHH9xSmON7I67V7xNABzM8jHzmWodMXU9rRwTYTbgr5dSZLRR3mYh26rvkaZeTpKSkQa9cnUxFRQULFizAbrejUqlYuXLA73zrV5oMTVS0V3CT33hUGGhzDUVu0MHhr6ixX0utMR3RoRyLVkNcQNwpihZ0B+uOGzcOq9XKpk2biEhNpnXfOAp2bSN44c24lNez46MOFiaHMjL09AG/AwlBED4CpgBegiBUAc8ASgBRFFcANwEPCYJgBQzAonMpWgOVEUc/j8yK1n5Xts6XayOuHfTK1clI69eFcazO58TogWc9PhNDQtkSHddSl2VD5qEhZn8+9us7GFbaQbvBC8s9z5P94kckuqajinfDa2EcMsEM7bXg1MqfF4Zww4clfB80jRt3ZeEcvJf7DA184RyA1m03lZ3zSaraQ6v3dQBsa20ftMrWUCQ6OpoDBw6cs91AeCscCGQ1ZAEQVdcdjyGPHgVZH1Js9cKhPQiw0+xUh7NZwc333dxzna3djDG/hfat+7DUlKD0dSEh2pf62FgO5WXjG5CKrLaKbeu+ZVpqAlsPp1Oyq5joCQPrrfN0iKJ4yznOvwG8cZnEuaQEuGrwdVGTWdHKnePD+lucKx5p/bow9h1pwUklJz7Apb9F6TVDQtnK/eEANrMcjcUdf7fD+Kk6kdmAWz9k/xufkahNRx7lhPfCGISMN2HrC2Du/uNNEuTc6PUXVjcHc+OIh2g4WEBkfDPJRjs5zjlUKK5nVlkzWyK78Fcr2avv5J6gwaNNS0gcz4GGA6hkKiLKc9FbfQkZNR0+n81P6mm0N0zAQVOMHQM3LLq7x13eldNI48otmA9+gbUu+4T+Et18sI9JoTKwGGXjJCzt/6NWrsJNXkXm151EpUcNGLe7RPcuthEh7oMySF5C4hj7yloYEeqOQj54yjsPHknPQlDUtVg9fRlx6CD2OSb8G0w0GEZSVFhPtJiCzRv85jgj/GcybPgThKbD3BVwy8cw9iEe63oVu2jjc1cNNsMs2uUK5hlbsam6EB0raW8fTqtBxzBHDfv0fVMnqa8YpN6MK5KB8FllNWSR4BWPR9sRGuxReBvzsbdWYGrzxYaaBic9HjZHopIiEEWRti2VNLz6JZ2b/oyx+TDbE5J467rr2JucQlfcTLDJSVy/gdjNG9HGCijUieTs2MmwoGKadE5U5PTZpmOJPmJEiDuVLQapKLXEoERvsFBQ386oMI/+FuW8GBLKltnVE98OK8p4HZGt7VisMsRFL2Hf2Y5MJifg5iCEVfOgox7mvQVx16PrNLL5UA1ftSfRMHU5sxzyWWtqxx51FQ25zsxo60Iuijhqc6i3e5BYtwW1TKDGZKHaODC2sms0GpqbmwfEQ1zi7IiiSHNzMxpN/7mgTTYTh1sOk+wSioPYTodLGELuGvYrUtB0+eEkr8Nk03PDHXcA0LGjmuZPfqQt403KfP24+fnXWfrwk3x07W386f7HefraNH5KHY1i2DWEl5Xh/8O7yBxTEWRKKo3taGVNZK7J6rf5SpyelBA3AA5V922OPQmJy0FmRSui2F0RYTAxJNyIuvp6EnNzUD5kwq3KyhHrHCq+3kekJh7NRC3KdYuwd7ZQ4TWJqjX/pdA2CWfRh+HWQPwEgcPyatwEKx1o+MGphFlNkxAV3zDKZCJDe5BS5XVMq26hbHh3BvZ9+k4CNap+njUEBQVRVVXFQMvnI3F6NBoNQUFB/TZ+fks+VruVCP3RZIVBqVDwf2yTP4DGEo27dheeoguhccFY6jqp+Go/XRmv0+Gk5d/XzeU3dYeZP/4mGjROfFDTzCq5HH1IFJavvma87BrC8r9DIf+IPJ9RHMnfwagoNQfrZlJb1Ip/9OBaGIcysf4uCAIcqm5j2nDf/hZHQuK8yChrQSETSAl2629RzoshoWyNqKyiOqaDMF0nRosC88yHCPquE7ObmcCm52huauQr5lBR1137WimzUSFUkaeoZpjgwlhDKmmEUUsLH9nduS5qCi0VW7hK08UerzZsmno626I41N6Oo1zFXn0nc337/+GhVCpPKC0hIXE2cptyAQivPIJVVOHl54+5qA15hyMAjQo9V8+9B9Fqp+mTAgqLPiHEYmbtxPE8ojEz7he/JqOsFZvYwTNh/sz0cuW+Q0f494KbUa/ZRLh9NEGFe2l2SKZO7UCzrBNnWQO6g/vwj57Zn1OXOA6tWkG4l9MVb9nS6XSsWrWKX/7y/NM+zp49m1WrVuHm5nbGNkuXLmXSpEnMmDHjIqS8MHoz9tatW1GpVIwfP/4ySnbx7CtrJT7QFUfV4FJfBpe0Z6C5pgKmmHGpsVLUNYvmLQWEyKPxTCvn4O5a1nELMuSkW2LwtrminOqLZ3IgmZmZ7N27F4P/fqbX+fG06M+DookMj/0k70liUvBuBFFEqT1ER+1U/PR7cA2aMeDitiQkekNucy6eGk8CqyposETg176FLcIYnI0+OCkLKTdAzJgY2jZW8H31PsYWHGBjaipJTlre1YzngWc3YD1aTUEpFxgX6cWrU8P5bWUt786dwpOrNbQ0FROX/zm6xNmUFh3izglleMU91M8zlziZhABX9g/CGol9iU6n48033zytsmW1WlEozvx4/Pbbb8/Z/7Jl/VevvDdjb926Fa1WO6iULZPVRnaljjvGhva3KOfNkIjZKg7REdbVidkmozP9HvyMwZjdO6j86TXWiDMJM3dwQ5ECv+wfUThlEerQiY+rK7Nnz2bevHlU6jv51qcGGY0sx5Htdk9U/ulgVZFkMuPknEWNTEFc3X40Mhm5HQY6rQO/UKeExPEcajpEvEcM7uY6WhURKIu/Yq98NkabLxpNMTGRqdi7rOzOLCd490fUenhS7uzEy/LR7D5SS2JUA49Ms/HqdYHcNT6U7Eodf3wvkzsVThyyy/n6mlga0+Yg2G3EHzmITJCzX3EVDJ/d31OXOImEQBeqdQZaOgdG/Glv0K9bR9G06eTFxlE0bTr6desuqr8nnniCkpISUlJSWLJkCVu3bmXixIlcf/31xMXFATB37lxGjhxJfHw8b731Vs+1YWFhNDU1UVZWRmxsLPfddx/x8fHMnDkTg8EAwF133dVTYicsLIxnnnmGESNGkJiYSH5+PgCNjY1cddVVxMfHc++99xIaGkpTU9Mpsmq1Wh577DHi4+OZPn16T+hIVlYWY8eOJSkpiXnz5vWU+znX2GVlZaxYsYLly5f3ZJBfvXo1CQkJJCcnM2nSpIu6t5eKQ9VtmKx20gZZcDwMEWUrOrQcD52F8oY0DFlVqOQaZKrP+KEpjas3b2LEFxsQ9n+E/MgO5P/7gMr7H6Bk9rW0ffstSUlJLFy4kDp9J9lhFagwcS3DMQU2037YmRmdXVgcmmjUtCJvcqfVZMEOZLZ19fe0JSR6TaelkyP6I0QhIhesWFzCsHc0odA5IGCjxd7E5IXX0rajioy6TQQ21rMmwY/PPObQJTbjHfw2R4R/8N/aP/LCwV9g/fZJHlFlEuSs5O21+YzS2fnE0YMjAd7kpKTi1VpCYLsLeds309EysAvaXokkBHQnNB0srkT9unXUPr0Ua00NiCLWmhpqn156UQrXCy+8QGRkJFlZWbz00ksAZGZm8uqrr1JYWAjAO++8w/79+8nIyOC11147bXHmoqIiHn74YXJzc3Fzc+Pzzz8/7XheXl5kZmby0EMP8fLLLwPw3HPPMW3aNHJzc7npppuoqKg47bWdnZ2kpaWRm5vL5MmTee655wBYvHgxL774Ijk5OSQmJvYcP9fYYWFhPPjggzz22GNkZWUxceJEli1bxvr168nOzmbt2rXndzMvExllLcDgC46HIaJsBe+qxWoVaE6+F19zCB0O5eRtrmHqhi24dlpRJdxE7g2LCd+3l+idOwj+9wrkbm5U//Z3VD7wANGhoYwfP57Muk7qvfYTj4ID8kjElnGMsHa/+SmcijB0JtDamocA7JVciRKDiMPNhxERCWvqTsXgqFFzUBaDp8kJH2UhRkJwdXHiq7wqpm//juxQH772vhlXp07uNW3n5q0Cf2y+kUfdF6N0dmTdqCryWrcz/cCbjHS3cXhfHb4dNj5KT8MQkorOzY2oqiJEi5WDWzb08+wlTib+mLJVMziUrYblryAaT0xVIRqNNCx/pU/HGT169AlxsK+99hrJycmMHTuWyspKioqKTrkmPDyclJQUAEaOHElZWdlp+54/f/4pbXbs2MGiRYuA7lqM7u6nVyJkMhkLFy4E4Pbbb2fHjh3o9Xp0Ol1P8ek777yTbdu29Xrsk0lPT+euu+5i5cqV2GwD03Ozv7yVME9HvLTq/hblvBkSylaBeDsHymcjNJtR2kTat/yTsKIyVJMnoZ3yZ/Jiokm650YcHB1ReHqinTyZ8M9W4/vUk3Ru30H1bx5lyoQJeHl58RMKCtCRJMbhEBKKS7MKH6sVd6ds2s2+xDZ/Q7BGJcVtSQwqjgXHx9TW0WHzwMuwh02amzBbfXFWFTNy0iz0O6s43LwXt452Po4eg2DXMMVShk3ph3LKteimXEN9RBrTk54l0COaDfGViKN8STvwX3xkRkz7m6hss1CUGkNWSjIORh2xXYGMmbugn2cvcTKujkqCPRzIrW7rb1F6hbX29PnaznT8QnFycur5eevWrWzcuJHdu3eTnZ1NamoqRuOpucnU6p8f/HK5HKvVetq+j7U7W5vecr6Jgnsz9ooVK3j++eeprKxk5MiRp7Xi9Tc5VfpBtwvxGENC2fK69R5Y8ASujWp0O5/HsV6Pblo8TvH306WWo3drRvv++5TddRdFb/+ajB/nsW//PIpjP8N+33A6fvyRhief4oY5c2jv7CLfswgnZOh9IjDmeDDWYATtESoVIm7Nnbgo5GS1d0n5rSQGDbnNufg7+RPcXk+DLQr3jj3U6brTUFjEWlKnjeSzwnom71xPqac7WU6TGCeUEWxpxjFWRXDgW0S03cKYhnuZ0PQgs5z0jHXV8qVPNknzruaqI58hmM24H9TxlW8QHb6R1PsHEli2j+ofc/p59hKnIzHQddBYthT+/ud1vDc4OzvT3t5+xvN6vR53d3ccHR3Jz89nz549FzzWmUhPT+fTTz8FYMOGDT0xVydjt9t7YrBWrVrFhAkTcHV1xd3dne3btwPwwQcf9Fi5esPJ8y8pKWHMmDEsW7YMb29vKisrL3Ral4SGNiN1bUYSg9z6W5QLYkgoW6HxnsgrDsO+dxHam8iZmEzs7S9jq+lir6KI8M8/pbngOyrm7KUi/Fs6GnKwHa5BiSuNI0vQz7PSvn49mi0bSExMpNXUxdd0oCUCpXIqKVYLBrmNTscaTG0xdBiN6Kw2ygyDJ7hU4srmUNMhYrQ+OIt6OpVB1OFOYIcVZ3k9nXIfTMU6dhoLiKipZE3YVCKEZmJaMzHMgmT/D5A7O6Jrn0He4Ul0GmYTobax0KWeG52bWKHexKSrJjKx9ge6dCY6jrSTm5xEZkoicquRpn+/dW4BJS478QGulDd3oTdY+luUc+Lz2KMIJyUEFjQafB579IL79PT0JD09nYSEBJYsWXLK+VmzZmG1WomNjeWJJ55g7NixFzzWmXjmmWfYsGEDCQkJrF69Gj8/P5ydnU9p5+TkxN69e0lISGDz5s0sXboUgPfee48lS5aQlJREVlZWz/HeMGfOHNasWdMTIL9kyRISExNJSEhg/PjxJCcn99k8+4Kcqu4Xg6RBVkD9GMJAts6kpaWJGRkZ52xnMRopuPoWZPX57ExPZ8aceBQ742iUm8iy72DmbTEUtb6MWu1HuP/DqPeYaXjhJeSurvi98n80uOyl7ff/Rl0sw/Xd/7Lyq++wqXx4oC0RDAdpdP8Li8PdkTdMIaJpFFXpViqcR7AiLnRA5NuSkDgbOqOOiZ9M5B6PGB7d/wO5its5IJppr76RYQ5bUI2ZQZPNh9Y1LzK8JI87ZzzL3Pov8bpDTpp8C+WWq2mXPcDkmBCaizLZvn07s2bNws3vEFWlf6XKLPCTZjGzszS8XOpMlUsolgl+LM7YREJVI/OXPY3K59QHyOkQBGG/KIppl/iWXBZ6u371Fz8WNnLnO3tZdd8Yxkd6Xfbx8/LyiI2N7XV7/bp1NCx/BWttLQp/f3weexTXOXMuoYSXHpPJhFwuR6FQsHv3bh566CGysrJOaafVagdEMerz/cz6kn/8UMgbm4s49NzVAzrH1pnWsCFh2Sp+5HfI6/PJSU3BNcyK/DsjgtyRvapSRt8ZQkHzX3B2TmJU2hf4h92Ex6JbCftoFYJSSc39jxGsugn/555FxE7r//2K2OHDUNpb2U4XZodoHPJciDab8XDKot3qSUjrJlSCwIF2aUeixMDncPNhAMKPxmA4mcrItEzBjgqV/AjJ40axob2WcYcO8F3IOMIM5Viv9idNvoVvSq9i2ZZrWb6pirlv7uKjSmcCQiPYsGEDWsUsEhPfwlcpkGb4kNbrZnKtmAdWK2KejtLh8eT7OVKwfn9/Tl/iDCQEuAAMmrgt1zlziN68idi8w0Rv3jToFS2AiooKRo0aRXJyMo888ggrV67sb5EGLDlVOqJ9nAe0onU2hoSyZTa50TgsjYJh0aQ0tiCqh9Mo0+OVqKO+/lW8vGaQmvI+SuXPVihNbCwh7/4XBIHqRx/DZ9h8tA/fhPxQB5GVX2O3Wtghr0SFBqV4E6NMJlodddQoLDjpOvBWKciW0j9IDALyWvIAiGlsRm/1xcVehEubHIVgxISVhvwmNGV7AdgYPBqZr5WrfT/jsC6OzNabeGhiBP+9Kp7bo/3YXdzCP0vcUTtqWb16Na7O6QRELCVMbaO08DeMuO8+RrXuR15v4Ce5F2aZnCKxvD+nL3EGPLVqfJzV5NUNDmVrKBIdHc2BAwfIzs5m3759jBo16rTtBoJVqz8RRZGDVfpB60KEIaJs+cwfw4+pESSJhQiH3ZA7enHY4TAeXp+j1Q4nIX45cvmpW0VVQUEE/PUvGHNzaXjhRULuXQaRnqi/yiQsxAN3dT2VGFAFjSDGIGIVQNQW0tURhWg1k9NhwDaA3bASEgAFLQX4O/oS2KWj2RZGuUyLr1lJoOoQ6rCr+LiygakZu8h3D0YtdHFb8hfoba6sL7+feLsG8zfVHF5div8+PYublchMctY2B6HX69m5cyfJ4XdQrUxloqaKz5o+5rZJkajtRsxFbbgvuJ35i+/s71sgcQaG+7tQUHfmIHEJiYFAtc5Ac6dZUrb6m31F3yMKduJzs3EYfQsdKiPuI1ejUGhISlyBXO7Y09ZgtvHZ/ipW/FjCm1uL+dE7Fpc776J11Sq69mUQ8OgfUTQJhJStRWG38LmsBUHlSVSZBwpRJMTpJ2wdw1HqDtFls1PUdepWYAmJgUR+az4Rjm44i3oMgge7NNdit7vjpSzAP2Yi+4VmoqvK2Ro0Aq/gJgK1tbiG/J4nQ2KJO2Im1MuJukQtb7jqaZuq4uUZ0XSJzpRZPdixYxc6nY55o/9DiUnNHPunZKXGM9Gcj7zFxLsFzZjs9v6+BRJnYLifM0UNHVht/fMZDeSYYYkT6c/P6uDR4PjBuhMRhoiyNcypk+nWXag008GupcJzM2pNCwnxr+DgEAhAl9nKKxsLSX9xM4+vzuaF7/L52/cF/GrVAW6RjWJD4lXU/+PvOE+/GkVUEF5bq1ApRfTyOmzYcOpYQKzZjMyxHIPFl4C27uRx2W2G/py6hMRZ6bJ0UaYvI9Ry1OVttVBmiAdARgO7y+qJyd2DTRA45BXCgoS1NMhj8K4cRdYPFcRN9Ee2sJStnr9DEbeUtYZfsqT+NubMLCTHHozVbufj/36JVuWKNvABZNhRVP+Zq+ZPRi0aac9v5fO6ln68AxJnI8bXGbPVTlnz5c8bqNFoaG5ulhSuQYAoijQ3N6M5aUfo5SKnWo9SLhDr37uNNgORwRlpdhIueeCUX4l6/gt0VXcgj1uDr+8CPDzSAahvM3LvexkcrNYzI9aH+yZGkBTkhiDAtsJG/rmlmOWRV1NcupPnN27E91e/o/rRx4hr3YNRO54sq44R3qkMt67kS0cjosxOnP4I6mCBrPYuFvoPvjpNElcGxbpiRERCW3UAyIVOXNvtqIROBCdXditVzP9pJzleUQT6VeGpacUif4Y9X5Til+TIa05/pDijiDF+YxgfMJ7Nh/Vk1O/nK/EdrH5p5DaMQq4vY9Pq/cyddx/Pl73DdO1B/icvZ4aymW9aNRhr9BBw+Xe7SZyb4UcfXvl17UT1csdoXxEUFERVVVVPnT+JgY1GoyEoKKhfxs6p0hHj54xaIe+X8fuCIaFsef76TxgOl9Lxk5EW/23YBSeGxzwFQH5dG7/47z70Bgtv35nG9FjfE66dGe/HVXG+/OWbw6wEZKsz+ccbj6GMCCFsfyVZk+xskbUyUhFFVJsai5OAVpuDsSMCNxlkSUHyEgOY/JbugrfDmvW027ypVsjxtDgQoMrF7DqSOlM9gc31fJYygdmj1lOrHI3hMxe8ItS85fUsJpORV6a+wrTgaQiCwK3DbVz72nY665uIjF9Lpr6NGKucHQd2E5sSSVDw3TQ0vM4M8TVq5/4b7/9loc/sgrTIfr4TEqcjykeLXCaQX9vOdUmXd2ylUnlCaRwJidNxLDj+2qSA/hblohgSbkR1dDQylziwQ0fYeoKDnkShcKZOb2Tx23uxiyKfPjDuFEXrGIIg8NS1cdwVIuMrz0T+sXI9not/gbpWxNdQBfIGrJgZ3ty9UyTQ8QBiezzq9iMc7jRglmJSJAYoBS0FaJWORHd20GQNI1szCrvdFT/lYbJFP4YfzsAmyGgJVOOtaUGonY/VYmdt0L/RW3WsuGoF00Om95QH0SjlvHxzMg2tDgQaH2FSWiMFdg9EVTPfvrOPeSGLWNfmhK/QRFHn9/zn9jh+fdcN/XwXJM6EWiEn3MuJfClIXmKAUtVqoM1oJSHQpb9FuSj6RNkSBOEdQRAaBEE4dIbzUwRB0AuCkHX0q/dpbnuBaBfp2FtNp3sBzTYtMTE3YjDbuO/9DDpNVt6/ewwJgWffxSAIAksfvJqp+mL+XQl1aZMQNGriK3NwkxnIktfhJS4k3GIBx0pMpiBcO3Mw2UUKOqUgeYmBSX5rPuGO7riKOrpsbtR2RQOgltWQ5+7LuKxMDnuEkpqYTYMQhm6zB43R+Ry2ZfHK1FcY7jH8lD5TQ9y5b1IEn+6r54H4J7AFG7AjUE4pBz6tJzF4ISUmOVdZP+U7Fy8UKtXlnrbEeTDcz5mCein9g8TA5HBt999mrL+kbAG8C8w6R5vtoiimHP1a1kfjAmAq0WFvtaAL3Iqb6z0APP5ZNodq9Lx2Syoxfr2LRZDJZPxpvC+OZgN/WJOL86xr8MrrQm6xsFPeiUzhQqzFTrXGQLOowLU9G4DcDilIXmLgYbPbKGotItzeXVbKggyXLjkqoQOrTE2p0kZUfSXZPhGkBWdRVz8DpYvAGpf/8EjqI4z1H4u1pQXTkSMY8/IQzT+Xp/r1tGjcHZW8urGEt269myOiC6jrKc6pYYryWr7RK3AT9JRWfUi1USprNZAZ7udMZYuBDtPFFUeWkLgU5NW2IQjdf6eDmT5RtkRR3Ab025Yj3c5CrMp2Cq3tJCXN4PPMar7JqWXJ1TGndR2W6ctYkb2CBesWMOvzWTy1/SnWlazDZrcRNm8Ovyz4jpxmMzti0hGMdkLqSjDTil00M6zLgw65DBenLOQ6O0pB4JCkbEkMQCraKzBYDYS2dydErBQc8LA4EKjKpdIhFt8j3QWiOyLlmAU18t3J7A35mhCPIBb5XEPVo49RND6d0mtmc2TefEpmXYPus88QLRa0agX3T4rkx8JGqpoFUkYnoBBEKtzLKV1rwNdjAqVmDbPFL1hTW92ft0HiHMT4dVsMpHxbEgORvNo2wj2dBm3m+GNczpitcYIgZAuC8J0gCPF92XFjxKfUxH6I2TYDi8KJ59blMjrMgwcnnRqU+3nh58z7ah5vZr2JRqEh1iOWnTU7eWrHUzy69VGMarh+dDijGvJ5/ogcRXgEw8tKcJcZKFPWEtc+EwB/pwMYOhNwsXVxqF1StiQGHgUtBQBEtXTRZXMhXxUBdmcCVIfZ4zuKcZn7aXBwIzKtkFLDZORKOXu1m3jacjUVc+bSsWkTnvffh8+TT+B+++0ITo7U/ulpSm9ZRFl1LumxFtydFLyysZBHr5lOo+CMTNlIS30Ho4zT+KpVxJl2rhW+7+c7IXE2jlkMJGVLYiCSV9s+6F2IcPmUrUwgVBTFZOB14MszNRQE4X5BEDIEQcjo7ZZgj8i72dvgTFxcGk98kYPFZudvNyUhkwk9beyinb9n/J1ndz/LaP/RbLx5I+9f8z7Lpy5n64KtPDn6SbZXbWfxd4uxzJ/J4tzvaDfbyRsxBZfqDpzb2tit7CLQOB1vmw0cK6ArDKeuUnI7DFKuGIkBR35LPgpBTlyHgWZrKK22EACcZFUc8AhmZMlhMn2jGe5VTFfmePZ5recWIQ3tn/+NKigIr4d/iX7Nl9S8+BI56zeyXShj1TQFXYcPk7X4Ju756iZU4f/H3vaVfF9wiBEj0nAUrOR5FmPb7EOXzI999jiCAhf1852QOBtB7g5o1QoKpLI9EgOMdqOFipauQZ1f6xiXRdkSRbFNFMWOoz9/CygFQTht4h1RFN8SRTFNFMU0b2/vXvWfn1+HXh9AGT5sLWjkiVnDCfNyOqHNP7P+ybu577IwZiH/nP5PfBx9es4JgsCtsbfy5vQ3qWqv4unqfxEX6cOotnJes4cBEFBdQbWtDRkyYi0iNRojZos7roZc2m12KqS4FIkBRkFrAcFOHnhZdXTYPFF3qZFhwSwTkNcX42Ax0RKpoYFAtA2+lDv+yNx3ipB7eqIMDeXLzTu479dPMfv191m8bDnP/fq/HJz0IjlpoxlWA//6NoDxPqmoXA/wx32/QB5WjgkFJkUrNqPIGPs0VlWXU2e8suu6DXQEQWCYr5Y8ybIlMcA4Zm2VLFu9RBAEP+Ho3nFBEEYfHbe5r/pXKBRExSawfPMRkoNcWTwu7ITzO6t3sjJnJXOj5vLHMX9EITu973d84Hj+NPZPHGg4wLezvViQtY5i0ZG2yFjCa6pwEzrQifVEmTyoU8pxUhWi6SgBkOK2JAYcxbpiQmQCCsFKC064W1X4KEsocY1hdOZ+zDIFXmOqqWoeTYHPTzy1UY2ga0P08uKvTl786aHHMTv5sKjcyq/yG5mgt5Hj5c8f7nyU/Am34JRfye/3eHKD12tYOiL4e+ZLtHo0E4iJ/Z6H8cqIR0Dg29Jv+/tWSJyDGD8XihskpVhiYDFUdiJC36V++AjYDcQIglAlCMI9giA8KAjCg0eb3AQcEgQhG3gNWCT2od9t8uTJVLnE09Bu4pnr409wH9Z11vHk9ieJdIvkqTFP9eQLOhPXRVzHVaFX8Y59O1p1JSlKA9+4x+LaqMelo50Mp2aGGboz07trD2LTaRAQpbgtiQFFm7mNus46gg3db4Z5Mh/kVhd8lQVkeqYysuAQuZ5hxPgXIxamIrSuI6iwFc2oUTw+eTafT7uGRZVmXt5fQZvpdaZf78QHN41h/6QERqk0/PLW6ymNHYtu1cfc7WDDUHUn41zv46DDXmQCtKraUXe68ITTC9ybeG8/3w2JcxHto6Wl00xzh6m/RZGQ6CGvtg1XByX+rv1TJqgv6avdiLeIougviqJSFMUgURTfFkVxhSiKK46ef0MUxXhRFJNFURwriuKuvhj3GGVNnby9/QjzUwMZEeJ+vFw8u/tZjDYjf5/ydxwUDufsSxAElo5dipvGjX/f6MSN+Rv4ziMWAL+qagrETobppyMXRTQOR1C2xeBsbZfSP0gMKEp03RbXEH0XNlFOqSwGUOCjLGSPQyjhLTXUB7nQhB/WDgM37zWiDAjgLa0Xe+NTeCLfyOKKep4M/ju3zb4Pb4MPjY2NuCkVfJo+nFu83Xns7rsxOTpj/sMSpoe5cCA3jsen/J5mdTPhsjayvbNo2+aAudPWvzdD4pxE+WgBKJKsWxIDiMO17cT5u5zTSDIYGBIZ5P/6XR5KucAfrjkxAeP26u3srN7Jr1N/TYRrBADN1R1s/6SQDW/nsuHtXH5aW0qn/sS3OTeNG4+OeJQS5y5Eww5kXl7U+EcQVl0J9k5UVhlhVjttGh12YzAuhnLJjSgxoChqLQIgrs1CqzUImak7hlElb8W1vBgAWWInlS2jUTV+gWeTmQIHJ/57/QJm11uZ3WbkV/7/R5yYwJZ3t/Dhhx/yz3/+k5dffplNG9bzwjB/Rgf589fb7kHsbOORDW/T2G5CaRjF8PhkXGwaCrz2YjZbObRtYKd+6EVSZkEQhNcEQSgWBCFHEIQRl1vGS020r6Rs9QVWmx2T1YbFJlUVuVhsdpGCurYh4UKEIVIb8XczY7g+ORBfl59NjRabhZf2vUSYSxiLhi+ita6TbR8XUpXfilwpQ+uuBhGKM+o5sKGC2HR/xt8YhVLVXehydsRs3jzwBmvSa5llqec7j1juyf0G9842KlUVDLM6sUPdRYDNiIuxgsOmRJrNVjwHeS4QiaFBUWsRjgo1UYYWKm3huFrUOMmaqHX2I/XgIQxyFX4JVZRmzWVy9rfg68vj9z5GuAWeyDXwx5DlqKwaog3RJE9IJiwsDJ1OR0lJCXv27KG0tJRn5s7n1rHpZG/bSFLhQaaFpvO/PZ68c8dt/DXzBYJtCj5LeZmbJ77X37fjXLwLvAG8f4bz1wDRR7/GAP86+n3I4OeiQatWUFx/ZQbJ69eto2H5K1hra7Bo4b3J0CkI3PqjiGcbNLvAx1Nk2EWR238U8WiDJhfIiIJRxQKebXasTnY+miznmyQ51+bYuHWTiMIkACI2tcj/psvQyQXu3ijiZAABEbnKju+INlzDul/W9WUO1Ge6YDN3P4cENzf8//gUrnPm9OPd6R/KmjsxWuxDYiciDBFla5ivM8N8T/xAVuWvoqytjH9O/yc1eW1sWHkImULG2LkRxE8IRKNVAqCr7+LADxXkbqumtbaT2b9MQqVRoJQpuTf5fpZ1LePqHz/h3YBF3JP7DUFVVWQlBBJtGs53Dll4OWbT0WEEbzjcYWCix9D4w5AY3BTpighWO+JEB+WiJw5WJ/xVmWS7JZJaup1C70AEZQu+uTtw7bTzbUocrW7uvLq7k92e+ylSlHO3/G7uW3wfDg4/u99HjhxJcXExa9as4ZN3/sPzC2/jb3MX8saLf+J32ZuYo/CjxQTeQeGYaqxkux9kxaF/8ez4Z/vvZpwDURS3CYIQdpYmNwDvH40z3SMIgpsgCP6iKNZeHgkvPYIgEOWjvSItW/p166h9eimisbvsmrId7vyuuwyc6mhksXcbPPiNHdHOCcdmZXYrTSCg7JSzYAN419mYfgAU4jHXl4DcJHDrd4AoHvfQFbCZ5dTudes5UrvXDdH+s8tM1OmoefIpgCtO4cqvHTo7EWGIuBFPpt3czr+z/016YDqeRyL55o1snL0cWPDUKEbOCutRtADcfB2ZevtwZtwdR02xnnWvZWM2dJetuCHyBnwEFzaHVxAYHkiNuz8+tXVU2YwM000FwNmxCHtr98PooORKlBgAiKJIsa6YYHv3wyNPFoFgd8RPWcBOh3BCdPW0Rmgo6xxFRMV+rG6uvHHTYmY02YjAyquu7zHJYRIPL/wl9sNttHxSQO2Le2n4Vza6b48QrPLhwQcfxNnZmew1qxk3OpXtyWnQUMgDpXv48kA1U8em4WBXEmCIYYz/oDcCBQKVx/1edfTYkCL6ClW2Gpa/0qNoHUNp+1mpOtuxkyOJNFaYeeDUdgAK8fTWDdEu0JDjTEOO8wmKVg9WKw3LXznXNIYcBfXtyISf4wkHO0NS2fqk4BPaLe3cqn6ArasKCEnw5MYlI3H2OPOOhmGj/Lj63ngaytrY/EE+ACq5ijtjF5MXIjBSlsluz2H4NTagMXcS2OGLg13E7lCDui0YB5uBvE5J2ZLofxoNjehNekI6ugBotgUB4KUshlI9AKr4DjT5Lvi2GtkeGYtJreaBfCNvOn6MTJDz9MQnafp3Dq2rCzEWtqIK0IIo0rGzmsY3s7FtbeDWhYuw2+14/Pg9a+cuAquJG/Q1bNhVwLBhwxDkCrxqJhHtNKHf7sXl5kKSMg8Uon21NLab0HVdWTkDrbV9a6CUXcA+e2uXHGuX/Mzn+1jGwUBRfTuhnk5olGe+L4OJIadsGawGPjj8ATMcryNvtR6fEGeuvi8BpfrcH1jkCB9GzQmnJLOB4v0NAMxLvhWVVaCp4ztyAmKR2+34N9RTrqgiyiqnRm1GaXTH1VRFfofxHCNISFx6ilu7A+Cj2+x02VxRmx0QsGJ0sJOUl0eXQo3XsGpCdmVhU8hZvuhurmu04WJv4we3HSzyuRHzf8qwtpjwvCMW/z+OwfOOOHx+mULA0nE4jfWnY2cNtlWVLLj+Rjqamoh3kvPjiDFY6nOYn7WbggYDw2KGEyrXseHQoH9QVAPBx/0edPTYKVxIUuaBQrRPdwjElZZvS+Hv36f9nc44dU4ZHG0oHM+8a7evZRwMFNa3Ez1ErFowBJWtL4q+oKvdROzemThoVcz+ZVJP0HtvGDEzBJ9QZ378qICuNjPOKmcm2iPY5d2AW1oCJrkKv9o6DjnqGWbxpUCtJEhegdZUSkGnEatdKtsj0b8U6bp3Isa3G6mzheBkc8RDUUGh8zCSyws44utLkzmEyPIj5IdE0uWo5d48Ix9qv8ZJ7sQNe8cgd1Hh++sUHOK9EI7LWydTy3GfG4XX3QnYdGYc17cxafwENJl72H/1dSjMBsYYO/huczZpqcmoBRvTAgb9zqy1wOKjuxLHAvqhFK91jCs1/YPPY48iaE70eljkYD5JaTrdsZNXe6MCNqSe2g7AKoD1NOMLMhGfpHZ8ktoRTmcWUyjweezRc01jSGGy2ihr7iLGb+jEQA8pZctis/DuoXe5vvoBbAa45qFEnFzV59WHTC5j2p2xmI1WdnxaCMDcmBvp1Ah4K/eS5RWJb10d9XYz0Z0jsAgCjg5FKAw1mEWRIwYpKaBE/1LUWoS70oFgaxvF9kBUVi2+ymL2y8MJbmugPVKBosgNpU3kP9cvYKLOhqOtg/We21nQMQsnmQNev0hA4XnmvHSaYe54Lo7F2mQgptAdPx8fnAw6DkVE09FwgOjvNhMSGkZwcDB2+8BWtnqRlPlboBQoBlYCv+wnUS8pgW4OOCjlFNVfWcqW65w5+P95GYqAABDA4gzvXQP/uk6g0QXsQKMLrLhWxr+uE2h26VayGl3g+1RochEQEbE42fh0Jrw7U87H14C159EjYlPbWXUNvDlHoMPhmJImIlfZ8B+twzXMgGuYAf/ROuSqny1cgpsbAX/9yxUXHF/a2InNLhLtO3SUrSGxG/EY35d9j0t5MB61oYyZF4F38Nk/KKPNjgg4yE/UOT0DtIyYGUrGt2WMmNXBxPGL8Mp5iXJhI+1+YxiTnYe7vpUQYzL4fINKU4W9NRACIK/TSLTT4M92KzF4KdIVEaxUoBAsFBEJogpvZQmNdXEAqIe34b9Jj87FhayYeF7b38WXTluRI+fq6jF4LB6Owu3cLymaKHc8FsbQ8lE+U+NHUF+ynp2TZpDw7r+It8nYvzuXe+6551JP96IRRfGWc5wXgYcvkzj9hkzWvSOxuPHKUragW+E6XqH5+2naTDruZ6PFxoLnNzJ1uA+/vSW153gS8NfTXFtY385Hy7fxh1nDGfVS5JnlOPp1pVN4NAXJMF/JjTgg+TxzLRPLbsY/ypWUq0JO2+ZAWxf3HSpj9O7DhG/LIXp7DtftL+TF0lr0lp+NvMnTg1Fp5GR8ewS5QslVXeEcdGzAlNb9wAqoq8Vs68DJLmJSN6Nt8UYQ7eRJOxIl+hG7aKdUV0qw9WhwvDUAAA9lGR5lLVgEOQ5B7fiVNLMteRQBRhspLUa+8tnIxLZUgibGohnmfrYhTsAxyRvtpCC0hyyMGpZCp0qgwd2DxpYszKu+vyRzlLh0RPlor9hcW+fDhsP1dJis3DIq+NyN6U5PNCLEjTUHqujDSnVDlsL6dhQygQgvSdkacBxsPIjngTiUqJhxV9wJ9REBKgwmbs8p5Zr9hexobWeEiyO/DfPlwWAfBAReLa9n6r4CtjR3F77UOClJmhZMSWYjzdUd3BB5A3YZCEFFVDt54VdbR5Gjngibmkq1DTeDI86WJvI7pSB5if6jur0ao81IWFu3O1thdUbASqejQFxlKVVenljqPQD4aOb1zK20sl+dh1Fu4nrLdFym9e7hcTyuV4Wi8HUkrsSDCHMnW9On4lGVR0C7gKmxqU/nJ3FpifLRUqM30m609LcoA5ovMqsIcNUwNsKz19fMHxFEYX0HuTVtl1CyoUFhfQdhXk6oFENGRRk6ytaazT8Q0ZLMiGuCcfE6MdZke0s7V2cU8pOug6ci/Nk3Lo4V8WEsCffnT5EBrBsZzTcjh+Ekl3FLTimvl9cDkDwtGKVaTsa3ZcRMuYGIWpFGwy4yfYbh3dhIDSaizH4UqFSEyipxNpVzWLJsSfQjJfrumojD2qHZ5o2DTYuHopxcx3CGNVWgD9HgnmOm0c2dRg9vrq+y8LXXj4Qa/Rk7eTrCBWyzFhQyPBbGoDQIpDkPp87bA6tMTpW1lsLXP+rrKUpcQo7t/ipp7OxnSQYuDe1GthU2Mjc18JSX+rNxXZI/KrmMNQcGdvmqgUBRffuQciHCEFG2GtubUO4OwuZiYPTVUSece6+6iUU5JfiolWxIi+GRUF+0ilMfKKkujvyQFsM8Hzf+r7SWT+ta0GiVJE4NojizgQ6bA2NbPCiS1dE6PAql1YpnUxOh7YmYZQJO6lLUxkoqjGY6bVLhXYn+4VgB6uGdBnJtw1EeDY4v1rujsluRRRkIyGjih9ETmNBqxWJrJkebx/X26TiN8D21w5os2PA0vDEK3poKXzwAOavhJFeIKkCL8+QgoivdiJSJZCQkoy3ZhabEiL1TenAPFiK8ux9wpVdg3FZvWZtVg12E+SPOL6+tm6OKacN9+CqrBqtUO/GMGMw2ylu6TqkKM9gZEsrW56u34mL0YuzNYciPMzuuqm3mD4VVTPVw4ZsR0YQ7nj3oVyOX8WpsCBPctPw2v4IfW9pJmhKEIAjk7axhiudYRAFMI7rH8G1oxF3fbUaWa6pB3x1wXyC5EiX6iVJ9KR5KDb72NgrswxBEJT7KEuxV3cqRo78emUHg+3FTuKrayjZtJgq7nLmTFp2Q4gGbFdY9Cm9Nhj1vgmswaFygdCt8cS+8NweaS04Y23lKMCoXB0bLosmPisK5s516JyXNH625fDdA4qII9XREIRMolSxbZ+SLzGqSg1yJ8jl/ZWD+iECaOkxsL5bc62eipLEDUURStgYiJgy0hpYxelR8z7Ev61v5XX4lUz2ceTsh7LTWrNOhksl4JzGcKEcNDx0uw+QkJzTBk7zddQxPnoFPq0itMotyZ198GhroEq2o7WDUtODY1P3HISU3legvSnQlBMpBLthosXbHX3kpS/GobKXZyRmHZoFmFzfqfPwY12DmO89tjLYl4x133IYSUzt8tBD2/xfG/xoeL4I7voDFX8Fv8+C6V6A2B/6VDke291wmU8lxvTqMsEZX3N3daXRzR1+9hybF8Mt8FyQuFKVcRoiHIyWSZeu0FDe0c7i2jXmpF1ataUqMD+6OSr6SXIlnZCjuRIQhomz95u47ePIPd/b8vlfXwa/zKhjj6sTbCeGoZec3TReFnDfjQtFbbfy5pIb4CQEY2sw0a4cxqkikwJhHnl8EXo1NVClNhNvUlKlFgjpsKOwmqWyPRL9gF+2U6EsINh19UFrdEbBicrQwrKGCpiAtHjkGtowcy9gWG3VCNfXqJmaFXo0gHLVq2W2wahGUbIE5r8LM58HR4+dBZDJI+wU8/BO4h8JHi6B6f89px1Qf1IEujDIFkZGQTGhpDrvdTpfKUWKgEuGtlSxbZ2BLfncJpqvi/S7oepVCxtThPvxY2IhNSoB9Wgrq21HJZYR6OvW3KH3KkFC2AOSybstVjdHMPbllBGtUvJcYjqP8wqYYp3XgwWAfPqptoTZQjZOrivwsPeONwVgEG7okd5Q2Kw4tTUSY/clXqYgSanE11XBYsmxJ9AO1nbUYrUYiOkQsogKV3Rl3RQWHrYF4G/TYIqyoiwU2p41nRo2Vn1wOobIrmTH+up872bEcynfA9a/ByLvOPJiLP9zxJTh6woc3QmN3AmBBJuA6O5yoDm+6QkKQiyLeeTsu6bwl+pZIbyeONHdKysBp+LGwkWgfLYFuZ074ey4mD/OmtcvCwWp9H0o2dCiu7yDcywnlBT67BypDajZGm51fHDqCwWbn3cRwXJUXl7P1t2G+BGmU/L64imHj/anIbSYubDrOBqiM6TZ1+tU34KuPpEsmw0lVgYOpXLJsSfQLx4Ljo9tF8m3DUFic8FWWUN/oAoCjnx6zWUNJSAQTGs1sdNvJOE0azk7d56naD1v/CvHzIeW2cw/o4t/tWhTk8Pk9YO0uYKyJdMMh3I1RQjifXDeXsOtnX5L5SlwaIr21mK12qluldex4Ok1W9h5pYfKwi6t5OTHaG0GArQUNfSTZ0KK4saOndNRQYkgpW88UV5PdbuCfcaEMO0sWd7vRSmdGHY3vHKL+lUya/5dH2+YK7MYT3R1OcjnPRwVR1GWidJgjogj17iNILbZTIBykwsUHn4YGtJ3dfxiiuhahs40Wi41ms+Q6OV/a2nIoLHqegsJlFBe/iNFY098iDSpKdaUAxBiN5FoTkIkqvBRHsNeJmGVytF1msobFMkpvp4l6GtUtXJtwNGu21dQd+K71g+v+AUIvt7R7hHdbwepyYNvfeg67TA9hWKcfbt7e2Czmvp6qxCUkwrvbfSPFbZ3IntJmzDY7U2J8LqofDycVyUFu/FjY2EeSDR2MFhuVLV1ESsrWwOXbRh3v1TTzULA3V3udueCBoaCF2hf20fpZEdYmA3JXFZaaDtp+KKf+lUyMJboT2l/t5UKi1oE39Tp8I1yobHEkqQza7B0UBoXg2dSE2SYgF8GgaUXZogKkHYnnS3nVx/xu/xquq5zI7KppXFcxmr/sfoGW5t39LdqgoURfgptChb9dT401HAAvZRmu9W00eLviVGBne8ooptba2Kc9hEZUMyV2RvfF+9+FllK4/lVw6H0GeQCGXwspt8P2v0PlPgDUkW44hbpzs208yQlJfThLiUtNpPexXFuSsnU8WwsacVDKGRV+nv8fp2HyMG+yKnW0dkovIsdzpKkTu4hk2RqoVBnN/Da/kmRnB56M8D9tG1EUaf+xiuZ3c1G4q/H+ZTJ+S9Lw+kUCfktG4f1gMoJcoGnlQTp2/2xREQSBR0J9KTWYMEY701xjIF49AoCWeCeUNhtieyuBVhWVKpEwXbdFq6BLUrZ6y978l7m70IzY6MqqA0/yxYHHeSn/Vb4zXsMvs3dSlvtaf4s4KCjVlRIosyMTRKy2bleHTNVKaGs9XYFyVMUCGXFJjGuysMltN+PcRuOgcABzF2x7GUInQOT0Cxt81l/BJQjW/gpsVgRBwGV6CGKbhc799X04S4lLjbuTCndHpZTY9DhEUWRrYQPjIz1R93Jn+9mYEuONKCKlgDiJYwp+lLekbA1IniiswiKKrIgLQ3WGnYftmyvRf3cEh0QvvB9KRh3i8vMOLEAd6oLPb0agGe6Bbl0JxqLWnnOzvV2JclTzkWt3CQtb8HSCm6A0sjvA0bOpmXCLB0UqJcMt9ShtBsmy1UtqGrfxSFUEtxdv5D+HnyGlrZ54vY5r63eyef8DtLX780idCmNTdn+LOqARRZESfQmhpi5syJDbnXGSNVBi8sLRakLub6RR5Y2zyg2rtYkqhzqmxBxVrPathM4GmPan3rsPT0bj0q1wNeZD5nsAqKPdcJ4ajDrMpY9mKXG5iPTWSolNj+NIUyeVLQamxFxcvNYxkoLccHdUSnFbJ1Hc0IEg/OzKHkoMCWXr/6IDeSs+7IxJSw2Hm2n7oRzHVB88bhmOTHX6NxOZSo7HLTEovB1pXpWPtak7QFQuCPw6xJf9ghV1kCO1BJF4xM4hWQENjm54NTXh1R5Ag0KBp7wWZ1Ml+VLZnnNis3Xx18M7eOnQ69xetY7/1U7klfxYXimI4pWiMRxu9OLLA7/BtcXG2/teRbRJcXBnor6rnk5LJxEd0CB6orRq8VaW0tjUrei4yfXsShrJ+EY7WY7dOwcnhU0GY1v3DsSoGRA67uKEGH4thIyHLX8BYxuCIOB6dRhK36G3cA51IrydJMvWcRyLr5o87OLitY4hlwlMjPZmW2GjVJj6OIobOghyd0BzAWXDBjp9omwJgvCOIAgNgiAcOsN5QRCE1wRBKBYEIUcQhBF9Me4xQh3UTPc8/duzpaGLlk8KUAZpcZ8fdYI163TI1Aq8FschCNC8Kg/x6Pbn+b7u+KmUFASpadbJiK9wxyxaKPELxKupCU1nd5yYoK5FYawjr6OrL6c4JNlU+A6uFR0kNeSyvGwa39iT+TRoPt+HzKIkIJVtdQF8XzeM5Xkv8IHsekp+/E1/izxgObYTMapT5LBtODKbAz7KI1gaZJgUCjStIj/FpzC+ycpPLtnEOQ7Hy8GrO1bL0ApTn+rpy2Sqp6FhPVXVq6iq+h9mcy9dHYIAV/8fdDV1K3ASg5ZIby1NHSbapILUAOw90kKQuwMhno591md6lCdNHWZJqT2O4oaOIelCBLi43Ag/8y7wBvD+Gc5fA0Qf/RoD/Ovo90uKaBNp+SgfQSnD8/a4XhfZVXg64HZDFC0f5dO1vx6nUX4oZQKL/D14v6WGhwEv1QTk4rfURjkwrtSIQ3cmCKyqJuTtFvQeIo1mC94q5aWb4AAiJyeH7777DoPhVIuek11NmjWCKJs/CFAiq2O3shATVhQo+YfyIQgXiBflXG+3Uilro1OQQ0w6bVZnVlqambUri09FP4Qfn8eEFaXNjo/ewiRVOo4KF0x2A4igljtgshmQyWQoZWoUbhpcrg7DKbVv3kgHKqX67p2I0UYz35oSEBDwUhyhudFKk68znuVWim4YRvSuTjK8D/Fg5INgt3dniQ8eC4EjsdstVFa+Q+mR17Hbf/4cC4uex8/3OiIiHkOjCTi7IIEjIHFBd4mf0fd3p4eQGHT8XCOxk5Rgt/4Vpp8RRZF9ZS1MjO4bF+Ix0sK6kwVnlLUMyYDw88VmFylt6mRitFd/i3JJ6BPLliiK24CWszS5AXhf7GYP4CYIwiVfhTt2VWOp7cTthkgUbmevi3gyDkleqEKc0W8ow27qdl/d4u9Bi1aO3VeD3ieNmAYFJZHd03ZubsPVJqNebcav+WiQ/BUSt5WTk8OXX355WkULoFNmYoeygBJ5HSWyOrYp8zAJVhAAQUAQBAQBLDIb+fIaOmVmELqvK1Y2YZKLIIBZZuu5zqKQUefhQK26C0EQ0Mgd0Sgcu39WOKKSaRAQsOlM6L4oovPA0I6NOKI/glauIMDeRps9CAA3eTl+umZMQVBBGAldSo4oKxFlIpNDJsORH7t3II66B4ullX0Z8yku+RseHumkpX1BevpOxoz+jsCAhdQ3fEdGxk10dBScW5ipT4HNArtev8SzlrhURB5L/9AgxW2VNXfR1GFmVJjHuRufBxFeTng6qdhbdrZH55VDdasBs9Xesxt2qHG5YrYCgcrjfq86euySYdUZafuhHE2MOw4J568pC4KA63UR2NsttG+tArrdlRPdteT4yWm1u5NYIGe/SwVGhRLv5iZCLM4UqVSkdHbvviq8QpStTZs2YbefvYq9TbCToSglQ1GKXThLjMLJXt6zeH2P9XkuRIudtvVl52w3mClrKyNAZkcm2JDZ3FAIXTR2KVDbrTi6dZAZk0B6o41sp3w8lB7EesZCxjvg4IE9ZhbZOQ/S1VVMYuKbJCf9G1eXZDRqP7TaYcTEPMuotM8B2J+5CJ0u4+zCeIRD4s3dVrPO5sswe4m+JtjjaEHqJknZ2ndUGRoVdvEpH45HEATSwtzJKGs9d+MrgOLGbvfQULXyDbgAeUEQ7hcEIUMQhIzGxgtP+qZbWwoiuN1w7jitM6EOccEhxZv27dXY2kwA3ObvSaaXHBGB8OYY7DIo9QrAs6kZny5vilVKQm21KG1dV4xlS6/vXdmJDsFIh9C396S3/dl0pj4dd6BxRF9KsMlAK24obFo8lBXUtXS/iTtZDGRHxzKmycJm95+YFDwRWXs95H+DmHorh4ufQa/PIC72JXy8rz5t/1ptDCNHrkal8iI75z4MhnMU0p34W7AYut2JEoMOpVxGsIcjZU1S7Om+Iy24OyoviRIwKsyDipYu6tuujGfF2Sg+akWVlK2LoxoIPu73oKPHTkEUxbdEUUwTRTHN2/vCfOSmUj3Gw804TwtB4XHmTPK9wfWqULDZ6dhTC8AsL1cMPiqsahkqRQJKUcaREDdc9XqcW92wCAJqRS1aUyWHr5Adia6uZ04iezxaUYNWvLjP43R99gb5ebqRBxNt5jaaDM2EdwnU2n1QWJ3wVRRjaFJiUKmQN8hoCIxEbm6hUdVCetAEOPAhiDaqQ72pr19LZMTj+Pped9ZxHBwCSUl+G1G0cyj3Eez2syRk9I6B2DmwdyUYpRpwg5EwT0dKm6Tg7YzyVkaGelzwS/vZGNUTtyVZt4obOvDSqnBzVPW3KJeEy6VsrQUWH92VOBbQi6JYeykGEkUR/YYyZM4qnCecI5i3Fyg8HdAM96DzpzpEix2NXMYN/h4U+SrQeSYS1aKhPMqATBTxaeiO1bKpG5Ebmijo6LoitvVOnz4d2Rnymx1DLspIs0aQZo1AJp5l0Tr5dp3l9h3r81wIShkuV4eds91gpUxfBkBEl0iuJQlBlOOlKEPdbKbVz4E6YxCxBgfyNUcAGO03CrI/whIxjpL693F3H0do6IO9GsvBIYTY2Bdoa8uipOTlszee9DiY9LDvPxczPYl+ItxLS3lz5xWxhp2JhnYjR5o6+9yFeIy4ABcclPIeV+WVTHFDx5CN14K+S/3wEbAbiBEEoUoQhHsEQXhQEIRjK/i3QClQDKwEftkX454OU2Er5rI2XKYF93r34bnQpgdi77TQld0dZD3H241CPyVmwYH4Qg8y/MqwAz5NBuQi6NWdOLVYaLNDk2Xo54ZKSkpi7ty5ODg4nPa8k13NBEsMkTY/Iu1+TLQMRy0qQAQRsXsxF0FplzPcFoCTXQVi93VRFi/UNgFEUNnlPdcprXb8Wgz4mxwRRRGjrQujtVu5NVq7MNuNiIjI3dS4zY8e0rsRj+i7lagoo4VaSxQAHvJyPNrasPqIZAUlMrLFRqY2l2Eu0XjoqqGlhJJwF2y2DoZFP31eb+2+PtcQGHg7FZVvnz1+yz8Z5v0bRv7iouYn0T+EeznSZbbR0D60XfBnY/9Ri9Oo8L4Njj+GUi4jNcTtile2RFGkpLFzSNZEPEafpH4QRfGWc5wXgYf7YqxzjIN+QzlydzVOo/z6rF91pCsKX0c6dtTgONKXMW5O6EIcYG8nQboYOtRVNLh44NXSgr9VQ5HKQJKugXK6g+SvhPQPSUlJJCWdvQae1drBq/99nK/yR9ApDyMi5RPkBU5MrLgf/+adTP/LQlyjh/W0/+bHDZR92ImvyYvOwD/zvvgUc4ev55pDzfxr2iT+OGI2+CVe6qkNeI7ojyAXBCKsbVjs3iixo+hqQml3ROvQQXZ0LI+0WvhvyAFuDloAuV/QrlVRbTlAUNAdaLUx5z1mdNQfaGraSGHRMkalfYkgnOG9LXnRRc5Oor8I8+rekVja2ImvS9+6/wcL+8pa0ShlJAT0LlTiQhgV5sHrm4toN1pw1gz9Z8XpaOk0ozdYJMvWYMF4uAVLdQcu00MRFH03NUEQcJ4QiKWuE1OpHrkgMDXYnTp3OTJ5AgJwxNcHj+YW/A0uFKmUxBrqACjqunLfCk9mf/U2nMr1VCgDGRO1gdLWFiYfWYi2o5Lpz153gqIFcO3kmWimt2Fw9MEn7zoe07zOltqRWP2D0epttGX/t59mMrA4oj+CvwxEQYbc5oyjvJkavRsAarOF2uBo7JZ6jDITY/xGw6EvKIkLRKl0JSL8whLFyuWOREX+gfb2XGprP+vD2UgMFMKPKltlzVdu3FZGeQvJQW6o+vB5cjKjwjywi5BZobtkYwx0jsUGRngN3WoTQ0rZat9WhdxdjeMlcBk5pngjaBR0ZXSndZjj40aRv5Iu5zCi2r0oDVahMZnwrXelQaHAS6hFYTNQdIXsSOwNmwsOsMEwAmdZBwWOOm44eAOioCXRfy+u8amnvebuhYtpdcyi2WcG1jxH3NvMFAXWMqMon2/0VWC3XeZZDDyO6I8QYjFSjzdyqxOeinJ0LU6YFQpaLR5Em7UUa8qRC3JG2pV0mKto1rQTEnw3SuWFv7H7+s7B1XUkxSUvY7W29+GMJAYCAa4OqBQyyq7QIHmT1UZebRupIZcmXusYycHd/4M5lbpLOs5A5sjRLPpDsSbiMYaMsmUq02Mub8N5YhCCvO93jQhKOY5JXhhym7CbbYxz09IcqAFkJJSHcjioO97fv/7oBcomHM015LZJDyEAq7Ude14NWYoYUoL2oK5U4mlKI7zhW1Kf/0dPO9FuPyEgVxAEpv9iAnahC0F+G/Osq9nSFI+fXM132lFQurUfZjNwsNgtVLRXEGqAClsAcpsDvooSaBHReTuQ65TIyFYbmc6HSfBKQFvwHZVBTshkagIDz+r9PyeCIDAs+mkslhbKy//dRzOSGCjIZAKhHlfujsT82nYsNpGkoEvnQgRw1iiJ8HYiu+rK3bVb2tSJUi4Q6Hb6uN+hwJBRttq3VSNzVOCY5nvJxnBM8UY02zEebkYuCKQO98QiA9+GEEp9W7DI5Pg3drsNzcoW5J16CqUaiQDsrd6GsU7ALshp9KhgStEklOZ2Rt4Rg6BWY2vvYOtv3uT9Oz7gg9vf43+3riR3+f8QRZFxiaNpDM2lzSUceYUPulofWoLacNDZ0R/6qL+n1q9UtVdhE22EdwkUm+MREPBUlOOs68TqLZIbHENKi4VdzlmM8RuDqWANdb5q/P1vQqm8+Dd2F5dEfLxnUVn1ARbLlfuwGKqEezldsZatnOruv+dLrWwBJAe5cbBad8nHGaiUNnYQ6umEQj5kVJJTGBIzszR0YTzcjNO4AGSqS1ctXBXmitxVTVdWd7LVa/09qPJSIKoSsCkEqt298Wlux8Euo05tI6iphRZRTrtVcnVtPnSA7dYkAh0r6NSZcBITCdZtxWf+A+hyCvjsV5+QaxqO2sMVrb87Zhdftub7suXhN7C2tXPTghsQ7R2Ithncal3LHlHDtSVH+Makv6Jdicd2IkaYrLRYwwBwMVehsVpwdOikNiACm6Uei9zCGLUX1doW7IJISHDf7RAMC3sYm62Dyqr3+qxPiYFBuJcT5c1d2OxXXvqHnEodHk6qy2JtSQx0pb7NdMUmNz3S1NkTIzhUGRLKVvu2KlDI0I67tOUWBZmAQ4o3xsIWbB1mxro5UeOrBLkngWZvSn098WhpIcCooUilJLW9BoCirivzH+gYNpsJY14zZfJAHIN/Ytr/t/ff4ZFc5502fJ+qrs4R3Y2cMZgcySFFSpRIiVSgqGg5UJbj2paTXqdd7+vw2uu119/uem1L9q69a61sr2zZlrWWFShRmaICKYYhOZyMQc5Ao4HOuavO90cDwyE5w5nhAKjuRt3X1dcA1dV1fnUGffrp5zzhwmtQ9DJ7XmNQiK3xmT89yZqjmzvu0PihP3833/fH7+YDH76f3nCB88YBvvJvP8GBwX0sRk6xGj6IezbP/HIXrU6DL3nugPlnzL5F07hkbFXyGEYLggrV9a1rtSoJOzsZdU6jKRqHYhPMdTiJBO/C7R7YNA0+3z4ikfuYnf1bK3aryeiPeCjrBgvJnVGg+XJOz6c43B3YkmKmL2XDe3ZqB24l6oZkejXf1MHx0CTGlutghMDb+lG9W1951n20FQwonI7jUBRadgUQCA4v7OZCt4FN19m14GFUs7OrWCuSP5rb2RmJIysnSMRdKOjkSNGav53O+PcY+MXf49H/9Dnyzihv+f52bv2J119a2OwujXf84TvY3ZljSt3Dxb/+AgdevwcwKGffzNG1SeIdcbwpg+rFh8y9QROZTE0SVAQCBzbdi1dbJrYWRBeCaWcvh9LwvO8CByMHySx+kYpdoatv8+teDfR/iGo1zdzcJzb92hbmsVMzEvPlKheXMxzu2votRIADnQEUAafmktsyXj0xnyhQ1o2mDo6HZjG29rbgu2tL+1pfwt7hwdbmvrSV+Jr9USoqtMT7OddVO9azYCejKgTFEoqs7njP1tdOP8P3jAMMtpzm+OggCJWhttOMf/E5Jir97GpZY+gtR172OiEE9/z7t+ExUjz+eJm3Dd9GzHOaldY72BU7xzO6gwcmF3kidtqEu6oPJlOT9OpllmQEteqm1TZBMaGRCrs45T/EwWSFx33PcSy0lyXbDHZctITu2nQdfv8hwi1vYHbu/2AYjfflQgjxNiHEiBBiTAjxG1d4/ieEECtCiJPrj582Q+d2s2FsTe6wuK2zC2kMCYe7g9synsuusrvNtyM9WxvNzgcizVtjC5rE2Npu3IcilGfS6Nky90YDzEZsaPpulluTFDQHnbEKALq2irO0xNlk0lzBJjN9dok1JYjedp7hlVsJpsYY+Dc/x7e/soarmuKNv/nAVV+rOTXe+CN7KThaePJPv4q6u4puc1FI3EpmqZWwN8fD2m5Izm7jHdUHUkqm0hP0lXQmK/2ohoM22zj2RIVKRDDasxtPPkZJLXNLKU+8xU5b6E0oyqbUMn4ZPT3/hnI5zvLyw1ty/a1CCKECfwHcD+wH3i+E2H+FU/9ZSnl0/bEjehC1+hy47eqOM7Y2jJ7tCI7f4HB3gNPzqR3XHmliB5R9AMvYelU494VBQvHCGp1OO/l2DacRxKv7mA630bm+MOXsadzpVUbSO2uhupxcYYHsig2BROQMFLWdzupTnPpGmoK9hbvf243d98oBqH1v2MdQOMmEPsgD0cNU5QpFx3GOxsZZbVtg0eiE0a9s0x3VD2vFNdLlLP15wXx1GICgMYurVMbpLEDLINP2OQSCrtSTSEXQMfgzW6anpeUu3O5dzM79n0b7wLgdGJNSTkgpy8AngXebrKkuEELQH955GYmn5pK0+520bmPl/EPdQdZyZeYSOys+bjKew+e0EfY0ZwPqDSxj61WgdXpQA3YK52r9rPr2hQE4nDjKZGuQYDJNS0ll0q5ycHWWJalSNgwzJZvGo+NPMFruoj14lteM9yOMKn2HDM6PCkJ6jKEHbruu69z5s29ASMnKtxaZD10gEdxN5/I8pysuXjObZnV85xlbG8HxA0VJVu8GwJOt1XurqBoDVR/nfOMMB3eRlGN4dC9e/8Et0yOEoKf7x8hkzpBKP7tl42wBXcDlrtG59WMv5X1CiFNCiH8RQvRsjzTzGYh4dpxn6/RcikPb6NUCOLI+3un5nbWVOBHPMhj1bksigplYxtarQAiBc1+Y0mgCWdG551A7ZRVaE7s511FBkZJDC05G7Xb2Z+YxhMJEofHiWDaDbz59nkm1Gxk9S1fmVsLJc1RCr6FgD3H49ddf6T/QG6Hbm2Cq0E57uxOEQiZ1nMqSn/1GjC9XBVR2VmzcZLpmbHVXqmAEUEWBYqoMwLh/kCNJne/5TnKnO0jKp9AeuHvLF7SOjvdis/mYnW26MhAPAf1SysPA14Ar3qAQ4oNCiBNCiBMrKyvbKnCr6I+4mU0UqOg74wtjulhhIp67ZPxsF3vafWiq4PkdFiQ/uZJr+kxEsIytV41rfxhZMSiOpzge8rHUouLJ9zLamQZgcM7OhGZjoFTzNOzEjEQpdRKzVUASzEmEEqJLf4qnTwVxVxLs++G7b+h6xx88hq462TsdoMwyWc+tHJ2foBxe5RHn7TD39NbcSJ0ylZrCDnh1DbXqxqctkUj4yHocPBM5RncmRVxLcEifA6B99y9suSZVddPZ8YOsrHyZYmlpy8fbJOaByz1V3evHLiGlXJVSbryJPwbceqULSSk/KqU8LqU8Ho1Gt0TsdtMf9qAbcsdsb51bqK3hB7YpE3EDh01lb7ufs/PpbR3XTPLlKgupomVsWVwdx2AAYVcpnlvFpghEyMBbCpBqSZO3O+iMQUlRcCi1/j0XcztjobqcmdXTxHJB/O5pbp/chaKX6OgpkLK1cWC/imq7sQK0nbcPExErLKRamQudJxnYhX8xxbgzS0vagZz89hbdSX0ymZqkG52YEcZW9RBVJ6kmFYoRlbXoLuLr9oLPmMVXtOMM7t0WXV1dP4yUOosLDdOg+mlgWAgxIISwAw8Cn7/8BCHE5UX83gWc30Z9pnKp/MMO2Uq8ZGx1+rd97P0dfs4tphst5vFVMxWvdVgZaPLgeLCMrVeNsCk494QonF9DGpLeXg+KFPQXhpgLtdIZr21p6VoCZynGmbU1kxVvP/964lku0Ien9TRtuSNEEqeZM27BVs1z5KfufVXXPHJfLyV7kOFCbSsxVThOOuHlDfElRhd3VnHTidQ4veUyU9V+FKnRqkziSJdRPWUCnm4ueqbY7W2l4CwTtV8puW5rcLv7CYXuZGHxU0hZ/1tPUsoq8CHgK9SMqE9JKc8KIX5fCPGu9dN+SQhxVgjxPPBLwE+Yo3b76d9h5R/OLaaJeB20+rYvOH6D/Z1+1nJlYpmdsROy8TfV7NXjwTK2bgrn3haMTJnKYo67XzuEBPrShxiPhmhJZrFVJWl7Dm86xoV01my5287Zs8tUhIZPr4Dip5OTnC/cSrcngSPoe1XXHH737dirOULpKBWWyLmP0DGTI+iN8eVqO5R3Ri/Kkl5iIbtIf1GwrA8B4CsvoEpJ1amxt6DxtP8093hq3sNo9/dtq76uzgcpFudZW/vuto77apFSPiyl3C2lHJJS/uH6sd+VUn5+/efflFIekFIekVK+UUp5wVzF20fYY8fnsO2YwqbnFtLsN8GrBVwad8O71uxMXqqxZRlbFq+Ac7jWyLc4mmB/RwtrPghk+jnXZqAakv1LKpN2jUOrU8wZKsYOcQ1DLV4rm1BRRZ5D02GQBi2hBLrqZM/d/a/6uqpNpTecZ03tIeYZIxkYonNhlkTLAufVPTD7xObdRB0zk55BIukrQE7vBMCdrsUHTgV6GU4VGXFOMiTiuAoGnsH3bqu+aPTNaFoL8wv/vK3jWmw+Qgj6d0hGYrlqMBrLsL/DHGNrb3vtS+i5xZ1hbE2s5OgIOHHbt6b2Xz1hGVs3geq3o7W7KY0lEUKge0qEslHGumrxWfvnNSY0jQOZOSqKjdli2WTF28f82lkWyi2EIqfpTe7Fn5liTduHo5Ji8B133NS19751H4ZqJ1xWkIpGMTPIdEkwnNR3TNzWRtmH9pKKMPwookgpWaGqKjwbOYZWWsSuGDhsKaKVCMLu3lZ9iuKgo/29xONfp1Rqjqy8ncxAxLMjPFtjsSwVXZrm2fI5NXpb3DvGszWxAxpQb2AZWzeJY1eI0lQKo6zTFZbYdRXDa6OgOehdsDGhaQxuZCTmd8Y+PMA/PvEcs6INh3cBm+ilrXCKs/o99AazKHbtpq7dc/dBnNU0rZk2pCxRNA6iLbjYX15gZnZnZCRuGFuh9UxEr7ZEJuki22KnEN7DlGOOw24BAiKh15uisbPzQaSssrj4aVPGt9g8+iMe5hMFSlXdbClbyoZHySzP1sbYO8GzJaVkYiVrGVsW14dzOAhVSXkqzZ37IwD0FQeYC7XSvVKhpAjcopaROJrdGfFEAKfPrSCFYCDuAKHQZh+hIrzse8uem762oir0tZfJ2PtJ28dJhA6wa2oOu3eZLxndUMpswh3UN5PpSaJIMkYIW9VNqzqJTIL0GwTc3ZzzjXGnx4ZWNggOPmiKRo9nkIMH/pyuLnPGt9g8BiJuDAmza829hp1bSOPUFFMNgP2dfqZWc+RKVdM0bAeJfIV0sWoZWxbXh30gAKqgOJpg3+37ydklbZm9TERbiCYK2KqSqraGvZLkdDxuttxtQUpJNqVidyywf6EfeymF9HrxlFbouu+K5YlumP0PHEIqKgYpiq4IWlyw7E1wWtsP09/blDHqmcnkBH3VMtOVfhRpJyon0Uo6uluwN6/ytPd5erUc4bREdN5ims62tgfQtKBp41tsDv3hjYzEJje2FlPsbfejKuZVM9/f4UdKuLDU3F8aN4Ljh6LN3YB6A8vYukkUu4qjz09pNInN56XiyBLOdHMuqqIakp4VSNoLBFILnEs1v2sYIJYcYbHSgq9lhEBlH+HUGUad99HTWkZRb6y21tXouGMvnmqCtkwbAJniYTJZ6M+qTR8kL6VkMj1Jf9FgRR8AwFuobVXPB7roSqfwOjPYFJ0W2xCozR98arG17IRaW1JKUzMRN7iUkdjkW4kbDagtz5bFdeMYDlFZyqFnyoQdOfxFFzM1G4C9S4IJTePw6gQzhrojitX9zXeeZUlEiMoSKG66xClW9F0M3tm/aWMIIeiKVKjae6iwQtZ9AO+s5GB5lthsc9fbiuVjFKpFuosqBaP2h+ZK16q1n2o9SsGYY6+zFlvTEn119cwsLC4n6LYTdGtMNnGQ/EKqSLpYNTVeC6Aj4CTo1po+SH4insOmCLpDLrOlbAuWsbUJOIeDAJTGkhxsrbmfVY+Xsmpj16KNcbuNQ5kZ8qqDeKW59+EBTp5fASR7l2oZcAF3HFulQM/bbt/UcQbu7MNQNNLaDIngMO2zMRzeRb5QaAe9sqlj1RMbPRHDJTtC96OIEnqiQN6tkYkeYcI9y2G3wJut4ui/z2S1Fs1Cf9jT1J6tDeNmn8nGlhBiRwTJT67k6A27sak7wwzZlLsUQrxNCDEihBgTQvzGFZ7/CSHEihDi5Prjpzdj3HpB6/QiXDaK40kOHurGEJLOcgdLwQjdMfGijMSLueZvlpzLKDic8/Qm+/Fk54l5DtCmrWJzOjZ1nP4334Kql3BWBYZqR0+1sOqJcU7bC4unNnWsemIqNQVAqOJArbpxa8vkUk7KQZUWZwenA2fo1sqEUwZ0HDVVq0XzMBBpfmNLiBdqXZnJvg4/I0tpdKN5d0Im4zujAfUGN21sCSFU4C+A+4H9wPuFEFfqDfLPUsqj64+P3ey49YRQBI5+P+XJFN5D+yhoRSLZXUy3ROiMlygJgYvaNs9ok/dIzOdjrFQC+EIXcRiDtORHmFHvpHdfcNPHsrkdRLU1AsU+AAqVvWSyBh1lB8w+uenj1QuTqUmcgKh6seluouokpMHwSfbkBOXgBRQBLbZdYLObLdeiSegPe1hIFSlWmrP8w8hymt4WNx6H+TGOe9t9FCsG0026bWsYksnVnVNjCzbHs3U7MCalnJBSloFPAu/ehOs2FI7BANXVIsLuw1ldIZppZTTswlExaE1C1ZZA1Qucii2bLXVL+Zcnn2ZZhIkaZVDstCvnSVejDD+wOVmIL6V3j5+qI7zeumcY74zKnsoM5ZnmDZKfSI3Tq1eYrfahGHba9EkUXZLwBQll4ww7q6BLgm1WvJbF5tEfqYUFTK82Z0bihaUMe9rM92oB7G2vbWWONGlG4kKqQLlqMLhDMhFhc4ytLmD2st/n1o+9lPcJIU4JIf5FCNGzCePWFY6BAACliRT9tgQO3cZctPbG7V+WJBxFIskZziVSZsrccr7y/DQg2bfkAWngdSYIlpfw7urdkvF23X8MgJy2RCowRPtMDJd7kcdjJWjSZISp1AT95Srx9UxEz3om4mTLMAl1lr1OnWCqgtJ/l5kyLZqMgSZuSF2s6EzFc3WxhQgw3OZFCBhZbk5jayc1oN5guyLTHgL6pZSHga8BH7/aiUKIDwohTgghTqysNE6bD63Ti3ColCZT7O+sxSbpXj+GEOxeEoxrGofio0wZ5tVv2Q5SCQObfYnuZB/e3AKrgf10tW/deKHd3fgqcWxVO7rqoJpqIeNZ4Tu2fZCc3rqBTSJfybOUX6GzYKNktALgStWMraXIcaaD54hqkmhSh+7bzJRq0WT0b5R/aMKtrbFYFkPCnnZzg+M3cGoq/WFP03q2Nso+WDFbN8Y8cLmnqnv92CWklKtSyo1eNR8DrrqnJKX8qJTyuJTyeDQa3QR528NG3FZpIkX08AAVRSeiR1j1BRlcUpiwaxzKzpK0ecg0acsLw6iSLLnxBUdxyAFChREWxDH6XzuwpeN2tuq4jSEAcpW9pHMVymo3zDRf3NZ0umZABktuFMOHEGVI5Mj5NdzBXSQizwMQ0obAvnMWMoutx+/UCHvsTRkkv1FAdE+deLYA9rT5mtbYmozn8NhVor7NTZqqZzbD2HoaGBZCDAgh7MCDwOcvP0EI0XHZr+8Czm/CuHWHfSBAdaWAvW8Y9FVa873MBlvpiknGNY3BYs0GHc03Z0biMxdPsigjtMsSKHY6xTlShQjdb9qaeK0Neo51owgHFWLk3MM4Z1T2FpebsrjpVHoKgFDFiVr14NJi5FNOKgGF7opG0BPHqEq8HW8wV6hFU9If8TTlNuLIUhq7TaE/vL0N21+JPe0+plZzTZmQMBHP0R/xIERz7/Rczk0bW1LKKvAh4CvUjKhPSSnPCiF+XwjxrvXTfkkIcVYI8TzwS8BP3Oy49YhjsBa3JSs+wpkpwtkWJsItBHNVbEWBZyMjMdOcAaYf++45dKGyP1aL1/K51mhhFdWztQtY/31HEFInpy2TDAzROrtK1DbP3PTElo5rBpOpSQTgKnuwVd2ElWlkBop+O/78MrucBu50FdFzp9lSLZqQ/rCnKbcRLyxlGG711lXNp73tPgwJo8tZs6VsOpPx7I4KjodNitmSUj4spdwtpRySUv7h+rHflVJ+fv3n35RSHpBSHpFSvlFKeWEzxq037F1ehF2hNJ1hl5pAQTAfrsXV9MUkVVsCYVR4fmn+GldqTOYWcwhbmq5kJ57cIonAbjq6t770gKPFT0CPoxo2dJsLPe3H8C7wpUI/VJqr1MZkaoI2Q2el0o1i2GmvjiMkLAU6yTrPErZJutZK0LO5BWQtLKDWkHo5XSJfbq7izCN1lIm4wcaW5oWl5ipuWqrqzCcKOyo4HqwK8puKUBXsfbV6W+3r2YkFX+0NM7AMa/YS0cQUZ5PNmZGYLdjx+S7ikP0ECmPMi6P0vWZr47U2aG8F13p2XqG8i4TIMuvbA4vPb8v428VEcoy+SpU1o1ZbzJuvBccvthwh0Vor5BoxouBtNU2jRfNyKUi+iRpSJ3JlYplSXcVrAfSFPTg1penitmbX8hhyZwXHg2VsbTqOPj+V5TyBPcNURJEAATIuD7sWYdyucWT1IlPNtwVPKhVjWQ8StadBcdEmRkjk2ui459i2jN99tBsbTnSZpKANoS/ZiRrA3IltGX87MKTBdHqGjqJKSdaMKXdqCUMRlFtvwQiOUamCJ3qHyUotmpX+cPNlJNZjcDyAqgiGW31NV/5hpzWg3sAytjYZe78fJKgtgziKS0SLHSwEo/TF1ss/ZGaI2XyUDMNsqZvK337rBEXhZNdarfpyyLFMi0iiurcn4LT/viMIQydvWyIdGKB1IsNgdRq9iZpSL+WWKBkVAiUPiu4DUYG1NAW/jagapMuVR2SqiJ7XmC3Voknpb8JaWyPr23R766Tsw+XsafddMgabhY2/nX7L2LK4Gew9fhAgdT/t8Yu0FEJMtbTTtqYzo9gYKs4hhcJEvnTtizUQ3x5ZAFGlfy2MvZSi5IvQ0bN9ab21uK0VqqpO0RnGGa9g987y5GR52zRsNRs9EQMVF7aqG6e2QiHloBxU8RmjtNgkbckyWMaWxRbhddiI+hxNVf5hZDlDwKXR5q+/MgR72nysZEqs5ZpnHZuM54h47QRcmtlSthXL2NpkFIeK1uGhslCgXU0CMB/uRJXQsqrgpdauZzTTPIsVQDpjYHdN4y/348+Os2Q/RN8dg9uqob0V7EYnAIViL1nHCk85hiDbOMVxX4nJ9CQA3qIXteqmRUxDXpAKBNEDtTIXgykFWq/UmtTCYnMYaLKMxJGlDHvafXVZhqAZg+Qn4rlL29E7CcvY2gLsfX7Ksxlau2tvlJQ/CEB/TFKxrYGhc3Jx9hWu0FhIKUmXXbR4F0CNEDEuslboou0N2xOvtUHPsW7c1SBSVijIXeTSkHP2wHxzxG1NJCfwSkmp3I5qOGiv1EpbxIJDlFtGKengCx8D1fxGuhbNS3/EzWSTBMhLKRldztZdJuIGG8ZWM5V/mIzvrAbUG1jG1hbg6PcjKwbewX0YModL8VO22ehflqzay7SlpjmzljBb5qYxMjnGigzSn6/FobXbx3HoxrbFa23Qe+8RFGlQUhbJ+Abxjxv0GGsw3xxxWxPJUXqqVdaMfgB8+QUA0i234vQuU8hLRLe1hWixtfRHPMSzJTLFitlSbprFVJFMqcrutvqs+dTqcxBwaVxskiD5TLHCSqbEQNQytiw2AXtfreyDEuzHm52ltRwlFogwuAwTdo2jKyNNlZH4v79zGikUhuNeFL2MzStpa9t+74ozHMBbiVOwpcn4egjNJ4kqs+THTm+7lq1gIjVBR1GlLGttrFypJXSbwNbaQ8RewZ2uWPFaFlvOwPoW0PRq43u3NoyY4Tr1bAkh2N3mbRpja6NkyE4r+wCWsbUl2IIO1IAD9ABtKxcJFoPMhLroi8GYTeNAdppFmw9DSrOlbgrn5hIIW4povhtfZpq4ex+dR7pM0RINVBEihFQ0KtkIwr3ItxZ90OBznS6nWSulCJS8qLoXRBV1NU0haMPvOAtAb6IE3cdNVmrR7PSFmycjcWN7bnedGltQMwQvLmeRDb6GAUzEa/M9EKlPT+JWYhlbW4S9309lpUqgXGvRMxfpx1mWpPM2BotzVBSN2WJzZJhkCwo+zwSq6MZfGSNW3UXX3UdM0dK5J4y3XKtBldeHSIsUF/zDsNbYrXsuZSKWa5mIdi1OIaVRCDiw+56iKmGYdnC3mCvUounpj9TCA5ohI3FkOUPE66DFs/WdLl4tu1u9pAq17bdGZyqeRwjoq6MelNuFZWxtEY4+P0a6TLSz9uGX9NW2ftpWBH6jZoBdzDS+a7haqbBW8dKu5kDY6FBHqWRdODraTNHT8/p92NDQ5Sp5xyDVZZWKKwwLz5miZ7OYTK1nIpa8qFUPIWagJEgEOxDBaRIlgb3zNpNVWuwE3HYb7X4nk02QkTi6nKnbeK0NNrxuF5sgSH4ynqUz4MKpqWZL2XYsY2uLsPfW3iDewQMgMwi7D0MI+pclVW0VpOTZ2WmTVd48XztxkpxwsydR+1MKulZpCZj3ZxXa34+jnCRvWyHj7yM8madPX0DON7axNZGawCYlSrGtlolYrnnqEsED+FwJqlnd2kK02DYGIp6G92wZhmQ0lq3rLUSA3e0bxlbjfzmfjOcY3IHB8WAZW1uG1u4Bm0AJDhBMTBKptLDm89G/DHF7hbbkDKfX1syWedP80zPjgEF3MoSjuEbRF6FzT9g0PUIIWuxpyjaFojOMY6VKUJslfr6xS21MJMfo1A3SRi8AgVytmXmxuxebAsF0BbpuNVOixQ6iP+Jp+Jit+WSBfFmve2NrY5uz0Y0tKeWOrbEFlrG1ZQibgr3TCzJAS3KCQNnPfKiX/phk3K5xNH6eqWrjBzzOr+ZRHct4q734cpPE1L1037XPVE0dfV7sMgJAudiB7lnk26kQGI2bAjqRHKW9pFJZvy9HaomKU8HRMQfAUKIK7YfMlNjQCCHeJoQYEUKMCSF+4wrPO4QQ/7z+/JNCiH4TZNYNgxEPiXyFZL5x4043jJd630YEGG5t/IzEeLZMpli1PFsWm4+91081JfFna16IufAuwhlYqGocTE8xp/kbPsMkV7LR4pkHNUJIjpPNBvEd3GOqpu7j/XjLQaTUKRqDpMoF5kL9sDpmqq5XS8WoMJ9bJlDyoOpepNCxraYoBm0EPU8RrwiG/cOgucyW2pAIIVTgL4D7gf3A+4UQLy3D/1NAQkq5C/gw8F+3V2V90Qw9EjdioOq17MPl7G7zMdrgGYkbfys7saApWMbWlmLv8UFV0hKu1d1KBDoAqCZtDJZmKapOFkuNWxiwWCyzpvvpq9SyZDq1MWyKD6GaG/zYedchbHqFioiR8/SjTttQnM6GDZKfzcyiSwN/2Y1a9aDZVimlbGQDARz+ORJFga3Lite6CW4HxqSUE1LKMvBJ4N0vOefdwMfXf/4X4F5Rj/1dtomND8xGbtszupyhze9oiB59u9u8ZEpVltJFs6W8aibXyz4M7sCyD2AZW1uKvWcjSP4gggwVR83oalsR+Ixaj8SRVNIseTfNZx5/hrLQ2LXqQEgdtzdHa4/5byTV5cBXXaGgpUn7+ojMpOnQ55GzJ82W9qrYyET0lTyouoeQnIGqIBnswaGVUTNVsIytm6ELuDyob2792BXPkVJWgRRgXnCiyfS2uFEETK40rrF1MZap+3itDZohI3FiJYddVegK7UwPvGVsbSFqyIHi1VBbBmmJjxPUA2RddvqXJfpGRuLMlNkyXzWfeX4KRIW2bBRPdoG0d4DOYz1mywIgEoaKzUVV86AkNLz2ORaeXzRb1qtiw9hyFqPYdAftpVomYrqjZg9EU2UrOL5OEEJ8UAhxQghxYmWlORqgXwm7TaE75GayQavI64ZkrAEyETe4ZGwtNW7c1kQ8R1/YjarsTIewZWxtIUKIde9WiEB6ikDFz2Kom76YZMVeoS0519AZiUvJMppzHge9eEsTxCt9tL72sNmyAOja14qnEgKgWOqm6lrmyWIE9KrJym6cieQYLbqkoPcB4M/VeiJW9+QpGrA7b4PIsJkSG5154PJvCd3rx654jhDCBgSA1ZdeSEr5USnlcSnl8Wg0ukVy64NaRmJjelpm1/IUK0ZDBMcDhDx2Il5HQwfJT6xkd2xwPFjG1pZj7/VhFBT8+RgA85F9dMdhStU4tnKOKb1xAx5zZY12ZxypuIkoYxRzPrRwfeysdL12L66qDynLlJQBkhmdxUgPrJw3W9oNM5YYob2sUrmsJ2LFoxANP8dMSWE4ehCUnVckcBN5GhgWQgwIIezAg8DnX3LO54EfX//5+4FHZCNHK28CgxEPU/F8QwZtj8YaJzh+g91t3ku6G42qbjCzlt+RbXo2sIytLWYjbivocgIQ9/dgMyCV1jiYmWCmQTMSk5kcScPLUK7mKep0TuLyBs0VdRnBvX04yklK6hIZXz/uaYlw2GHhpNnSbggpJVPpGQIlDzbdU8tEjCcoBB14PEtkChLNite6KdZjsD4EfAU4D3xKSnlWCPH7Qoh3rZ/210BYCDEG/BrwsvIQO43+sJtsqcpKtvHayFxqQN3aOB/+u9t8jMUaMyNxPlmgossd2YB6A5vZApode7cPBHgHDqCILCXXeu+6hI1BMUfe5iFeqRK1139GzOX887eeQRcqA0kXql7C5lFo31U/ffmEEPiVJEu2EhnvAJ3zGWTvPPp0FfUWs9VdP8v5ZQp6mUAphFp1Y1PXKGdUUt0RVJHCkanC/ga6oTpFSvkw8PBLjv3uZT8XgR/Ybl31zEC0ZqhMxfO0+pwmq7kxRpczdASc+JyNs+7uavWSLVVZSBXpCjZWkPnEeiKFtY1osWUoThu2qBs1PERLcgo3fiqqoGMF/LLWI3FkLW6yyhvn4QsLIMq0FNrwZmdYde2m8zX1FTfU1unEULwYqh2Z9uCxzzJzsrGClieStWB4f8mDUvUSkrNgCFKttS3FzpRVOd7CHAYv1dpqvK2t0Vi2obYQ4fKMxMaL25rY4TW2YJOMLav68itj7/GB0oJ/dZxAxcdSS5S+GOhaHHSDp6YnzZZ4w8TTFdzuGRTRjbc6SSofJXDsoNmyXkT30R585Zq3rVzpoeSI8ZzR2lBB8uOpcQBcpSia7qCtVPu9sAcWK4J9eMH/0ioFFhZbT2fQhV1VmIw3VkbipUzEBtpChBe2PMcasPzDxEqWgEujxWM3W4pp3LSxZVVfvjb2Xh/oKv5yCoCFyAH6lyVLmk5nYo4zawmTFd44uYpGu5YERSOqjlEtB1AcDrNlvYiuNxzErtuRskBR6SedgVi4HVYumC3tuplIjuM1JHp5vSdidh4pIDB8numSwnDrUdi5tTUtTERVBL1hd8N5tmbX8pSqBsMNkom4QSNnJE7GcwxEPOzgOsCb4tmyqi9fA3v3epC8VosPiAeG8BZhsaxxbPUsk4aZ6m6cldUUKcPL7nSt12CncwZftD6yEC/HGQnhKcUoqstkfL14J3WEU4XFk2ZLu25GE+dpLWsY1HoiOpNLVPwqXleKQk7i6LaC4y3Moz/ceA2pLwXHN9g2ItQyEi82YEbiZDy3o4PjYXOMLav68jXQ2j0ITcHTNYyi5si7WgEoJjQOZCaZtQcaKsPkk985iRSCnpQXrZLF8DrpONBhtqwrEnQVKGhVst4uAgsZosxTHW+M8g9SSiZTkwRLHmzV9UzElST5QC041pOpQqcVHG9hHkNRD1OreXSjcdavS2UfGmwbEdYzEpczDfV5kS9XWUwVd3RwPNRhgHwzVmAWqkDr8qJGdhHMzWNTAxiAtmZjoDhL1uZlpdw4cURfGV0EUSJQaseTmyahDdF+50t3juuDjoEgCC9S0ZAZHy77HNMnGyMhYa24RrpSwF9yo+oebOoa1ZxKMtpCwYC+TBk6j5kt02IHMxj1UK4aLCQLZku5bkaXM3Q2WCbiBrtaveTKOgupxumR+EID6sYzbjeTzTC2Nq36MjRvBWZ7tw9hCxNYHiNQ9bISCtAVA6+oZSSei710yuqXeKaKzz2DUDvw6ZNkc0GcQ4Nmy7oi3bcN4ivVKsmXKr0U7HHOypaGCJKfSF2eieghpM8AkO2zMV1S2O+Mgrt+ym1Y7Dw2PkDHVxpna+vicpZdDbiFCI2ZkbhR9mEnZyLC5hhbVvXl68De6wMUAtXaH95idA/9MYluW4WKzhNTU6bquxFyFQddahqESps2hk4EodSdkxSAttfsx14FQ+Yp2fpIJxSWom0QHzFb2jXZKPvgKdYyEVtLtaxVx8EFpssKe9qsLUQLc9nYGppokIbUuiEZX2m8TMQNNrY+RxvI2BpfySLEzq6xBZtgbFnVl6+PS5Xk7bXU13hgL21JWMagb22Sc+mUiequn7nlJBnpZneqZit3uGYJtLearOrq2NxOfJUXguQDUxWEU0HOnzRb2jWZSI3jMEBUaj0RA9k5DBt4WtMUcwau7ttMVmix0wl77PidNiYaJCNxIxOxURpQv5QXMhIbY76hZoh3BV04tZ3dUmxTKshb1ZevjRp0oHg03C09KLY8aXcthyCZsnMsfp7zvsaIvfnUd08C0J324igl0AN+Oo70vPKLTCborTCpQtbTSddSBmN4kcrFGPY6dwyNrZ0jUrEjZG2r0LkaoxJQQYFgWreKmVqYjhCCwai3YTISN7bfdjVY2YfLabQeieMrWYaijTvfm0V97v00IUII7L0+bNHd+CsxhC0IgJ7Q2J+bYsbR0hAZJl8bXwalhKfSiSc/zZroJ3L7AbNlvSKdw2FU4UUqNoxMALdjlpmTa2bLuiYTyQkCJTdq1Y0UOmo8QbrFy3JFsLtUhfZDZku0sGAw4mmYbcRGzkTcoJEyEg1DMrGSs4wtLGNrW7H3+BD2EKHYJF7dQ8LrxhNX6SvNUlDdLBbrv6FrPKMT8MyArQ2vnCSX9WPv7jZb1ivSc8duvKUgAOVqLzltjRElWNdB8ulymng5Q6DkQdF9aCKOUVJIdTmYKivs83SB1lj90Syak8Goh8VUkXwDZFRfbOBMxA2G22oZifMNkAG6lC5SqOg7Pl4LLGNrW9mI2woUcwgEC23D9KxIvGIRpOTU3ITJCq9NrmKnT9Zc8R32MVDb6r4qcOSW3TjKFQyZo6T1kkkoLLVG6zpIfjxZa8sTLL44E1HsyzJdVNnbbm0hWtQHg+tei0bwbl1czrK7vTHjtTZopIzEjSxVy7NlGVvbyqVK8g4nAPHgMD0rUFETKKUKT87MmCnvmkwsrJHHxXCi5r7udM8S7Ok0WdW1UTQNn75CUY2R8fbinywjXQI5d9JsaVdlNDEKgLfYjl3XaC3UDHHXQJJy3sDTfbuZ8iwsLrGR0j9R53FbVd2oZSI2aHD8BrtbN4yt+o/bGl/fth1qtTxblrG1jSguG2rYgTvQgdAKZN0D2AxYzansWRnlYr6+G7r+83pwfEfWj7MQp+SN0HGs31RN10soYFDUIOfpxL+UJsQSpXMXzZZ1VcaTYzgMgVqt9UT0Z+YxXFByC6LZihUcb1E31Hre1ZoN1zPTa3nKVaOh47UAAm6NVl9j9EiciOfwOW1EvfXVN9cMLGNrm3H0BrBFduFlFUOr9bvLJTWOrZ1nWtR3R/RvTsQRShG33om7OE1C7yJ4/KDZsq6Lrr2tqHiRigrZAG77HNNn6rcB+MjqGVrKTlQjCIBjdYlS0MZUWbC/CkT3mqrPwmIDp6bSGXDVfUbiRm2qPQ2+jQi1exhtBM/WSpbBqLfuQ022A8vY2mbsvT6E5iWytojb8JBzOlHWbOzJTzPrjKDXcYbJalYn6J5H2iL4mKCQD6K11m+Nrcvped0+vOuV5MuVXrJaggnVW7dB8rVMRA9q1YMUZZR4lnSbg6mSwj5fHyg7u2aNRX0xGK3/jMSNbbddDe7ZAhhu9TEay2DUeU/K8ViOISs4HrCMrW3nUtxWJolAMNs+SHhF0FuepaQ6mUrVp7dFSkm26mRITwPQ6RgFR7vJqq6f0MEhnOUshsxSsveRTqgstUXqMkh+tbBKopIjWPSA7sNBDAxBaVAyVVbZ12EVM7WoL2rlH7J1XY7g4nKGnhYXbvumlJc0ld1tXooVg9lE/YaeZEtVltJFKzh+HcvY2ma0Dg8ISdBRS9tfDQ3TvwyaugSG5Inx+vvwBzg3E6OEnaFk7fdO9wKhvvouZno5QlHwGWuU1HitkvxkEekSGNMnzZb2MjYyEQNFL1rFTbg6DYBjd5pqzsDf8xoz5VlYvIzBaK0cQSxTv+VrLi5n2NPgwfEbDLfVf5D85Lqn0/Js1bCMrW1G2BRsrU7cgS6wF8l4BnBWoFLM4kpneWZ5yWyJV+Sfv3sKgPZcAFd+iYK3jY5bh0xWdWO0tEBBE+TcHfiXMgTkErmzY2bLehljyZomb6kLzVCJ5ieRAlbDCgOFshUcb1F3bHgvxuq0snlFN5iM5y4ZKY3O7vUK+PUcJG+VfXgxlrFlAo7BFtRQHx4lga7VtuKSKTtHVs4wXtVNVndlvju9hiIKOIwu3KVpUuU2fMcaIzh+g64DndikpxYknwngtM8ydyZttqyXMZq4gFNX0PRaSydvag7DB6NI9ksNgn0mK7SweDEbcVDjdZqROBXPUdHlJSOl0fE5NToDzrpuSD2+kkVVBL1ht9lS6gLL2DIBR68foTqIZuI4pZeC3YGesHEoPca0FjBb3hVJ5CQt3gWkLYhPTFAoBLGFQmbLuiF6X38AT7mmuVLtIW1PMet01F2Q/MXVswTLHmx67Vu4PRajENGYKiscCOwCK7PHos5o8zvwOmx169na2G5r9BpblzPc5mOkjrcRx1ey9IRcOGxWMg9YxpYpbFSSD6XStSD5zgG8KyrDxWmWnFGy5YrJCl+MYUiyupPdpdobu9t1EcVV/8VMX4pvuBdXMbkeJN9POq6x1BqGlQtmS7uElJKJ1BSBoht0H1LkUdIl8j0q0yWVfV13mi3RwuJlCCEYavXWrbE1spxBEc21pbW7zcv4Sha9TjMSR5ezTbNtuxlYxpYJqGEn2AyC9lqQfDw0RFcMWqvzADw/V19xRM+MLlBBYzApEFKny7NIy1C/2bJuGCEEfpFYD5LvITRZxHCBPnHSbGmXWCmskNXLhEq1TESvXARA7skj8jr+3jtMVmhhcWV2RevX2BpdztAX9uDUmsfLMtzmo1w1mF6tv5Ibl2LkmqDMxmZhGVsmIIRAa3fiCfaAvUjWPYi3CFolBiWd707WV4/ET33vNADRQhB3fpGsu4O247tNVvXqCEVUippK1tOBbzmFjyVSz4+bLesSY4maoe0rBXGWnYSLUwDMtSvsL1nB8Rb1y65WL7FMiXSxvjzzUPNsNdsH/5467pE4vZqjakiGmyRGbjOwjC2TcA5HUXztuO0pdK22JVdKVWmLL3AhW1/fDp+YS6MqeTS6cVamSBVa8Rw+YLasV0X34S40wwdCRcmGcNpnWbhQP7VqRhK10h/eUj82KQhnp5AOyVmXwX6bH1yNFSdnsXPYCJKvN+9WsaIzFc+xtwkqx1/OcJsXIWBkqb7mG7hU3X5XtLnm/GawjC2TcAyEEEKhLZfCgZ+SzUUhqXF89QzTSn217UkVoM2zhFQ9+NUJSsUQqq8x30R9bziMp1z7UKhWe4nbCiz4NajWR32gC6uncVftOPUoAO61BaotCpNlhf2hPSars7C4OvVqbI3FshgS9rT7zZayqbjtNnpb3Iws119G9ZjVgPplWMaWSWwEyYfTNa/KTGc/9riN/blxpp2tdVOJuVTRyeou9uZrb+he5wiKp8tkVa8eT18nruIqhkxTdPSSj9lYamtBLp01WxoAF+JnCBa9qFUvEgNteYVCu1qrHN/9OrPlWVhclZ6QC7uqMF5nxtbFJuqJ+FJ2t/kYWaq/bcTRWJbuUHNU698sLGPLJBSXDWEvE7LVguRjkSGiMcFgaYaczcNMYsVkhTW++fwYBgr9KQ3FqNDpixPZO2y2rJvCp6YoqWtkfH20TOXAUaU6cs5sWZT1MtPZJVqKHgw9iEoCRdfJDRoESzqBPsvYsqhfbKrCQMRTd56tkaUMdptCfxPWe9rb7mNqNU+xUl/1GUdj2aaLkbtZLGPLRLQOF85QL9KVJ+8eJJCHYGkBKgbfHqkPT8u/nKjFELUUQ7hzc6TsXURv22uyqpsj3GanpGnk3G14Y2l8cpHYc+YnJUykJtCRhIo+tIqbYHUGgLFuOFSuQFtjFZG12HnsavXWXWHTC0sZdkW92NTm+7jb0+5DN2RdzfmGHqvsw4tpvr++BsK5vwPF6cdrz2DYaltzIp3GkcxwIh4zWV2N08tFHFoGRXTjNKbI5MK49u8zW9ZN0XdrP3bdD0JBybWgOWdZnSuaLYuRtZphGyi146raiBYmQJE822Jw0BEFm8Nkhc2HEKJFCPE1IcTo+r9XzEAQQuhCiJPrj89vt85GYajVy8xafXlaLi5nmnILEV7ISKynrcTZtTzlqnEphs+ihmVsmYhzVy0Iuq2QR8NL3uEln9A4Ej/PhFEfVcKzJYVORwypOgjYxilXwigul9myboruNxzBXXYCoFd7WVIqzEdUqBRM1TWydh7VELgrvQAEkzPIAEzoCgeih0zV1sT8BvANKeUw8I31369EQUp5dP3xru2T11jsavViSJiqk9pPqXyFxVSxaY2t/ogHu6owUkflH0bXt5EtY+vFWMaWiWjtHpBVWjNlAKa7BlDjNg6nLzLhjJisDhLZIjnDyb50beEcdJ9Ha4K+fM7WMJ7iMoZMUnT2UVh0sBIJYcycMlXXuZXn8Je82Kq1DwZHbJFSRCFWhv19bzRVWxPzbuDj6z9/HHiPeVIan1111pD6Ymw9OL5Jt7Q0VWEw6qkrz9bo+pxbxtaLuSljy3LB3xxCFSjuMkG7F4kk3jJIJKYwXJxh1d7Ccipuqr4vPHkWEPSm7diqeaL+LNGDjVnM9KX47VlKapK0r5foVBpFLVI6fd40PVJKLibGCRa96EYISRE1kyPZo9BX0XH33WWatianTcr1Mv2wBLRd5TynEOKEEOIJIcR7tkda4zEY9aCIF3oRms2FpebNRNxgb3t9ZSSOLWdp9zvxOzWzpdQVN+vZslzwN4m9x4s90APeHAXXAO4SdGVmQJd868IZU7V9/sw0AP5KFFd+mhTdtBxvzGKmLyXS7aVsc1Jwt+FdSeNhnvlnZkzTs1JYIaOXCBe9KFUfbmMBATw/AIcMFQLdpmlrdIQQXxdCnLnC492Xnydr9VauVnOlT0p5HPhh4CNCiKGrjPXBdaPsxMpKfWQUbydOTaU/7GG0Tra1RpbS+Jw2OgJOs6VsGXva/SymiqQK9VG5fzSWtSrHX4GbNbYsF/xN4jrSi1BUfFoO1G4k4MisItIlno4tmaptfLWK15lA2jpwMUEmG8Ix3NhlHzbov2MYVzUIgJKPIpyLZLPmFTbdCI73l1vwljWixUlA8kSrzkFvL4j6iOFrRKSU90kpD17h8TlgWQjRAbD+7xUzU6SU8+v/TgCPAseuct5HpZTHpZTHo9HoltxPvbO7zVc3MUQXl7LsafMhmvj9s6e9ZtjUQ9sew5CMxbJN1fB7s7hZY8tywd8kzr3tAHTly9hwkfGEqSRgKD7BWNUwTZeUkkzZzi4ZB6ESdoxSNSIIrTlcw513HcZRqS3Aut7PpNSY7VCRWXO8ERfX2/QEyv2oUtCSngQfjAqVg+3HTdG0Q/g88OPrP/848LmXniCECAkhHOs/R4DXAeYXZqtTdrf7mIrnTM9IlFJyYSnN7ibeQoQXKuPXw1bizFqeQkVnX0dzz/mr4ZrG1na64NfH21FueNWjgZGhdb3ywFTXIGLVxrHECFPOsGm6zszGqaCxO1Xz9uzxnsMe3WWans3G5vXgLS2iEyfv7kOdE6yFAlRPP2uKntOxZ3FVnDgrtbBH18oilbDAMGD30FtM0bRD+C/Am4UQo8B9678jhDguhPjY+jn7gBNCiOeBbwL/RUppGVtXYW+7D0OaHyS/lC6SLlabrifiS+kMOPE5bHVhbL0QI9dcrZE2g2saW9vpgl8/Z8e54ZWAgd8VwVB11kJDhFYEe3ITLDrbSGQTpmj65HdqRkdnzoWjuIrLp9F+rLl68wXcRcpKjrS/n/D0KhppVk9eNEXL2dgpQgU/VaMFiY5jLcZSl8ruchV7122maNoJSClXpZT3SimH19e6tfXjJ6SUP73+8+NSykNSyiPr//61uarrm93rmX9mb2udX6y1GNvf0dwf/EII9nb4Lt2vmYwsZRACdlsxWy/jZrcRLRf8JuAcCGJz+lH9WcrOQRwVwe7UJFQMvnPBnHIE35pKoykVnEYHjvIUiWIn3lsOm6Jlq2gbDKGrPsqOIN7VMl5lnrWLqW3XkS6nWSqniBR9UAlglzEUafBYn+SQzQda8wb3WjQf/WF3rfaTyZ6Wcws142NvkxtbUDMozy+mMQxze+peWErT2+K2eiJegZs1tiwX/CbgOl7bVW1RiiiiHUPY8KWXUVJlvrcwb4qmtZxCizuBroVxq+PkskHsfY1fY+tyBt9wAFclAIBaaKfgWiHtzYCxvbFy51drJSdCxRC+soNwqdY66DsdcDjYHKU2LHYONlVhqNVrepD8ucU0/WE3Xkfzf/Dv7/STK+vMrOVN1TGylGn6bdtXy00ZW5YLfnNw7mpH6iV68hIFleVwN8aqQU98lov69gfJJ/Ml8oaDvYU1ANpdI0hbO0Jprhq4kVv34SxlQeoYso/xso/pTh/61IVt1XE2XuuDGSz3YzcE0fQYwmuwYlc43HfPtmqxsNgM9rR5uVgHnq39nc3v1QLY31H70njOxK3EQllnajVnxWtdheb69GxQhCIQJIlW7cALleSPJc8x5mrfdj0PPXkaEAwlDYTU2e8fwdff2M2nr4SiaXj1GLqIkfX14x7TKdk1sie3twn4c0tP4Sq7cJVrCRHelVnKIQWfLukbfse2arGw2Az2tPtZMLH2U6ZYYWo13/TxWhsMt3lRFXFp69QMRmMZDInl2boKlrFVJ9iiKi53lKqrSMa3i8CawoHUOMv2MHPL09uq5V+fn0YgiRSCuPJzVLQokdsObquG7SLUIimpOhlfL9H5Bdz6MsvPbO98n42dIljwU5JRJAaOeIzZdoXDhoLwd2yrFguLzWCj9pNZxU03suJ2imfLqansinpNDZLfmHPL2LoylrFVJ7gOdiCEgtOTRdpqsVF71iagZPCl89sbJD+xZuB2FsDWg90YJ5VrxX3kyLZq2C56DnWhEKJqc+NN2HA4ZymVtm/BSpVSrFQzRIo+RMWPTa6gSJ2v9hkc8fZsmw4Li81kIyPRrLitDQ/PxvbaTmB/p9/UbcSRpQxOTaEv7DFNQz1jGVt1gve1B5BGlTbdwEaIgt2PP7WCLVngubXt65FY0Q2yZQf9xJGKnYDzAsVCCFtLy7Zp2E4G3nQUZ9UFgFrqZtSmMd9RQV+5YhWTTefcai1XpKUcJlCyEy5NAvBUl8KRjtu3RYOFxWbTFXThddhMi9s6t5CmxWOnze8wZXwz2N9Ra9uzliubMv6FpTTDrT5UpXmr9d8MlrFVJ6hBH7IYo79QWxwmuwdgzaAnPseY6t42HY+NTKKjcjBZK0i423cG1du7beNvN+7+blyFJaQsUNGGSMbcxAJ+is+c3Jbxz6ycBiBU7sWxERzvMci6FQ7ufvc1Xm1hUZ8IIdjd5uW8WcbWYpr9Hf6mbtPzUja2TM3aSrQyEV8Zy9iqI1RviZAWwFB0llqHccZUDiQuMurppVrdnm8rf/+d2pZlV8aFvbRGjzdFy8FD2zK2GQgh8KkpdLFKyj9A20QMm8yx+PTYtoz/1NzjuMputHIEAG9sllxY0FcBf3tzbt1a7Az2rdd+qjUX2T4qusHIcmbHxGttsG89GcCMIPl4tkQ8W2aPZWxdFcvYqiPsA0FUVUMEs1Scu3CUBLfERyjg4KmLz2+LhmcXddz2InY6sVfGWSv3Ebi1uT/0o10uKqqXnKeDSGwNj7JIObk9lfsvrJ4nVPCTXw+Od64tcbJL5ZgjZDWftmhoDnQGyBSrzK4VtnXciZUc5aqxYzIRN2jx2OkIOE2J27qwuBEcv7Pm/EawjK06wvOa3UhpENLK2OhCV+zsS4yhpCo8MrH1bWR0Q5Iu2ok6cuhaEKd2kXQqhGPfvi0f20wG7hjGqftBKDhzrSRdCVZb4+hrW7sFEi/ESco8kaIfe9mHZqygGlUe3gWHI83rTbTYGRxY9yydXdjergznFmvj7TTPFtTitszwbJ1Z/z8+sAPn/HqxjK06wnVgGCO7yGDBgUBhKTKAL5HAEc9wvrT13w6fHFuP10rVAvK7vGfRZRTF0dxBpt13H8NWKYI0EPoA58tRZlpbKD67td7E51dq128ptxEqakSKY6BIJtoFRwbfvKVjW1hsNXvaa8HSZ7bZ2Do9l8apKQxGdl5W3IFOP2MrWQplfVvHPTOfoivoIuSxb+u4jYRlbNURQlURIkmb9CGRTHYPoS4LhtamGXNtfb2lv1uP1xpMglotctg/irfvwJaPazaqz4uvPI9khax3EPdYEanrLD61tZXkn5x/CmEohIs92KWgdW0E/BKHItg19PYtHdvCYqtxairDrV7ObrOn5dRckgOdAWzqzvt4O9QdRDfkJe/ednF2Ic3BLsur9UrsvL/GOkdr17Crdqr+HFn/LpwZhdtWTjPt7GRucWJLx356roLLUcJbiWIvTVE2OgjfcXxLx6wXwiEDXZGk/f20z0/jlYuUV1e3dMzHZ76DvxigpHcC4FmaZjmicEz1odisb4gWjc/+Tv+2GltV3eDMQorD3TunvtblbNz387PbZ2ylixUm4zkOde3MOb9eLGOrznAdq5VZ8LlLqPRjCIU74ucQmQqfO/30lo1rGJJUwY7HbVC1d6CpIyQzrbiOHduyMeuJvlt6UGQE3eaiJWmn6F4iFVmkupLbkvHKepm5whzRQgC92oJBCWc2zncGJMfDze9NtNgZHOgMsJIpEUsXt2W80ViWYsXgSHdwW8arN9r8Ttr8Dk7NJbdtzI0YsQOWsfWKWMZWneG94xb01Cw9FRUVB/FQFx1rC2hreZ5Jb12G3InJKarYuCWxAEIh6jtNqRhs2mKmL6X/vuMoRi1F3V7s44TsYLrdT+7p01sy3vm18+hCEi214Cs58VRnEcB3BlRutbYQLZqEg5eC5LfHu7VhZOxUzxbA4e4gp+a2z7N1Zr421sHOnTvn14NlbNUZtnAYWVqgrxwEYKxnGPtKmZbVOBedWxe39bFHnwVg71oFRS9za/A0jvDwlo1Xb7i62/EW5kFmKDt3oU+rlA2FlSe3pt7WUwvPANBS7iZUVmjPXUBoBvGQ4MCuB7ZkTAuL7Wb/NmckPj+Xwue00b+DW8Yc6Q4wEc+RLm5PE/Az8yna/U6ivuZOpLpZLGOrDtHaVTyqRsWVJRXcgyOlcnT5PGPuXpZik1sy5hMzEo+rhLfchr00gVt6CB+/bUvGqleCrgKQIxncRd/MCB59mWp+HlnZ/Myer489gqPsRpS7EQjCsTEKLYJDqh/NiteyaBJ8To2+sJsz89vn2TrcHUDZwS1jDq9voZ7ZJu/WGSs4/rqwjK06xH20D2noeAJlbMouDKFwV+w0IlPhsycf3/TxUvkimZIDr9ug4uxEsY2wmuvEfeutmz5WPdO9N4xBlJIjRFvcoOxaJtk5TXF0cwPlpZRMpkcI54Pk9TYkEvfSLKd7DW6LWPFaFs3FgU4/Z7chO65Y0bmwmLlkbOxUNgLVn98GYytXqjK+kuWgFa91TSxjqw7x3H4LemKSgYqGKp2shvrYuzqJbSXPM6nNj9v63IknkSjcFl8AoDVwilwygH2gf9PHqmeG3nQERagAuAoDPCU6mWz1s/bEqU0dZzG3SEEp0lpqwVV2oxpr2PQiX91j45ah+zd1LAsLsznQGWB2rUAqv7XbWucX01QNyeEd/sEf8tjpbXFvS5B8rR2TFa91PVjGVh2i9fUhc9MMXIrb2oNvJY07nmZsC+K2PvH0PDahs2u1iqKXuDVwBpu3f0c1cQUIHN6DK7+EMDJUHcNk5lQqeQf5c7Ob2t/tsdknAQhX2ogUNcLFMVAl5zoUjg68ddPGsbCoBzYyA0/NJ7d0nNPrgdqHe4JbOk4jcLg7sC1B8peC43e4gXs9WMZWHSKEQGtVcagKFXeCRGgP9pTC3qVxRpx9LMc2r96WlJLpNReOkIGn2oqtPIFfd9Fy6x2bNkajIBSFkG0NRWZIBocZmDmPn3lyvlGq8c2r4P/pcw+jVe04C724DEFb/ALVoGSXPYDbvnMDey2ak8M9AYSA52aSWzrO87MpIl47nQHnlo7TCBzpDjKfLBDPlrZ0nFPzKSJeB21+Kzj+WljGVp3iOtqLrBTxBSR2BtAVjQdiT0Cyyj8+9bVNG+fCwhQl3Y7PBmVnJ0K7SDzdhefOOzdtjEaiZ28Lumij5AjRFa+S8S6z2rVK7rm5Tbm+lJKx9EmiuQhpowcA3+IY490Gd7XvjAKyFjsLv1NjuNXLczNb29z9udkER7qDO84jfyVeKG6a3NJxnptJcqzXmvPrwTK26hT3rbdSXTnHUNGJgsZc2yCHYuM44hlOlDZvS+uvv1MrlHrP3BQAkfCz5JN+HMO7Nm2MRmL4rbfA+sLhyw/w7fJeZp0RVh/fnEbgo8lRSkqRzkIUd8kHMouzsMY3hlXu2Pu+TRnDwqLeONYT4rnZ5KZux19OPFtiYiXHbQM7oy7gtTjcHURTBU9PbZ2Bu5otMRnPcUtvaMvGaCYsY6tOce7bi5EYoc/wI9EZ792DP5bFFUvzjG8/5cLm7Md/bQTczhIDqwK1kuFO91kcLUMIZWf+afgP7caTn0cxMkhtmNR8FUemQrkwQSWWv+nr/+PzXwYgUuykLa8RKl1ECMmJHo2jnTtv69ZiZ3CsN0gyX2Fq9ebfQ1fixLpRcVu/9cEP4LKrHOwKcGJqbcvG2NgWvrXPmvPrYWd+ojYAwmbD3udCEwLDvUbeuw+lLLhlfoSk7uEzT3z2pseYjc+TKrgxwi6wDSDleTwVP8HbX3/zN9CgCEWhxZnBZhRJBHdzcOYZHK5pst0XyD63dNPXf2TqG7iKPsp6H24p6Fw9gwwYHAj1Ylet+loWzcmxde/HVm0lPj21hsOmWIHal3F7fwun5lIUt6BOIMCzMwlsitjR1fpvBMvYqmM8d96CvjZJi1fFrfdScPh4a+wptKUcj8Zv/hvLx779LUBw5+o8Vc2L6jvFWqoD9x0728PSf7idshqm7AjSE7dz1u5iujNP4omxm9oGKeklUnKKtlyYgl7LKvXPjzHXaXDXwH2bJd/Cou7Y1erF67BtWZD801NrHOkJ4rCpW3L9RuR4fwtl3diyrMRnphPs7/Tj1Kw5vx5sN/NiIcQPAL8H7ANul1KeuMp5bwP+DFCBj0kp/8vNjLtT8Nz5WhKf+gsOBu7nG85lHn7gLVQ1lZ8a+wqO2Cx/8eX3I4FSLsvutts50nI3SkFguCTPr32LM/lRqu296KoNl8sFQKFQwO10YI/N4Zuf5mcUB06jSqtnN0e870eoAeJ/vwRyEVnQmfDGOaGNky5k8bu8HK8MMZANUzByPL/6TWJiFilrGnzhCK9/8MfY9/o3mjtx65w6dYpvfOMbpFIpvDg5Xh5k0NHO82vf4uLyU6idvZRbu8kXS5fmpJDJUGnrwWjXUHSFXKUb1+fizGgq89W/pPrgf8fh9SIEtMoejoTfiEvxoLo1pJQvm7PL592Dg4+Uf5tOI4SQDlwBkHf9O064/5W7rX6IFk2MqgiO9AR4bnbzPVu5UpWzC2l+/u6hTb92I3N8fXvv6ak1bt/kWLbquhH3Q7f1bOp1m5mb9WydAb4P+PbVThBCqMBfAPcD+4H3CyH23+S4OwL7QD+yukBCWyUTuEjVbqsFb2sapY4+0opGKZuh172XQ47XoRRqgd1KQeB276LcMYCu1uzpQqFAoVArX5Avlkh6W6j4W3AaJXo9u7ktcj9uWy2rROaryILOmLLItyqnSReyAKQLWb5VOc24soRb8XJb+G20Gt2UshmQkkx8ha9+9H9w/jvfNGfCLuPUqVM89NBDpFK1b3VZinxHu8BEaYlDjtfhjxwg6W0hX6ylRtfmJEypox/DpoEAw2aQ7+qh4m9BVnSqsgpIStkMrUY3t4XfhlvxIhAYV5mzy+c9R4nvahdYVBK4hUAIgeIOc6/4cbqmLFe8RXNzrCfE+cUMhfLmbms9N5NEN6QVHP8SQh47w63eLYnburCUoVDRucWK17pubsrYklKel1KOXOO024ExKeWElLIMfBJ4982Mu1MQQuA6MsAJ2xiIl2xfKSrlaBcAh0N3Y1O0Fz39nDaNfKX+YNd4PcAJ2wS6MF50TBcGJ2y1Ol82ReNw6O4XPV8tl/jOJ//uuu5vK/nGN75BpfLiitUb2m2KRqLFD8pL3N+KUnu86NgL83Q5NzJnV9JwOQ5pJ/PVmWvckYVFY3OsN4huyEvFRzeLp6bWUATc0hvc1Os2A8f7WzgxnUA3NjcL9JnpmofSmvPrZztitrqA2ct+n1s/dkWEEB8UQpwQQpxYWVnZcnH1jvd1ryUnyld8Tmq1gGq37eVNQLOieM1rv9LrX+kalx+/0mszq/Frjr3VbHi0XsqG9vxV5vRKbMzT5dzonF3rHD25tcUHLa6MEOIHhBBnhRCGEOKqhc6EEG8TQowIIcaEEL+xnRqbhaPrld1PTG+up+XE1Br7Ovz4nC//8rPTuX0gRKZY5eJyZlOv++xMgja/g66ga1Ov28xcM2ZLCPF1oP0KT/22lPJzmy1ISvlR4KMAx48f35qiLA2E5447cH/7u+RdL6/QKyo1gyFfTePRXrwN5ZXOa37wv9LrX+kaXvlCheZ8Nf2y533hyCuOux0EAoErGlwb2t3Sft0G18Y8Xc6NztmVNFyOGrQqMJvERijEX13thMtCId5M7cvi00KIz0spz22PxMYn9dBDrH34Izy8sEDiES+/+RY7XxzO0K75+eVEkgdWZkGoIHW+GO3hz0JBlipp/HY/QghSpRQPjPp4/7cNtFgSVBV0nUo0iP+2KqePlPjN/2/9+ZUUlWiAf3qDwheG0yhCwZAGAXvg0rVeGHeOVKyT2Ck/1dU0to4OWn/1Vwi8851mTxmphx4i9uGPUF1cxBb203o4Dfk1YmdCVHNgCwdoPZwm0LrAF6Pdl+Ys4AggpSRVTqEIBe9eg//9Zx5+4nGBtpK6dK1A6wK4atuAX1RK/Fm4hSVV8MCo/9I8Xn7uxhhDJxO8/1H42bTB2Nc762a+6p1reraklPdJKQ9e4XG9htY8cHkUXff6MYvrwBYOc0tsGVW+5L/K0LGv1KbxVOJbVI0Xb5kdq/QhXsl1fI3XAxyvDr5sXFUqHK8OAlA1KpxKfOvFeu0OXv/gj13XvW0l9957L5r24m+6G9qrRoXQWhqMl8SOGEbt8aJjL8zT5dzInF1Jw+UITcH/1v5XviGLLcEKhdh6Ug89xOLv/C7VhQUE0JLO8oOfXeO1Z6ssVlL8nlvyRY+7Zmh53PyeW7JYSSGpGQzJUpLXnq3yg59dqxlaAHrtvautJPnZr2b5ya9UXnheSrRYkh/87BqvO6tjyNp7euNaEnlp3EcX/Sx+S6caT4GUVBcWWPyd3yX10EOmzNUGl88ZUlKNp1h81GDhyQDVLCCpHfuWzqOL/hfNWbKUJFWufdE0pMFd53R+9AupS3Oz8brUlBMKa3xRKfJ7kRCLquC1Z/UXzeNLxxg8ucYHHzaIpg0E1M18NQLbsY34NDAshBgQQtiBB4HPb8O4TcORY0e5c66KpttAglIu4ViYQs/mKNidzOTOc7r0GIarZlwZLkk+P4Z9cRJVrwLgcrkuZcYVdQErS9jTayCczBTO8nT8YfJ6BolEcdsQLpVdRgd3a4fwu7wA+F1e7tYOMWS0kzeyPL36ZWLKHA6vD4TAF4nylg9+qC6yEQ8fPsw73/lOAoGa98mLk9dX9jLoaOd06THS8bMEs2u4nTWPktvpIJhdxbE4dWnO7AY4F5dr8yQlZVstBk5VFJbL0zy9+mXyRvYV58zlciFVFYnEJe3cVdlLT7UdvZxHSknBUyH4fcN4jrWaMEsW18kNhUJYvJjYhz+CLL7Y2+uswg8/WluviorCn4WCAPxZKEjxCgWVf/hRibN65es7q/CW53jZ85ePcSWKioL2nAepv3g8WSwS+/BHXvmmtpgrzZk0BLzki5zUa/dwpTnb4EpzJ3WF2Ckf8OI5v9q5G2Nc8fk6mK9G4GZLP7wX+O9AFPiiEOKklPKtQohOaiUe3i6lrAohPgR8hVrph7+RUp69aeU7CN9999HzD7/KYPi3+GK6SNl4nPu/e4IfeevvsHxrHx90foF3/uDvvOg1vbyBKzl2//0//RGfev4Axpvu5T9/+nmSvgj39v8ittM5hj72Ry+rHN8NvOEqunZz/6bc31Zx+PBhDh8+/LLjvVe9oxeTPT/K3314AhlU6Jz/On9wX4zftNvpaJui++l/R8cHj+AYfPlW4uVzZhiSW/7y5zE83+OB6Xfwr7kgw+Uc933z3/LofRUe+O2v4/FbhtZWsp2hEEKIDwIfBOjt7d3MSzcs1cXFKx4PXxaBsLReH2vpKnWywi+PVngRylVsqmu9LniV56+mebu4kfGvdg8bXG0OqvmXz/nVzt0Y46rXMnm+GoGbzUb8jJSyW0rpkFK2SSnfun58QUr59svOe1hKuVtKOSSl/MObFb3TcOzbh+qposksihhH2G5FCpX3rXwDx2SSx+2HmZ357DWvk0g+x0Pnd+HyVnnbxAlSgd3EvSfZVTZwD92+Y1v0XA3P3l2EcpN4qsushW/l6NJzLAaXGFFamHWeIvG5UaR+9cxDgP/7zBSG8ySt2SgLop3+kkpr4RRCGHzjWDd9/r5tupudy3aGQkgpPyqlPC6lPB6NRm9WelNg6+i44vHVy3JM2qv6i/59pXOvhHGVxOtrvS55leevpnm7uJHxr3YPG1xtDmzul8/51c7dGOOq1zJ5vhoB69O1ARBC4HvzfVTGv8M+6cRheBkd3s/bR5+CnM7pUj+fePxRqtXsVa+h6wX+/Msfp1B2kBqMcu/pKaRQ8bV+j5VED743vnUb76gxEELQ261SUMMUXRGOT3fxUL4LdXwQx+CT5JfzZB9fuOrrM8UK/+nRf0RqOYbyQ6SNbpwIuqdPYLRVeO3hd2zj3VjcBFYoxE3Q+qu/gnC+OCmkaIN/vKdmITkNg19OJAH45UQS50vjJqmdW7zKPkzRBl89xsuev3yMK+E0DCrHcgj1xeMJp5PWX/2VV76pLeZKcyYUCS8pKyPU2j1cac42uNLcCdWg9XAtQ/HyOb/auRtjXPH5OpivRsAythoE3333UZ78NkOBAaoizbm+O3Fmqrw5/iSu0TW+4HkjJ57/b1d9/clzf8rfn3kjHk+ZPcY0Ff0Aulzi7cYZClM2PHfeuY130zgM37cPQ2gIo0Jb/lZi5XHsrc8zG73IqOsiya9NXbVB9Ue+ehHd/008RR++XDctSQ8SneDyCE/uE9zbd+82343FSxFCvFcIMQfcSS0U4ivrxzuFEA8DSCmrwEYoxHngU1YoxPUTeOc76fiD38fW2QlCUAgH+F9v8fLYARsdWoDfywseyOVBqDyQy/N7eUGHFkAgCNgDBB1BHj9g41PvaaHSGqxdVFWRwIrXw6fe08L/eav2wvNCUGkN8qn3tPDYARVF1D7mNq4lEJfGvacjTcfdKrZIAITA1tlJxx/8vunZdS+dM1skQMc9Cp2vSWHzAoLasbtV7ulIv2jOgo4gAXstvEERCo8dUPn4OwLEPO4XrnW3SqC/CK4WHjCc/F48QYcuefyA+qJ5fOkYZw8E+Kv7BWsBFSmom/lqBG4qZsti+3DdcguKS6DKRRzVGQS3kAu6+LHZL/GV1tcytRTioWyZjuj/prfnpxHihW90S0uf57e/5UWvqqzd1sF/+OyfsRL4KcZbP0t/0UZ86LUoHo+Jd1e/RN94By3/56+pOjTWwrdwaPEzfH7XIV5/5ji37P8sJ5/7f7j1o6eI/NQh7B0vzOHJ2SR/d+rLOHuW2bd0CxccvdxTVgkXT2ETZT53Rw8/GT1i4p1ZQC0UAvjMFY4vAC8KhQAe3kZpTUXgne+89IGsG5In/uBrvNXdxh//wMvfAw+sP16Jqm5w7A++xtsPdvBfv/8w//kK5xyGKx5/mbb1R71x+Zy96PgVzr3WnJ2ZT/EOvsuf/MAR3ndr9w2/fuOcj/6P7xIbELzuv73uGmdbvBTLs9UgCFXF+6Y3Unj6/3Jr1YcqbTx1+A5aZgu8h2+gTaT5nO2NfOGJb3Lhwm+Rzpwhn5/k3Llf55++91FG5oYQ3XaOFc6iJA8gZZE9vq8TX+4g8K7vM/v26hZhszHUL8hrrZTtfu65OMyZ8hJ+/0XWQuMEw89wspRm5aOnyD65SCWW59vfneYDf/k4rvAjOMouOvL9GMlWXFLQN/EoenuFB46+/0UGsYXFTkFVBK8fjvDIhRiVa8Q8Xo1nZ5JkilXu2WPFxV0PBzr9RH0OHr346guFr+XKnJpP8Ybd1py/Gixjq4EIvP3tVBcv0NU/REWOknO8mYrdxg9PfRmvrUD2vME/iO/nS2cWeerpd/O9J+7jf52t8BdPfxDVLjEGPfzao39DLHqciZYnebCwSGXehveuu8y+tbpm7/vuxDBUVKNAoPIa/NUYj7hSXHzs/Rj7Ps2KUeRPymt8+jPn+U9/+hg//YUz+Dznke4Z9qR3Ma+1c7BgQ4oswdgoT+wVvGvXu8y+LQsL03jnkU7WcmUeG3t13Sa+dGYRu6rwumHzCyg3AkII7t4d5dsXVyhXX52B+43zy0gJd1vG1qvCMrYaCPcdd6D19VKZ+Tb7E+O4KwGev+V2fCclv+36C+y5AvMnHfzT2rt46MyP8D9P/jJffPZNKA7I3tHBz6f+kuLsa5BCQQk/hqPow3X7OxGa1ebilfAdO0hbYRSPHmMlegsPPNPGiWoCW9ezjMQ7GLrtwxxXqvwBBT5OiaBzEtn9D3hKHvpT/YyUu+irqgysPoZq03niTXfS7rlSJQILi53BPXui+Jw2Pn/y6gkmV6OiG3z+5AL37W/Fb7XouW7ecbiDVKHCN0dir+r1nzu5QG+L+1LbJYsbwzK2GgihKIR+6EHyj32WfX2HydsmWfTfT8nn4OAXl/gPBz/KQH6ZlUkHn1u4nROxISoBF5VjId6a+iL3/dMp5ttfz4LvLD9ZPkliwkPg3ZaH5VoIIdh9OEBaq9VNOhC/AyGLfFJbIDO9j4I2R89tf8xD/hifcKzS3fEwRalz58qdLGiD7Eo5kEi6Rh6l2FfhB279UZPvyMLCXBw2lfsPtvOVs0sUK1cu93A1Hh1ZYTVX5n23vDz2yOLq3LUrQtTn4F+fnbvh1y6nizw2Huc9x7qs8IdXiWVsNRiB974HYddQnIv0LH0HT7mF5197FNuqYPeT4zx4x6f4mdlHeFfiKXZHVlADcOfYI/zCyU+wUH0HVc3HYvujDBdVyulOnEesIO3rYdeDb8JRTBCsXGQp8jreePI4KVnikd5HeeTxd3A+5uSZY/+NPx76n4w6Zzm6ehRvIcJ38+0cqtoIFcdwlFP8zd0+7um5x+zbsbAwnXcf7SJX1nnkwo15Wj79zBwRr92KHbpBbKrCe4528siFGInc9fWF3eDzJxeQEt5ztHOL1DU/lrHVYNhCIfz330/2i5/ktX0HSDtmiOvvYXmoC8/XVY6eGsd+/xTP9HSxkHLyk56/5eftfw+P9DPT8ybOR7/HDxlPsDLeQuD7f8T6lnKdOHt7GLaNk9O60W1O3rzopbj0XmZkkS/s/jp/Z+T5oyUbk3qBPck97Fkd4OvO3dxa0vDqgsGLn0ftKLPvrb+AXbWbfTsWFqZzx2CYqM9xQ1uJiVyZb1xY5l1HutBU6+PrRvm+W7qp6JKHTt3Y9u1nnpvnSE+Qwah3i5Q1P9ZfawMSev+DGPk8zj4PQ2P/iE138fyed7PY2UHg0zbe+M3T/P96/oj/cei3uf+xE4T/h51ze3+EopYnFfkyb8pWKUx7CP3QD5p9Kw3F0Z+8B1mRhEoXWfDfzbtWFbLjv05b8RB+TWdXZpB3Td3PPWt384yvn3TazR1FG8HCBMG1Cb563MGP7v8Rs2/DwqIuUBXBA4c6eGQkxtp1eloeOrVARZe871arNeWrYV+Hn30dfj797BUbIFyRkaUM5xbTvNfyat0UlrHVgDiPHMFz110k/u5vubN3L0n3p7HlDzB62+s4v3cXnsdUWv+zRtvv2vF8y8Yzx3+avKeHx/s+y3/MXGB1MkTg/T9p1da6QfyvvZ0h/Twle5CqzclrZr2o0TbGJj/A6uLPctTVhTNi42/UCM+ko9xld2IzYP+Fj+OIlLH98K/i0aw5t7DY4AOv6aWiG3z02xPXPFc3JJ94Ypq97T4OdNZjZazG4H23dPH8bJKLy5nrOv//nphFVQTvOGIZWzeDZWw1IEII2n7rNzGKRYTLxtu//T1mQyeppu5mevDdfOneN/H0nbczcux1PHLPb5L2HuV0+7d4vfIEXSUnmYtuWj7wAbNvo+EQQnDsh19Dueqmq/pt4sGj/PGzXyC8T2cp38bfjL+d/z1/J6uVIHu7JYfi0LX2JM70CieO2fixA5ZXy8LicobbfLzzcCcff3yKeLb0iud++pk5Li5n+X/eNLxN6pqT9x7rwm1X+cjXL17z3Fi6yCeenOYdhzuIeB3boK55sYytBsUxOEjLBz5A5ktfpvNND3Bo8m851/ZdtHw/Nvl2Ep73MRv8QaCTx/r/ldXWL/BzmSUWH3Xg//4PoAaDZt9CQxJ68z0M5Z9jUXsdofxFlmxv46dPPsE7hk9x+PAyBw6t8ZZQjPvPamjVDEPn/gXHUIHqz/8ebs1ttnwLi7rjl+8bplTV+V+Pjl/1nEJZ50++NsLRniBvP2SVTbkZwl4HP/P6QR4+vcRzM4lXPPfPHxmlqkt+7c27t0ld82IZWw1M5Bd/ATUUonDqeY5Penhn4Tt8Y/+HWfRNsuKaZzR8gi/s+0vCrhP8Q2yM9GQ3Va2PyAc/aLb0hkUoCq/5xXsJJCZosc/iqKQxCvex+7luHlwe4J0LIQ6NdqDIInc+85/w+tP8y/e/nvfve9Bs6RYWdclQ1Mt7j3Xz909Ms5wuXvGcv3lskuV0id96+z4rqWcT+Jk3DBL22PkvX7qAlPKK50yv5vjkU7M8eHsPfWEr/OFmsYytBkb1++n60z+hurSMsNno//wC/zkTwOj9MInBP8Ho+AQ/XnmKjyTHKRaPsHrCoPNP/hg1YMU73Ay+u+7idUfLzOq3ssf1EH2LX8NWaCcxIqmOO3EX57n7u7+PizST+zU+9IGPWh8QFhavwC/fO4yU8HOfeIZMsfKi507OJvmfj47z5v1t3D7QYpLC5sLrsPFL9w7z5OTaFUtvSCn5o6+MYFMFv2Rt224K4mpWbT1w/PhxeeLECbNl1D35EyeY+eDPgmEgi0W8RwfQyiO4wzm0XUdIZ/ez9n+/TPTf/hqRn/kZs+U2BbJc5tkf/TWe9j/AIdu/4j99hlLegasQR5E6/sEicY9C6M8fprdjj9lyGwYhxDNSyuNm69gMrPXrxvjK2SV+8R+e5UhPkI//m9vxOmx8cyTGL3ziWSI+O//0M3fQHbK24jeLctXg/j/7NkupIh/78du4cygM1Ayt3//COf72sSl+5b5hfuU+awvxRrjaGmYZW01C4cxZVv7yL8k/8QQynwdNw3XkCKXRUYxslpYf/VFa//2vIxTLmblZlKenGf3gL3PRcQtqn4tOnieQH0crF0kUA+z/2GdwBEJmy2woLGNrZ/Ol04t86J+eQxUCv8tGIl9hb7uPv/3J22j1Oc2W13Qsp4v8yMeeZHotz++8Yz+tPgdfO7fMvzwzx0++rp/ffcd+yyt/g1jG1g5BSkny0/9K4ZlnKJ45ja2jg7Zf/3Ucw5YreCswCgXi/+uvWPj7f0EpF3B4NLxveD0d//E/oritb+E3imVsWTw+FudbF1fIlKqXtru8DpvZspqWRK7Mj//tU5yaS1069qE37uLfvmW3ZWi9Cixjy8JiC6nG4wCo4bC1QN0ElrFlYbH9lKsGo7EMAoHXYaM3bH1RfLVcbQ2zvi5YWGwCtkjEbAkWFhYWrwq7TbEKxW4xVgCPhYWFhYWFhcUWYhlbFhYWFhYWFhZbiGVsWVhYWFhYWFhsITdlbAkhfkAIcVYIYQghrhrUKoSYEkKcFkKcFEJYEaMWFhYWFhYWO4abDZA/A3wf8FfXce4bpZTxmxzPwsLCwsLCwqKhuCljS0p5HrBS3S0sLCwsLCwsrsJ2xWxJ4KtCiGeEEFYXZAsLCwsLC4sdwzU9W0KIrwPtV3jqt6WUn7vOce6SUs4LIVqBrwkhLkgpv32V8T4IfBCgt7f3Oi9vYWFhYWFhYVGfXNPYklLed7ODSCnn1/+NCSE+A9wOXNHYklJ+FPgo1Cow3+zYFhYWFhYWFhZmsuXbiEIIjxDCt/Ez8BZqgfUWFhYWFhYWFk3PTfVGFEK8F/jvQBRIAiellG8VQnQCH5NSvl0IMQh8Zv0lNuAfpZR/eJ3XXwGmr1NOBKjXbMd61WbpunHqVVu96oIb09YnpYxupZjtwlq/tpx61QX1q61edUH9artRXVdcw+q6EfWNIIQ4Ua8NbOtVm6XrxqlXbfWqC+pbW71Qz3NUr9rqVRfUr7Z61QX1q22zdFkV5C0sLCwsLCwsthDL2LKwsLCwsLCw2EKaydj6qNkCXoF61WbpunHqVVu96oL61lYv1PMc1au2etUF9autXnVB/WrbFF1NE7NlYWFhYWFhYVGPNJNny8LCwsLCwsKi7mgqY0sI8QdCiFNCiJNCiK+ul6AwHSHEfxNCXFjX9hkhRNBsTRsIIX5ACHFWCGEIIUzPBBFCvE0IMSKEGBNC/IbZejYQQvyNECImhKirGnFCiB4hxDeFEOfW/x9/2WxNAEIIpxDiKSHE8+u6/qPZmuqdel2/oH7XMGv9uj6s9evG2ew1rKm2EYUQfillev3nXwL2Syl/zmRZCCHeAjwipawKIf4rgJTy/zVZFgBCiH2AAfwV8O+klCdM1KICF4E3A3PA08D7pZTnzNK0gRDiDUAW+Dsp5UGz9WwghOgAOqSUz64XD34GeI/ZcyZq3ek9UsqsEEIDvgv8spTyCTN11TP1un5B/a5h1vp1fVjr142z2WtYU3m2NhaqdTzUGmCbjpTyq1LK6vqvTwDdZuq5HCnleSnliNk61rkdGJNSTkgpy8AngXebrAmA9V6ea2breClSykUp5bPrP2eA80CXuapA1siu/6qtP+ri/Viv1Ov6BfW7hlnr1/VhrV83zmavYU1lbAEIIf5QCDELfAD4XbP1XIF/A3zJbBF1Shcwe9nvc9TJG68REEL0A8eAJ02WAtS+6QshTgIx4GtSyrrQVc80wPoF1hp2Naz16yaot/ULNncNazhjSwjxdSHEmSs83g0gpfxtKWUP8A/Ah+pF1/o5vw1U17VtG9ejzaKxEUJ4gU8Dv/ISD4lpSCl1KeVRal6Q24UQdbN9YRb1un5dj7b1c7Z9DbPWr+anHtcv2Nw1zLZpqrYJKeV913nqPwAPA/9hC+Vc4lq6hBA/AbwDuFduc6DcDcyZ2cwDPZf93r1+zOIVWI8n+DTwD1LKfzVbz0uRUiaFEN8E3sYOb0Jfr+sX1O8aZq1fzU29r1+wOWtYw3m2XgkhxPBlv74buGCWlssRQrwN+PfAu6SUebP11DFPA8NCiAEhhB14EPi8yZrqmvUgzr8Gzksp/9RsPRsIIaIbGWtCCBe1oOG6eD/WK/W6foG1hl0n1vp1g9Tr+gWbv4Y1Wzbip4E91LJTpoGfk1Ka/s1CCDEGOIDV9UNP1FGW0XuB/w5EgSRwUkr5VhP1vB34CKACfyOl/EOztFyOEOKfgHuodYBfBv6DlPKvTRUFCCHuAr4DnKb2dw/wW1LKh81TBUKIw8DHqf0/KsCnpJS/b6ameqde1y+o3zXMWr+uD2v9unE2ew1rKmPLwsLCwsLCwqLeaKptRAsLCwsLCwuLesMytiwsLCwsLCwsthDL2LKwsLCwsLCw2EIsY8vCwsLCwsLCYguxjC0LCwsLCwsLiy3EMrYsLCwsLCwsLLYQy9iysLCwsLCwsNhCLGPLwsLCwsLCwmIL+f8D9PXUAhdKKesAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print sampled lines\n",
    "fig, ax = plt.subplots(1, model.n_hidden_layers+1, figsize=((model.n_hidden_layers+1)*5, 5))\n",
    "ax = ax.flatten()\n",
    "for i in range(model.n_hidden_layers):\n",
    "    for model_line in lines[5:]: # hidden outputs of each sampled model\n",
    "        line = model_line[i]\n",
    "        ax[i].plot(X_test[:,0], line.numpy()[:,0])\n",
    "    # for model_line in lines[690:701]: # hidden outputs of each sampled model\n",
    "    #     line = model_line[i]\n",
    "    #     ax[i].plot(X_test.numpy()[:,0], line.numpy()[:,0], 'b')\n",
    "for x, y in ds_train:\n",
    "    ax[-2].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "# for x, y in ds_test:\n",
    "    # ax[-1].plot(x[:,0], y[:,0], '*', label='ground truth')\n",
    "ax[-2].legend()\n",
    "\n",
    "# compute the mean of the sampled lines\n",
    "line_output = []\n",
    "for model_line in lines[5:]:\n",
    "    line_output.append(model_line[-1]) #the final layer\n",
    "line_mean = tf.reduce_mean(tf.concat(line_output, axis=-1), axis=-1)\n",
    "ax[-1].plot(X_test[:,0], line_mean.numpy(), label='mean')\n",
    "for x, y in ds_train:\n",
    "    ax[-1].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "ax[-1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-layer DGPs (fixing kernel params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "d_in = 1\n",
    "d_out = 1\n",
    "model = DemoRegressionDGP(d_in, d_out, n_hidden_layers=2, n_rf=100, n_gp=1,\n",
    "                          likelihood=Gaussian(variance=0.01, trainable=False),\n",
    "                          kernel_type_list=['RBF' for i in range(2)], kernel_trainable=False,\n",
    "                          random_fixed=True, input_cat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.kernel_list[0].length_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.kernel_list[0].amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training settings\n",
    "lr_0 = 0.02\n",
    "beta = 0.\n",
    "total_epochs = 100000\n",
    "start_sampling_epoch = 0\n",
    "epochs_per_cycle = 50\n",
    "print_epoch_cycle = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 11:08:17.205677: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-08-20 11:08:17.223249: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-20 11:08:17.853445: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-08-20 11:08:17.853520: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Sampling at Epoch 49  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49\n",
      "Mean Log Likelihood -- train: -6.2812275886535645, -- test: -50.384490966796875 \n",
      "Root Mean Squared Error -- train: 0.39153221249580383, -- test: 1.01752769947052 \n",
      " \n",
      "#################### Sampling at Epoch 99  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99\n",
      "Mean Log Likelihood -- train: -6.182208061218262, -- test: -46.8999137878418 \n",
      "Root Mean Squared Error -- train: 0.388994961977005, -- test: 0.9826856851577759 \n",
      " \n",
      "#################### Sampling at Epoch 149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 149\n",
      "Mean Log Likelihood -- train: -6.187300682067871, -- test: -50.227108001708984 \n",
      "Root Mean Squared Error -- train: 0.38912585377693176, -- test: 1.0159798860549927 \n",
      " \n",
      "#################### Sampling at Epoch 199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 199\n",
      "Mean Log Likelihood -- train: -6.2272868156433105, -- test: -50.600685119628906 \n",
      "Root Mean Squared Error -- train: 0.39015209674835205, -- test: 1.0196502208709717 \n",
      " \n",
      "#################### Sampling at Epoch 249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 249\n",
      "Mean Log Likelihood -- train: -6.221449375152588, -- test: -49.8454475402832 \n",
      "Root Mean Squared Error -- train: 0.39000245928764343, -- test: 1.012216329574585 \n",
      " \n",
      "#################### Sampling at Epoch 299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 299\n",
      "Mean Log Likelihood -- train: -6.201781272888184, -- test: -49.19670486450195 \n",
      "Root Mean Squared Error -- train: 0.3894978165626526, -- test: 1.005786657333374 \n",
      " \n",
      "#################### Sampling at Epoch 349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 349\n",
      "Mean Log Likelihood -- train: -6.235255718231201, -- test: -51.348182678222656 \n",
      "Root Mean Squared Error -- train: 0.39035630226135254, -- test: 1.0269548892974854 \n",
      " \n",
      "#################### Sampling at Epoch 399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 399\n",
      "Mean Log Likelihood -- train: -6.199501991271973, -- test: -52.624046325683594 \n",
      "Root Mean Squared Error -- train: 0.38943931460380554, -- test: 1.039304494857788 \n",
      " \n",
      "#################### Sampling at Epoch 449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 449\n",
      "Mean Log Likelihood -- train: -6.219862937927246, -- test: -52.29206848144531 \n",
      "Root Mean Squared Error -- train: 0.3899618089199066, -- test: 1.0361052751541138 \n",
      " \n",
      "#################### Sampling at Epoch 499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 499\n",
      "Mean Log Likelihood -- train: -6.202525615692139, -- test: -52.305030822753906 \n",
      "Root Mean Squared Error -- train: 0.3895169198513031, -- test: 1.036230444908142 \n",
      " \n",
      "#################### Sampling at Epoch 549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 549\n",
      "Mean Log Likelihood -- train: -6.2031402587890625, -- test: -50.082698822021484 \n",
      "Root Mean Squared Error -- train: 0.3895326852798462, -- test: 1.0145574808120728 \n",
      " \n",
      "#################### Sampling at Epoch 599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 599\n",
      "Mean Log Likelihood -- train: -6.0759758949279785, -- test: -45.83755874633789 \n",
      "Root Mean Squared Error -- train: 0.3862544000148773, -- test: 0.9718149304389954 \n",
      " \n",
      "#################### Sampling at Epoch 649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 649\n",
      "Mean Log Likelihood -- train: -6.062093734741211, -- test: -46.5944938659668 \n",
      "Root Mean Squared Error -- train: 0.3858948051929474, -- test: 0.9795727729797363 \n",
      " \n",
      "#################### Sampling at Epoch 699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 699\n",
      "Mean Log Likelihood -- train: -6.052733898162842, -- test: -40.4983024597168 \n",
      "Root Mean Squared Error -- train: 0.38565218448638916, -- test: 0.91522616147995 \n",
      " \n",
      "#################### Sampling at Epoch 749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 749\n",
      "Mean Log Likelihood -- train: -5.96099853515625, -- test: -40.72367858886719 \n",
      "Root Mean Squared Error -- train: 0.3832661211490631, -- test: 0.9176853895187378 \n",
      " \n",
      "#################### Sampling at Epoch 799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 799\n",
      "Mean Log Likelihood -- train: -6.080305099487305, -- test: -40.23782730102539 \n",
      "Root Mean Squared Error -- train: 0.38636642694473267, -- test: 0.9123756885528564 \n",
      " \n",
      "#################### Sampling at Epoch 849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 849\n",
      "Mean Log Likelihood -- train: -6.065811634063721, -- test: -39.87166213989258 \n",
      "Root Mean Squared Error -- train: 0.3859911561012268, -- test: 0.9083535671234131 \n",
      " \n",
      "#################### Sampling at Epoch 899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 899\n",
      "Mean Log Likelihood -- train: -5.932156562805176, -- test: -39.16710662841797 \n",
      "Root Mean Squared Error -- train: 0.3825128376483917, -- test: 0.9005638360977173 \n",
      " \n",
      "#################### Sampling at Epoch 949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 949\n",
      "Mean Log Likelihood -- train: -5.986954689025879, -- test: -42.34716796875 \n",
      "Root Mean Squared Error -- train: 0.38394275307655334, -- test: 0.9352092146873474 \n",
      " \n",
      "#################### Sampling at Epoch 999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 999\n",
      "Mean Log Likelihood -- train: -5.861599922180176, -- test: -39.43983459472656 \n",
      "Root Mean Squared Error -- train: 0.38066378235816956, -- test: 0.9035870432853699 \n",
      " \n",
      "#################### Sampling at Epoch 1049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1049\n",
      "Mean Log Likelihood -- train: -5.865438461303711, -- test: -38.7469596862793 \n",
      "Root Mean Squared Error -- train: 0.38076460361480713, -- test: 0.8958861827850342 \n",
      " \n",
      "#################### Sampling at Epoch 1099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1099\n",
      "Mean Log Likelihood -- train: -5.844356060028076, -- test: -40.760826110839844 \n",
      "Root Mean Squared Error -- train: 0.3802105188369751, -- test: 0.9180901050567627 \n",
      " \n",
      "#################### Sampling at Epoch 1149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1149\n",
      "Mean Log Likelihood -- train: -5.811779975891113, -- test: -39.957427978515625 \n",
      "Root Mean Squared Error -- train: 0.37935277819633484, -- test: 0.9092972278594971 \n",
      " \n",
      "#################### Sampling at Epoch 1199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1199\n",
      "Mean Log Likelihood -- train: -5.844831466674805, -- test: -36.29608154296875 \n",
      "Root Mean Squared Error -- train: 0.38022303581237793, -- test: 0.868098258972168 \n",
      " \n",
      "#################### Sampling at Epoch 1249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1249\n",
      "Mean Log Likelihood -- train: -5.726862907409668, -- test: -33.36151885986328 \n",
      "Root Mean Squared Error -- train: 0.3771076500415802, -- test: 0.8336085677146912 \n",
      " \n",
      "#################### Sampling at Epoch 1299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1299\n",
      "Mean Log Likelihood -- train: -5.678187370300293, -- test: -34.56871795654297 \n",
      "Root Mean Squared Error -- train: 0.3758147060871124, -- test: 0.8479664921760559 \n",
      " \n",
      "#################### Sampling at Epoch 1349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1349\n",
      "Mean Log Likelihood -- train: -5.6434197425842285, -- test: -34.83952331542969 \n",
      "Root Mean Squared Error -- train: 0.37488842010498047, -- test: 0.8511541485786438 \n",
      " \n",
      "#################### Sampling at Epoch 1399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1399\n",
      "Mean Log Likelihood -- train: -5.5544962882995605, -- test: -29.604764938354492 \n",
      "Root Mean Squared Error -- train: 0.37250885367393494, -- test: 0.7872536778450012 \n",
      " \n",
      "#################### Sampling at Epoch 1449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1449\n",
      "Mean Log Likelihood -- train: -5.550692558288574, -- test: -25.915363311767578 \n",
      "Root Mean Squared Error -- train: 0.3724067509174347, -- test: 0.7389047145843506 \n",
      " \n",
      "#################### Sampling at Epoch 1499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1499\n",
      "Mean Log Likelihood -- train: -5.510482311248779, -- test: -27.000713348388672 \n",
      "Root Mean Squared Error -- train: 0.37132543325424194, -- test: 0.7534501552581787 \n",
      " \n",
      "#################### Sampling at Epoch 1549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1549\n",
      "Mean Log Likelihood -- train: -5.487623691558838, -- test: -26.943984985351562 \n",
      "Root Mean Squared Error -- train: 0.3707093298435211, -- test: 0.7526968717575073 \n",
      " \n",
      "#################### Sampling at Epoch 1599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1599\n",
      "Mean Log Likelihood -- train: -5.468087673187256, -- test: -29.566957473754883 \n",
      "Root Mean Squared Error -- train: 0.3701819181442261, -- test: 0.7867732048034668 \n",
      " \n",
      "#################### Sampling at Epoch 1649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1649\n",
      "Mean Log Likelihood -- train: -5.471607685089111, -- test: -31.265077590942383 \n",
      "Root Mean Squared Error -- train: 0.3702770173549652, -- test: 0.8080683350563049 \n",
      " \n",
      "#################### Sampling at Epoch 1699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1699\n",
      "Mean Log Likelihood -- train: -5.428159713745117, -- test: -32.83711242675781 \n",
      "Root Mean Squared Error -- train: 0.36910179257392883, -- test: 0.8272939324378967 \n",
      " \n",
      "#################### Sampling at Epoch 1749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1749\n",
      "Mean Log Likelihood -- train: -5.390157699584961, -- test: -33.23710632324219 \n",
      "Root Mean Squared Error -- train: 0.3680707514286041, -- test: 0.8321147561073303 \n",
      " \n",
      "#################### Sampling at Epoch 1799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1799\n",
      "Mean Log Likelihood -- train: -5.430308818817139, -- test: -34.028106689453125 \n",
      "Root Mean Squared Error -- train: 0.3691600263118744, -- test: 0.8415669798851013 \n",
      " \n",
      "#################### Sampling at Epoch 1849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1849\n",
      "Mean Log Likelihood -- train: -5.345282554626465, -- test: -38.0052604675293 \n",
      "Root Mean Squared Error -- train: 0.36684951186180115, -- test: 0.8875686526298523 \n",
      " \n",
      "#################### Sampling at Epoch 1899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1899\n",
      "Mean Log Likelihood -- train: -5.3504767417907715, -- test: -37.0076789855957 \n",
      "Root Mean Squared Error -- train: 0.3669911026954651, -- test: 0.876257061958313 \n",
      " \n",
      "#################### Sampling at Epoch 1949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1949\n",
      "Mean Log Likelihood -- train: -5.388815879821777, -- test: -32.256038665771484 \n",
      "Root Mean Squared Error -- train: 0.368034303188324, -- test: 0.8202399611473083 \n",
      " \n",
      "#################### Sampling at Epoch 1999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 1999\n",
      "Mean Log Likelihood -- train: -5.359954833984375, -- test: -32.818668365478516 \n",
      "Root Mean Squared Error -- train: 0.3672492504119873, -- test: 0.8270708918571472 \n",
      " \n",
      "#################### Sampling at Epoch 2049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2049\n",
      "Mean Log Likelihood -- train: -5.421599388122559, -- test: -34.04110336303711 \n",
      "Root Mean Squared Error -- train: 0.36892402172088623, -- test: 0.8417214155197144 \n",
      " \n",
      "#################### Sampling at Epoch 2099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2099\n",
      "Mean Log Likelihood -- train: -5.4419941902160645, -- test: -39.65357208251953 \n",
      "Root Mean Squared Error -- train: 0.36947640776634216, -- test: 0.9059494137763977 \n",
      " \n",
      "#################### Sampling at Epoch 2149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2149\n",
      "Mean Log Likelihood -- train: -5.474093914031982, -- test: -41.94189453125 \n",
      "Root Mean Squared Error -- train: 0.3703441917896271, -- test: 0.9308655858039856 \n",
      " \n",
      "#################### Sampling at Epoch 2199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2199\n",
      "Mean Log Likelihood -- train: -5.506065845489502, -- test: -41.223060607910156 \n",
      "Root Mean Squared Error -- train: 0.37120649218559265, -- test: 0.9231111407279968 \n",
      " \n",
      "#################### Sampling at Epoch 2249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2249\n",
      "Mean Log Likelihood -- train: -5.406574726104736, -- test: -40.877471923828125 \n",
      "Root Mean Squared Error -- train: 0.3685165345668793, -- test: 0.9193597435951233 \n",
      " \n",
      "#################### Sampling at Epoch 2299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2299\n",
      "Mean Log Likelihood -- train: -5.385973930358887, -- test: -38.34272384643555 \n",
      "Root Mean Squared Error -- train: 0.36795708537101746, -- test: 0.8913626670837402 \n",
      " \n",
      "#################### Sampling at Epoch 2349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2349\n",
      "Mean Log Likelihood -- train: -5.374114513397217, -- test: -42.499603271484375 \n",
      "Root Mean Squared Error -- train: 0.3676346242427826, -- test: 0.9368376731872559 \n",
      " \n",
      "#################### Sampling at Epoch 2399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2399\n",
      "Mean Log Likelihood -- train: -5.374783992767334, -- test: -36.310874938964844 \n",
      "Root Mean Squared Error -- train: 0.3676528334617615, -- test: 0.868268609046936 \n",
      " \n",
      "#################### Sampling at Epoch 2449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2449\n",
      "Mean Log Likelihood -- train: -5.382800102233887, -- test: -36.25053405761719 \n",
      "Root Mean Squared Error -- train: 0.3678708076477051, -- test: 0.8675733804702759 \n",
      " \n",
      "#################### Sampling at Epoch 2499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2499\n",
      "Mean Log Likelihood -- train: -5.33803129196167, -- test: -36.52613067626953 \n",
      "Root Mean Squared Error -- train: 0.3666518032550812, -- test: 0.8707442283630371 \n",
      " \n",
      "#################### Sampling at Epoch 2549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2549\n",
      "Mean Log Likelihood -- train: -5.38264799118042, -- test: -34.8342170715332 \n",
      "Root Mean Squared Error -- train: 0.3678666651248932, -- test: 0.8510918021202087 \n",
      " \n",
      "#################### Sampling at Epoch 2599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2599\n",
      "Mean Log Likelihood -- train: -5.401246070861816, -- test: -31.608789443969727 \n",
      "Root Mean Squared Error -- train: 0.3683719038963318, -- test: 0.8123106956481934 \n",
      " \n",
      "#################### Sampling at Epoch 2649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2649\n",
      "Mean Log Likelihood -- train: -5.363507270812988, -- test: -33.60481262207031 \n",
      "Root Mean Squared Error -- train: 0.3673459589481354, -- test: 0.8365220427513123 \n",
      " \n",
      "#################### Sampling at Epoch 2699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2699\n",
      "Mean Log Likelihood -- train: -5.333413600921631, -- test: -34.5576057434082 \n",
      "Root Mean Squared Error -- train: 0.3665258586406708, -- test: 0.8478355407714844 \n",
      " \n",
      "#################### Sampling at Epoch 2749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2749\n",
      "Mean Log Likelihood -- train: -5.27252197265625, -- test: -34.52729034423828 \n",
      "Root Mean Squared Error -- train: 0.36486074328422546, -- test: 0.8474778532981873 \n",
      " \n",
      "#################### Sampling at Epoch 2799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2799\n",
      "Mean Log Likelihood -- train: -5.292835712432861, -- test: -32.28097152709961 \n",
      "Root Mean Squared Error -- train: 0.36541709303855896, -- test: 0.8205439448356628 \n",
      " \n",
      "#################### Sampling at Epoch 2849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2849\n",
      "Mean Log Likelihood -- train: -5.34796142578125, -- test: -30.494253158569336 \n",
      "Root Mean Squared Error -- train: 0.3669225573539734, -- test: 0.7984723448753357 \n",
      " \n",
      "#################### Sampling at Epoch 2899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2899\n",
      "Mean Log Likelihood -- train: -5.245513916015625, -- test: -30.225341796875 \n",
      "Root Mean Squared Error -- train: 0.3641197681427002, -- test: 0.7950973510742188 \n",
      " \n",
      "#################### Sampling at Epoch 2949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2949\n",
      "Mean Log Likelihood -- train: -5.277360439300537, -- test: -32.76862335205078 \n",
      "Root Mean Squared Error -- train: 0.3649933636188507, -- test: 0.8264655470848083 \n",
      " \n",
      "#################### Sampling at Epoch 2999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 2999\n",
      "Mean Log Likelihood -- train: -5.290583610534668, -- test: -35.810020446777344 \n",
      "Root Mean Squared Error -- train: 0.3653554618358612, -- test: 0.862480878829956 \n",
      " \n",
      "#################### Sampling at Epoch 3049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3049\n",
      "Mean Log Likelihood -- train: -5.241494655609131, -- test: -35.623722076416016 \n",
      "Root Mean Squared Error -- train: 0.36400938034057617, -- test: 0.8603181838989258 \n",
      " \n",
      "#################### Sampling at Epoch 3099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3099\n",
      "Mean Log Likelihood -- train: -5.267302513122559, -- test: -36.434688568115234 \n",
      "Root Mean Squared Error -- train: 0.36471766233444214, -- test: 0.8696934580802917 \n",
      " \n",
      "#################### Sampling at Epoch 3149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3149\n",
      "Mean Log Likelihood -- train: -5.251461982727051, -- test: -34.781219482421875 \n",
      "Root Mean Squared Error -- train: 0.36428308486938477, -- test: 0.8504689335823059 \n",
      " \n",
      "#################### Sampling at Epoch 3199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3199\n",
      "Mean Log Likelihood -- train: -5.240694999694824, -- test: -33.48085021972656 \n",
      "Root Mean Squared Error -- train: 0.36398741602897644, -- test: 0.8350389003753662 \n",
      " \n",
      "#################### Sampling at Epoch 3249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3249\n",
      "Mean Log Likelihood -- train: -5.2745137214660645, -- test: -30.101133346557617 \n",
      "Root Mean Squared Error -- train: 0.3649153411388397, -- test: 0.7935335636138916 \n",
      " \n",
      "#################### Sampling at Epoch 3299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3299\n",
      "Mean Log Likelihood -- train: -5.315684795379639, -- test: -31.053861618041992 \n",
      "Root Mean Squared Error -- train: 0.3660418391227722, -- test: 0.8054503202438354 \n",
      " \n",
      "#################### Sampling at Epoch 3349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3349\n",
      "Mean Log Likelihood -- train: -5.3213887214660645, -- test: -30.81218910217285 \n",
      "Root Mean Squared Error -- train: 0.3661976456642151, -- test: 0.8024442791938782 \n",
      " \n",
      "#################### Sampling at Epoch 3399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3399\n",
      "Mean Log Likelihood -- train: -5.354588031768799, -- test: -31.345693588256836 \n",
      "Root Mean Squared Error -- train: 0.36710307002067566, -- test: 0.8090653419494629 \n",
      " \n",
      "#################### Sampling at Epoch 3449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3449\n",
      "Mean Log Likelihood -- train: -5.3108344078063965, -- test: -32.05375671386719 \n",
      "Root Mean Squared Error -- train: 0.36590930819511414, -- test: 0.8177701830863953 \n",
      " \n",
      "#################### Sampling at Epoch 3499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3499\n",
      "Mean Log Likelihood -- train: -5.316502094268799, -- test: -31.888832092285156 \n",
      "Root Mean Squared Error -- train: 0.3660641610622406, -- test: 0.8157508373260498 \n",
      " \n",
      "#################### Sampling at Epoch 3549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3549\n",
      "Mean Log Likelihood -- train: -5.287425518035889, -- test: -32.62069320678711 \n",
      "Root Mean Squared Error -- train: 0.3652690052986145, -- test: 0.8246737718582153 \n",
      " \n",
      "#################### Sampling at Epoch 3599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3599\n",
      "Mean Log Likelihood -- train: -5.303720951080322, -- test: -31.916790008544922 \n",
      "Root Mean Squared Error -- train: 0.3657148480415344, -- test: 0.8160935640335083 \n",
      " \n",
      "#################### Sampling at Epoch 3649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3649\n",
      "Mean Log Likelihood -- train: -5.323221206665039, -- test: -31.372146606445312 \n",
      "Root Mean Squared Error -- train: 0.36624765396118164, -- test: 0.8093922734260559 \n",
      " \n",
      "#################### Sampling at Epoch 3699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3699\n",
      "Mean Log Likelihood -- train: -5.286474704742432, -- test: -32.161842346191406 \n",
      "Root Mean Squared Error -- train: 0.36524295806884766, -- test: 0.8190907835960388 \n",
      " \n",
      "#################### Sampling at Epoch 3749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3749\n",
      "Mean Log Likelihood -- train: -5.371784687042236, -- test: -30.701929092407227 \n",
      "Root Mean Squared Error -- train: 0.36757123470306396, -- test: 0.8010690212249756 \n",
      " \n",
      "#################### Sampling at Epoch 3799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3799\n",
      "Mean Log Likelihood -- train: -5.364336013793945, -- test: -28.28553009033203 \n",
      "Root Mean Squared Error -- train: 0.36736851930618286, -- test: 0.7703139185905457 \n",
      " \n",
      "#################### Sampling at Epoch 3849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3849\n",
      "Mean Log Likelihood -- train: -5.309560775756836, -- test: -25.472190856933594 \n",
      "Root Mean Squared Error -- train: 0.3658744990825653, -- test: 0.7328824400901794 \n",
      " \n",
      "#################### Sampling at Epoch 3899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3899\n",
      "Mean Log Likelihood -- train: -5.3106279373168945, -- test: -29.710420608520508 \n",
      "Root Mean Squared Error -- train: 0.3659036457538605, -- test: 0.7885945439338684 \n",
      " \n",
      "#################### Sampling at Epoch 3949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3949\n",
      "Mean Log Likelihood -- train: -5.292167663574219, -- test: -28.983888626098633 \n",
      "Root Mean Squared Error -- train: 0.3653987944126129, -- test: 0.7793270945549011 \n",
      " \n",
      "#################### Sampling at Epoch 3999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 3999\n",
      "Mean Log Likelihood -- train: -5.282808303833008, -- test: -26.796823501586914 \n",
      "Root Mean Squared Error -- train: 0.3651425540447235, -- test: 0.7507392168045044 \n",
      " \n",
      "#################### Sampling at Epoch 4049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4049\n",
      "Mean Log Likelihood -- train: -5.298939228057861, -- test: -28.768293380737305 \n",
      "Root Mean Squared Error -- train: 0.36558404564857483, -- test: 0.7765557169914246 \n",
      " \n",
      "#################### Sampling at Epoch 4099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4099\n",
      "Mean Log Likelihood -- train: -5.340989112854004, -- test: -26.822059631347656 \n",
      "Root Mean Squared Error -- train: 0.3667324483394623, -- test: 0.7510753273963928 \n",
      " \n",
      "#################### Sampling at Epoch 4149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4149\n",
      "Mean Log Likelihood -- train: -5.300074100494385, -- test: -26.078685760498047 \n",
      "Root Mean Squared Error -- train: 0.3656150996685028, -- test: 0.741111695766449 \n",
      " \n",
      "#################### Sampling at Epoch 4199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4199\n",
      "Mean Log Likelihood -- train: -5.290764808654785, -- test: -29.9124698638916 \n",
      "Root Mean Squared Error -- train: 0.36536040902137756, -- test: 0.7911525368690491 \n",
      " \n",
      "#################### Sampling at Epoch 4249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4249\n",
      "Mean Log Likelihood -- train: -5.37151575088501, -- test: -32.00095748901367 \n",
      "Root Mean Squared Error -- train: 0.367563933134079, -- test: 0.8171243071556091 \n",
      " \n",
      "#################### Sampling at Epoch 4299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4299\n",
      "Mean Log Likelihood -- train: -5.312124729156494, -- test: -32.899078369140625 \n",
      "Root Mean Squared Error -- train: 0.3659445643424988, -- test: 0.8280425667762756 \n",
      " \n",
      "#################### Sampling at Epoch 4349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4349\n",
      "Mean Log Likelihood -- train: -5.419411659240723, -- test: -31.68488311767578 \n",
      "Root Mean Squared Error -- train: 0.36886468529701233, -- test: 0.8132469058036804 \n",
      " \n",
      "#################### Sampling at Epoch 4399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4399\n",
      "Mean Log Likelihood -- train: -5.344075679779053, -- test: -30.68732452392578 \n",
      "Root Mean Squared Error -- train: 0.3668166399002075, -- test: 0.8008865714073181 \n",
      " \n",
      "#################### Sampling at Epoch 4449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4449\n",
      "Mean Log Likelihood -- train: -5.346794605255127, -- test: -29.138755798339844 \n",
      "Root Mean Squared Error -- train: 0.3668907582759857, -- test: 0.7813116908073425 \n",
      " \n",
      "#################### Sampling at Epoch 4499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4499\n",
      "Mean Log Likelihood -- train: -5.328698635101318, -- test: -34.076820373535156 \n",
      "Root Mean Squared Error -- train: 0.3663972020149231, -- test: 0.8421456813812256 \n",
      " \n",
      "#################### Sampling at Epoch 4549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4549\n",
      "Mean Log Likelihood -- train: -5.414482593536377, -- test: -30.94430160522461 \n",
      "Root Mean Squared Error -- train: 0.3687310218811035, -- test: 0.8040889501571655 \n",
      " \n",
      "#################### Sampling at Epoch 4599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4599\n",
      "Mean Log Likelihood -- train: -5.3126044273376465, -- test: -35.91472625732422 \n",
      "Root Mean Squared Error -- train: 0.36595767736434937, -- test: 0.8636941313743591 \n",
      " \n",
      "#################### Sampling at Epoch 4649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4649\n",
      "Mean Log Likelihood -- train: -5.378193378448486, -- test: -33.610748291015625 \n",
      "Root Mean Squared Error -- train: 0.3677455484867096, -- test: 0.8365930318832397 \n",
      " \n",
      "#################### Sampling at Epoch 4699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4699\n",
      "Mean Log Likelihood -- train: -5.310195446014404, -- test: -32.8048095703125 \n",
      "Root Mean Squared Error -- train: 0.36589181423187256, -- test: 0.8269033432006836 \n",
      " \n",
      "#################### Sampling at Epoch 4749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4749\n",
      "Mean Log Likelihood -- train: -5.33577823638916, -- test: -31.84418487548828 \n",
      "Root Mean Squared Error -- train: 0.36659035086631775, -- test: 0.8152033686637878 \n",
      " \n",
      "#################### Sampling at Epoch 4799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4799\n",
      "Mean Log Likelihood -- train: -5.307551383972168, -- test: -32.028682708740234 \n",
      "Root Mean Squared Error -- train: 0.3658195436000824, -- test: 0.8174635171890259 \n",
      " \n",
      "#################### Sampling at Epoch 4849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4849\n",
      "Mean Log Likelihood -- train: -5.315300941467285, -- test: -32.347877502441406 \n",
      "Root Mean Squared Error -- train: 0.36603131890296936, -- test: 0.821358859539032 \n",
      " \n",
      "#################### Sampling at Epoch 4899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4899\n",
      "Mean Log Likelihood -- train: -5.321194648742676, -- test: -28.878154754638672 \n",
      "Root Mean Squared Error -- train: 0.3661923110485077, -- test: 0.7779691219329834 \n",
      " \n",
      "#################### Sampling at Epoch 4949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4949\n",
      "Mean Log Likelihood -- train: -5.299983024597168, -- test: -28.64940643310547 \n",
      "Root Mean Squared Error -- train: 0.365612655878067, -- test: 0.7750232815742493 \n",
      " \n",
      "#################### Sampling at Epoch 4999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 4999\n",
      "Mean Log Likelihood -- train: -5.3141655921936035, -- test: -30.627225875854492 \n",
      "Root Mean Squared Error -- train: 0.36600032448768616, -- test: 0.8001358509063721 \n",
      " \n",
      "#################### Sampling at Epoch 5049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5049\n",
      "Mean Log Likelihood -- train: -5.315169811248779, -- test: -32.79426193237305 \n",
      "Root Mean Squared Error -- train: 0.3660277724266052, -- test: 0.8267757296562195 \n",
      " \n",
      "#################### Sampling at Epoch 5099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5099\n",
      "Mean Log Likelihood -- train: -5.342244625091553, -- test: -32.84535598754883 \n",
      "Root Mean Squared Error -- train: 0.36676672101020813, -- test: 0.8273935317993164 \n",
      " \n",
      "#################### Sampling at Epoch 5149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5149\n",
      "Mean Log Likelihood -- train: -5.315061569213867, -- test: -32.40426254272461 \n",
      "Root Mean Squared Error -- train: 0.36602482199668884, -- test: 0.8220451474189758 \n",
      " \n",
      "#################### Sampling at Epoch 5199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5199\n",
      "Mean Log Likelihood -- train: -5.346390724182129, -- test: -31.391759872436523 \n",
      "Root Mean Squared Error -- train: 0.36687973141670227, -- test: 0.8096345663070679 \n",
      " \n",
      "#################### Sampling at Epoch 5249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5249\n",
      "Mean Log Likelihood -- train: -5.319718360900879, -- test: -31.617448806762695 \n",
      "Root Mean Squared Error -- train: 0.3661520183086395, -- test: 0.8124173283576965 \n",
      " \n",
      "#################### Sampling at Epoch 5299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5299\n",
      "Mean Log Likelihood -- train: -5.415589809417725, -- test: -31.444093704223633 \n",
      "Root Mean Squared Error -- train: 0.3687610626220703, -- test: 0.8102806806564331 \n",
      " \n",
      "#################### Sampling at Epoch 5349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5349\n",
      "Mean Log Likelihood -- train: -5.3840861320495605, -- test: -32.62178039550781 \n",
      "Root Mean Squared Error -- train: 0.36790576577186584, -- test: 0.8246870040893555 \n",
      " \n",
      "#################### Sampling at Epoch 5399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5399\n",
      "Mean Log Likelihood -- train: -5.408854961395264, -- test: -31.7482967376709 \n",
      "Root Mean Squared Error -- train: 0.36857837438583374, -- test: 0.8140262961387634 \n",
      " \n",
      "#################### Sampling at Epoch 5449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5449\n",
      "Mean Log Likelihood -- train: -5.3502020835876465, -- test: -29.880603790283203 \n",
      "Root Mean Squared Error -- train: 0.3669835925102234, -- test: 0.7907496094703674 \n",
      " \n",
      "#################### Sampling at Epoch 5499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5499\n",
      "Mean Log Likelihood -- train: -5.381384372711182, -- test: -31.302719116210938 \n",
      "Root Mean Squared Error -- train: 0.36783233284950256, -- test: 0.8085340261459351 \n",
      " \n",
      "#################### Sampling at Epoch 5549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5549\n",
      "Mean Log Likelihood -- train: -5.418244361877441, -- test: -33.884647369384766 \n",
      "Root Mean Squared Error -- train: 0.3688330352306366, -- test: 0.8398606181144714 \n",
      " \n",
      "#################### Sampling at Epoch 5599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5599\n",
      "Mean Log Likelihood -- train: -5.486691474914551, -- test: -34.249412536621094 \n",
      "Root Mean Squared Error -- train: 0.3706841468811035, -- test: 0.844192624092102 \n",
      " \n",
      "#################### Sampling at Epoch 5649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5649\n",
      "Mean Log Likelihood -- train: -5.399065017700195, -- test: -34.29795455932617 \n",
      "Root Mean Squared Error -- train: 0.36831265687942505, -- test: 0.8447673916816711 \n",
      " \n",
      "#################### Sampling at Epoch 5699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5699\n",
      "Mean Log Likelihood -- train: -5.342560768127441, -- test: -31.001934051513672 \n",
      "Root Mean Squared Error -- train: 0.3667753040790558, -- test: 0.804805338382721 \n",
      " \n",
      "#################### Sampling at Epoch 5749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5749\n",
      "Mean Log Likelihood -- train: -5.393829345703125, -- test: -34.72559356689453 \n",
      "Root Mean Squared Error -- train: 0.36817049980163574, -- test: 0.8498145937919617 \n",
      " \n",
      "#################### Sampling at Epoch 5799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5799\n",
      "Mean Log Likelihood -- train: -5.312636375427246, -- test: -32.840816497802734 \n",
      "Root Mean Squared Error -- train: 0.3659585416316986, -- test: 0.8273386359214783 \n",
      " \n",
      "#################### Sampling at Epoch 5849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5849\n",
      "Mean Log Likelihood -- train: -5.325199604034424, -- test: -32.27906799316406 \n",
      "Root Mean Squared Error -- train: 0.36630168557167053, -- test: 0.8205207586288452 \n",
      " \n",
      "#################### Sampling at Epoch 5899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5899\n",
      "Mean Log Likelihood -- train: -5.373039245605469, -- test: -35.25239562988281 \n",
      "Root Mean Squared Error -- train: 0.3676053583621979, -- test: 0.8559911251068115 \n",
      " \n",
      "#################### Sampling at Epoch 5949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5949\n",
      "Mean Log Likelihood -- train: -5.374110698699951, -- test: -34.440738677978516 \n",
      "Root Mean Squared Error -- train: 0.36763453483581543, -- test: 0.846455991268158 \n",
      " \n",
      "#################### Sampling at Epoch 5999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 5999\n",
      "Mean Log Likelihood -- train: -5.42584228515625, -- test: -35.248146057128906 \n",
      "Root Mean Squared Error -- train: 0.36903899908065796, -- test: 0.8559414744377136 \n",
      " \n",
      "#################### Sampling at Epoch 6049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6049\n",
      "Mean Log Likelihood -- train: -5.440079689025879, -- test: -39.899131774902344 \n",
      "Root Mean Squared Error -- train: 0.36942461133003235, -- test: 0.9086558818817139 \n",
      " \n",
      "#################### Sampling at Epoch 6099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6099\n",
      "Mean Log Likelihood -- train: -5.451467990875244, -- test: -39.861671447753906 \n",
      "Root Mean Squared Error -- train: 0.36973270773887634, -- test: 0.9082435965538025 \n",
      " \n",
      "#################### Sampling at Epoch 6149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6149\n",
      "Mean Log Likelihood -- train: -5.373895168304443, -- test: -35.313724517822266 \n",
      "Root Mean Squared Error -- train: 0.36762869358062744, -- test: 0.8567073345184326 \n",
      " \n",
      "#################### Sampling at Epoch 6199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6199\n",
      "Mean Log Likelihood -- train: -5.388266563415527, -- test: -32.68473434448242 \n",
      "Root Mean Squared Error -- train: 0.36801934242248535, -- test: 0.8254499435424805 \n",
      " \n",
      "#################### Sampling at Epoch 6249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6249\n",
      "Mean Log Likelihood -- train: -5.350636959075928, -- test: -34.795257568359375 \n",
      "Root Mean Squared Error -- train: 0.3669954836368561, -- test: 0.8506339192390442 \n",
      " \n",
      "#################### Sampling at Epoch 6299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6299\n",
      "Mean Log Likelihood -- train: -5.4022345542907715, -- test: -32.77910232543945 \n",
      "Root Mean Squared Error -- train: 0.3683987259864807, -- test: 0.8265923857688904 \n",
      " \n",
      "#################### Sampling at Epoch 6349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6349\n",
      "Mean Log Likelihood -- train: -5.394840717315674, -- test: -32.4873046875 \n",
      "Root Mean Squared Error -- train: 0.3681979477405548, -- test: 0.8230547308921814 \n",
      " \n",
      "#################### Sampling at Epoch 6399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6399\n",
      "Mean Log Likelihood -- train: -5.428460597991943, -- test: -30.26531219482422 \n",
      "Root Mean Squared Error -- train: 0.3691099286079407, -- test: 0.7955998778343201 \n",
      " \n",
      "#################### Sampling at Epoch 6449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6449\n",
      "Mean Log Likelihood -- train: -5.371069431304932, -- test: -29.209548950195312 \n",
      "Root Mean Squared Error -- train: 0.3675517737865448, -- test: 0.782217264175415 \n",
      " \n",
      "#################### Sampling at Epoch 6499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6499\n",
      "Mean Log Likelihood -- train: -5.344980716705322, -- test: -29.103178024291992 \n",
      "Root Mean Squared Error -- train: 0.36684131622314453, -- test: 0.7808562517166138 \n",
      " \n",
      "#################### Sampling at Epoch 6549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6549\n",
      "Mean Log Likelihood -- train: -5.306475639343262, -- test: -28.624095916748047 \n",
      "Root Mean Squared Error -- train: 0.36579015851020813, -- test: 0.7746966481208801 \n",
      " \n",
      "#################### Sampling at Epoch 6599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6599\n",
      "Mean Log Likelihood -- train: -5.377974033355713, -- test: -25.2159366607666 \n",
      "Root Mean Squared Error -- train: 0.36773958802223206, -- test: 0.7293776273727417 \n",
      " \n",
      "#################### Sampling at Epoch 6649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6649\n",
      "Mean Log Likelihood -- train: -5.311947822570801, -- test: -25.525531768798828 \n",
      "Root Mean Squared Error -- train: 0.3659397065639496, -- test: 0.7336099743843079 \n",
      " \n",
      "#################### Sampling at Epoch 6699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6699\n",
      "Mean Log Likelihood -- train: -5.342244625091553, -- test: -26.66122055053711 \n",
      "Root Mean Squared Error -- train: 0.36676672101020813, -- test: 0.748930811882019 \n",
      " \n",
      "#################### Sampling at Epoch 6749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6749\n",
      "Mean Log Likelihood -- train: -5.382808208465576, -- test: -30.067367553710938 \n",
      "Root Mean Squared Error -- train: 0.3678710162639618, -- test: 0.7931079864501953 \n",
      " \n",
      "#################### Sampling at Epoch 6799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6799\n",
      "Mean Log Likelihood -- train: -5.3069305419921875, -- test: -28.86831283569336 \n",
      "Root Mean Squared Error -- train: 0.3658025860786438, -- test: 0.7778427004814148 \n",
      " \n",
      "#################### Sampling at Epoch 6849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6849\n",
      "Mean Log Likelihood -- train: -5.337418556213379, -- test: -28.047351837158203 \n",
      "Root Mean Squared Error -- train: 0.36663511395454407, -- test: 0.7672157287597656 \n",
      " \n",
      "#################### Sampling at Epoch 6899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6899\n",
      "Mean Log Likelihood -- train: -5.288958549499512, -- test: -29.408124923706055 \n",
      "Root Mean Squared Error -- train: 0.3653109669685364, -- test: 0.784751832485199 \n",
      " \n",
      "#################### Sampling at Epoch 6949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6949\n",
      "Mean Log Likelihood -- train: -5.372985363006592, -- test: -28.542766571044922 \n",
      "Root Mean Squared Error -- train: 0.3676038980484009, -- test: 0.7736459970474243 \n",
      " \n",
      "#################### Sampling at Epoch 6999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 6999\n",
      "Mean Log Likelihood -- train: -5.330206871032715, -- test: -28.561891555786133 \n",
      "Root Mean Squared Error -- train: 0.3664383590221405, -- test: 0.7738932967185974 \n",
      " \n",
      "#################### Sampling at Epoch 7049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7049\n",
      "Mean Log Likelihood -- train: -5.398172855377197, -- test: -30.431726455688477 \n",
      "Root Mean Squared Error -- train: 0.36828845739364624, -- test: 0.7976888418197632 \n",
      " \n",
      "#################### Sampling at Epoch 7099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7099\n",
      "Mean Log Likelihood -- train: -5.364527225494385, -- test: -32.303016662597656 \n",
      "Root Mean Squared Error -- train: 0.3673737645149231, -- test: 0.8208125829696655 \n",
      " \n",
      "#################### Sampling at Epoch 7149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7149\n",
      "Mean Log Likelihood -- train: -5.360517501831055, -- test: -34.526832580566406 \n",
      "Root Mean Squared Error -- train: 0.3672645688056946, -- test: 0.8474724292755127 \n",
      " \n",
      "#################### Sampling at Epoch 7199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7199\n",
      "Mean Log Likelihood -- train: -5.341434955596924, -- test: -32.310264587402344 \n",
      "Root Mean Squared Error -- train: 0.36674463748931885, -- test: 0.8209008574485779 \n",
      " \n",
      "#################### Sampling at Epoch 7249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7249\n",
      "Mean Log Likelihood -- train: -5.327239036560059, -- test: -28.84573745727539 \n",
      "Root Mean Squared Error -- train: 0.36635738611221313, -- test: 0.7775523066520691 \n",
      " \n",
      "#################### Sampling at Epoch 7299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7299\n",
      "Mean Log Likelihood -- train: -5.33512544631958, -- test: -27.228540420532227 \n",
      "Root Mean Squared Error -- train: 0.3665725290775299, -- test: 0.756467878818512 \n",
      " \n",
      "#################### Sampling at Epoch 7349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7349\n",
      "Mean Log Likelihood -- train: -5.331638813018799, -- test: -27.753244400024414 \n",
      "Root Mean Squared Error -- train: 0.36647742986679077, -- test: 0.7633726596832275 \n",
      " \n",
      "#################### Sampling at Epoch 7399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7399\n",
      "Mean Log Likelihood -- train: -5.325138568878174, -- test: -27.687179565429688 \n",
      "Root Mean Squared Error -- train: 0.3663000166416168, -- test: 0.7625067234039307 \n",
      " \n",
      "#################### Sampling at Epoch 7449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7449\n",
      "Mean Log Likelihood -- train: -5.34019660949707, -- test: -27.137365341186523 \n",
      "Root Mean Squared Error -- train: 0.3667108714580536, -- test: 0.7552616596221924 \n",
      " \n",
      "#################### Sampling at Epoch 7499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7499\n",
      "Mean Log Likelihood -- train: -5.3480753898620605, -- test: -26.704011917114258 \n",
      "Root Mean Squared Error -- train: 0.3669256567955017, -- test: 0.7495019435882568 \n",
      " \n",
      "#################### Sampling at Epoch 7549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7549\n",
      "Mean Log Likelihood -- train: -5.3233513832092285, -- test: -29.557701110839844 \n",
      "Root Mean Squared Error -- train: 0.36625123023986816, -- test: 0.7866555452346802 \n",
      " \n",
      "#################### Sampling at Epoch 7599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7599\n",
      "Mean Log Likelihood -- train: -5.3350510597229, -- test: -31.074722290039062 \n",
      "Root Mean Squared Error -- train: 0.36657053232192993, -- test: 0.8057091236114502 \n",
      " \n",
      "#################### Sampling at Epoch 7649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7649\n",
      "Mean Log Likelihood -- train: -5.40117073059082, -- test: -29.171785354614258 \n",
      "Root Mean Squared Error -- train: 0.36836984753608704, -- test: 0.7817343473434448 \n",
      " \n",
      "#################### Sampling at Epoch 7699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7699\n",
      "Mean Log Likelihood -- train: -5.344049453735352, -- test: -28.341533660888672 \n",
      "Root Mean Squared Error -- train: 0.3668158948421478, -- test: 0.7710406184196472 \n",
      " \n",
      "#################### Sampling at Epoch 7749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7749\n",
      "Mean Log Likelihood -- train: -5.290890216827393, -- test: -26.11014175415039 \n",
      "Root Mean Squared Error -- train: 0.36536383628845215, -- test: 0.7415360808372498 \n",
      " \n",
      "#################### Sampling at Epoch 7799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7799\n",
      "Mean Log Likelihood -- train: -5.285688877105713, -- test: -28.913890838623047 \n",
      "Root Mean Squared Error -- train: 0.36522141098976135, -- test: 0.7784283757209778 \n",
      " \n",
      "#################### Sampling at Epoch 7849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7849\n",
      "Mean Log Likelihood -- train: -5.3654937744140625, -- test: -28.840648651123047 \n",
      "Root Mean Squared Error -- train: 0.36740005016326904, -- test: 0.7774868607521057 \n",
      " \n",
      "#################### Sampling at Epoch 7899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7899\n",
      "Mean Log Likelihood -- train: -5.323127269744873, -- test: -28.664579391479492 \n",
      "Root Mean Squared Error -- train: 0.3662450909614563, -- test: 0.7752190232276917 \n",
      " \n",
      "#################### Sampling at Epoch 7949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7949\n",
      "Mean Log Likelihood -- train: -5.319159984588623, -- test: -26.100053787231445 \n",
      "Root Mean Squared Error -- train: 0.366136759519577, -- test: 0.7414000034332275 \n",
      " \n",
      "#################### Sampling at Epoch 7999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 7999\n",
      "Mean Log Likelihood -- train: -5.2573933601379395, -- test: -24.300600051879883 \n",
      "Root Mean Squared Error -- train: 0.36444586515426636, -- test: 0.7167181968688965 \n",
      " \n",
      "#################### Sampling at Epoch 8049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8049\n",
      "Mean Log Likelihood -- train: -5.260601997375488, -- test: -24.164836883544922 \n",
      "Root Mean Squared Error -- train: 0.3645339012145996, -- test: 0.7148213982582092 \n",
      " \n",
      "#################### Sampling at Epoch 8099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8099\n",
      "Mean Log Likelihood -- train: -5.21977424621582, -- test: -22.99786949157715 \n",
      "Root Mean Squared Error -- train: 0.36341220140457153, -- test: 0.6983053088188171 \n",
      " \n",
      "#################### Sampling at Epoch 8149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8149\n",
      "Mean Log Likelihood -- train: -5.312922954559326, -- test: -23.8117618560791 \n",
      "Root Mean Squared Error -- train: 0.3659663796424866, -- test: 0.7098648548126221 \n",
      " \n",
      "#################### Sampling at Epoch 8199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8199\n",
      "Mean Log Likelihood -- train: -5.323181629180908, -- test: -24.692485809326172 \n",
      "Root Mean Squared Error -- train: 0.36624661087989807, -- test: 0.7221652269363403 \n",
      " \n",
      "#################### Sampling at Epoch 8249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8249\n",
      "Mean Log Likelihood -- train: -5.303558826446533, -- test: -20.3895263671875 \n",
      "Root Mean Squared Error -- train: 0.36571040749549866, -- test: 0.6598965525627136 \n",
      " \n",
      "#################### Sampling at Epoch 8299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8299\n",
      "Mean Log Likelihood -- train: -5.3394694328308105, -- test: -19.350847244262695 \n",
      "Root Mean Squared Error -- train: 0.36669105291366577, -- test: 0.6439641714096069 \n",
      " \n",
      "#################### Sampling at Epoch 8349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8349\n",
      "Mean Log Likelihood -- train: -5.323799133300781, -- test: -21.621360778808594 \n",
      "Root Mean Squared Error -- train: 0.3662634491920471, -- test: 0.6783068180084229 \n",
      " \n",
      "#################### Sampling at Epoch 8399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8399\n",
      "Mean Log Likelihood -- train: -5.291070461273193, -- test: -19.631393432617188 \n",
      "Root Mean Squared Error -- train: 0.3653687536716461, -- test: 0.648306131362915 \n",
      " \n",
      "#################### Sampling at Epoch 8449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8449\n",
      "Mean Log Likelihood -- train: -5.274592876434326, -- test: -19.559585571289062 \n",
      "Root Mean Squared Error -- train: 0.36491748690605164, -- test: 0.6471975445747375 \n",
      " \n",
      "#################### Sampling at Epoch 8499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8499\n",
      "Mean Log Likelihood -- train: -5.298285007476807, -- test: -20.134857177734375 \n",
      "Root Mean Squared Error -- train: 0.3655661642551422, -- test: 0.6560259461402893 \n",
      " \n",
      "#################### Sampling at Epoch 8549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8549\n",
      "Mean Log Likelihood -- train: -5.323347091674805, -- test: -20.8538875579834 \n",
      "Root Mean Squared Error -- train: 0.3662511110305786, -- test: 0.6668962836265564 \n",
      " \n",
      "#################### Sampling at Epoch 8599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8599\n",
      "Mean Log Likelihood -- train: -5.323421955108643, -- test: -15.9757080078125 \n",
      "Root Mean Squared Error -- train: 0.366253137588501, -- test: 0.5892258286476135 \n",
      " \n",
      "#################### Sampling at Epoch 8649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8649\n",
      "Mean Log Likelihood -- train: -5.31180477142334, -- test: -18.434621810913086 \n",
      "Root Mean Squared Error -- train: 0.3659358322620392, -- test: 0.6295755505561829 \n",
      " \n",
      "#################### Sampling at Epoch 8699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8699\n",
      "Mean Log Likelihood -- train: -5.268139839172363, -- test: -18.740476608276367 \n",
      "Root Mean Squared Error -- train: 0.36474061012268066, -- test: 0.6344150304794312 \n",
      " \n",
      "#################### Sampling at Epoch 8749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8749\n",
      "Mean Log Likelihood -- train: -5.293947219848633, -- test: -18.192455291748047 \n",
      "Root Mean Squared Error -- train: 0.3654474914073944, -- test: 0.6257172226905823 \n",
      " \n",
      "#################### Sampling at Epoch 8799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8799\n",
      "Mean Log Likelihood -- train: -5.276197910308838, -- test: -17.759201049804688 \n",
      "Root Mean Squared Error -- train: 0.3649614751338959, -- test: 0.6187543272972107 \n",
      " \n",
      "#################### Sampling at Epoch 8849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8849\n",
      "Mean Log Likelihood -- train: -5.28729772567749, -- test: -15.308259010314941 \n",
      "Root Mean Squared Error -- train: 0.36526548862457275, -- test: 0.5777872204780579 \n",
      " \n",
      "#################### Sampling at Epoch 8899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8899\n",
      "Mean Log Likelihood -- train: -5.328458309173584, -- test: -16.89619255065918 \n",
      "Root Mean Squared Error -- train: 0.3663906455039978, -- test: 0.6046459674835205 \n",
      " \n",
      "#################### Sampling at Epoch 8949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8949\n",
      "Mean Log Likelihood -- train: -5.255153179168701, -- test: -14.7144775390625 \n",
      "Root Mean Squared Error -- train: 0.36438441276550293, -- test: 0.567417323589325 \n",
      " \n",
      "#################### Sampling at Epoch 8999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 8999\n",
      "Mean Log Likelihood -- train: -5.234746932983398, -- test: -12.80569839477539 \n",
      "Root Mean Squared Error -- train: 0.36382395029067993, -- test: 0.5327165126800537 \n",
      " \n",
      "#################### Sampling at Epoch 9049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9049\n",
      "Mean Log Likelihood -- train: -5.221405029296875, -- test: -11.261434555053711 \n",
      "Root Mean Squared Error -- train: 0.363457053899765, -- test: 0.5028932094573975 \n",
      " \n",
      "#################### Sampling at Epoch 9099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9099\n",
      "Mean Log Likelihood -- train: -5.207826614379883, -- test: -9.437381744384766 \n",
      "Root Mean Squared Error -- train: 0.36308327317237854, -- test: 0.4652102589607239 \n",
      " \n",
      "#################### Sampling at Epoch 9149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9149\n",
      "Mean Log Likelihood -- train: -5.247446537017822, -- test: -8.72940444946289 \n",
      "Root Mean Squared Error -- train: 0.3641728460788727, -- test: 0.4497343897819519 \n",
      " \n",
      "#################### Sampling at Epoch 9199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9199\n",
      "Mean Log Likelihood -- train: -5.272101402282715, -- test: -11.05813217163086 \n",
      "Root Mean Squared Error -- train: 0.3648492395877838, -- test: 0.4988342225551605 \n",
      " \n",
      "#################### Sampling at Epoch 9249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9249\n",
      "Mean Log Likelihood -- train: -5.31056547164917, -- test: -8.830954551696777 \n",
      "Root Mean Squared Error -- train: 0.36590197682380676, -- test: 0.45198675990104675 \n",
      " \n",
      "#################### Sampling at Epoch 9299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9299\n",
      "Mean Log Likelihood -- train: -5.208876609802246, -- test: -8.653231620788574 \n",
      "Root Mean Squared Error -- train: 0.3631121814250946, -- test: 0.44803744554519653 \n",
      " \n",
      "#################### Sampling at Epoch 9349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9349\n",
      "Mean Log Likelihood -- train: -5.256722927093506, -- test: -8.556650161743164 \n",
      "Root Mean Squared Error -- train: 0.36442747712135315, -- test: 0.4458765685558319 \n",
      " \n",
      "#################### Sampling at Epoch 9399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9399\n",
      "Mean Log Likelihood -- train: -5.27016019821167, -- test: -7.200502872467041 \n",
      "Root Mean Squared Error -- train: 0.3647960424423218, -- test: 0.4143464267253876 \n",
      " \n",
      "#################### Sampling at Epoch 9449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9449\n",
      "Mean Log Likelihood -- train: -5.205570697784424, -- test: -8.50836181640625 \n",
      "Root Mean Squared Error -- train: 0.3630211055278778, -- test: 0.444792240858078 \n",
      " \n",
      "#################### Sampling at Epoch 9499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9499\n",
      "Mean Log Likelihood -- train: -5.292322158813477, -- test: -9.981062889099121 \n",
      "Root Mean Squared Error -- train: 0.36540302634239197, -- test: 0.476753830909729 \n",
      " \n",
      "#################### Sampling at Epoch 9549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9549\n",
      "Mean Log Likelihood -- train: -5.268462181091309, -- test: -9.564855575561523 \n",
      "Root Mean Squared Error -- train: 0.3647494912147522, -- test: 0.46794232726097107 \n",
      " \n",
      "#################### Sampling at Epoch 9599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9599\n",
      "Mean Log Likelihood -- train: -5.2995781898498535, -- test: -10.5172700881958 \n",
      "Root Mean Squared Error -- train: 0.3656015694141388, -- test: 0.4878712296485901 \n",
      " \n",
      "#################### Sampling at Epoch 9649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9649\n",
      "Mean Log Likelihood -- train: -5.259554386138916, -- test: -14.34449577331543 \n",
      "Root Mean Squared Error -- train: 0.3645051419734955, -- test: 0.5608590245246887 \n",
      " \n",
      "#################### Sampling at Epoch 9699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9699\n",
      "Mean Log Likelihood -- train: -5.360403537750244, -- test: -12.666608810424805 \n",
      "Root Mean Squared Error -- train: 0.36726149916648865, -- test: 0.530099093914032 \n",
      " \n",
      "#################### Sampling at Epoch 9749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9749\n",
      "Mean Log Likelihood -- train: -5.318178653717041, -- test: -10.51009750366211 \n",
      "Root Mean Squared Error -- train: 0.3661099672317505, -- test: 0.4877241551876068 \n",
      " \n",
      "#################### Sampling at Epoch 9799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9799\n",
      "Mean Log Likelihood -- train: -5.334244728088379, -- test: -8.807064056396484 \n",
      "Root Mean Squared Error -- train: 0.3665485382080078, -- test: 0.4514578580856323 \n",
      " \n",
      "#################### Sampling at Epoch 9849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9849\n",
      "Mean Log Likelihood -- train: -5.2495527267456055, -- test: -9.435171127319336 \n",
      "Root Mean Squared Error -- train: 0.3642306625843048, -- test: 0.4651627242565155 \n",
      " \n",
      "#################### Sampling at Epoch 9899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9899\n",
      "Mean Log Likelihood -- train: -5.273523330688477, -- test: -10.43282699584961 \n",
      "Root Mean Squared Error -- train: 0.36488819122314453, -- test: 0.4861373007297516 \n",
      " \n",
      "#################### Sampling at Epoch 9949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9949\n",
      "Mean Log Likelihood -- train: -5.247430324554443, -- test: -11.98185920715332 \n",
      "Root Mean Squared Error -- train: 0.36417239904403687, -- test: 0.5170204043388367 \n",
      " \n",
      "#################### Sampling at Epoch 9999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 9999\n",
      "Mean Log Likelihood -- train: -5.2591753005981445, -- test: -11.866623878479004 \n",
      "Root Mean Squared Error -- train: 0.36449477076530457, -- test: 0.5147867798805237 \n",
      " \n",
      "#################### Sampling at Epoch 10049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10049\n",
      "Mean Log Likelihood -- train: -5.230947494506836, -- test: -13.198426246643066 \n",
      "Root Mean Squared Error -- train: 0.36371949315071106, -- test: 0.5400384068489075 \n",
      " \n",
      "#################### Sampling at Epoch 10099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10099\n",
      "Mean Log Likelihood -- train: -5.299288749694824, -- test: -13.16183090209961 \n",
      "Root Mean Squared Error -- train: 0.36559364199638367, -- test: 0.5393603444099426 \n",
      " \n",
      "#################### Sampling at Epoch 10149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10149\n",
      "Mean Log Likelihood -- train: -5.253340721130371, -- test: -13.030001640319824 \n",
      "Root Mean Squared Error -- train: 0.3643346428871155, -- test: 0.5369105339050293 \n",
      " \n",
      "#################### Sampling at Epoch 10199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10199\n",
      "Mean Log Likelihood -- train: -5.241446018218994, -- test: -12.269082069396973 \n",
      "Root Mean Squared Error -- train: 0.3640080392360687, -- test: 0.5225462317466736 \n",
      " \n",
      "#################### Sampling at Epoch 10249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10249\n",
      "Mean Log Likelihood -- train: -5.2308220863342285, -- test: -13.264230728149414 \n",
      "Root Mean Squared Error -- train: 0.3637160658836365, -- test: 0.541255533695221 \n",
      " \n",
      "#################### Sampling at Epoch 10299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10299\n",
      "Mean Log Likelihood -- train: -5.329977512359619, -- test: -13.030200004577637 \n",
      "Root Mean Squared Error -- train: 0.3664321005344391, -- test: 0.5369142889976501 \n",
      " \n",
      "#################### Sampling at Epoch 10349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10349\n",
      "Mean Log Likelihood -- train: -5.303711891174316, -- test: -13.541406631469727 \n",
      "Root Mean Squared Error -- train: 0.36571457982063293, -- test: 0.5463525056838989 \n",
      " \n",
      "#################### Sampling at Epoch 10399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10399\n",
      "Mean Log Likelihood -- train: -5.347685813903809, -- test: -12.208098411560059 \n",
      "Root Mean Squared Error -- train: 0.3669150471687317, -- test: 0.5213779211044312 \n",
      " \n",
      "#################### Sampling at Epoch 10449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10449\n",
      "Mean Log Likelihood -- train: -5.268083572387695, -- test: -9.26777458190918 \n",
      "Root Mean Squared Error -- train: 0.3647390902042389, -- test: 0.4615499973297119 \n",
      " \n",
      "#################### Sampling at Epoch 10499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10499\n",
      "Mean Log Likelihood -- train: -5.301638603210449, -- test: -9.11206340789795 \n",
      "Root Mean Squared Error -- train: 0.36565789580345154, -- test: 0.45816388726234436 \n",
      " \n",
      "#################### Sampling at Epoch 10549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10549\n",
      "Mean Log Likelihood -- train: -5.201932907104492, -- test: -11.029510498046875 \n",
      "Root Mean Squared Error -- train: 0.3629209101200104, -- test: 0.49826011061668396 \n",
      " \n",
      "#################### Sampling at Epoch 10599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10599\n",
      "Mean Log Likelihood -- train: -5.160223484039307, -- test: -9.882149696350098 \n",
      "Root Mean Squared Error -- train: 0.36176979541778564, -- test: 0.4746745526790619 \n",
      " \n",
      "#################### Sampling at Epoch 10649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10649\n",
      "Mean Log Likelihood -- train: -5.123526096343994, -- test: -11.477033615112305 \n",
      "Root Mean Squared Error -- train: 0.36075398325920105, -- test: 0.50716233253479 \n",
      " \n",
      "#################### Sampling at Epoch 10699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10699\n",
      "Mean Log Likelihood -- train: -5.185673713684082, -- test: -12.1367769241333 \n",
      "Root Mean Squared Error -- train: 0.3624725937843323, -- test: 0.5200081467628479 \n",
      " \n",
      "#################### Sampling at Epoch 10749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10749\n",
      "Mean Log Likelihood -- train: -5.192590236663818, -- test: -11.936345100402832 \n",
      "Root Mean Squared Error -- train: 0.3626633882522583, -- test: 0.5161393284797668 \n",
      " \n",
      "#################### Sampling at Epoch 10799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10799\n",
      "Mean Log Likelihood -- train: -5.289441108703613, -- test: -9.358268737792969 \n",
      "Root Mean Squared Error -- train: 0.3653241693973541, -- test: 0.4635065197944641 \n",
      " \n",
      "#################### Sampling at Epoch 10849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10849\n",
      "Mean Log Likelihood -- train: -5.199434280395508, -- test: -11.044225692749023 \n",
      "Root Mean Squared Error -- train: 0.3628520965576172, -- test: 0.49855536222457886 \n",
      " \n",
      "#################### Sampling at Epoch 10899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10899\n",
      "Mean Log Likelihood -- train: -5.219925880432129, -- test: -8.759337425231934 \n",
      "Root Mean Squared Error -- train: 0.3634163439273834, -- test: 0.4503994584083557 \n",
      " \n",
      "#################### Sampling at Epoch 10949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10949\n",
      "Mean Log Likelihood -- train: -5.272957801818848, -- test: -11.309845924377441 \n",
      "Root Mean Squared Error -- train: 0.36487269401550293, -- test: 0.5038549304008484 \n",
      " \n",
      "#################### Sampling at Epoch 10999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 10999\n",
      "Mean Log Likelihood -- train: -5.2637481689453125, -- test: -11.83034896850586 \n",
      "Root Mean Squared Error -- train: 0.3646202087402344, -- test: 0.514081597328186 \n",
      " \n",
      "#################### Sampling at Epoch 11049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11049\n",
      "Mean Log Likelihood -- train: -5.138566970825195, -- test: -9.06877613067627 \n",
      "Root Mean Squared Error -- train: 0.3611706793308258, -- test: 0.4572181701660156 \n",
      " \n",
      "#################### Sampling at Epoch 11099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11099\n",
      "Mean Log Likelihood -- train: -5.1566081047058105, -- test: -9.541869163513184 \n",
      "Root Mean Squared Error -- train: 0.3616698682308197, -- test: 0.4674508571624756 \n",
      " \n",
      "#################### Sampling at Epoch 11149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11149\n",
      "Mean Log Likelihood -- train: -5.155418872833252, -- test: -10.667043685913086 \n",
      "Root Mean Squared Error -- train: 0.3616369962692261, -- test: 0.49093157052993774 \n",
      " \n",
      "#################### Sampling at Epoch 11199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11199\n",
      "Mean Log Likelihood -- train: -5.275999069213867, -- test: -7.770267486572266 \n",
      "Root Mean Squared Error -- train: 0.3649560213088989, -- test: 0.42787647247314453 \n",
      " \n",
      "#################### Sampling at Epoch 11249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11249\n",
      "Mean Log Likelihood -- train: -5.2000322341918945, -- test: -8.727058410644531 \n",
      "Root Mean Squared Error -- train: 0.3628685176372528, -- test: 0.44968220591545105 \n",
      " \n",
      "#################### Sampling at Epoch 11299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11299\n",
      "Mean Log Likelihood -- train: -5.153139114379883, -- test: -8.614477157592773 \n",
      "Root Mean Squared Error -- train: 0.3615739345550537, -- test: 0.4471716284751892 \n",
      " \n",
      "#################### Sampling at Epoch 11349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11349\n",
      "Mean Log Likelihood -- train: -5.141291618347168, -- test: -8.88220500946045 \n",
      "Root Mean Squared Error -- train: 0.36124610900878906, -- test: 0.4531192183494568 \n",
      " \n",
      "#################### Sampling at Epoch 11399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11399\n",
      "Mean Log Likelihood -- train: -5.113292217254639, -- test: -9.004961967468262 \n",
      "Root Mean Squared Error -- train: 0.3604702353477478, -- test: 0.45582032203674316 \n",
      " \n",
      "#################### Sampling at Epoch 11449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11449\n",
      "Mean Log Likelihood -- train: -5.166243553161621, -- test: -8.110187530517578 \n",
      "Root Mean Squared Error -- train: 0.36193621158599854, -- test: 0.435748428106308 \n",
      " \n",
      "#################### Sampling at Epoch 11499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11499\n",
      "Mean Log Likelihood -- train: -5.0986409187316895, -- test: -9.290821075439453 \n",
      "Root Mean Squared Error -- train: 0.3600635230541229, -- test: 0.46204906702041626 \n",
      " \n",
      "#################### Sampling at Epoch 11549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11549\n",
      "Mean Log Likelihood -- train: -5.061535835266113, -- test: -15.076472282409668 \n",
      "Root Mean Squared Error -- train: 0.3590315282344818, -- test: 0.5737615823745728 \n",
      " \n",
      "#################### Sampling at Epoch 11599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11599\n",
      "Mean Log Likelihood -- train: -5.076684951782227, -- test: -13.559978485107422 \n",
      "Root Mean Squared Error -- train: 0.3594532310962677, -- test: 0.5466923117637634 \n",
      " \n",
      "#################### Sampling at Epoch 11649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11649\n",
      "Mean Log Likelihood -- train: -5.112347602844238, -- test: -14.84280776977539 \n",
      "Root Mean Squared Error -- train: 0.36044397950172424, -- test: 0.5696744918823242 \n",
      " \n",
      "#################### Sampling at Epoch 11699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11699\n",
      "Mean Log Likelihood -- train: -5.0805745124816895, -- test: -14.724806785583496 \n",
      "Root Mean Squared Error -- train: 0.35956141352653503, -- test: 0.567599356174469 \n",
      " \n",
      "#################### Sampling at Epoch 11749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11749\n",
      "Mean Log Likelihood -- train: -5.028419494628906, -- test: -16.909927368164062 \n",
      "Root Mean Squared Error -- train: 0.3581079840660095, -- test: 0.6048730611801147 \n",
      " \n",
      "#################### Sampling at Epoch 11799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11799\n",
      "Mean Log Likelihood -- train: -5.077245235443115, -- test: -17.522645950317383 \n",
      "Root Mean Squared Error -- train: 0.35946881771087646, -- test: 0.6149193644523621 \n",
      " \n",
      "#################### Sampling at Epoch 11849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11849\n",
      "Mean Log Likelihood -- train: -5.121170997619629, -- test: -18.177467346191406 \n",
      "Root Mean Squared Error -- train: 0.360688716173172, -- test: 0.6254776120185852 \n",
      " \n",
      "#################### Sampling at Epoch 11899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11899\n",
      "Mean Log Likelihood -- train: -5.140050411224365, -- test: -14.809599876403809 \n",
      "Root Mean Squared Error -- train: 0.36121174693107605, -- test: 0.5690913200378418 \n",
      " \n",
      "#################### Sampling at Epoch 11949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11949\n",
      "Mean Log Likelihood -- train: -5.113134384155273, -- test: -16.761354446411133 \n",
      "Root Mean Squared Error -- train: 0.3604658246040344, -- test: 0.6024118065834045 \n",
      " \n",
      "#################### Sampling at Epoch 11999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 11999\n",
      "Mean Log Likelihood -- train: -5.0918121337890625, -- test: -16.861818313598633 \n",
      "Root Mean Squared Error -- train: 0.35987380146980286, -- test: 0.6040772199630737 \n",
      " \n",
      "#################### Sampling at Epoch 12049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12049\n",
      "Mean Log Likelihood -- train: -5.201492786407471, -- test: -15.92672348022461 \n",
      "Root Mean Squared Error -- train: 0.3629087805747986, -- test: 0.5883939266204834 \n",
      " \n",
      "#################### Sampling at Epoch 12099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12099\n",
      "Mean Log Likelihood -- train: -5.220900535583496, -- test: -17.73705291748047 \n",
      "Root Mean Squared Error -- train: 0.36344316601753235, -- test: 0.6183962821960449 \n",
      " \n",
      "#################### Sampling at Epoch 12149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12149\n",
      "Mean Log Likelihood -- train: -5.081445217132568, -- test: -18.653444290161133 \n",
      "Root Mean Squared Error -- train: 0.35958564281463623, -- test: 0.6330417394638062 \n",
      " \n",
      "#################### Sampling at Epoch 12199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12199\n",
      "Mean Log Likelihood -- train: -5.165283203125, -- test: -22.39379119873047 \n",
      "Root Mean Squared Error -- train: 0.3619096577167511, -- test: 0.6896004676818848 \n",
      " \n",
      "#################### Sampling at Epoch 12249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12249\n",
      "Mean Log Likelihood -- train: -5.217923641204834, -- test: -24.181407928466797 \n",
      "Root Mean Squared Error -- train: 0.36336126923561096, -- test: 0.7150532007217407 \n",
      " \n",
      "#################### Sampling at Epoch 12299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12299\n",
      "Mean Log Likelihood -- train: -5.17771053314209, -- test: -22.750154495239258 \n",
      "Root Mean Squared Error -- train: 0.3622528314590454, -- test: 0.6947488784790039 \n",
      " \n",
      "#################### Sampling at Epoch 12349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12349\n",
      "Mean Log Likelihood -- train: -5.218120098114014, -- test: -24.547945022583008 \n",
      "Root Mean Squared Error -- train: 0.36336666345596313, -- test: 0.720160961151123 \n",
      " \n",
      "#################### Sampling at Epoch 12399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12399\n",
      "Mean Log Likelihood -- train: -5.090237617492676, -- test: -24.786710739135742 \n",
      "Root Mean Squared Error -- train: 0.3598300516605377, -- test: 0.7234688401222229 \n",
      " \n",
      "#################### Sampling at Epoch 12449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12449\n",
      "Mean Log Likelihood -- train: -5.081057071685791, -- test: -25.1326904296875 \n",
      "Root Mean Squared Error -- train: 0.3595748245716095, -- test: 0.7282353639602661 \n",
      " \n",
      "#################### Sampling at Epoch 12499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12499\n",
      "Mean Log Likelihood -- train: -5.153970241546631, -- test: -24.07516860961914 \n",
      "Root Mean Squared Error -- train: 0.3615969121456146, -- test: 0.7135658860206604 \n",
      " \n",
      "#################### Sampling at Epoch 12549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12549\n",
      "Mean Log Likelihood -- train: -5.033738136291504, -- test: -23.700746536254883 \n",
      "Root Mean Squared Error -- train: 0.358256459236145, -- test: 0.7082993388175964 \n",
      " \n",
      "#################### Sampling at Epoch 12599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12599\n",
      "Mean Log Likelihood -- train: -5.089291572570801, -- test: -25.421621322631836 \n",
      "Root Mean Squared Error -- train: 0.3598037660121918, -- test: 0.7321921586990356 \n",
      " \n",
      "#################### Sampling at Epoch 12649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12649\n",
      "Mean Log Likelihood -- train: -5.0919294357299805, -- test: -24.261693954467773 \n",
      "Root Mean Squared Error -- train: 0.3598770797252655, -- test: 0.7161751389503479 \n",
      " \n",
      "#################### Sampling at Epoch 12699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12699\n",
      "Mean Log Likelihood -- train: -5.186551570892334, -- test: -24.89527130126953 \n",
      "Root Mean Squared Error -- train: 0.36249682307243347, -- test: 0.7249677777290344 \n",
      " \n",
      "#################### Sampling at Epoch 12749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12749\n",
      "Mean Log Likelihood -- train: -5.102517604827881, -- test: -23.237783432006836 \n",
      "Root Mean Squared Error -- train: 0.3601711690425873, -- test: 0.7017325758934021 \n",
      " \n",
      "#################### Sampling at Epoch 12799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12799\n",
      "Mean Log Likelihood -- train: -5.037895202636719, -- test: -23.539161682128906 \n",
      "Root Mean Squared Error -- train: 0.3583724796772003, -- test: 0.7060142755508423 \n",
      " \n",
      "#################### Sampling at Epoch 12849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12849\n",
      "Mean Log Likelihood -- train: -5.080240249633789, -- test: -21.713109970092773 \n",
      "Root Mean Squared Error -- train: 0.3595521152019501, -- test: 0.6796581149101257 \n",
      " \n",
      "#################### Sampling at Epoch 12899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12899\n",
      "Mean Log Likelihood -- train: -5.1057820320129395, -- test: -24.71591567993164 \n",
      "Root Mean Squared Error -- train: 0.36026182770729065, -- test: 0.7224896550178528 \n",
      " \n",
      "#################### Sampling at Epoch 12949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12949\n",
      "Mean Log Likelihood -- train: -5.130014896392822, -- test: -22.041601181030273 \n",
      "Root Mean Squared Error -- train: 0.3609338402748108, -- test: 0.6844742298126221 \n",
      " \n",
      "#################### Sampling at Epoch 12999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 12999\n",
      "Mean Log Likelihood -- train: -5.0630950927734375, -- test: -23.57872772216797 \n",
      "Root Mean Squared Error -- train: 0.35907498002052307, -- test: 0.7065744996070862 \n",
      " \n",
      "#################### Sampling at Epoch 13049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13049\n",
      "Mean Log Likelihood -- train: -5.071742534637451, -- test: -23.6964168548584 \n",
      "Root Mean Squared Error -- train: 0.3593157231807709, -- test: 0.7082381248474121 \n",
      " \n",
      "#################### Sampling at Epoch 13099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13099\n",
      "Mean Log Likelihood -- train: -5.089659690856934, -- test: -23.976919174194336 \n",
      "Root Mean Squared Error -- train: 0.35981401801109314, -- test: 0.7121877074241638 \n",
      " \n",
      "#################### Sampling at Epoch 13149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13149\n",
      "Mean Log Likelihood -- train: -5.14300012588501, -- test: -22.754148483276367 \n",
      "Root Mean Squared Error -- train: 0.3612934350967407, -- test: 0.6948063969612122 \n",
      " \n",
      "#################### Sampling at Epoch 13199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13199\n",
      "Mean Log Likelihood -- train: -5.1437554359436035, -- test: -22.502351760864258 \n",
      "Root Mean Squared Error -- train: 0.3613143265247345, -- test: 0.6911728978157043 \n",
      " \n",
      "#################### Sampling at Epoch 13249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13249\n",
      "Mean Log Likelihood -- train: -5.092545509338379, -- test: -22.4202880859375 \n",
      "Root Mean Squared Error -- train: 0.3598942160606384, -- test: 0.6899845600128174 \n",
      " \n",
      "#################### Sampling at Epoch 13299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13299\n",
      "Mean Log Likelihood -- train: -5.088659763336182, -- test: -23.197181701660156 \n",
      "Root Mean Squared Error -- train: 0.3597862124443054, -- test: 0.7011537551879883 \n",
      " \n",
      "#################### Sampling at Epoch 13349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13349\n",
      "Mean Log Likelihood -- train: -5.062109470367432, -- test: -23.861652374267578 \n",
      "Root Mean Squared Error -- train: 0.35904747247695923, -- test: 0.7105673551559448 \n",
      " \n",
      "#################### Sampling at Epoch 13399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13399\n",
      "Mean Log Likelihood -- train: -5.088368892669678, -- test: -24.208345413208008 \n",
      "Root Mean Squared Error -- train: 0.35977813601493835, -- test: 0.7154298424720764 \n",
      " \n",
      "#################### Sampling at Epoch 13449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13449\n",
      "Mean Log Likelihood -- train: -5.050755977630615, -- test: -22.55459213256836 \n",
      "Root Mean Squared Error -- train: 0.35873115062713623, -- test: 0.6919283270835876 \n",
      " \n",
      "#################### Sampling at Epoch 13499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13499\n",
      "Mean Log Likelihood -- train: -5.00452995300293, -- test: -23.25882339477539 \n",
      "Root Mean Squared Error -- train: 0.3574402332305908, -- test: 0.7020323872566223 \n",
      " \n",
      "#################### Sampling at Epoch 13549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13549\n",
      "Mean Log Likelihood -- train: -5.118334770202637, -- test: -25.044557571411133 \n",
      "Root Mean Squared Error -- train: 0.36061009764671326, -- test: 0.7270241379737854 \n",
      " \n",
      "#################### Sampling at Epoch 13599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13599\n",
      "Mean Log Likelihood -- train: -5.022207736968994, -- test: -24.197362899780273 \n",
      "Root Mean Squared Error -- train: 0.35793444514274597, -- test: 0.7152762413024902 \n",
      " \n",
      "#################### Sampling at Epoch 13649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13649\n",
      "Mean Log Likelihood -- train: -5.0262980461120605, -- test: -22.638046264648438 \n",
      "Root Mean Squared Error -- train: 0.3580487370491028, -- test: 0.6931333541870117 \n",
      " \n",
      "#################### Sampling at Epoch 13699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13699\n",
      "Mean Log Likelihood -- train: -5.010883808135986, -- test: -23.709400177001953 \n",
      "Root Mean Squared Error -- train: 0.35761794447898865, -- test: 0.7084213495254517 \n",
      " \n",
      "#################### Sampling at Epoch 13749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13749\n",
      "Mean Log Likelihood -- train: -5.021730422973633, -- test: -23.175657272338867 \n",
      "Root Mean Squared Error -- train: 0.35792115330696106, -- test: 0.7008466720581055 \n",
      " \n",
      "#################### Sampling at Epoch 13799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13799\n",
      "Mean Log Likelihood -- train: -5.081060409545898, -- test: -22.4991455078125 \n",
      "Root Mean Squared Error -- train: 0.35957491397857666, -- test: 0.6911265254020691 \n",
      " \n",
      "#################### Sampling at Epoch 13849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13849\n",
      "Mean Log Likelihood -- train: -5.042908668518066, -- test: -22.754554748535156 \n",
      "Root Mean Squared Error -- train: 0.35851237177848816, -- test: 0.6948122382164001 \n",
      " \n",
      "#################### Sampling at Epoch 13899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13899\n",
      "Mean Log Likelihood -- train: -5.09947395324707, -- test: -22.44540023803711 \n",
      "Root Mean Squared Error -- train: 0.3600866496562958, -- test: 0.6903483867645264 \n",
      " \n",
      "#################### Sampling at Epoch 13949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13949\n",
      "Mean Log Likelihood -- train: -5.073863506317139, -- test: -21.098787307739258 \n",
      "Root Mean Squared Error -- train: 0.3593747317790985, -- test: 0.6705584526062012 \n",
      " \n",
      "#################### Sampling at Epoch 13999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 13999\n",
      "Mean Log Likelihood -- train: -5.046206474304199, -- test: -21.975502014160156 \n",
      "Root Mean Squared Error -- train: 0.3586043417453766, -- test: 0.6835078001022339 \n",
      " \n",
      "#################### Sampling at Epoch 14049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14049\n",
      "Mean Log Likelihood -- train: -5.080970287322998, -- test: -22.524145126342773 \n",
      "Root Mean Squared Error -- train: 0.3595724105834961, -- test: 0.6914881467819214 \n",
      " \n",
      "#################### Sampling at Epoch 14099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14099\n",
      "Mean Log Likelihood -- train: -5.032011985778809, -- test: -23.1560115814209 \n",
      "Root Mean Squared Error -- train: 0.3582082688808441, -- test: 0.700566291809082 \n",
      " \n",
      "#################### Sampling at Epoch 14149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14149\n",
      "Mean Log Likelihood -- train: -5.006036758422852, -- test: -24.654218673706055 \n",
      "Root Mean Squared Error -- train: 0.3574824035167694, -- test: 0.721635103225708 \n",
      " \n",
      "#################### Sampling at Epoch 14199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14199\n",
      "Mean Log Likelihood -- train: -5.111462593078613, -- test: -25.552473068237305 \n",
      "Root Mean Squared Error -- train: 0.3604194223880768, -- test: 0.7339770793914795 \n",
      " \n",
      "#################### Sampling at Epoch 14249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14249\n",
      "Mean Log Likelihood -- train: -5.054389953613281, -- test: -24.819780349731445 \n",
      "Root Mean Squared Error -- train: 0.3588324785232544, -- test: 0.723925769329071 \n",
      " \n",
      "#################### Sampling at Epoch 14299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14299\n",
      "Mean Log Likelihood -- train: -5.097929000854492, -- test: -25.888992309570312 \n",
      "Root Mean Squared Error -- train: 0.3600437343120575, -- test: 0.738547682762146 \n",
      " \n",
      "#################### Sampling at Epoch 14349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14349\n",
      "Mean Log Likelihood -- train: -5.008214950561523, -- test: -24.53360366821289 \n",
      "Root Mean Squared Error -- train: 0.35754331946372986, -- test: 0.7199618220329285 \n",
      " \n",
      "#################### Sampling at Epoch 14399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14399\n",
      "Mean Log Likelihood -- train: -5.045125484466553, -- test: -26.049375534057617 \n",
      "Root Mean Squared Error -- train: 0.35857415199279785, -- test: 0.7407160997390747 \n",
      " \n",
      "#################### Sampling at Epoch 14449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14449\n",
      "Mean Log Likelihood -- train: -5.008612155914307, -- test: -25.925451278686523 \n",
      "Root Mean Squared Error -- train: 0.35755443572998047, -- test: 0.739041268825531 \n",
      " \n",
      "#################### Sampling at Epoch 14499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14499\n",
      "Mean Log Likelihood -- train: -5.057570934295654, -- test: -25.885086059570312 \n",
      "Root Mean Squared Error -- train: 0.358921080827713, -- test: 0.7384948134422302 \n",
      " \n",
      "#################### Sampling at Epoch 14549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14549\n",
      "Mean Log Likelihood -- train: -5.163895606994629, -- test: -26.464624404907227 \n",
      "Root Mean Squared Error -- train: 0.36187130212783813, -- test: 0.7463011145591736 \n",
      " \n",
      "#################### Sampling at Epoch 14599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14599\n",
      "Mean Log Likelihood -- train: -5.121795177459717, -- test: -25.492341995239258 \n",
      "Root Mean Squared Error -- train: 0.36070603132247925, -- test: 0.7331573963165283 \n",
      " \n",
      "#################### Sampling at Epoch 14649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14649\n",
      "Mean Log Likelihood -- train: -5.131805419921875, -- test: -25.67949676513672 \n",
      "Root Mean Squared Error -- train: 0.3609834313392639, -- test: 0.7357056736946106 \n",
      " \n",
      "#################### Sampling at Epoch 14699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14699\n",
      "Mean Log Likelihood -- train: -5.099702835083008, -- test: -24.652929306030273 \n",
      "Root Mean Squared Error -- train: 0.36009302735328674, -- test: 0.7216173410415649 \n",
      " \n",
      "#################### Sampling at Epoch 14749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14749\n",
      "Mean Log Likelihood -- train: -5.166409969329834, -- test: -23.988046646118164 \n",
      "Root Mean Squared Error -- train: 0.36194077134132385, -- test: 0.7123439311981201 \n",
      " \n",
      "#################### Sampling at Epoch 14799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14799\n",
      "Mean Log Likelihood -- train: -5.216114521026611, -- test: -24.556434631347656 \n",
      "Root Mean Squared Error -- train: 0.3633114695549011, -- test: 0.7202788591384888 \n",
      " \n",
      "#################### Sampling at Epoch 14849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14849\n",
      "Mean Log Likelihood -- train: -5.085633277893066, -- test: -23.526399612426758 \n",
      "Root Mean Squared Error -- train: 0.35970211029052734, -- test: 0.7058334350585938 \n",
      " \n",
      "#################### Sampling at Epoch 14899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14899\n",
      "Mean Log Likelihood -- train: -5.187209129333496, -- test: -25.18966293334961 \n",
      "Root Mean Squared Error -- train: 0.3625149726867676, -- test: 0.7290171980857849 \n",
      " \n",
      "#################### Sampling at Epoch 14949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14949\n",
      "Mean Log Likelihood -- train: -5.161375999450684, -- test: -24.581806182861328 \n",
      "Root Mean Squared Error -- train: 0.3618016541004181, -- test: 0.7206310629844666 \n",
      " \n",
      "#################### Sampling at Epoch 14999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 14999\n",
      "Mean Log Likelihood -- train: -5.043734073638916, -- test: -24.51849365234375 \n",
      "Root Mean Squared Error -- train: 0.35853537917137146, -- test: 0.7197518348693848 \n",
      " \n",
      "#################### Sampling at Epoch 15049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15049\n",
      "Mean Log Likelihood -- train: -5.061441898345947, -- test: -24.027944564819336 \n",
      "Root Mean Squared Error -- train: 0.3590289354324341, -- test: 0.7129037976264954 \n",
      " \n",
      "#################### Sampling at Epoch 15099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15099\n",
      "Mean Log Likelihood -- train: -5.062387943267822, -- test: -23.5928897857666 \n",
      "Root Mean Squared Error -- train: 0.3590552508831024, -- test: 0.706774890422821 \n",
      " \n",
      "#################### Sampling at Epoch 15149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15149\n",
      "Mean Log Likelihood -- train: -5.082183361053467, -- test: -25.647890090942383 \n",
      "Root Mean Squared Error -- train: 0.35960617661476135, -- test: 0.73527592420578 \n",
      " \n",
      "#################### Sampling at Epoch 15199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15199\n",
      "Mean Log Likelihood -- train: -5.063559055328369, -- test: -24.065044403076172 \n",
      "Root Mean Squared Error -- train: 0.35908791422843933, -- test: 0.7134239673614502 \n",
      " \n",
      "#################### Sampling at Epoch 15249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15249\n",
      "Mean Log Likelihood -- train: -5.126568794250488, -- test: -24.933813095092773 \n",
      "Root Mean Squared Error -- train: 0.3608383238315582, -- test: 0.7254992723464966 \n",
      " \n",
      "#################### Sampling at Epoch 15299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15299\n",
      "Mean Log Likelihood -- train: -5.101893901824951, -- test: -22.330982208251953 \n",
      "Root Mean Squared Error -- train: 0.3601538836956024, -- test: 0.6886889934539795 \n",
      " \n",
      "#################### Sampling at Epoch 15349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15349\n",
      "Mean Log Likelihood -- train: -5.192346096038818, -- test: -22.914810180664062 \n",
      "Root Mean Squared Error -- train: 0.3626566529273987, -- test: 0.6971148252487183 \n",
      " \n",
      "#################### Sampling at Epoch 15399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15399\n",
      "Mean Log Likelihood -- train: -5.215586185455322, -- test: -25.602033615112305 \n",
      "Root Mean Squared Error -- train: 0.3632969260215759, -- test: 0.734652042388916 \n",
      " \n",
      "#################### Sampling at Epoch 15449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15449\n",
      "Mean Log Likelihood -- train: -5.349778175354004, -- test: -26.16413116455078 \n",
      "Root Mean Squared Error -- train: 0.36697205901145935, -- test: 0.7422637939453125 \n",
      " \n",
      "#################### Sampling at Epoch 15499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15499\n",
      "Mean Log Likelihood -- train: -5.251911640167236, -- test: -26.812288284301758 \n",
      "Root Mean Squared Error -- train: 0.36429542303085327, -- test: 0.7509452104568481 \n",
      " \n",
      "#################### Sampling at Epoch 15549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15549\n",
      "Mean Log Likelihood -- train: -5.271677494049072, -- test: -27.206323623657227 \n",
      "Root Mean Squared Error -- train: 0.3648376166820526, -- test: 0.7561741471290588 \n",
      " \n",
      "#################### Sampling at Epoch 15599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15599\n",
      "Mean Log Likelihood -- train: -5.267760753631592, -- test: -26.603496551513672 \n",
      "Root Mean Squared Error -- train: 0.36473020911216736, -- test: 0.748159646987915 \n",
      " \n",
      "#################### Sampling at Epoch 15649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15649\n",
      "Mean Log Likelihood -- train: -5.3337321281433105, -- test: -25.286943435668945 \n",
      "Root Mean Squared Error -- train: 0.366534560918808, -- test: 0.7303504347801208 \n",
      " \n",
      "#################### Sampling at Epoch 15699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15699\n",
      "Mean Log Likelihood -- train: -5.311595439910889, -- test: -20.342098236083984 \n",
      "Root Mean Squared Error -- train: 0.36593014001846313, -- test: 0.6591774225234985 \n",
      " \n",
      "#################### Sampling at Epoch 15749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15749\n",
      "Mean Log Likelihood -- train: -5.256861209869385, -- test: -24.346010208129883 \n",
      "Root Mean Squared Error -- train: 0.3644312918186188, -- test: 0.717351496219635 \n",
      " \n",
      "#################### Sampling at Epoch 15799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15799\n",
      "Mean Log Likelihood -- train: -5.290432929992676, -- test: -22.845064163208008 \n",
      "Root Mean Squared Error -- train: 0.3653513193130493, -- test: 0.696113646030426 \n",
      " \n",
      "#################### Sampling at Epoch 15849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15849\n",
      "Mean Log Likelihood -- train: -5.240776062011719, -- test: -19.81983184814453 \n",
      "Root Mean Squared Error -- train: 0.36398962140083313, -- test: 0.6512062549591064 \n",
      " \n",
      "#################### Sampling at Epoch 15899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15899\n",
      "Mean Log Likelihood -- train: -5.218039035797119, -- test: -19.730501174926758 \n",
      "Root Mean Squared Error -- train: 0.36336439847946167, -- test: 0.6498330235481262 \n",
      " \n",
      "#################### Sampling at Epoch 15949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15949\n",
      "Mean Log Likelihood -- train: -5.28136682510376, -- test: -19.980302810668945 \n",
      "Root Mean Squared Error -- train: 0.3651030957698822, -- test: 0.6536657810211182 \n",
      " \n",
      "#################### Sampling at Epoch 15999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 15999\n",
      "Mean Log Likelihood -- train: -5.256013870239258, -- test: -22.51006507873535 \n",
      "Root Mean Squared Error -- train: 0.364408016204834, -- test: 0.6912844777107239 \n",
      " \n",
      "#################### Sampling at Epoch 16049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16049\n",
      "Mean Log Likelihood -- train: -5.307169437408447, -- test: -23.988304138183594 \n",
      "Root Mean Squared Error -- train: 0.3658091127872467, -- test: 0.7123475074768066 \n",
      " \n",
      "#################### Sampling at Epoch 16099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16099\n",
      "Mean Log Likelihood -- train: -5.253581523895264, -- test: -22.515249252319336 \n",
      "Root Mean Squared Error -- train: 0.36434128880500793, -- test: 0.6913594603538513 \n",
      " \n",
      "#################### Sampling at Epoch 16149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16149\n",
      "Mean Log Likelihood -- train: -5.261768817901611, -- test: -22.505826950073242 \n",
      "Root Mean Squared Error -- train: 0.364565908908844, -- test: 0.6912232041358948 \n",
      " \n",
      "#################### Sampling at Epoch 16199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16199\n",
      "Mean Log Likelihood -- train: -5.2608466148376465, -- test: -24.595630645751953 \n",
      "Root Mean Squared Error -- train: 0.36454060673713684, -- test: 0.720822811126709 \n",
      " \n",
      "#################### Sampling at Epoch 16249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16249\n",
      "Mean Log Likelihood -- train: -5.260900020599365, -- test: -26.26058578491211 \n",
      "Root Mean Squared Error -- train: 0.36454206705093384, -- test: 0.7435621619224548 \n",
      " \n",
      "#################### Sampling at Epoch 16299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16299\n",
      "Mean Log Likelihood -- train: -5.227659225463867, -- test: -23.914112091064453 \n",
      "Root Mean Squared Error -- train: 0.3636291027069092, -- test: 0.7113052606582642 \n",
      " \n",
      "#################### Sampling at Epoch 16349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16349\n",
      "Mean Log Likelihood -- train: -5.215795040130615, -- test: -22.976346969604492 \n",
      "Root Mean Squared Error -- train: 0.36330264806747437, -- test: 0.697996973991394 \n",
      " \n",
      "#################### Sampling at Epoch 16399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16399\n",
      "Mean Log Likelihood -- train: -5.212314128875732, -- test: -24.299833297729492 \n",
      "Root Mean Squared Error -- train: 0.3632068634033203, -- test: 0.7167075276374817 \n",
      " \n",
      "#################### Sampling at Epoch 16449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16449\n",
      "Mean Log Likelihood -- train: -5.1491498947143555, -- test: -23.617835998535156 \n",
      "Root Mean Squared Error -- train: 0.36146360635757446, -- test: 0.7071277499198914 \n",
      " \n",
      "#################### Sampling at Epoch 16499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16499\n",
      "Mean Log Likelihood -- train: -5.12699556350708, -- test: -22.16131591796875 \n",
      "Root Mean Squared Error -- train: 0.36085015535354614, -- test: 0.6862210035324097 \n",
      " \n",
      "#################### Sampling at Epoch 16549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16549\n",
      "Mean Log Likelihood -- train: -5.149119853973389, -- test: -17.71533203125 \n",
      "Root Mean Squared Error -- train: 0.3614627718925476, -- test: 0.6180449724197388 \n",
      " \n",
      "#################### Sampling at Epoch 16599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16599\n",
      "Mean Log Likelihood -- train: -5.094613552093506, -- test: -21.134021759033203 \n",
      "Root Mean Squared Error -- train: 0.3599516451358795, -- test: 0.6710837483406067 \n",
      " \n",
      "#################### Sampling at Epoch 16649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16649\n",
      "Mean Log Likelihood -- train: -5.064152717590332, -- test: -20.949399948120117 \n",
      "Root Mean Squared Error -- train: 0.3591043949127197, -- test: 0.6683269143104553 \n",
      " \n",
      "#################### Sampling at Epoch 16699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16699\n",
      "Mean Log Likelihood -- train: -5.13135290145874, -- test: -21.7021484375 \n",
      "Root Mean Squared Error -- train: 0.3609708845615387, -- test: 0.6794967651367188 \n",
      " \n",
      "#################### Sampling at Epoch 16749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16749\n",
      "Mean Log Likelihood -- train: -5.263847351074219, -- test: -22.141185760498047 \n",
      "Root Mean Squared Error -- train: 0.36462292075157166, -- test: 0.6859275698661804 \n",
      " \n",
      "#################### Sampling at Epoch 16799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16799\n",
      "Mean Log Likelihood -- train: -5.099036693572998, -- test: -20.556900024414062 \n",
      "Root Mean Squared Error -- train: 0.360074520111084, -- test: 0.662428081035614 \n",
      " \n",
      "#################### Sampling at Epoch 16849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16849\n",
      "Mean Log Likelihood -- train: -5.067289352416992, -- test: -20.204551696777344 \n",
      "Root Mean Squared Error -- train: 0.35919174551963806, -- test: 0.657087504863739 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 11:17:13.013965: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Sampling at Epoch 16899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16899\n",
      "Mean Log Likelihood -- train: -5.0889506340026855, -- test: -21.28748321533203 \n",
      "Root Mean Squared Error -- train: 0.3597942888736725, -- test: 0.6733666062355042 \n",
      " \n",
      "#################### Sampling at Epoch 16949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16949\n",
      "Mean Log Likelihood -- train: -5.057218551635742, -- test: -22.898420333862305 \n",
      "Root Mean Squared Error -- train: 0.35891127586364746, -- test: 0.6968796849250793 \n",
      " \n",
      "#################### Sampling at Epoch 16999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 16999\n",
      "Mean Log Likelihood -- train: -5.0142822265625, -- test: -23.40601348876953 \n",
      "Root Mean Squared Error -- train: 0.3577129542827606, -- test: 0.7041258215904236 \n",
      " \n",
      "#################### Sampling at Epoch 17049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17049\n",
      "Mean Log Likelihood -- train: -5.03955078125, -- test: -23.342330932617188 \n",
      "Root Mean Squared Error -- train: 0.35841867327690125, -- test: 0.7032208442687988 \n",
      " \n",
      "#################### Sampling at Epoch 17099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17099\n",
      "Mean Log Likelihood -- train: -4.9831695556640625, -- test: -23.437978744506836 \n",
      "Root Mean Squared Error -- train: 0.35684213042259216, -- test: 0.7045796513557434 \n",
      " \n",
      "#################### Sampling at Epoch 17149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17149\n",
      "Mean Log Likelihood -- train: -4.931641101837158, -- test: -20.223615646362305 \n",
      "Root Mean Squared Error -- train: 0.35539522767066956, -- test: 0.6573775410652161 \n",
      " \n",
      "#################### Sampling at Epoch 17199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17199\n",
      "Mean Log Likelihood -- train: -4.9437174797058105, -- test: -21.825571060180664 \n",
      "Root Mean Squared Error -- train: 0.35573485493659973, -- test: 0.681310772895813 \n",
      " \n",
      "#################### Sampling at Epoch 17249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17249\n",
      "Mean Log Likelihood -- train: -5.018660545349121, -- test: -23.6234073638916 \n",
      "Root Mean Squared Error -- train: 0.3578353524208069, -- test: 0.7072065472602844 \n",
      " \n",
      "#################### Sampling at Epoch 17299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17299\n",
      "Mean Log Likelihood -- train: -5.016928672790527, -- test: -23.13019561767578 \n",
      "Root Mean Squared Error -- train: 0.3577869236469269, -- test: 0.7001977562904358 \n",
      " \n",
      "#################### Sampling at Epoch 17349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17349\n",
      "Mean Log Likelihood -- train: -5.034228324890137, -- test: -23.13408660888672 \n",
      "Root Mean Squared Error -- train: 0.35827013850212097, -- test: 0.7002533078193665 \n",
      " \n",
      "#################### Sampling at Epoch 17399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17399\n",
      "Mean Log Likelihood -- train: -5.100200176239014, -- test: -25.62384605407715 \n",
      "Root Mean Squared Error -- train: 0.36010682582855225, -- test: 0.7349488735198975 \n",
      " \n",
      "#################### Sampling at Epoch 17449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17449\n",
      "Mean Log Likelihood -- train: -5.033626079559326, -- test: -24.671859741210938 \n",
      "Root Mean Squared Error -- train: 0.3582533299922943, -- test: 0.7218796014785767 \n",
      " \n",
      "#################### Sampling at Epoch 17499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17499\n",
      "Mean Log Likelihood -- train: -5.014126777648926, -- test: -22.892955780029297 \n",
      "Root Mean Squared Error -- train: 0.357708603143692, -- test: 0.6968013048171997 \n",
      " \n",
      "#################### Sampling at Epoch 17549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17549\n",
      "Mean Log Likelihood -- train: -5.057830810546875, -- test: -24.326587677001953 \n",
      "Root Mean Squared Error -- train: 0.3589283227920532, -- test: 0.7170806527137756 \n",
      " \n",
      "#################### Sampling at Epoch 17599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17599\n",
      "Mean Log Likelihood -- train: -5.119744777679443, -- test: -24.817441940307617 \n",
      "Root Mean Squared Error -- train: 0.3606491982936859, -- test: 0.7238934636116028 \n",
      " \n",
      "#################### Sampling at Epoch 17649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17649\n",
      "Mean Log Likelihood -- train: -5.188161373138428, -- test: -19.338857650756836 \n",
      "Root Mean Squared Error -- train: 0.36254122853279114, -- test: 0.6437779664993286 \n",
      " \n",
      "#################### Sampling at Epoch 17699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17699\n",
      "Mean Log Likelihood -- train: -5.180338382720947, -- test: -15.725838661193848 \n",
      "Root Mean Squared Error -- train: 0.36232540011405945, -- test: 0.5849698185920715 \n",
      " \n",
      "#################### Sampling at Epoch 17749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17749\n",
      "Mean Log Likelihood -- train: -5.027827739715576, -- test: -11.757255554199219 \n",
      "Root Mean Squared Error -- train: 0.35809147357940674, -- test: 0.5126578211784363 \n",
      " \n",
      "#################### Sampling at Epoch 17799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17799\n",
      "Mean Log Likelihood -- train: -5.142858982086182, -- test: -10.503862380981445 \n",
      "Root Mean Squared Error -- train: 0.36128950119018555, -- test: 0.4875963032245636 \n",
      " \n",
      "#################### Sampling at Epoch 17849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17849\n",
      "Mean Log Likelihood -- train: -5.0679216384887695, -- test: -12.772375106811523 \n",
      "Root Mean Squared Error -- train: 0.3592093586921692, -- test: 0.5320906043052673 \n",
      " \n",
      "#################### Sampling at Epoch 17899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17899\n",
      "Mean Log Likelihood -- train: -5.169111251831055, -- test: -12.036038398742676 \n",
      "Root Mean Squared Error -- train: 0.36201539635658264, -- test: 0.5180672407150269 \n",
      " \n",
      "#################### Sampling at Epoch 17949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17949\n",
      "Mean Log Likelihood -- train: -5.024937629699707, -- test: -9.590570449829102 \n",
      "Root Mean Squared Error -- train: 0.3580107092857361, -- test: 0.4684915244579315 \n",
      " \n",
      "#################### Sampling at Epoch 17999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 17999\n",
      "Mean Log Likelihood -- train: -5.08951473236084, -- test: -11.757671356201172 \n",
      "Root Mean Squared Error -- train: 0.3598099648952484, -- test: 0.5126659274101257 \n",
      " \n",
      "#################### Sampling at Epoch 18049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18049\n",
      "Mean Log Likelihood -- train: -5.1695475578308105, -- test: -12.636601448059082 \n",
      "Root Mean Squared Error -- train: 0.36202743649482727, -- test: 0.529532790184021 \n",
      " \n",
      "#################### Sampling at Epoch 18099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18099\n",
      "Mean Log Likelihood -- train: -5.273033142089844, -- test: -13.931857109069824 \n",
      "Root Mean Squared Error -- train: 0.36487478017807007, -- test: 0.5534528493881226 \n",
      " \n",
      "#################### Sampling at Epoch 18149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18149\n",
      "Mean Log Likelihood -- train: -5.171727657318115, -- test: -11.691786766052246 \n",
      "Root Mean Squared Error -- train: 0.3620876669883728, -- test: 0.5113791823387146 \n",
      " \n",
      "#################### Sampling at Epoch 18199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18199\n",
      "Mean Log Likelihood -- train: -5.102865695953369, -- test: -8.875794410705566 \n",
      "Root Mean Squared Error -- train: 0.3601808249950409, -- test: 0.45297771692276 \n",
      " \n",
      "#################### Sampling at Epoch 18249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18249\n",
      "Mean Log Likelihood -- train: -5.096837997436523, -- test: -9.386309623718262 \n",
      "Root Mean Squared Error -- train: 0.3600134253501892, -- test: 0.4641111195087433 \n",
      " \n",
      "#################### Sampling at Epoch 18299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18299\n",
      "Mean Log Likelihood -- train: -5.006779670715332, -- test: -9.472792625427246 \n",
      "Root Mean Squared Error -- train: 0.35750317573547363, -- test: 0.46597081422805786 \n",
      " \n",
      "#################### Sampling at Epoch 18349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18349\n",
      "Mean Log Likelihood -- train: -5.046112537384033, -- test: -9.402828216552734 \n",
      "Root Mean Squared Error -- train: 0.3586016893386841, -- test: 0.4644668698310852 \n",
      " \n",
      "#################### Sampling at Epoch 18399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18399\n",
      "Mean Log Likelihood -- train: -5.043606758117676, -- test: -6.767910003662109 \n",
      "Root Mean Squared Error -- train: 0.3585318326950073, -- test: 0.4037711024284363 \n",
      " \n",
      "#################### Sampling at Epoch 18449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18449\n",
      "Mean Log Likelihood -- train: -5.097411155700684, -- test: -4.857080459594727 \n",
      "Root Mean Squared Error -- train: 0.3600293695926666, -- test: 0.35329103469848633 \n",
      " \n",
      "#################### Sampling at Epoch 18499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18499\n",
      "Mean Log Likelihood -- train: -5.028611183166504, -- test: -4.921740531921387 \n",
      "Root Mean Squared Error -- train: 0.3581133186817169, -- test: 0.35511651635169983 \n",
      " \n",
      "#################### Sampling at Epoch 18549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 18549\n",
      "Mean Log Likelihood -- train: -5.022943019866943, -- test: -5.56256103515625 \n",
      "Root Mean Squared Error -- train: 0.3579550087451935, -- test: 0.37272530794143677 \n",
      " \n",
      "#################### Sampling at Epoch 22249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22249\n",
      "Mean Log Likelihood -- train: -5.254702091217041, -- test: -17.82196044921875 \n",
      "Root Mean Squared Error -- train: 0.36437204480171204, -- test: 0.6197677850723267 \n",
      " \n",
      "#################### Sampling at Epoch 22299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22299\n",
      "Mean Log Likelihood -- train: -5.179765224456787, -- test: -18.112817764282227 \n",
      "Root Mean Squared Error -- train: 0.3623095750808716, -- test: 0.6244431734085083 \n",
      " \n",
      "#################### Sampling at Epoch 22349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22349\n",
      "Mean Log Likelihood -- train: -5.154106616973877, -- test: -19.283432006835938 \n",
      "Root Mean Squared Error -- train: 0.36160072684288025, -- test: 0.6429164409637451 \n",
      " \n",
      "#################### Sampling at Epoch 22399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22399\n",
      "Mean Log Likelihood -- train: -5.173776149749756, -- test: -19.088668823242188 \n",
      "Root Mean Squared Error -- train: 0.36214423179626465, -- test: 0.6398798823356628 \n",
      " \n",
      "#################### Sampling at Epoch 22449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22449\n",
      "Mean Log Likelihood -- train: -5.182586193084717, -- test: -15.80554485321045 \n",
      "Root Mean Squared Error -- train: 0.36238744854927063, -- test: 0.586330771446228 \n",
      " \n",
      "#################### Sampling at Epoch 22499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22499\n",
      "Mean Log Likelihood -- train: -5.209794521331787, -- test: -15.335467338562012 \n",
      "Root Mean Squared Error -- train: 0.36313748359680176, -- test: 0.5782579183578491 \n",
      " \n",
      "#################### Sampling at Epoch 22549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22549\n",
      "Mean Log Likelihood -- train: -5.356468677520752, -- test: -16.163320541381836 \n",
      "Root Mean Squared Error -- train: 0.3671543300151825, -- test: 0.5924013257026672 \n",
      " \n",
      "#################### Sampling at Epoch 22599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22599\n",
      "Mean Log Likelihood -- train: -5.130441188812256, -- test: -13.438806533813477 \n",
      "Root Mean Squared Error -- train: 0.3609456419944763, -- test: 0.5444713830947876 \n",
      " \n",
      "#################### Sampling at Epoch 22649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22649\n",
      "Mean Log Likelihood -- train: -5.190807819366455, -- test: -13.013419151306152 \n",
      "Root Mean Squared Error -- train: 0.3626142144203186, -- test: 0.5366016626358032 \n",
      " \n",
      "#################### Sampling at Epoch 22699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22699\n",
      "Mean Log Likelihood -- train: -5.275891304016113, -- test: -14.799128532409668 \n",
      "Root Mean Squared Error -- train: 0.36495310068130493, -- test: 0.5689073204994202 \n",
      " \n",
      "#################### Sampling at Epoch 22749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22749\n",
      "Mean Log Likelihood -- train: -5.148436546325684, -- test: -13.800777435302734 \n",
      "Root Mean Squared Error -- train: 0.3614438772201538, -- test: 0.5510793924331665 \n",
      " \n",
      "#################### Sampling at Epoch 22799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22799\n",
      "Mean Log Likelihood -- train: -5.078821659088135, -- test: -10.40250015258789 \n",
      "Root Mean Squared Error -- train: 0.35951265692710876, -- test: 0.4855130612850189 \n",
      " \n",
      "#################### Sampling at Epoch 22849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22849\n",
      "Mean Log Likelihood -- train: -5.160249710083008, -- test: -12.706573486328125 \n",
      "Root Mean Squared Error -- train: 0.36177054047584534, -- test: 0.5308524966239929 \n",
      " \n",
      "#################### Sampling at Epoch 22899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22899\n",
      "Mean Log Likelihood -- train: -5.155957221984863, -- test: -12.808147430419922 \n",
      "Root Mean Squared Error -- train: 0.36165186762809753, -- test: 0.5327624678611755 \n",
      " \n",
      "#################### Sampling at Epoch 22949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22949\n",
      "Mean Log Likelihood -- train: -5.153036117553711, -- test: -12.708012580871582 \n",
      "Root Mean Squared Error -- train: 0.3615711033344269, -- test: 0.5308796167373657 \n",
      " \n",
      "#################### Sampling at Epoch 22999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 22999\n",
      "Mean Log Likelihood -- train: -5.136734962463379, -- test: -14.388385772705078 \n",
      "Root Mean Squared Error -- train: 0.36111998558044434, -- test: 0.5616410374641418 \n",
      " \n",
      "#################### Sampling at Epoch 23049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23049\n",
      "Mean Log Likelihood -- train: -5.053050518035889, -- test: -13.767570495605469 \n",
      "Root Mean Squared Error -- train: 0.3587951362133026, -- test: 0.5504764318466187 \n",
      " \n",
      "#################### Sampling at Epoch 23099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23099\n",
      "Mean Log Likelihood -- train: -4.997000217437744, -- test: -14.438443183898926 \n",
      "Root Mean Squared Error -- train: 0.3572295010089874, -- test: 0.562531590461731 \n",
      " \n",
      "#################### Sampling at Epoch 23149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23149\n",
      "Mean Log Likelihood -- train: -5.026800632476807, -- test: -18.734514236450195 \n",
      "Root Mean Squared Error -- train: 0.358062744140625, -- test: 0.6343210339546204 \n",
      " \n",
      "#################### Sampling at Epoch 23199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23199\n",
      "Mean Log Likelihood -- train: -5.048525810241699, -- test: -19.517593383789062 \n",
      "Root Mean Squared Error -- train: 0.3586690127849579, -- test: 0.646548330783844 \n",
      " \n",
      "#################### Sampling at Epoch 23249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23249\n",
      "Mean Log Likelihood -- train: -4.975014686584473, -- test: -18.806076049804688 \n",
      "Root Mean Squared Error -- train: 0.35661354660987854, -- test: 0.6354482173919678 \n",
      " \n",
      "#################### Sampling at Epoch 23299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23299\n",
      "Mean Log Likelihood -- train: -4.966540336608887, -- test: -18.318626403808594 \n",
      "Root Mean Squared Error -- train: 0.3563758134841919, -- test: 0.6277304291725159 \n",
      " \n",
      "#################### Sampling at Epoch 23349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23349\n",
      "Mean Log Likelihood -- train: -4.993906497955322, -- test: -18.075279235839844 \n",
      "Root Mean Squared Error -- train: 0.3571428954601288, -- test: 0.6238417029380798 \n",
      " \n",
      "#################### Sampling at Epoch 23399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23399\n",
      "Mean Log Likelihood -- train: -4.97850227355957, -- test: -16.406856536865234 \n",
      "Root Mean Squared Error -- train: 0.35671132802963257, -- test: 0.5964981317520142 \n",
      " \n",
      "#################### Sampling at Epoch 23449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23449\n",
      "Mean Log Likelihood -- train: -4.991446018218994, -- test: -15.82931900024414 \n",
      "Root Mean Squared Error -- train: 0.3570740222930908, -- test: 0.5867361426353455 \n",
      " \n",
      "#################### Sampling at Epoch 23499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23499\n",
      "Mean Log Likelihood -- train: -4.935926914215088, -- test: -16.94220733642578 \n",
      "Root Mean Squared Error -- train: 0.3555157780647278, -- test: 0.6054065823554993 \n",
      " \n",
      "#################### Sampling at Epoch 23549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23549\n",
      "Mean Log Likelihood -- train: -5.0533342361450195, -- test: -18.25655746459961 \n",
      "Root Mean Squared Error -- train: 0.35880306363105774, -- test: 0.6267408728599548 \n",
      " \n",
      "#################### Sampling at Epoch 23599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23599\n",
      "Mean Log Likelihood -- train: -5.04359245300293, -- test: -19.577964782714844 \n",
      "Root Mean Squared Error -- train: 0.3585314452648163, -- test: 0.6474814414978027 \n",
      " \n",
      "#################### Sampling at Epoch 23649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23649\n",
      "Mean Log Likelihood -- train: -5.074248313903809, -- test: -21.842615127563477 \n",
      "Root Mean Squared Error -- train: 0.3593854308128357, -- test: 0.6815608739852905 \n",
      " \n",
      "#################### Sampling at Epoch 23699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23699\n",
      "Mean Log Likelihood -- train: -4.939845561981201, -- test: -20.947998046875 \n",
      "Root Mean Squared Error -- train: 0.3556259870529175, -- test: 0.6683059930801392 \n",
      " \n",
      "#################### Sampling at Epoch 23749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23749\n",
      "Mean Log Likelihood -- train: -5.0426459312438965, -- test: -22.59778594970703 \n",
      "Root Mean Squared Error -- train: 0.3585050106048584, -- test: 0.6925522089004517 \n",
      " \n",
      "#################### Sampling at Epoch 23799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23799\n",
      "Mean Log Likelihood -- train: -5.060940742492676, -- test: -23.82073211669922 \n",
      "Root Mean Squared Error -- train: 0.35901495814323425, -- test: 0.7099912762641907 \n",
      " \n",
      "#################### Sampling at Epoch 23849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23849\n",
      "Mean Log Likelihood -- train: -5.091448783874512, -- test: -23.478078842163086 \n",
      "Root Mean Squared Error -- train: 0.3598636984825134, -- test: 0.7051485776901245 \n",
      " \n",
      "#################### Sampling at Epoch 23899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23899\n",
      "Mean Log Likelihood -- train: -5.091720104217529, -- test: -21.700742721557617 \n",
      "Root Mean Squared Error -- train: 0.3598712682723999, -- test: 0.6794760823249817 \n",
      " \n",
      "#################### Sampling at Epoch 23949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23949\n",
      "Mean Log Likelihood -- train: -5.031540393829346, -- test: -21.258747100830078 \n",
      "Root Mean Squared Error -- train: 0.35819512605667114, -- test: 0.6729397177696228 \n",
      " \n",
      "#################### Sampling at Epoch 23999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 23999\n",
      "Mean Log Likelihood -- train: -5.02964973449707, -- test: -21.60385513305664 \n",
      "Root Mean Squared Error -- train: 0.35814234614372253, -- test: 0.6780487298965454 \n",
      " \n",
      "#################### Sampling at Epoch 24049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24049\n",
      "Mean Log Likelihood -- train: -5.1216349601745605, -- test: -22.769428253173828 \n",
      "Root Mean Squared Error -- train: 0.3607015907764435, -- test: 0.6950262188911438 \n",
      " \n",
      "#################### Sampling at Epoch 24099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24099\n",
      "Mean Log Likelihood -- train: -5.116800308227539, -- test: -21.41665267944336 \n",
      "Root Mean Squared Error -- train: 0.36056751012802124, -- test: 0.6752821803092957 \n",
      " \n",
      "#################### Sampling at Epoch 24149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24149\n",
      "Mean Log Likelihood -- train: -5.101926803588867, -- test: -21.55065155029297 \n",
      "Root Mean Squared Error -- train: 0.36015477776527405, -- test: 0.6772635579109192 \n",
      " \n",
      "#################### Sampling at Epoch 24199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24199\n",
      "Mean Log Likelihood -- train: -5.142457485198975, -- test: -21.440427780151367 \n",
      "Root Mean Squared Error -- train: 0.36127838492393494, -- test: 0.6756341457366943 \n",
      " \n",
      "#################### Sampling at Epoch 24249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24249\n",
      "Mean Log Likelihood -- train: -5.155845642089844, -- test: -21.119182586669922 \n",
      "Root Mean Squared Error -- train: 0.3616487681865692, -- test: 0.6708625555038452 \n",
      " \n",
      "#################### Sampling at Epoch 24299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24299\n",
      "Mean Log Likelihood -- train: -5.169508934020996, -- test: -22.81572723388672 \n",
      "Root Mean Squared Error -- train: 0.3620263934135437, -- test: 0.6956920623779297 \n",
      " \n",
      "#################### Sampling at Epoch 24349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24349\n",
      "Mean Log Likelihood -- train: -5.188885688781738, -- test: -22.266843795776367 \n",
      "Root Mean Squared Error -- train: 0.3625612258911133, -- test: 0.6877570748329163 \n",
      " \n",
      "#################### Sampling at Epoch 24399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24399\n",
      "Mean Log Likelihood -- train: -5.127380847930908, -- test: -22.307191848754883 \n",
      "Root Mean Squared Error -- train: 0.3608608543872833, -- test: 0.6883435249328613 \n",
      " \n",
      "#################### Sampling at Epoch 24449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24449\n",
      "Mean Log Likelihood -- train: -5.137602806091309, -- test: -23.194475173950195 \n",
      "Root Mean Squared Error -- train: 0.3611440062522888, -- test: 0.7011151313781738 \n",
      " \n",
      "#################### Sampling at Epoch 24499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24499\n",
      "Mean Log Likelihood -- train: -5.118675708770752, -- test: -21.51276206970215 \n",
      "Root Mean Squared Error -- train: 0.36061951518058777, -- test: 0.6767038702964783 \n",
      " \n",
      "#################### Sampling at Epoch 24549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24549\n",
      "Mean Log Likelihood -- train: -5.079087257385254, -- test: -21.808767318725586 \n",
      "Root Mean Squared Error -- train: 0.3595200479030609, -- test: 0.6810641288757324 \n",
      " \n",
      "#################### Sampling at Epoch 24599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24599\n",
      "Mean Log Likelihood -- train: -5.04975700378418, -- test: -21.36493682861328 \n",
      "Root Mean Squared Error -- train: 0.3587033152580261, -- test: 0.6745159029960632 \n",
      " \n",
      "#################### Sampling at Epoch 24649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24649\n",
      "Mean Log Likelihood -- train: -5.033882141113281, -- test: -22.9025936126709 \n",
      "Root Mean Squared Error -- train: 0.35826048254966736, -- test: 0.6969395875930786 \n",
      " \n",
      "#################### Sampling at Epoch 24699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24699\n",
      "Mean Log Likelihood -- train: -5.047247409820557, -- test: -22.703290939331055 \n",
      "Root Mean Squared Error -- train: 0.3586333394050598, -- test: 0.6940739750862122 \n",
      " \n",
      "#################### Sampling at Epoch 24749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24749\n",
      "Mean Log Likelihood -- train: -5.077553749084473, -- test: -22.978361129760742 \n",
      "Root Mean Squared Error -- train: 0.3594774007797241, -- test: 0.6980258822441101 \n",
      " \n",
      "#################### Sampling at Epoch 24799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24799\n",
      "Mean Log Likelihood -- train: -5.05769157409668, -- test: -22.06683921813965 \n",
      "Root Mean Squared Error -- train: 0.3589244782924652, -- test: 0.6848428249359131 \n",
      " \n",
      "#################### Sampling at Epoch 24849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24849\n",
      "Mean Log Likelihood -- train: -5.1015095710754395, -- test: -24.309852600097656 \n",
      "Root Mean Squared Error -- train: 0.36014318466186523, -- test: 0.7168472409248352 \n",
      " \n",
      "#################### Sampling at Epoch 24899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24899\n",
      "Mean Log Likelihood -- train: -5.120177268981934, -- test: -24.163415908813477 \n",
      "Root Mean Squared Error -- train: 0.3606611490249634, -- test: 0.7148014903068542 \n",
      " \n",
      "#################### Sampling at Epoch 24949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24949\n",
      "Mean Log Likelihood -- train: -5.138646602630615, -- test: -22.846406936645508 \n",
      "Root Mean Squared Error -- train: 0.3611729145050049, -- test: 0.6961328983306885 \n",
      " \n",
      "#################### Sampling at Epoch 24999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 24999\n",
      "Mean Log Likelihood -- train: -5.1173014640808105, -- test: -21.708152770996094 \n",
      "Root Mean Squared Error -- train: 0.3605814278125763, -- test: 0.6795850992202759 \n",
      " \n",
      "#################### Sampling at Epoch 25049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25049\n",
      "Mean Log Likelihood -- train: -5.104074954986572, -- test: -21.463790893554688 \n",
      "Root Mean Squared Error -- train: 0.36021438241004944, -- test: 0.6759798526763916 \n",
      " \n",
      "#################### Sampling at Epoch 25099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25099\n",
      "Mean Log Likelihood -- train: -5.144655704498291, -- test: -21.769250869750977 \n",
      "Root Mean Squared Error -- train: 0.3613392412662506, -- test: 0.6804835796356201 \n",
      " \n",
      "#################### Sampling at Epoch 25149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25149\n",
      "Mean Log Likelihood -- train: -5.170265197753906, -- test: -22.23760223388672 \n",
      "Root Mean Squared Error -- train: 0.3620472848415375, -- test: 0.6873317360877991 \n",
      " \n",
      "#################### Sampling at Epoch 25199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25199\n",
      "Mean Log Likelihood -- train: -5.178709030151367, -- test: -22.981067657470703 \n",
      "Root Mean Squared Error -- train: 0.36228039860725403, -- test: 0.6980646252632141 \n",
      " \n",
      "#################### Sampling at Epoch 25249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25249\n",
      "Mean Log Likelihood -- train: -5.22670841217041, -- test: -22.938430786132812 \n",
      "Root Mean Squared Error -- train: 0.36360296607017517, -- test: 0.6974535584449768 \n",
      " \n",
      "#################### Sampling at Epoch 25299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25299\n",
      "Mean Log Likelihood -- train: -5.13923454284668, -- test: -21.900224685668945 \n",
      "Root Mean Squared Error -- train: 0.3611891567707062, -- test: 0.6824055910110474 \n",
      " \n",
      "#################### Sampling at Epoch 25349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25349\n",
      "Mean Log Likelihood -- train: -5.18480110168457, -- test: -22.634994506835938 \n",
      "Root Mean Squared Error -- train: 0.3624485433101654, -- test: 0.6930893659591675 \n",
      " \n",
      "#################### Sampling at Epoch 25399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25399\n",
      "Mean Log Likelihood -- train: -5.064565658569336, -- test: -22.362577438354492 \n",
      "Root Mean Squared Error -- train: 0.3591158986091614, -- test: 0.6891476511955261 \n",
      " \n",
      "#################### Sampling at Epoch 25449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25449\n",
      "Mean Log Likelihood -- train: -4.985398292541504, -- test: -21.6495418548584 \n",
      "Root Mean Squared Error -- train: 0.3569045960903168, -- test: 0.678722083568573 \n",
      " \n",
      "#################### Sampling at Epoch 25499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25499\n",
      "Mean Log Likelihood -- train: -4.958719253540039, -- test: -21.034473419189453 \n",
      "Root Mean Squared Error -- train: 0.3561563193798065, -- test: 0.6695986390113831 \n",
      " \n",
      "#################### Sampling at Epoch 25549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25549\n",
      "Mean Log Likelihood -- train: -4.968146800994873, -- test: -22.07843780517578 \n",
      "Root Mean Squared Error -- train: 0.3564209043979645, -- test: 0.68501216173172 \n",
      " \n",
      "#################### Sampling at Epoch 25599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25599\n",
      "Mean Log Likelihood -- train: -4.944823265075684, -- test: -20.831876754760742 \n",
      "Root Mean Squared Error -- train: 0.3557659089565277, -- test: 0.6665661931037903 \n",
      " \n",
      "#################### Sampling at Epoch 25649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25649\n",
      "Mean Log Likelihood -- train: -5.005186080932617, -- test: -21.94571304321289 \n",
      "Root Mean Squared Error -- train: 0.35745859146118164, -- test: 0.6830718517303467 \n",
      " \n",
      "#################### Sampling at Epoch 25699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25699\n",
      "Mean Log Likelihood -- train: -5.10774564743042, -- test: -21.564048767089844 \n",
      "Root Mean Squared Error -- train: 0.36031630635261536, -- test: 0.6774613261222839 \n",
      " \n",
      "#################### Sampling at Epoch 25749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25749\n",
      "Mean Log Likelihood -- train: -4.995127201080322, -- test: -21.208932876586914 \n",
      "Root Mean Squared Error -- train: 0.35717710852622986, -- test: 0.6721990704536438 \n",
      " \n",
      "#################### Sampling at Epoch 25799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25799\n",
      "Mean Log Likelihood -- train: -4.888833999633789, -- test: -21.362842559814453 \n",
      "Root Mean Squared Error -- train: 0.3541886508464813, -- test: 0.6744848489761353 \n",
      " \n",
      "#################### Sampling at Epoch 25849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25849\n",
      "Mean Log Likelihood -- train: -4.881896018981934, -- test: -21.068796157836914 \n",
      "Root Mean Squared Error -- train: 0.3539927303791046, -- test: 0.6701110601425171 \n",
      " \n",
      "#################### Sampling at Epoch 25899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25899\n",
      "Mean Log Likelihood -- train: -4.881914138793945, -- test: -20.843036651611328 \n",
      "Root Mean Squared Error -- train: 0.3539932370185852, -- test: 0.6667336225509644 \n",
      " \n",
      "#################### Sampling at Epoch 25949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25949\n",
      "Mean Log Likelihood -- train: -4.924086570739746, -- test: -20.22286033630371 \n",
      "Root Mean Squared Error -- train: 0.35518255829811096, -- test: 0.6573660373687744 \n",
      " \n",
      "#################### Sampling at Epoch 25999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 25999\n",
      "Mean Log Likelihood -- train: -4.982702255249023, -- test: -21.197219848632812 \n",
      "Root Mean Squared Error -- train: 0.35682904720306396, -- test: 0.6720247864723206 \n",
      " \n",
      "#################### Sampling at Epoch 26049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26049\n",
      "Mean Log Likelihood -- train: -4.971829414367676, -- test: -21.201513290405273 \n",
      "Root Mean Squared Error -- train: 0.3565242290496826, -- test: 0.6720886826515198 \n",
      " \n",
      "#################### Sampling at Epoch 26099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26099\n",
      "Mean Log Likelihood -- train: -4.925046443939209, -- test: -21.528261184692383 \n",
      "Root Mean Squared Error -- train: 0.355209618806839, -- test: 0.6769328713417053 \n",
      " \n",
      "#################### Sampling at Epoch 26149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26149\n",
      "Mean Log Likelihood -- train: -4.892274379730225, -- test: -20.956613540649414 \n",
      "Root Mean Squared Error -- train: 0.3542857766151428, -- test: 0.6684348583221436 \n",
      " \n",
      "#################### Sampling at Epoch 26199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26199\n",
      "Mean Log Likelihood -- train: -4.928437232971191, -- test: -22.560644149780273 \n",
      "Root Mean Squared Error -- train: 0.3553050458431244, -- test: 0.6920157670974731 \n",
      " \n",
      "#################### Sampling at Epoch 26249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26249\n",
      "Mean Log Likelihood -- train: -4.922095775604248, -- test: -20.723304748535156 \n",
      "Root Mean Squared Error -- train: 0.3551265299320221, -- test: 0.6649353504180908 \n",
      " \n",
      "#################### Sampling at Epoch 26299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26299\n",
      "Mean Log Likelihood -- train: -5.004576683044434, -- test: -22.344436645507812 \n",
      "Root Mean Squared Error -- train: 0.3574415445327759, -- test: 0.6888843178749084 \n",
      " \n",
      "#################### Sampling at Epoch 26349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26349\n",
      "Mean Log Likelihood -- train: -4.980391502380371, -- test: -22.8757266998291 \n",
      "Root Mean Squared Error -- train: 0.3567642867565155, -- test: 0.6965539455413818 \n",
      " \n",
      "#################### Sampling at Epoch 26399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26399\n",
      "Mean Log Likelihood -- train: -4.90380859375, -- test: -21.87082290649414 \n",
      "Root Mean Squared Error -- train: 0.35461118817329407, -- test: 0.6819745898246765 \n",
      " \n",
      "#################### Sampling at Epoch 26449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26449\n",
      "Mean Log Likelihood -- train: -4.890093803405762, -- test: -23.0505428314209 \n",
      "Root Mean Squared Error -- train: 0.35422420501708984, -- test: 0.6990591287612915 \n",
      " \n",
      "#################### Sampling at Epoch 26499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26499\n",
      "Mean Log Likelihood -- train: -4.9666571617126465, -- test: -23.155927658081055 \n",
      "Root Mean Squared Error -- train: 0.35637909173965454, -- test: 0.7005650997161865 \n",
      " \n",
      "#################### Sampling at Epoch 26549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26549\n",
      "Mean Log Likelihood -- train: -4.906868934631348, -- test: -23.357017517089844 \n",
      "Root Mean Squared Error -- train: 0.35469749569892883, -- test: 0.703429639339447 \n",
      " \n",
      "#################### Sampling at Epoch 26599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26599\n",
      "Mean Log Likelihood -- train: -4.892453193664551, -- test: -23.026479721069336 \n",
      "Root Mean Squared Error -- train: 0.35429081320762634, -- test: 0.6987148523330688 \n",
      " \n",
      "#################### Sampling at Epoch 26649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26649\n",
      "Mean Log Likelihood -- train: -4.914610385894775, -- test: -22.563547134399414 \n",
      "Root Mean Squared Error -- train: 0.35491564869880676, -- test: 0.6920576691627502 \n",
      " \n",
      "#################### Sampling at Epoch 26699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26699\n",
      "Mean Log Likelihood -- train: -4.839555263519287, -- test: -22.236650466918945 \n",
      "Root Mean Squared Error -- train: 0.3527946174144745, -- test: 0.6873178482055664 \n",
      " \n",
      "#################### Sampling at Epoch 26749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26749\n",
      "Mean Log Likelihood -- train: -4.891426086425781, -- test: -20.97895050048828 \n",
      "Root Mean Squared Error -- train: 0.3542618453502655, -- test: 0.6687690019607544 \n",
      " \n",
      "#################### Sampling at Epoch 26799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26799\n",
      "Mean Log Likelihood -- train: -4.89300537109375, -- test: -21.414539337158203 \n",
      "Root Mean Squared Error -- train: 0.3543064296245575, -- test: 0.6752508282661438 \n",
      " \n",
      "#################### Sampling at Epoch 26849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26849\n",
      "Mean Log Likelihood -- train: -4.900580883026123, -- test: -20.95486831665039 \n",
      "Root Mean Squared Error -- train: 0.35452014207839966, -- test: 0.6684087514877319 \n",
      " \n",
      "#################### Sampling at Epoch 26899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26899\n",
      "Mean Log Likelihood -- train: -4.9300031661987305, -- test: -20.585878372192383 \n",
      "Root Mean Squared Error -- train: 0.3553491234779358, -- test: 0.662865400314331 \n",
      " \n",
      "#################### Sampling at Epoch 26949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26949\n",
      "Mean Log Likelihood -- train: -4.93250846862793, -- test: -22.077909469604492 \n",
      "Root Mean Squared Error -- train: 0.3554196059703827, -- test: 0.6850044131278992 \n",
      " \n",
      "#################### Sampling at Epoch 26999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 26999\n",
      "Mean Log Likelihood -- train: -4.936185836791992, -- test: -21.648481369018555 \n",
      "Root Mean Squared Error -- train: 0.3555230498313904, -- test: 0.6787065267562866 \n",
      " \n",
      "#################### Sampling at Epoch 27049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27049\n",
      "Mean Log Likelihood -- train: -4.882872581481934, -- test: -21.484315872192383 \n",
      "Root Mean Squared Error -- train: 0.35402029752731323, -- test: 0.6762834191322327 \n",
      " \n",
      "#################### Sampling at Epoch 27099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27099\n",
      "Mean Log Likelihood -- train: -4.941915988922119, -- test: -19.408166885375977 \n",
      "Root Mean Squared Error -- train: 0.35568422079086304, -- test: 0.6448536515235901 \n",
      " \n",
      "#################### Sampling at Epoch 27149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27149\n",
      "Mean Log Likelihood -- train: -4.919592380523682, -- test: -21.3253231048584 \n",
      "Root Mean Squared Error -- train: 0.3550560176372528, -- test: 0.6739283204078674 \n",
      " \n",
      "#################### Sampling at Epoch 27199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27199\n",
      "Mean Log Likelihood -- train: -4.961817741394043, -- test: -19.92380714416504 \n",
      "Root Mean Squared Error -- train: 0.3562433123588562, -- test: 0.6528009176254272 \n",
      " \n",
      "#################### Sampling at Epoch 27249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27249\n",
      "Mean Log Likelihood -- train: -4.940081596374512, -- test: -23.754560470581055 \n",
      "Root Mean Squared Error -- train: 0.35563263297080994, -- test: 0.7090585827827454 \n",
      " \n",
      "#################### Sampling at Epoch 27299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27299\n",
      "Mean Log Likelihood -- train: -4.972282886505127, -- test: -24.058019638061523 \n",
      "Root Mean Squared Error -- train: 0.3565369248390198, -- test: 0.7133255004882812 \n",
      " \n",
      "#################### Sampling at Epoch 27349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27349\n",
      "Mean Log Likelihood -- train: -4.93907356262207, -- test: -22.034862518310547 \n",
      "Root Mean Squared Error -- train: 0.35560426115989685, -- test: 0.6843757629394531 \n",
      " \n",
      "#################### Sampling at Epoch 27399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27399\n",
      "Mean Log Likelihood -- train: -5.060564994812012, -- test: -21.933168411254883 \n",
      "Root Mean Squared Error -- train: 0.35900452733039856, -- test: 0.6828881502151489 \n",
      " \n",
      "#################### Sampling at Epoch 27449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27449\n",
      "Mean Log Likelihood -- train: -4.94207763671875, -- test: -20.178054809570312 \n",
      "Root Mean Squared Error -- train: 0.35568875074386597, -- test: 0.6566841006278992 \n",
      " \n",
      "#################### Sampling at Epoch 27499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27499\n",
      "Mean Log Likelihood -- train: -5.02148962020874, -- test: -19.16900634765625 \n",
      "Root Mean Squared Error -- train: 0.35791438817977905, -- test: 0.6411341428756714 \n",
      " \n",
      "#################### Sampling at Epoch 27549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27549\n",
      "Mean Log Likelihood -- train: -4.9417853355407715, -- test: -19.730552673339844 \n",
      "Root Mean Squared Error -- train: 0.35568052530288696, -- test: 0.6498337984085083 \n",
      " \n",
      "#################### Sampling at Epoch 27599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27599\n",
      "Mean Log Likelihood -- train: -4.940231800079346, -- test: -21.482797622680664 \n",
      "Root Mean Squared Error -- train: 0.3556368350982666, -- test: 0.6762609481811523 \n",
      " \n",
      "#################### Sampling at Epoch 27649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27649\n",
      "Mean Log Likelihood -- train: -5.037492752075195, -- test: -19.799802780151367 \n",
      "Root Mean Squared Error -- train: 0.35836124420166016, -- test: 0.6508985757827759 \n",
      " \n",
      "#################### Sampling at Epoch 27699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27699\n",
      "Mean Log Likelihood -- train: -4.9305949211120605, -- test: -18.490766525268555 \n",
      "Root Mean Squared Error -- train: 0.3553657829761505, -- test: 0.6304666996002197 \n",
      " \n",
      "#################### Sampling at Epoch 27749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27749\n",
      "Mean Log Likelihood -- train: -5.00616455078125, -- test: -15.469316482543945 \n",
      "Root Mean Squared Error -- train: 0.35748594999313354, -- test: 0.5805680155754089 \n",
      " \n",
      "#################### Sampling at Epoch 27799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27799\n",
      "Mean Log Likelihood -- train: -4.94842004776001, -- test: -19.529848098754883 \n",
      "Root Mean Squared Error -- train: 0.35586702823638916, -- test: 0.6467378735542297 \n",
      " \n",
      "#################### Sampling at Epoch 27849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27849\n",
      "Mean Log Likelihood -- train: -4.966588020324707, -- test: -21.484750747680664 \n",
      "Root Mean Squared Error -- train: 0.35637715458869934, -- test: 0.6762897968292236 \n",
      " \n",
      "#################### Sampling at Epoch 27899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27899\n",
      "Mean Log Likelihood -- train: -5.018281936645508, -- test: -20.83527374267578 \n",
      "Root Mean Squared Error -- train: 0.35782477259635925, -- test: 0.6666171550750732 \n",
      " \n",
      "#################### Sampling at Epoch 27949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27949\n",
      "Mean Log Likelihood -- train: -4.922999382019043, -- test: -21.392881393432617 \n",
      "Root Mean Squared Error -- train: 0.3551519513130188, -- test: 0.6749300360679626 \n",
      " \n",
      "#################### Sampling at Epoch 27999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 27999\n",
      "Mean Log Likelihood -- train: -4.948430061340332, -- test: -21.719953536987305 \n",
      "Root Mean Squared Error -- train: 0.35586729645729065, -- test: 0.6797587275505066 \n",
      " \n",
      "#################### Sampling at Epoch 28049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28049\n",
      "Mean Log Likelihood -- train: -4.998403549194336, -- test: -21.58768081665039 \n",
      "Root Mean Squared Error -- train: 0.3572687804698944, -- test: 0.6778100728988647 \n",
      " \n",
      "#################### Sampling at Epoch 28099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28099\n",
      "Mean Log Likelihood -- train: -4.9238386154174805, -- test: -22.983510971069336 \n",
      "Root Mean Squared Error -- train: 0.35517558455467224, -- test: 0.698099672794342 \n",
      " \n",
      "#################### Sampling at Epoch 28149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28149\n",
      "Mean Log Likelihood -- train: -4.924447059631348, -- test: -23.076343536376953 \n",
      "Root Mean Squared Error -- train: 0.35519272089004517, -- test: 0.6994282007217407 \n",
      " \n",
      "#################### Sampling at Epoch 28199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28199\n",
      "Mean Log Likelihood -- train: -4.917191028594971, -- test: -22.935890197753906 \n",
      "Root Mean Squared Error -- train: 0.35498836636543274, -- test: 0.6974171996116638 \n",
      " \n",
      "#################### Sampling at Epoch 28249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28249\n",
      "Mean Log Likelihood -- train: -4.911868572235107, -- test: -23.342329025268555 \n",
      "Root Mean Squared Error -- train: 0.35483840107917786, -- test: 0.703220784664154 \n",
      " \n",
      "#################### Sampling at Epoch 28299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28299\n",
      "Mean Log Likelihood -- train: -4.839457988739014, -- test: -23.87018394470215 \n",
      "Root Mean Squared Error -- train: 0.35279184579849243, -- test: 0.7106873989105225 \n",
      " \n",
      "#################### Sampling at Epoch 28349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28349\n",
      "Mean Log Likelihood -- train: -4.82148551940918, -- test: -22.890016555786133 \n",
      "Root Mean Squared Error -- train: 0.35228201746940613, -- test: 0.6967591047286987 \n",
      " \n",
      "#################### Sampling at Epoch 28399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28399\n",
      "Mean Log Likelihood -- train: -4.819478511810303, -- test: -22.971782684326172 \n",
      "Root Mean Squared Error -- train: 0.35222506523132324, -- test: 0.6979316473007202 \n",
      " \n",
      "#################### Sampling at Epoch 28449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28449\n",
      "Mean Log Likelihood -- train: -4.882753372192383, -- test: -22.270591735839844 \n",
      "Root Mean Squared Error -- train: 0.3540169298648834, -- test: 0.687811553478241 \n",
      " \n",
      "#################### Sampling at Epoch 28499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28499\n",
      "Mean Log Likelihood -- train: -4.930188179016113, -- test: -22.50665855407715 \n",
      "Root Mean Squared Error -- train: 0.35535433888435364, -- test: 0.6912351846694946 \n",
      " \n",
      "#################### Sampling at Epoch 28549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28549\n",
      "Mean Log Likelihood -- train: -4.883749008178711, -- test: -22.662744522094727 \n",
      "Root Mean Squared Error -- train: 0.354045033454895, -- test: 0.6934896111488342 \n",
      " \n",
      "#################### Sampling at Epoch 28599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28599\n",
      "Mean Log Likelihood -- train: -4.947089195251465, -- test: -22.096216201782227 \n",
      "Root Mean Squared Error -- train: 0.3558296263217926, -- test: 0.685271680355072 \n",
      " \n",
      "#################### Sampling at Epoch 28649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28649\n",
      "Mean Log Likelihood -- train: -5.039334297180176, -- test: -23.522380828857422 \n",
      "Root Mean Squared Error -- train: 0.35841262340545654, -- test: 0.705776572227478 \n",
      " \n",
      "#################### Sampling at Epoch 28699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28699\n",
      "Mean Log Likelihood -- train: -4.958455562591553, -- test: -22.796554565429688 \n",
      "Root Mean Squared Error -- train: 0.356148898601532, -- test: 0.6954164505004883 \n",
      " \n",
      "#################### Sampling at Epoch 28749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28749\n",
      "Mean Log Likelihood -- train: -4.981173515319824, -- test: -21.95899200439453 \n",
      "Root Mean Squared Error -- train: 0.35678619146347046, -- test: 0.6832662224769592 \n",
      " \n",
      "#################### Sampling at Epoch 28799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28799\n",
      "Mean Log Likelihood -- train: -4.964786052703857, -- test: -22.18618392944336 \n",
      "Root Mean Squared Error -- train: 0.3563266098499298, -- test: 0.6865832805633545 \n",
      " \n",
      "#################### Sampling at Epoch 28849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28849\n",
      "Mean Log Likelihood -- train: -4.908899784088135, -- test: -22.360145568847656 \n",
      "Root Mean Squared Error -- train: 0.3547547459602356, -- test: 0.6891123652458191 \n",
      " \n",
      "#################### Sampling at Epoch 28899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28899\n",
      "Mean Log Likelihood -- train: -4.9861650466918945, -- test: -23.74551010131836 \n",
      "Root Mean Squared Error -- train: 0.3569260537624359, -- test: 0.7089309096336365 \n",
      " \n",
      "#################### Sampling at Epoch 28949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28949\n",
      "Mean Log Likelihood -- train: -5.024218559265137, -- test: -23.619892120361328 \n",
      "Root Mean Squared Error -- train: 0.35799065232276917, -- test: 0.7071568369865417 \n",
      " \n",
      "#################### Sampling at Epoch 28999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 28999\n",
      "Mean Log Likelihood -- train: -5.0243144035339355, -- test: -24.628454208374023 \n",
      "Root Mean Squared Error -- train: 0.35799333453178406, -- test: 0.7212780714035034 \n",
      " \n",
      "#################### Sampling at Epoch 29049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29049\n",
      "Mean Log Likelihood -- train: -5.046848773956299, -- test: -23.14885711669922 \n",
      "Root Mean Squared Error -- train: 0.3586222529411316, -- test: 0.7004641890525818 \n",
      " \n",
      "#################### Sampling at Epoch 29099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29099\n",
      "Mean Log Likelihood -- train: -4.995728492736816, -- test: -22.503101348876953 \n",
      "Root Mean Squared Error -- train: 0.3571939170360565, -- test: 0.6911836862564087 \n",
      " \n",
      "#################### Sampling at Epoch 29149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29149\n",
      "Mean Log Likelihood -- train: -4.982881546020508, -- test: -22.406538009643555 \n",
      "Root Mean Squared Error -- train: 0.3568340837955475, -- test: 0.6897852420806885 \n",
      " \n",
      "#################### Sampling at Epoch 29199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29199\n",
      "Mean Log Likelihood -- train: -5.0026679039001465, -- test: -21.743619918823242 \n",
      "Root Mean Squared Error -- train: 0.35738813877105713, -- test: 0.6801068782806396 \n",
      " \n",
      "#################### Sampling at Epoch 29249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29249\n",
      "Mean Log Likelihood -- train: -4.916436195373535, -- test: -22.711389541625977 \n",
      "Root Mean Squared Error -- train: 0.3549671173095703, -- test: 0.6941906809806824 \n",
      " \n",
      "#################### Sampling at Epoch 29299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29299\n",
      "Mean Log Likelihood -- train: -4.930592060089111, -- test: -21.681737899780273 \n",
      "Root Mean Squared Error -- train: 0.35536566376686096, -- test: 0.6791963577270508 \n",
      " \n",
      "#################### Sampling at Epoch 29349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29349\n",
      "Mean Log Likelihood -- train: -4.956910133361816, -- test: -21.193147659301758 \n",
      "Root Mean Squared Error -- train: 0.3561055064201355, -- test: 0.671964168548584 \n",
      " \n",
      "#################### Sampling at Epoch 29399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29399\n",
      "Mean Log Likelihood -- train: -5.039098739624023, -- test: -22.062002182006836 \n",
      "Root Mean Squared Error -- train: 0.35840603709220886, -- test: 0.6847721934318542 \n",
      " \n",
      "#################### Sampling at Epoch 29449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29449\n",
      "Mean Log Likelihood -- train: -4.9737114906311035, -- test: -21.97223663330078 \n",
      "Root Mean Squared Error -- train: 0.3565770089626312, -- test: 0.6834600567817688 \n",
      " \n",
      "#################### Sampling at Epoch 29499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29499\n",
      "Mean Log Likelihood -- train: -4.965331077575684, -- test: -20.802186965942383 \n",
      "Root Mean Squared Error -- train: 0.3563418984413147, -- test: 0.6661205887794495 \n",
      " \n",
      "#################### Sampling at Epoch 29549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29549\n",
      "Mean Log Likelihood -- train: -4.966672420501709, -- test: -20.030616760253906 \n",
      "Root Mean Squared Error -- train: 0.35637953877449036, -- test: 0.6544350981712341 \n",
      " \n",
      "#################### Sampling at Epoch 29599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29599\n",
      "Mean Log Likelihood -- train: -4.893945217132568, -- test: -20.29454803466797 \n",
      "Root Mean Squared Error -- train: 0.35433295369148254, -- test: 0.6584556698799133 \n",
      " \n",
      "#################### Sampling at Epoch 29649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29649\n",
      "Mean Log Likelihood -- train: -4.893658638000488, -- test: -21.472402572631836 \n",
      "Root Mean Squared Error -- train: 0.3543248176574707, -- test: 0.6761072278022766 \n",
      " \n",
      "#################### Sampling at Epoch 29699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29699\n",
      "Mean Log Likelihood -- train: -4.8714447021484375, -- test: -21.0765380859375 \n",
      "Root Mean Squared Error -- train: 0.35369735956192017, -- test: 0.6702265739440918 \n",
      " \n",
      "#################### Sampling at Epoch 29749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29749\n",
      "Mean Log Likelihood -- train: -4.8655548095703125, -- test: -19.31461524963379 \n",
      "Root Mean Squared Error -- train: 0.3535308241844177, -- test: 0.6434012651443481 \n",
      " \n",
      "#################### Sampling at Epoch 29799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29799\n",
      "Mean Log Likelihood -- train: -4.921323776245117, -- test: -20.918411254882812 \n",
      "Root Mean Squared Error -- train: 0.3551047742366791, -- test: 0.6678630709648132 \n",
      " \n",
      "#################### Sampling at Epoch 29849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29849\n",
      "Mean Log Likelihood -- train: -4.902475833892822, -- test: -17.49529266357422 \n",
      "Root Mean Squared Error -- train: 0.3545736074447632, -- test: 0.614474356174469 \n",
      " \n",
      "#################### Sampling at Epoch 29899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29899\n",
      "Mean Log Likelihood -- train: -4.9201884269714355, -- test: -15.770354270935059 \n",
      "Root Mean Squared Error -- train: 0.3550727665424347, -- test: 0.5857303142547607 \n",
      " \n",
      "#################### Sampling at Epoch 29949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29949\n",
      "Mean Log Likelihood -- train: -5.038024425506592, -- test: -19.49475860595703 \n",
      "Root Mean Squared Error -- train: 0.35837608575820923, -- test: 0.646195113658905 \n",
      " \n",
      "#################### Sampling at Epoch 29999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 29999\n",
      "Mean Log Likelihood -- train: -5.070347309112549, -- test: -19.23934555053711 \n",
      "Root Mean Squared Error -- train: 0.3592768609523773, -- test: 0.6422303318977356 \n",
      " \n",
      "#################### Sampling at Epoch 30049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30049\n",
      "Mean Log Likelihood -- train: -4.972398281097412, -- test: -15.647665977478027 \n",
      "Root Mean Squared Error -- train: 0.35654017329216003, -- test: 0.5836318731307983 \n",
      " \n",
      "#################### Sampling at Epoch 30099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30099\n",
      "Mean Log Likelihood -- train: -4.959567070007324, -- test: -15.946113586425781 \n",
      "Root Mean Squared Error -- train: 0.3561801016330719, -- test: 0.5887233018875122 \n",
      " \n",
      "#################### Sampling at Epoch 30149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30149\n",
      "Mean Log Likelihood -- train: -4.957479953765869, -- test: -17.54383087158203 \n",
      "Root Mean Squared Error -- train: 0.3561215102672577, -- test: 0.615263819694519 \n",
      " \n",
      "#################### Sampling at Epoch 30199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30199\n",
      "Mean Log Likelihood -- train: -4.972023963928223, -- test: -17.015382766723633 \n",
      "Root Mean Squared Error -- train: 0.35652968287467957, -- test: 0.6066139936447144 \n",
      " \n",
      "#################### Sampling at Epoch 30249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30249\n",
      "Mean Log Likelihood -- train: -5.048140525817871, -- test: -16.2425479888916 \n",
      "Root Mean Squared Error -- train: 0.3586582541465759, -- test: 0.5937371850013733 \n",
      " \n",
      "#################### Sampling at Epoch 30299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30299\n",
      "Mean Log Likelihood -- train: -5.089620113372803, -- test: -18.109785079956055 \n",
      "Root Mean Squared Error -- train: 0.3598128855228424, -- test: 0.6243945956230164 \n",
      " \n",
      "#################### Sampling at Epoch 30349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30349\n",
      "Mean Log Likelihood -- train: -5.089842796325684, -- test: -16.50969886779785 \n",
      "Root Mean Squared Error -- train: 0.35981908440589905, -- test: 0.5982197523117065 \n",
      " \n",
      "#################### Sampling at Epoch 30399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30399\n",
      "Mean Log Likelihood -- train: -5.069860935211182, -- test: -15.455605506896973 \n",
      "Root Mean Squared Error -- train: 0.3592633008956909, -- test: 0.5803318023681641 \n",
      " \n",
      "#################### Sampling at Epoch 30449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30449\n",
      "Mean Log Likelihood -- train: -5.12622594833374, -- test: -16.883750915527344 \n",
      "Root Mean Squared Error -- train: 0.36082881689071655, -- test: 0.6044402122497559 \n",
      " \n",
      "#################### Sampling at Epoch 30499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30499\n",
      "Mean Log Likelihood -- train: -5.001429080963135, -- test: -16.958080291748047 \n",
      "Root Mean Squared Error -- train: 0.35735347867012024, -- test: 0.6056686639785767 \n",
      " \n",
      "#################### Sampling at Epoch 30549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30549\n",
      "Mean Log Likelihood -- train: -5.04559326171875, -- test: -17.126510620117188 \n",
      "Root Mean Squared Error -- train: 0.35858720541000366, -- test: 0.6084432005882263 \n",
      " \n",
      "#################### Sampling at Epoch 30599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30599\n",
      "Mean Log Likelihood -- train: -5.049670696258545, -- test: -16.827421188354492 \n",
      "Root Mean Squared Error -- train: 0.3587009012699127, -- test: 0.6035075187683105 \n",
      " \n",
      "#################### Sampling at Epoch 30649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30649\n",
      "Mean Log Likelihood -- train: -5.0337982177734375, -- test: -15.394512176513672 \n",
      "Root Mean Squared Error -- train: 0.3582581579685211, -- test: 0.5792781114578247 \n",
      " \n",
      "#################### Sampling at Epoch 30699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30699\n",
      "Mean Log Likelihood -- train: -5.042762756347656, -- test: -14.936253547668457 \n",
      "Root Mean Squared Error -- train: 0.35850825905799866, -- test: 0.5713124871253967 \n",
      " \n",
      "#################### Sampling at Epoch 30749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30749\n",
      "Mean Log Likelihood -- train: -4.982583522796631, -- test: -12.080029487609863 \n",
      "Root Mean Squared Error -- train: 0.35682573914527893, -- test: 0.5189157128334045 \n",
      " \n",
      "#################### Sampling at Epoch 30799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30799\n",
      "Mean Log Likelihood -- train: -5.088346481323242, -- test: -12.994091987609863 \n",
      "Root Mean Squared Error -- train: 0.3597775101661682, -- test: 0.536241352558136 \n",
      " \n",
      "#################### Sampling at Epoch 30849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30849\n",
      "Mean Log Likelihood -- train: -5.033254623413086, -- test: -12.332877159118652 \n",
      "Root Mean Squared Error -- train: 0.3582429587841034, -- test: 0.5237656831741333 \n",
      " \n",
      "#################### Sampling at Epoch 30899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30899\n",
      "Mean Log Likelihood -- train: -4.994474411010742, -- test: -12.652299880981445 \n",
      "Root Mean Squared Error -- train: 0.3571588397026062, -- test: 0.5298291444778442 \n",
      " \n",
      "#################### Sampling at Epoch 30949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30949\n",
      "Mean Log Likelihood -- train: -5.051426410675049, -- test: -14.708081245422363 \n",
      "Root Mean Squared Error -- train: 0.3587498664855957, -- test: 0.5673046112060547 \n",
      " \n",
      "#################### Sampling at Epoch 30999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 30999\n",
      "Mean Log Likelihood -- train: -5.074344158172607, -- test: -15.8098783493042 \n",
      "Root Mean Squared Error -- train: 0.3593881130218506, -- test: 0.5864046812057495 \n",
      " \n",
      "#################### Sampling at Epoch 31049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31049\n",
      "Mean Log Likelihood -- train: -5.073328495025635, -- test: -18.699634552001953 \n",
      "Root Mean Squared Error -- train: 0.35935983061790466, -- test: 0.6337710022926331 \n",
      " \n",
      "#################### Sampling at Epoch 31099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31099\n",
      "Mean Log Likelihood -- train: -5.108315944671631, -- test: -17.40384864807129 \n",
      "Root Mean Squared Error -- train: 0.3603321313858032, -- test: 0.6129844188690186 \n",
      " \n",
      "#################### Sampling at Epoch 31149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31149\n",
      "Mean Log Likelihood -- train: -5.090958595275879, -- test: -17.219404220581055 \n",
      "Root Mean Squared Error -- train: 0.35985010862350464, -- test: 0.6099680066108704 \n",
      " \n",
      "#################### Sampling at Epoch 31199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31199\n",
      "Mean Log Likelihood -- train: -5.185879707336426, -- test: -17.646007537841797 \n",
      "Root Mean Squared Error -- train: 0.3624783158302307, -- test: 0.6169222593307495 \n",
      " \n",
      "#################### Sampling at Epoch 31249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31249\n",
      "Mean Log Likelihood -- train: -5.122970104217529, -- test: -16.952184677124023 \n",
      "Root Mean Squared Error -- train: 0.360738605260849, -- test: 0.6055713295936584 \n",
      " \n",
      "#################### Sampling at Epoch 31299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31299\n",
      "Mean Log Likelihood -- train: -5.167391777038574, -- test: -15.09918212890625 \n",
      "Root Mean Squared Error -- train: 0.36196789145469666, -- test: 0.5741572976112366 \n",
      " \n",
      "#################### Sampling at Epoch 31349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31349\n",
      "Mean Log Likelihood -- train: -5.099565029144287, -- test: -15.303413391113281 \n",
      "Root Mean Squared Error -- train: 0.36008915305137634, -- test: 0.5777034163475037 \n",
      " \n",
      "#################### Sampling at Epoch 31399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31399\n",
      "Mean Log Likelihood -- train: -5.135793209075928, -- test: -16.464710235595703 \n",
      "Root Mean Squared Error -- train: 0.3610938787460327, -- test: 0.5974672436714172 \n",
      " \n",
      "#################### Sampling at Epoch 31449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31449\n",
      "Mean Log Likelihood -- train: -5.02880859375, -- test: -17.185413360595703 \n",
      "Root Mean Squared Error -- train: 0.35811883211135864, -- test: 0.6094105243682861 \n",
      " \n",
      "#################### Sampling at Epoch 31499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31499\n",
      "Mean Log Likelihood -- train: -5.066953659057617, -- test: -18.96295738220215 \n",
      "Root Mean Squared Error -- train: 0.3591823875904083, -- test: 0.6379122734069824 \n",
      " \n",
      "#################### Sampling at Epoch 31549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31549\n",
      "Mean Log Likelihood -- train: -5.023766994476318, -- test: -17.57494354248047 \n",
      "Root Mean Squared Error -- train: 0.3579780161380768, -- test: 0.6157692670822144 \n",
      " \n",
      "#################### Sampling at Epoch 31599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31599\n",
      "Mean Log Likelihood -- train: -5.012008190155029, -- test: -18.32910919189453 \n",
      "Root Mean Squared Error -- train: 0.35764938592910767, -- test: 0.6278973817825317 \n",
      " \n",
      "#################### Sampling at Epoch 31649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31649\n",
      "Mean Log Likelihood -- train: -4.936905860900879, -- test: -17.68389320373535 \n",
      "Root Mean Squared Error -- train: 0.3555432856082916, -- test: 0.6175360679626465 \n",
      " \n",
      "#################### Sampling at Epoch 31699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31699\n",
      "Mean Log Likelihood -- train: -4.960154056549072, -- test: -19.374107360839844 \n",
      "Root Mean Squared Error -- train: 0.3561965823173523, -- test: 0.6443252563476562 \n",
      " \n",
      "#################### Sampling at Epoch 31749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31749\n",
      "Mean Log Likelihood -- train: -4.8770856857299805, -- test: -18.180587768554688 \n",
      "Root Mean Squared Error -- train: 0.35385680198669434, -- test: 0.6255275011062622 \n",
      " \n",
      "#################### Sampling at Epoch 31799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31799\n",
      "Mean Log Likelihood -- train: -4.892895698547363, -- test: -18.8173770904541 \n",
      "Root Mean Squared Error -- train: 0.3543033301830292, -- test: 0.6356260776519775 \n",
      " \n",
      "#################### Sampling at Epoch 31849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31849\n",
      "Mean Log Likelihood -- train: -4.981186389923096, -- test: -18.697532653808594 \n",
      "Root Mean Squared Error -- train: 0.3567865490913391, -- test: 0.6337378025054932 \n",
      " \n",
      "#################### Sampling at Epoch 31899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31899\n",
      "Mean Log Likelihood -- train: -4.950112342834473, -- test: -18.717500686645508 \n",
      "Root Mean Squared Error -- train: 0.35591456294059753, -- test: 0.6340528130531311 \n",
      " \n",
      "#################### Sampling at Epoch 31949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31949\n",
      "Mean Log Likelihood -- train: -4.916404724121094, -- test: -18.514490127563477 \n",
      "Root Mean Squared Error -- train: 0.3549662232398987, -- test: 0.6308428645133972 \n",
      " \n",
      "#################### Sampling at Epoch 31999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 31999\n",
      "Mean Log Likelihood -- train: -4.977661609649658, -- test: -18.853797912597656 \n",
      "Root Mean Squared Error -- train: 0.3566877543926239, -- test: 0.6361988186836243 \n",
      " \n",
      "#################### Sampling at Epoch 32049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32049\n",
      "Mean Log Likelihood -- train: -4.966741561889648, -- test: -19.413719177246094 \n",
      "Root Mean Squared Error -- train: 0.35638147592544556, -- test: 0.6449397802352905 \n",
      " \n",
      "#################### Sampling at Epoch 32099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32099\n",
      "Mean Log Likelihood -- train: -5.010977268218994, -- test: -19.038244247436523 \n",
      "Root Mean Squared Error -- train: 0.35762056708335876, -- test: 0.639091432094574 \n",
      " \n",
      "#################### Sampling at Epoch 32149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32149\n",
      "Mean Log Likelihood -- train: -4.965579032897949, -- test: -19.333093643188477 \n",
      "Root Mean Squared Error -- train: 0.3563488721847534, -- test: 0.6436883807182312 \n",
      " \n",
      "#################### Sampling at Epoch 32199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32199\n",
      "Mean Log Likelihood -- train: -4.9514923095703125, -- test: -19.335617065429688 \n",
      "Root Mean Squared Error -- train: 0.3559533655643463, -- test: 0.6437276601791382 \n",
      " \n",
      "#################### Sampling at Epoch 32249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32249\n",
      "Mean Log Likelihood -- train: -4.964295864105225, -- test: -19.290794372558594 \n",
      "Root Mean Squared Error -- train: 0.3563128411769867, -- test: 0.6430309414863586 \n",
      " \n",
      "#################### Sampling at Epoch 32299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32299\n",
      "Mean Log Likelihood -- train: -5.029940605163574, -- test: -20.054044723510742 \n",
      "Root Mean Squared Error -- train: 0.358150452375412, -- test: 0.6547929644584656 \n",
      " \n",
      "#################### Sampling at Epoch 32349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32349\n",
      "Mean Log Likelihood -- train: -5.044730186462402, -- test: -20.3972110748291 \n",
      "Root Mean Squared Error -- train: 0.3585631549358368, -- test: 0.6600130200386047 \n",
      " \n",
      "#################### Sampling at Epoch 32399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32399\n",
      "Mean Log Likelihood -- train: -5.079024314880371, -- test: -20.709150314331055 \n",
      "Root Mean Squared Error -- train: 0.35951828956604004, -- test: 0.6647224426269531 \n",
      " \n",
      "#################### Sampling at Epoch 32449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32449\n",
      "Mean Log Likelihood -- train: -5.0016584396362305, -- test: -20.167211532592773 \n",
      "Root Mean Squared Error -- train: 0.3573598861694336, -- test: 0.6565189361572266 \n",
      " \n",
      "#################### Sampling at Epoch 32499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32499\n",
      "Mean Log Likelihood -- train: -4.9770026206970215, -- test: -19.7196102142334 \n",
      "Root Mean Squared Error -- train: 0.35666927695274353, -- test: 0.6496654152870178 \n",
      " \n",
      "#################### Sampling at Epoch 32549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32549\n",
      "Mean Log Likelihood -- train: -4.991431713104248, -- test: -20.965734481811523 \n",
      "Root Mean Squared Error -- train: 0.3570736050605774, -- test: 0.6685713529586792 \n",
      " \n",
      "#################### Sampling at Epoch 32599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32599\n",
      "Mean Log Likelihood -- train: -5.029420375823975, -- test: -20.30048370361328 \n",
      "Root Mean Squared Error -- train: 0.3581359386444092, -- test: 0.6585457921028137 \n",
      " \n",
      "#################### Sampling at Epoch 32649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32649\n",
      "Mean Log Likelihood -- train: -5.011464595794678, -- test: -21.136255264282227 \n",
      "Root Mean Squared Error -- train: 0.35763418674468994, -- test: 0.6711170077323914 \n",
      " \n",
      "#################### Sampling at Epoch 32699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32699\n",
      "Mean Log Likelihood -- train: -5.080541133880615, -- test: -20.915517807006836 \n",
      "Root Mean Squared Error -- train: 0.359560489654541, -- test: 0.6678197979927063 \n",
      " \n",
      "#################### Sampling at Epoch 32749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32749\n",
      "Mean Log Likelihood -- train: -4.952591896057129, -- test: -19.5067195892334 \n",
      "Root Mean Squared Error -- train: 0.3559842109680176, -- test: 0.6463801860809326 \n",
      " \n",
      "#################### Sampling at Epoch 32799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32799\n",
      "Mean Log Likelihood -- train: -4.956293106079102, -- test: -19.333955764770508 \n",
      "Root Mean Squared Error -- train: 0.35608819127082825, -- test: 0.6437017917633057 \n",
      " \n",
      "#################### Sampling at Epoch 32849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32849\n",
      "Mean Log Likelihood -- train: -5.011387825012207, -- test: -18.222532272338867 \n",
      "Root Mean Squared Error -- train: 0.357632040977478, -- test: 0.6261976957321167 \n",
      " \n",
      "#################### Sampling at Epoch 32899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32899\n",
      "Mean Log Likelihood -- train: -4.972743511199951, -- test: -19.007518768310547 \n",
      "Root Mean Squared Error -- train: 0.35654982924461365, -- test: 0.6386104226112366 \n",
      " \n",
      "#################### Sampling at Epoch 32949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32949\n",
      "Mean Log Likelihood -- train: -5.025784969329834, -- test: -18.67061996459961 \n",
      "Root Mean Squared Error -- train: 0.3580344021320343, -- test: 0.633313000202179 \n",
      " \n",
      "#################### Sampling at Epoch 32999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 32999\n",
      "Mean Log Likelihood -- train: -4.971098899841309, -- test: -20.362260818481445 \n",
      "Root Mean Squared Error -- train: 0.3565037250518799, -- test: 0.6594832539558411 \n",
      " \n",
      "#################### Sampling at Epoch 33049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33049\n",
      "Mean Log Likelihood -- train: -5.042712211608887, -- test: -20.019468307495117 \n",
      "Root Mean Squared Error -- train: 0.3585068881511688, -- test: 0.6542646884918213 \n",
      " \n",
      "#################### Sampling at Epoch 33099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33099\n",
      "Mean Log Likelihood -- train: -4.934341907501221, -- test: -19.129409790039062 \n",
      "Root Mean Squared Error -- train: 0.3554711937904358, -- test: 0.6405162215232849 \n",
      " \n",
      "#################### Sampling at Epoch 33149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33149\n",
      "Mean Log Likelihood -- train: -4.973803520202637, -- test: -20.02297019958496 \n",
      "Root Mean Squared Error -- train: 0.35657957196235657, -- test: 0.6543182134628296 \n",
      " \n",
      "#################### Sampling at Epoch 33199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33199\n",
      "Mean Log Likelihood -- train: -5.017335891723633, -- test: -19.902849197387695 \n",
      "Root Mean Squared Error -- train: 0.35779833793640137, -- test: 0.6524798274040222 \n",
      " \n",
      "#################### Sampling at Epoch 33249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33249\n",
      "Mean Log Likelihood -- train: -4.998899936676025, -- test: -19.778461456298828 \n",
      "Root Mean Squared Error -- train: 0.3572826683521271, -- test: 0.6505706310272217 \n",
      " \n",
      "#################### Sampling at Epoch 33299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33299\n",
      "Mean Log Likelihood -- train: -4.9760284423828125, -- test: -20.528789520263672 \n",
      "Root Mean Squared Error -- train: 0.356641948223114, -- test: 0.6620035171508789 \n",
      " \n",
      "#################### Sampling at Epoch 33349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33349\n",
      "Mean Log Likelihood -- train: -5.024816036224365, -- test: -20.61272430419922 \n",
      "Root Mean Squared Error -- train: 0.3580073416233063, -- test: 0.6632702946662903 \n",
      " \n",
      "#################### Sampling at Epoch 33399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33399\n",
      "Mean Log Likelihood -- train: -4.9735870361328125, -- test: -20.289567947387695 \n",
      "Root Mean Squared Error -- train: 0.35657352209091187, -- test: 0.6583799719810486 \n",
      " \n",
      "#################### Sampling at Epoch 33449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33449\n",
      "Mean Log Likelihood -- train: -5.050561904907227, -- test: -20.53494644165039 \n",
      "Root Mean Squared Error -- train: 0.35872578620910645, -- test: 0.6620965003967285 \n",
      " \n",
      "#################### Sampling at Epoch 33499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33499\n",
      "Mean Log Likelihood -- train: -5.010428428649902, -- test: -20.162925720214844 \n",
      "Root Mean Squared Error -- train: 0.3576052188873291, -- test: 0.6564536690711975 \n",
      " \n",
      "#################### Sampling at Epoch 33549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33549\n",
      "Mean Log Likelihood -- train: -5.039514064788818, -- test: -20.490320205688477 \n",
      "Root Mean Squared Error -- train: 0.35841765999794006, -- test: 0.6614221930503845 \n",
      " \n",
      "#################### Sampling at Epoch 33599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33599\n",
      "Mean Log Likelihood -- train: -5.0701422691345215, -- test: -20.75342559814453 \n",
      "Root Mean Squared Error -- train: 0.35927116870880127, -- test: 0.6653881669044495 \n",
      " \n",
      "#################### Sampling at Epoch 33649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33649\n",
      "Mean Log Likelihood -- train: -5.049222469329834, -- test: -19.993986129760742 \n",
      "Root Mean Squared Error -- train: 0.3586884140968323, -- test: 0.6538751125335693 \n",
      " \n",
      "#################### Sampling at Epoch 33699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33699\n",
      "Mean Log Likelihood -- train: -5.055813789367676, -- test: -19.63566017150879 \n",
      "Root Mean Squared Error -- train: 0.35887211561203003, -- test: 0.6483719348907471 \n",
      " \n",
      "#################### Sampling at Epoch 33749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33749\n",
      "Mean Log Likelihood -- train: -4.998580455780029, -- test: -19.151111602783203 \n",
      "Root Mean Squared Error -- train: 0.35727375745773315, -- test: 0.6408549547195435 \n",
      " \n",
      "#################### Sampling at Epoch 33799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33799\n",
      "Mean Log Likelihood -- train: -5.041146755218506, -- test: -19.177766799926758 \n",
      "Root Mean Squared Error -- train: 0.35846319794654846, -- test: 0.6412708759307861 \n",
      " \n",
      "#################### Sampling at Epoch 33849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33849\n",
      "Mean Log Likelihood -- train: -5.021887302398682, -- test: -19.173416137695312 \n",
      "Root Mean Squared Error -- train: 0.35792550444602966, -- test: 0.641202986240387 \n",
      " \n",
      "#################### Sampling at Epoch 33899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33899\n",
      "Mean Log Likelihood -- train: -4.947744846343994, -- test: -18.16106414794922 \n",
      "Root Mean Squared Error -- train: 0.3558480441570282, -- test: 0.6252152919769287 \n",
      " \n",
      "#################### Sampling at Epoch 33949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33949\n",
      "Mean Log Likelihood -- train: -5.068388938903809, -- test: -19.8531494140625 \n",
      "Root Mean Squared Error -- train: 0.3592223525047302, -- test: 0.6517176628112793 \n",
      " \n",
      "#################### Sampling at Epoch 33999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 33999\n",
      "Mean Log Likelihood -- train: -5.079537868499756, -- test: -17.64046859741211 \n",
      "Root Mean Squared Error -- train: 0.35953259468078613, -- test: 0.6168324947357178 \n",
      " \n",
      "#################### Sampling at Epoch 34049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34049\n",
      "Mean Log Likelihood -- train: -4.922365188598633, -- test: -18.398466110229492 \n",
      "Root Mean Squared Error -- train: 0.35513409972190857, -- test: 0.6290010213851929 \n",
      " \n",
      "#################### Sampling at Epoch 34099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34099\n",
      "Mean Log Likelihood -- train: -4.936105728149414, -- test: -18.154312133789062 \n",
      "Root Mean Squared Error -- train: 0.3555208146572113, -- test: 0.6251072883605957 \n",
      " \n",
      "#################### Sampling at Epoch 34149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34149\n",
      "Mean Log Likelihood -- train: -4.956113338470459, -- test: -18.653152465820312 \n",
      "Root Mean Squared Error -- train: 0.3560831546783447, -- test: 0.6330370903015137 \n",
      " \n",
      "#################### Sampling at Epoch 34199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34199\n",
      "Mean Log Likelihood -- train: -4.884199619293213, -- test: -18.638460159301758 \n",
      "Root Mean Squared Error -- train: 0.35405778884887695, -- test: 0.6328049302101135 \n",
      " \n",
      "#################### Sampling at Epoch 34249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34249\n",
      "Mean Log Likelihood -- train: -4.8887038230896, -- test: -18.22738265991211 \n",
      "Root Mean Squared Error -- train: 0.35418498516082764, -- test: 0.6262751817703247 \n",
      " \n",
      "#################### Sampling at Epoch 34299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34299\n",
      "Mean Log Likelihood -- train: -4.935697555541992, -- test: -18.211196899414062 \n",
      "Root Mean Squared Error -- train: 0.35550934076309204, -- test: 0.6260166168212891 \n",
      " \n",
      "#################### Sampling at Epoch 34349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34349\n",
      "Mean Log Likelihood -- train: -4.971844673156738, -- test: -18.847681045532227 \n",
      "Root Mean Squared Error -- train: 0.35652464628219604, -- test: 0.6361026167869568 \n",
      " \n",
      "#################### Sampling at Epoch 34399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34399\n",
      "Mean Log Likelihood -- train: -4.904688835144043, -- test: -19.113414764404297 \n",
      "Root Mean Squared Error -- train: 0.354636013507843, -- test: 0.6402665376663208 \n",
      " \n",
      "#################### Sampling at Epoch 34449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34449\n",
      "Mean Log Likelihood -- train: -4.959561824798584, -- test: -19.02080726623535 \n",
      "Root Mean Squared Error -- train: 0.35617995262145996, -- test: 0.6388185024261475 \n",
      " \n",
      "#################### Sampling at Epoch 34499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34499\n",
      "Mean Log Likelihood -- train: -4.928678035736084, -- test: -18.87287139892578 \n",
      "Root Mean Squared Error -- train: 0.3553118109703064, -- test: 0.6364985108375549 \n",
      " \n",
      "#################### Sampling at Epoch 34549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34549\n",
      "Mean Log Likelihood -- train: -4.939863204956055, -- test: -18.69440269470215 \n",
      "Root Mean Squared Error -- train: 0.3556264638900757, -- test: 0.6336884498596191 \n",
      " \n",
      "#################### Sampling at Epoch 34599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34599\n",
      "Mean Log Likelihood -- train: -5.006472587585449, -- test: -18.54595184326172 \n",
      "Root Mean Squared Error -- train: 0.357494592666626, -- test: 0.6313413977622986 \n",
      " \n",
      "#################### Sampling at Epoch 34649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34649\n",
      "Mean Log Likelihood -- train: -5.000278949737549, -- test: -18.484317779541016 \n",
      "Root Mean Squared Error -- train: 0.35732126235961914, -- test: 0.6303644180297852 \n",
      " \n",
      "#################### Sampling at Epoch 34699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34699\n",
      "Mean Log Likelihood -- train: -5.0706706047058105, -- test: -17.53336524963379 \n",
      "Root Mean Squared Error -- train: 0.3592858612537384, -- test: 0.6150936484336853 \n",
      " \n",
      "#################### Sampling at Epoch 34749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34749\n",
      "Mean Log Likelihood -- train: -5.095261573791504, -- test: -17.676189422607422 \n",
      "Root Mean Squared Error -- train: 0.3599696457386017, -- test: 0.6174112558364868 \n",
      " \n",
      "#################### Sampling at Epoch 34799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34799\n",
      "Mean Log Likelihood -- train: -5.042096138000488, -- test: -18.188217163085938 \n",
      "Root Mean Squared Error -- train: 0.35848966240882874, -- test: 0.6256494522094727 \n",
      " \n",
      "#################### Sampling at Epoch 34849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34849\n",
      "Mean Log Likelihood -- train: -5.147270202636719, -- test: -18.06932830810547 \n",
      "Root Mean Squared Error -- train: 0.36141157150268555, -- test: 0.6237463355064392 \n",
      " \n",
      "#################### Sampling at Epoch 34899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34899\n",
      "Mean Log Likelihood -- train: -5.13212251663208, -- test: -19.406293869018555 \n",
      "Root Mean Squared Error -- train: 0.3609922230243683, -- test: 0.6448246240615845 \n",
      " \n",
      "#################### Sampling at Epoch 34949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34949\n",
      "Mean Log Likelihood -- train: -5.090956687927246, -- test: -20.15290069580078 \n",
      "Root Mean Squared Error -- train: 0.35985004901885986, -- test: 0.656300961971283 \n",
      " \n",
      "#################### Sampling at Epoch 34999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 34999\n",
      "Mean Log Likelihood -- train: -5.116318702697754, -- test: -19.540748596191406 \n",
      "Root Mean Squared Error -- train: 0.36055415868759155, -- test: 0.6469064354896545 \n",
      " \n",
      "#################### Sampling at Epoch 35049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35049\n",
      "Mean Log Likelihood -- train: -5.099329471588135, -- test: -19.740571975708008 \n",
      "Root Mean Squared Error -- train: 0.3600826561450958, -- test: 0.6499879360198975 \n",
      " \n",
      "#################### Sampling at Epoch 35099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35099\n",
      "Mean Log Likelihood -- train: -5.1067376136779785, -- test: -19.027849197387695 \n",
      "Root Mean Squared Error -- train: 0.3602883219718933, -- test: 0.6389287114143372 \n",
      " \n",
      "#################### Sampling at Epoch 35149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35149\n",
      "Mean Log Likelihood -- train: -4.995665073394775, -- test: -19.8931827545166 \n",
      "Root Mean Squared Error -- train: 0.35719212889671326, -- test: 0.6523316502571106 \n",
      " \n",
      "#################### Sampling at Epoch 35199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35199\n",
      "Mean Log Likelihood -- train: -5.003976345062256, -- test: -19.07023048400879 \n",
      "Root Mean Squared Error -- train: 0.3574247360229492, -- test: 0.6395916938781738 \n",
      " \n",
      "#################### Sampling at Epoch 35249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35249\n",
      "Mean Log Likelihood -- train: -5.005745887756348, -- test: -18.709867477416992 \n",
      "Root Mean Squared Error -- train: 0.35747426748275757, -- test: 0.63393235206604 \n",
      " \n",
      "#################### Sampling at Epoch 35299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35299\n",
      "Mean Log Likelihood -- train: -5.0068745613098145, -- test: -19.086612701416016 \n",
      "Root Mean Squared Error -- train: 0.35750582814216614, -- test: 0.6398478150367737 \n",
      " \n",
      "#################### Sampling at Epoch 35349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35349\n",
      "Mean Log Likelihood -- train: -4.98236608505249, -- test: -18.953540802001953 \n",
      "Root Mean Squared Error -- train: 0.35681962966918945, -- test: 0.6377646327018738 \n",
      " \n",
      "#################### Sampling at Epoch 35399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35399\n",
      "Mean Log Likelihood -- train: -4.976475238800049, -- test: -18.582242965698242 \n",
      "Root Mean Squared Error -- train: 0.35665449500083923, -- test: 0.6319159269332886 \n",
      " \n",
      "#################### Sampling at Epoch 35449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35449\n",
      "Mean Log Likelihood -- train: -5.039003372192383, -- test: -20.59613800048828 \n",
      "Root Mean Squared Error -- train: 0.35840341448783875, -- test: 0.6630200743675232 \n",
      " \n",
      "#################### Sampling at Epoch 35499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35499\n",
      "Mean Log Likelihood -- train: -5.050915718078613, -- test: -20.329843521118164 \n",
      "Root Mean Squared Error -- train: 0.3587356209754944, -- test: 0.6589915156364441 \n",
      " \n",
      "#################### Sampling at Epoch 35549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35549\n",
      "Mean Log Likelihood -- train: -5.044782638549805, -- test: -20.076858520507812 \n",
      "Root Mean Squared Error -- train: 0.3585646152496338, -- test: 0.6551412343978882 \n",
      " \n",
      "#################### Sampling at Epoch 35599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35599\n",
      "Mean Log Likelihood -- train: -5.067601680755615, -- test: -20.341583251953125 \n",
      "Root Mean Squared Error -- train: 0.35920044779777527, -- test: 0.659169614315033 \n",
      " \n",
      "#################### Sampling at Epoch 35649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35649\n",
      "Mean Log Likelihood -- train: -5.055365085601807, -- test: -19.6807918548584 \n",
      "Root Mean Squared Error -- train: 0.3588596284389496, -- test: 0.6490676403045654 \n",
      " \n",
      "#################### Sampling at Epoch 35699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35699\n",
      "Mean Log Likelihood -- train: -5.0406084060668945, -- test: -20.458269119262695 \n",
      "Root Mean Squared Error -- train: 0.35844817757606506, -- test: 0.6609374284744263 \n",
      " \n",
      "#################### Sampling at Epoch 35749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35749\n",
      "Mean Log Likelihood -- train: -5.015552997589111, -- test: -20.536073684692383 \n",
      "Root Mean Squared Error -- train: 0.35774847865104675, -- test: 0.662113606929779 \n",
      " \n",
      "#################### Sampling at Epoch 35799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35799\n",
      "Mean Log Likelihood -- train: -5.05145788192749, -- test: -20.802946090698242 \n",
      "Root Mean Squared Error -- train: 0.35875073075294495, -- test: 0.6661319732666016 \n",
      " \n",
      "#################### Sampling at Epoch 35849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35849\n",
      "Mean Log Likelihood -- train: -5.131568431854248, -- test: -19.372282028198242 \n",
      "Root Mean Squared Error -- train: 0.3609768748283386, -- test: 0.6442969441413879 \n",
      " \n",
      "#################### Sampling at Epoch 35899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35899\n",
      "Mean Log Likelihood -- train: -5.114194869995117, -- test: -20.687936782836914 \n",
      "Root Mean Squared Error -- train: 0.3604952394962311, -- test: 0.6644032597541809 \n",
      " \n",
      "#################### Sampling at Epoch 35949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35949\n",
      "Mean Log Likelihood -- train: -5.098413944244385, -- test: -19.414260864257812 \n",
      "Root Mean Squared Error -- train: 0.36005720496177673, -- test: 0.6449481248855591 \n",
      " \n",
      "#################### Sampling at Epoch 35999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 35999\n",
      "Mean Log Likelihood -- train: -5.024787902832031, -- test: -20.133304595947266 \n",
      "Root Mean Squared Error -- train: 0.3580065369606018, -- test: 0.6560022234916687 \n",
      " \n",
      "#################### Sampling at Epoch 36049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36049\n",
      "Mean Log Likelihood -- train: -5.020784378051758, -- test: -20.369470596313477 \n",
      "Root Mean Squared Error -- train: 0.3578946888446808, -- test: 0.6595925092697144 \n",
      " \n",
      "#################### Sampling at Epoch 36099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36099\n",
      "Mean Log Likelihood -- train: -5.071320533752441, -- test: -20.480581283569336 \n",
      "Root Mean Squared Error -- train: 0.35930395126342773, -- test: 0.6612749695777893 \n",
      " \n",
      "#################### Sampling at Epoch 36149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36149\n",
      "Mean Log Likelihood -- train: -5.1323418617248535, -- test: -19.422060012817383 \n",
      "Root Mean Squared Error -- train: 0.3609983026981354, -- test: 0.6450690627098083 \n",
      " \n",
      "#################### Sampling at Epoch 36199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36199\n",
      "Mean Log Likelihood -- train: -5.057694435119629, -- test: -20.191761016845703 \n",
      "Root Mean Squared Error -- train: 0.35892453789711, -- test: 0.6568928360939026 \n",
      " \n",
      "#################### Sampling at Epoch 36249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36249\n",
      "Mean Log Likelihood -- train: -5.100151062011719, -- test: -21.031391143798828 \n",
      "Root Mean Squared Error -- train: 0.3601054549217224, -- test: 0.6695526242256165 \n",
      " \n",
      "#################### Sampling at Epoch 36299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36299\n",
      "Mean Log Likelihood -- train: -5.098618507385254, -- test: -20.381820678710938 \n",
      "Root Mean Squared Error -- train: 0.3600628972053528, -- test: 0.6597797274589539 \n",
      " \n",
      "#################### Sampling at Epoch 36349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36349\n",
      "Mean Log Likelihood -- train: -5.241278171539307, -- test: -21.616504669189453 \n",
      "Root Mean Squared Error -- train: 0.36400339007377625, -- test: 0.6782352328300476 \n",
      " \n",
      "#################### Sampling at Epoch 36399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36399\n",
      "Mean Log Likelihood -- train: -5.139254570007324, -- test: -20.42864227294922 \n",
      "Root Mean Squared Error -- train: 0.36118972301483154, -- test: 0.660489022731781 \n",
      " \n",
      "#################### Sampling at Epoch 36449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36449\n",
      "Mean Log Likelihood -- train: -5.077410697937012, -- test: -19.77832794189453 \n",
      "Root Mean Squared Error -- train: 0.35947343707084656, -- test: 0.6505686044692993 \n",
      " \n",
      "#################### Sampling at Epoch 36499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36499\n",
      "Mean Log Likelihood -- train: -5.008690357208252, -- test: -20.523601531982422 \n",
      "Root Mean Squared Error -- train: 0.35755661129951477, -- test: 0.661925196647644 \n",
      " \n",
      "#################### Sampling at Epoch 36549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36549\n",
      "Mean Log Likelihood -- train: -5.089006423950195, -- test: -21.086355209350586 \n",
      "Root Mean Squared Error -- train: 0.35979586839675903, -- test: 0.6703730225563049 \n",
      " \n",
      "#################### Sampling at Epoch 36599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36599\n",
      "Mean Log Likelihood -- train: -5.049612045288086, -- test: -20.15716552734375 \n",
      "Root Mean Squared Error -- train: 0.3586992919445038, -- test: 0.6563659310340881 \n",
      " \n",
      "#################### Sampling at Epoch 36649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36649\n",
      "Mean Log Likelihood -- train: -5.068525314331055, -- test: -20.048389434814453 \n",
      "Root Mean Squared Error -- train: 0.35922613739967346, -- test: 0.654706597328186 \n",
      " \n",
      "#################### Sampling at Epoch 36699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36699\n",
      "Mean Log Likelihood -- train: -5.072415351867676, -- test: -19.530933380126953 \n",
      "Root Mean Squared Error -- train: 0.35933443903923035, -- test: 0.6467546224594116 \n",
      " \n",
      "#################### Sampling at Epoch 36749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36749\n",
      "Mean Log Likelihood -- train: -5.024421215057373, -- test: -19.025432586669922 \n",
      "Root Mean Squared Error -- train: 0.3579963147640228, -- test: 0.6388908624649048 \n",
      " \n",
      "#################### Sampling at Epoch 36799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36799\n",
      "Mean Log Likelihood -- train: -5.084902286529541, -- test: -17.757732391357422 \n",
      "Root Mean Squared Error -- train: 0.35968178510665894, -- test: 0.6187306046485901 \n",
      " \n",
      "#################### Sampling at Epoch 36849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36849\n",
      "Mean Log Likelihood -- train: -5.046059608459473, -- test: -18.2030029296875 \n",
      "Root Mean Squared Error -- train: 0.3586002290248871, -- test: 0.6258857846260071 \n",
      " \n",
      "#################### Sampling at Epoch 36899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36899\n",
      "Mean Log Likelihood -- train: -5.076624870300293, -- test: -18.42462730407715 \n",
      "Root Mean Squared Error -- train: 0.359451562166214, -- test: 0.6294167637825012 \n",
      " \n",
      "#################### Sampling at Epoch 36949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36949\n",
      "Mean Log Likelihood -- train: -5.006039619445801, -- test: -18.866134643554688 \n",
      "Root Mean Squared Error -- train: 0.3574824631214142, -- test: 0.6363925933837891 \n",
      " \n",
      "#################### Sampling at Epoch 36999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 36999\n",
      "Mean Log Likelihood -- train: -5.0698628425598145, -- test: -18.82938575744629 \n",
      "Root Mean Squared Error -- train: 0.3592633605003357, -- test: 0.6358149647712708 \n",
      " \n",
      "#################### Sampling at Epoch 37049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37049\n",
      "Mean Log Likelihood -- train: -4.9869608879089355, -- test: -18.009586334228516 \n",
      "Root Mean Squared Error -- train: 0.3569483757019043, -- test: 0.6227877736091614 \n",
      " \n",
      "#################### Sampling at Epoch 37099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37099\n",
      "Mean Log Likelihood -- train: -4.930441379547119, -- test: -18.66211700439453 \n",
      "Root Mean Squared Error -- train: 0.3553614318370819, -- test: 0.6331787109375 \n",
      " \n",
      "#################### Sampling at Epoch 37149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37149\n",
      "Mean Log Likelihood -- train: -5.047578811645508, -- test: -18.3470401763916 \n",
      "Root Mean Squared Error -- train: 0.3586426079273224, -- test: 0.6281828880310059 \n",
      " \n",
      "#################### Sampling at Epoch 37199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37199\n",
      "Mean Log Likelihood -- train: -4.984074115753174, -- test: -18.76629066467285 \n",
      "Root Mean Squared Error -- train: 0.3568674921989441, -- test: 0.6348218321800232 \n",
      " \n",
      "#################### Sampling at Epoch 37249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37249\n",
      "Mean Log Likelihood -- train: -5.040428161621094, -- test: -18.84966278076172 \n",
      "Root Mean Squared Error -- train: 0.35844314098358154, -- test: 0.6361337304115295 \n",
      " \n",
      "#################### Sampling at Epoch 37299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37299\n",
      "Mean Log Likelihood -- train: -4.988161563873291, -- test: -18.03856658935547 \n",
      "Root Mean Squared Error -- train: 0.3569819927215576, -- test: 0.6232529878616333 \n",
      " \n",
      "#################### Sampling at Epoch 37349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37349\n",
      "Mean Log Likelihood -- train: -5.019958972930908, -- test: -18.006092071533203 \n",
      "Root Mean Squared Error -- train: 0.3578716218471527, -- test: 0.6227316856384277 \n",
      " \n",
      "#################### Sampling at Epoch 37399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37399\n",
      "Mean Log Likelihood -- train: -5.070725440979004, -- test: -19.626018524169922 \n",
      "Root Mean Squared Error -- train: 0.35928741097450256, -- test: 0.6482231616973877 \n",
      " \n",
      "#################### Sampling at Epoch 37449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37449\n",
      "Mean Log Likelihood -- train: -5.068749904632568, -- test: -19.096782684326172 \n",
      "Root Mean Squared Error -- train: 0.3592323958873749, -- test: 0.6400067210197449 \n",
      " \n",
      "#################### Sampling at Epoch 37499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37499\n",
      "Mean Log Likelihood -- train: -5.017515659332275, -- test: -19.431838989257812 \n",
      "Root Mean Squared Error -- train: 0.3578033149242401, -- test: 0.6452206373214722 \n",
      " \n",
      "#################### Sampling at Epoch 37549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37549\n",
      "Mean Log Likelihood -- train: -4.978617191314697, -- test: -18.258872985839844 \n",
      "Root Mean Squared Error -- train: 0.35671454668045044, -- test: 0.6267778277397156 \n",
      " \n",
      "#################### Sampling at Epoch 37599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37599\n",
      "Mean Log Likelihood -- train: -5.008040428161621, -- test: -18.112279891967773 \n",
      "Root Mean Squared Error -- train: 0.3575384318828583, -- test: 0.6244345903396606 \n",
      " \n",
      "#################### Sampling at Epoch 37649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37649\n",
      "Mean Log Likelihood -- train: -5.03709602355957, -- test: -19.746471405029297 \n",
      "Root Mean Squared Error -- train: 0.3583501875400543, -- test: 0.6500787138938904 \n",
      " \n",
      "#################### Sampling at Epoch 37699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37699\n",
      "Mean Log Likelihood -- train: -5.057726860046387, -- test: -20.32047462463379 \n",
      "Root Mean Squared Error -- train: 0.3589254319667816, -- test: 0.65884929895401 \n",
      " \n",
      "#################### Sampling at Epoch 37749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37749\n",
      "Mean Log Likelihood -- train: -5.090080738067627, -- test: -19.579986572265625 \n",
      "Root Mean Squared Error -- train: 0.3598257005214691, -- test: 0.6475126147270203 \n",
      " \n",
      "#################### Sampling at Epoch 37799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37799\n",
      "Mean Log Likelihood -- train: -5.06831693649292, -- test: -20.222261428833008 \n",
      "Root Mean Squared Error -- train: 0.35922035574913025, -- test: 0.6573569774627686 \n",
      " \n",
      "#################### Sampling at Epoch 37849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37849\n",
      "Mean Log Likelihood -- train: -5.076063632965088, -- test: -20.330224990844727 \n",
      "Root Mean Squared Error -- train: 0.35943594574928284, -- test: 0.6589972972869873 \n",
      " \n",
      "#################### Sampling at Epoch 37899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37899\n",
      "Mean Log Likelihood -- train: -5.053184509277344, -- test: -20.468507766723633 \n",
      "Root Mean Squared Error -- train: 0.3587988615036011, -- test: 0.6610923409461975 \n",
      " \n",
      "#################### Sampling at Epoch 37949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37949\n",
      "Mean Log Likelihood -- train: -5.0596771240234375, -- test: -20.9437198638916 \n",
      "Root Mean Squared Error -- train: 0.3589797616004944, -- test: 0.6682419776916504 \n",
      " \n",
      "#################### Sampling at Epoch 37999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 37999\n",
      "Mean Log Likelihood -- train: -4.980101108551025, -- test: -19.852842330932617 \n",
      "Root Mean Squared Error -- train: 0.3567561209201813, -- test: 0.651712954044342 \n",
      " \n",
      "#################### Sampling at Epoch 38049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38049\n",
      "Mean Log Likelihood -- train: -5.043475151062012, -- test: -19.552898406982422 \n",
      "Root Mean Squared Error -- train: 0.35852816700935364, -- test: 0.647094190120697 \n",
      " \n",
      "#################### Sampling at Epoch 38099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38099\n",
      "Mean Log Likelihood -- train: -5.032370090484619, -- test: -20.219348907470703 \n",
      "Root Mean Squared Error -- train: 0.358218252658844, -- test: 0.6573126316070557 \n",
      " \n",
      "#################### Sampling at Epoch 38149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38149\n",
      "Mean Log Likelihood -- train: -5.0828938484191895, -- test: -22.925077438354492 \n",
      "Root Mean Squared Error -- train: 0.3596259355545044, -- test: 0.697262167930603 \n",
      " \n",
      "#################### Sampling at Epoch 38199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38199\n",
      "Mean Log Likelihood -- train: -5.079948902130127, -- test: -21.889955520629883 \n",
      "Root Mean Squared Error -- train: 0.3595440089702606, -- test: 0.6822551488876343 \n",
      " \n",
      "#################### Sampling at Epoch 38249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38249\n",
      "Mean Log Likelihood -- train: -5.069289207458496, -- test: -21.76923179626465 \n",
      "Root Mean Squared Error -- train: 0.3592474162578583, -- test: 0.6804832816123962 \n",
      " \n",
      "#################### Sampling at Epoch 38299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38299\n",
      "Mean Log Likelihood -- train: -5.0590667724609375, -- test: -22.7099552154541 \n",
      "Root Mean Squared Error -- train: 0.3589627742767334, -- test: 0.6941699981689453 \n",
      " \n",
      "#################### Sampling at Epoch 38349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38349\n",
      "Mean Log Likelihood -- train: -5.013862133026123, -- test: -22.096778869628906 \n",
      "Root Mean Squared Error -- train: 0.35770121216773987, -- test: 0.6852798461914062 \n",
      " \n",
      "#################### Sampling at Epoch 38399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38399\n",
      "Mean Log Likelihood -- train: -4.979633808135986, -- test: -22.65207290649414 \n",
      "Root Mean Squared Error -- train: 0.3567430377006531, -- test: 0.6933357119560242 \n",
      " \n",
      "#################### Sampling at Epoch 38449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38449\n",
      "Mean Log Likelihood -- train: -5.061439037322998, -- test: -22.0659236907959 \n",
      "Root Mean Squared Error -- train: 0.3590288460254669, -- test: 0.6848294734954834 \n",
      " \n",
      "#################### Sampling at Epoch 38499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38499\n",
      "Mean Log Likelihood -- train: -5.076915264129639, -- test: -21.99075698852539 \n",
      "Root Mean Squared Error -- train: 0.35945963859558105, -- test: 0.683730959892273 \n",
      " \n",
      "#################### Sampling at Epoch 38549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38549\n",
      "Mean Log Likelihood -- train: -5.095208644866943, -- test: -22.862163543701172 \n",
      "Root Mean Squared Error -- train: 0.3599681854248047, -- test: 0.6963592171669006 \n",
      " \n",
      "#################### Sampling at Epoch 38599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38599\n",
      "Mean Log Likelihood -- train: -5.025670528411865, -- test: -22.70816421508789 \n",
      "Root Mean Squared Error -- train: 0.3580312132835388, -- test: 0.6941441893577576 \n",
      " \n",
      "#################### Sampling at Epoch 38649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38649\n",
      "Mean Log Likelihood -- train: -5.051109313964844, -- test: -22.675703048706055 \n",
      "Root Mean Squared Error -- train: 0.35874101519584656, -- test: 0.6936764121055603 \n",
      " \n",
      "#################### Sampling at Epoch 38699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38699\n",
      "Mean Log Likelihood -- train: -5.089937686920166, -- test: -22.37554931640625 \n",
      "Root Mean Squared Error -- train: 0.35982173681259155, -- test: 0.689335823059082 \n",
      " \n",
      "#################### Sampling at Epoch 38749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38749\n",
      "Mean Log Likelihood -- train: -5.0591349601745605, -- test: -22.458145141601562 \n",
      "Root Mean Squared Error -- train: 0.3589646816253662, -- test: 0.6905329823493958 \n",
      " \n",
      "#################### Sampling at Epoch 38799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38799\n",
      "Mean Log Likelihood -- train: -5.019238471984863, -- test: -23.180282592773438 \n",
      "Root Mean Squared Error -- train: 0.35785147547721863, -- test: 0.7009126543998718 \n",
      " \n",
      "#################### Sampling at Epoch 38849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38849\n",
      "Mean Log Likelihood -- train: -5.1045331954956055, -- test: -23.924901962280273 \n",
      "Root Mean Squared Error -- train: 0.36022713780403137, -- test: 0.7114569544792175 \n",
      " \n",
      "#################### Sampling at Epoch 38899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38899\n",
      "Mean Log Likelihood -- train: -5.06507682800293, -- test: -22.434829711914062 \n",
      "Root Mean Squared Error -- train: 0.3591301143169403, -- test: 0.6901953220367432 \n",
      " \n",
      "#################### Sampling at Epoch 38949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38949\n",
      "Mean Log Likelihood -- train: -5.1350507736206055, -- test: -22.92734146118164 \n",
      "Root Mean Squared Error -- train: 0.3610733151435852, -- test: 0.6972945928573608 \n",
      " \n",
      "#################### Sampling at Epoch 38999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 38999\n",
      "Mean Log Likelihood -- train: -5.153716087341309, -- test: -24.043241500854492 \n",
      "Root Mean Squared Error -- train: 0.3615899085998535, -- test: 0.713118314743042 \n",
      " \n",
      "#################### Sampling at Epoch 39049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39049\n",
      "Mean Log Likelihood -- train: -5.145524024963379, -- test: -23.791980743408203 \n",
      "Root Mean Squared Error -- train: 0.3613632917404175, -- test: 0.7095862030982971 \n",
      " \n",
      "#################### Sampling at Epoch 39099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39099\n",
      "Mean Log Likelihood -- train: -5.123273849487305, -- test: -23.0245361328125 \n",
      "Root Mean Squared Error -- train: 0.36074700951576233, -- test: 0.6986870169639587 \n",
      " \n",
      "#################### Sampling at Epoch 39149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39149\n",
      "Mean Log Likelihood -- train: -5.095278263092041, -- test: -23.972055435180664 \n",
      "Root Mean Squared Error -- train: 0.3599701225757599, -- test: 0.7121194005012512 \n",
      " \n",
      "#################### Sampling at Epoch 39199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39199\n",
      "Mean Log Likelihood -- train: -5.105031967163086, -- test: -24.548463821411133 \n",
      "Root Mean Squared Error -- train: 0.36024099588394165, -- test: 0.7201681733131409 \n",
      " \n",
      "#################### Sampling at Epoch 39249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39249\n",
      "Mean Log Likelihood -- train: -5.060402870178223, -- test: -23.172119140625 \n",
      "Root Mean Squared Error -- train: 0.35899999737739563, -- test: 0.7007961869239807 \n",
      " \n",
      "#################### Sampling at Epoch 39299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39299\n",
      "Mean Log Likelihood -- train: -5.073015213012695, -- test: -22.044448852539062 \n",
      "Root Mean Squared Error -- train: 0.35935112833976746, -- test: 0.6845157742500305 \n",
      " \n",
      "#################### Sampling at Epoch 39349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39349\n",
      "Mean Log Likelihood -- train: -5.063534736633301, -- test: -23.303241729736328 \n",
      "Root Mean Squared Error -- train: 0.359087198972702, -- test: 0.7026647329330444 \n",
      " \n",
      "#################### Sampling at Epoch 39399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39399\n",
      "Mean Log Likelihood -- train: -5.048086643218994, -- test: -22.611839294433594 \n",
      "Root Mean Squared Error -- train: 0.35865676403045654, -- test: 0.6927551627159119 \n",
      " \n",
      "#################### Sampling at Epoch 39449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39449\n",
      "Mean Log Likelihood -- train: -5.0674262046813965, -- test: -22.056678771972656 \n",
      "Root Mean Squared Error -- train: 0.3591955602169037, -- test: 0.6846944689750671 \n",
      " \n",
      "#################### Sampling at Epoch 39499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39499\n",
      "Mean Log Likelihood -- train: -5.101351737976074, -- test: -21.582355499267578 \n",
      "Root Mean Squared Error -- train: 0.36013880372047424, -- test: 0.6777315139770508 \n",
      " \n",
      "#################### Sampling at Epoch 39549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39549\n",
      "Mean Log Likelihood -- train: -5.1405181884765625, -- test: -22.81499671936035 \n",
      "Root Mean Squared Error -- train: 0.3612247109413147, -- test: 0.6956815719604492 \n",
      " \n",
      "#################### Sampling at Epoch 39599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39599\n",
      "Mean Log Likelihood -- train: -5.152586936950684, -- test: -23.676359176635742 \n",
      "Root Mean Squared Error -- train: 0.3615586757659912, -- test: 0.7079548835754395 \n",
      " \n",
      "#################### Sampling at Epoch 39649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39649\n",
      "Mean Log Likelihood -- train: -5.205938816070557, -- test: -23.280540466308594 \n",
      "Root Mean Squared Error -- train: 0.363031268119812, -- test: 0.7023415565490723 \n",
      " \n",
      "#################### Sampling at Epoch 39699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39699\n",
      "Mean Log Likelihood -- train: -5.146569728851318, -- test: -22.4805965423584 \n",
      "Root Mean Squared Error -- train: 0.36139219999313354, -- test: 0.6908580660820007 \n",
      " \n",
      "#################### Sampling at Epoch 39749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39749\n",
      "Mean Log Likelihood -- train: -5.229974269866943, -- test: -25.134374618530273 \n",
      "Root Mean Squared Error -- train: 0.3636927604675293, -- test: 0.728258490562439 \n",
      " \n",
      "#################### Sampling at Epoch 39799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39799\n",
      "Mean Log Likelihood -- train: -5.179244041442871, -- test: -25.584064483642578 \n",
      "Root Mean Squared Error -- train: 0.3622951805591583, -- test: 0.7344074249267578 \n",
      " \n",
      "#################### Sampling at Epoch 39849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39849\n",
      "Mean Log Likelihood -- train: -5.213974952697754, -- test: -25.50967788696289 \n",
      "Root Mean Squared Error -- train: 0.36325258016586304, -- test: 0.7333937883377075 \n",
      " \n",
      "#################### Sampling at Epoch 39899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39899\n",
      "Mean Log Likelihood -- train: -5.2364068031311035, -- test: -25.731948852539062 \n",
      "Root Mean Squared Error -- train: 0.3638695776462555, -- test: 0.7364182472229004 \n",
      " \n",
      "#################### Sampling at Epoch 39949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39949\n",
      "Mean Log Likelihood -- train: -5.211427688598633, -- test: -26.894197463989258 \n",
      "Root Mean Squared Error -- train: 0.3631824553012848, -- test: 0.7520350813865662 \n",
      " \n",
      "#################### Sampling at Epoch 39999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 39999\n",
      "Mean Log Likelihood -- train: -5.272755146026611, -- test: -27.277334213256836 \n",
      "Root Mean Squared Error -- train: 0.3648671507835388, -- test: 0.7571126818656921 \n",
      " \n",
      "#################### Sampling at Epoch 40049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40049\n",
      "Mean Log Likelihood -- train: -5.345982074737549, -- test: -29.04119110107422 \n",
      "Root Mean Squared Error -- train: 0.3668685853481293, -- test: 0.7800620794296265 \n",
      " \n",
      "#################### Sampling at Epoch 40099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40099\n",
      "Mean Log Likelihood -- train: -5.27569055557251, -- test: -30.360849380493164 \n",
      "Root Mean Squared Error -- train: 0.3649475872516632, -- test: 0.7967997789382935 \n",
      " \n",
      "#################### Sampling at Epoch 40149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40149\n",
      "Mean Log Likelihood -- train: -5.278657913208008, -- test: -30.78557586669922 \n",
      "Root Mean Squared Error -- train: 0.36502888798713684, -- test: 0.8021124601364136 \n",
      " \n",
      "#################### Sampling at Epoch 40199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40199\n",
      "Mean Log Likelihood -- train: -5.297799587249756, -- test: -29.585336685180664 \n",
      "Root Mean Squared Error -- train: 0.3655528724193573, -- test: 0.7870068550109863 \n",
      " \n",
      "#################### Sampling at Epoch 40249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40249\n",
      "Mean Log Likelihood -- train: -5.280264377593994, -- test: -26.917076110839844 \n",
      "Root Mean Squared Error -- train: 0.36507290601730347, -- test: 0.7523393034934998 \n",
      " \n",
      "#################### Sampling at Epoch 40299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40299\n",
      "Mean Log Likelihood -- train: -5.314451217651367, -- test: -25.458045959472656 \n",
      "Root Mean Squared Error -- train: 0.36600813269615173, -- test: 0.732689380645752 \n",
      " \n",
      "#################### Sampling at Epoch 40349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40349\n",
      "Mean Log Likelihood -- train: -5.342927932739258, -- test: -26.569232940673828 \n",
      "Root Mean Squared Error -- train: 0.36678534746170044, -- test: 0.7477015256881714 \n",
      " \n",
      "#################### Sampling at Epoch 40399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40399\n",
      "Mean Log Likelihood -- train: -5.3583197593688965, -- test: -26.193222045898438 \n",
      "Root Mean Squared Error -- train: 0.3672047257423401, -- test: 0.7426555752754211 \n",
      " \n",
      "#################### Sampling at Epoch 40449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40449\n",
      "Mean Log Likelihood -- train: -5.39238977432251, -- test: -25.538164138793945 \n",
      "Root Mean Squared Error -- train: 0.3681314289569855, -- test: 0.7337821125984192 \n",
      " \n",
      "#################### Sampling at Epoch 40499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40499\n",
      "Mean Log Likelihood -- train: -5.458655834197998, -- test: -24.605186462402344 \n",
      "Root Mean Squared Error -- train: 0.3699270784854889, -- test: 0.7209553122520447 \n",
      " \n",
      "#################### Sampling at Epoch 40549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40549\n",
      "Mean Log Likelihood -- train: -5.362586498260498, -- test: -24.386812210083008 \n",
      "Root Mean Squared Error -- train: 0.3673209249973297, -- test: 0.7179200649261475 \n",
      " \n",
      "#################### Sampling at Epoch 40599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40599\n",
      "Mean Log Likelihood -- train: -5.373795509338379, -- test: -24.019655227661133 \n",
      "Root Mean Squared Error -- train: 0.3676259517669678, -- test: 0.7127875089645386 \n",
      " \n",
      "#################### Sampling at Epoch 40649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40649\n",
      "Mean Log Likelihood -- train: -5.36317777633667, -- test: -25.489580154418945 \n",
      "Root Mean Squared Error -- train: 0.36733701825141907, -- test: 0.7331196665763855 \n",
      " \n",
      "#################### Sampling at Epoch 40699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40699\n",
      "Mean Log Likelihood -- train: -5.339802265167236, -- test: -25.391504287719727 \n",
      "Root Mean Squared Error -- train: 0.36670011281967163, -- test: 0.7317807078361511 \n",
      " \n",
      "#################### Sampling at Epoch 40749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40749\n",
      "Mean Log Likelihood -- train: -5.294581890106201, -- test: -23.750627517700195 \n",
      "Root Mean Squared Error -- train: 0.36546486616134644, -- test: 0.7090030908584595 \n",
      " \n",
      "#################### Sampling at Epoch 40799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40799\n",
      "Mean Log Likelihood -- train: -5.337655067443848, -- test: -24.236589431762695 \n",
      "Root Mean Squared Error -- train: 0.3666415512561798, -- test: 0.7158244848251343 \n",
      " \n",
      "#################### Sampling at Epoch 40849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40849\n",
      "Mean Log Likelihood -- train: -5.334994316101074, -- test: -24.883056640625 \n",
      "Root Mean Squared Error -- train: 0.3665689527988434, -- test: 0.7247993350028992 \n",
      " \n",
      "#################### Sampling at Epoch 40899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40899\n",
      "Mean Log Likelihood -- train: -5.278049945831299, -- test: -23.787216186523438 \n",
      "Root Mean Squared Error -- train: 0.3650122284889221, -- test: 0.7095190286636353 \n",
      " \n",
      "#################### Sampling at Epoch 40949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40949\n",
      "Mean Log Likelihood -- train: -5.33571195602417, -- test: -24.27790069580078 \n",
      "Root Mean Squared Error -- train: 0.3665885627269745, -- test: 0.7164013981819153 \n",
      " \n",
      "#################### Sampling at Epoch 40999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 40999\n",
      "Mean Log Likelihood -- train: -5.443934917449951, -- test: -25.279376983642578 \n",
      "Root Mean Squared Error -- train: 0.3695289194583893, -- test: 0.7302467823028564 \n",
      " \n",
      "#################### Sampling at Epoch 41049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41049\n",
      "Mean Log Likelihood -- train: -5.367941856384277, -- test: -25.122802734375 \n",
      "Root Mean Squared Error -- train: 0.36746665835380554, -- test: 0.7280995845794678 \n",
      " \n",
      "#################### Sampling at Epoch 41099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41099\n",
      "Mean Log Likelihood -- train: -5.42209005355835, -- test: -25.281293869018555 \n",
      "Root Mean Squared Error -- train: 0.36893731355667114, -- test: 0.7302730679512024 \n",
      " \n",
      "#################### Sampling at Epoch 41149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41149\n",
      "Mean Log Likelihood -- train: -5.441540718078613, -- test: -25.201223373413086 \n",
      "Root Mean Squared Error -- train: 0.36946412920951843, -- test: 0.7291758060455322 \n",
      " \n",
      "#################### Sampling at Epoch 41199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41199\n",
      "Mean Log Likelihood -- train: -5.506247043609619, -- test: -27.254955291748047 \n",
      "Root Mean Squared Error -- train: 0.37121134996414185, -- test: 0.7568170428276062 \n",
      " \n",
      "#################### Sampling at Epoch 41249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41249\n",
      "Mean Log Likelihood -- train: -5.530011177062988, -- test: -29.142969131469727 \n",
      "Root Mean Squared Error -- train: 0.37185096740722656, -- test: 0.781365692615509 \n",
      " \n",
      "#################### Sampling at Epoch 41299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41299\n",
      "Mean Log Likelihood -- train: -5.469080448150635, -- test: -28.61554527282715 \n",
      "Root Mean Squared Error -- train: 0.3702087700366974, -- test: 0.7745861411094666 \n",
      " \n",
      "#################### Sampling at Epoch 41349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41349\n",
      "Mean Log Likelihood -- train: -5.605685710906982, -- test: -29.415761947631836 \n",
      "Root Mean Squared Error -- train: 0.373880535364151, -- test: 0.7848491072654724 \n",
      " \n",
      "#################### Sampling at Epoch 41399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41399\n",
      "Mean Log Likelihood -- train: -5.59174919128418, -- test: -25.392793655395508 \n",
      "Root Mean Squared Error -- train: 0.373507559299469, -- test: 0.7317982912063599 \n",
      " \n",
      "#################### Sampling at Epoch 41449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41449\n",
      "Mean Log Likelihood -- train: -5.610410690307617, -- test: -27.414871215820312 \n",
      "Root Mean Squared Error -- train: 0.37400686740875244, -- test: 0.7589271068572998 \n",
      " \n",
      "#################### Sampling at Epoch 41499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41499\n",
      "Mean Log Likelihood -- train: -5.511904716491699, -- test: -28.21490478515625 \n",
      "Root Mean Squared Error -- train: 0.3713637590408325, -- test: 0.7693964838981628 \n",
      " \n",
      "#################### Sampling at Epoch 41549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41549\n",
      "Mean Log Likelihood -- train: -5.462697505950928, -- test: -26.803977966308594 \n",
      "Root Mean Squared Error -- train: 0.3700363039970398, -- test: 0.7508345246315002 \n",
      " \n",
      "#################### Sampling at Epoch 41599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41599\n",
      "Mean Log Likelihood -- train: -5.469099998474121, -- test: -29.303850173950195 \n",
      "Root Mean Squared Error -- train: 0.370209276676178, -- test: 0.7834218740463257 \n",
      " \n",
      "#################### Sampling at Epoch 41649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41649\n",
      "Mean Log Likelihood -- train: -5.428527355194092, -- test: -26.41136932373047 \n",
      "Root Mean Squared Error -- train: 0.3691117465496063, -- test: 0.7455872297286987 \n",
      " \n",
      "#################### Sampling at Epoch 41699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41699\n",
      "Mean Log Likelihood -- train: -5.515451908111572, -- test: -27.39413070678711 \n",
      "Root Mean Squared Error -- train: 0.3714592158794403, -- test: 0.7586537599563599 \n",
      " \n",
      "#################### Sampling at Epoch 41749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41749\n",
      "Mean Log Likelihood -- train: -5.489484786987305, -- test: -28.483928680419922 \n",
      "Root Mean Squared Error -- train: 0.370759516954422, -- test: 0.7728851437568665 \n",
      " \n",
      "#################### Sampling at Epoch 41799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41799\n",
      "Mean Log Likelihood -- train: -5.385512351989746, -- test: -28.194469451904297 \n",
      "Root Mean Squared Error -- train: 0.36794450879096985, -- test: 0.7691308856010437 \n",
      " \n",
      "#################### Sampling at Epoch 41849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41849\n",
      "Mean Log Likelihood -- train: -5.398993015289307, -- test: -28.786174774169922 \n",
      "Root Mean Squared Error -- train: 0.36831071972846985, -- test: 0.7767859697341919 \n",
      " \n",
      "#################### Sampling at Epoch 41899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41899\n",
      "Mean Log Likelihood -- train: -5.383536338806152, -- test: -31.068870544433594 \n",
      "Root Mean Squared Error -- train: 0.3678908050060272, -- test: 0.8056365847587585 \n",
      " \n",
      "#################### Sampling at Epoch 41949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41949\n",
      "Mean Log Likelihood -- train: -5.452279090881348, -- test: -33.775962829589844 \n",
      "Root Mean Squared Error -- train: 0.3697546720504761, -- test: 0.8385655879974365 \n",
      " \n",
      "#################### Sampling at Epoch 41999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 41999\n",
      "Mean Log Likelihood -- train: -5.416754722595215, -- test: -33.49162292480469 \n",
      "Root Mean Squared Error -- train: 0.36879265308380127, -- test: 0.8351678252220154 \n",
      " \n",
      "#################### Sampling at Epoch 42049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42049\n",
      "Mean Log Likelihood -- train: -5.391804218292236, -- test: -33.287235260009766 \n",
      "Root Mean Squared Error -- train: 0.36811548471450806, -- test: 0.8327170610427856 \n",
      " \n",
      "#################### Sampling at Epoch 42099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42099\n",
      "Mean Log Likelihood -- train: -5.451645851135254, -- test: -33.74081039428711 \n",
      "Root Mean Squared Error -- train: 0.36973753571510315, -- test: 0.8381462097167969 \n",
      " \n",
      "#################### Sampling at Epoch 42149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42149\n",
      "Mean Log Likelihood -- train: -5.343155860900879, -- test: -34.87381362915039 \n",
      "Root Mean Squared Error -- train: 0.3667915463447571, -- test: 0.8515568971633911 \n",
      " \n",
      "#################### Sampling at Epoch 42199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42199\n",
      "Mean Log Likelihood -- train: -5.364741325378418, -- test: -34.08675765991211 \n",
      "Root Mean Squared Error -- train: 0.3673795759677887, -- test: 0.8422636389732361 \n",
      " \n",
      "#################### Sampling at Epoch 42249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42249\n",
      "Mean Log Likelihood -- train: -5.39124870300293, -- test: -37.56010818481445 \n",
      "Root Mean Squared Error -- train: 0.3681003749370575, -- test: 0.8825390338897705 \n",
      " \n",
      "#################### Sampling at Epoch 42299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42299\n",
      "Mean Log Likelihood -- train: -5.390940189361572, -- test: -38.828338623046875 \n",
      "Root Mean Squared Error -- train: 0.36809203028678894, -- test: 0.8967941999435425 \n",
      " \n",
      "#################### Sampling at Epoch 42349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42349\n",
      "Mean Log Likelihood -- train: -5.374924659729004, -- test: -36.038211822509766 \n",
      "Root Mean Squared Error -- train: 0.3676566779613495, -- test: 0.8651226758956909 \n",
      " \n",
      "#################### Sampling at Epoch 42399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42399\n",
      "Mean Log Likelihood -- train: -5.358888149261475, -- test: -33.709678649902344 \n",
      "Root Mean Squared Error -- train: 0.3672202229499817, -- test: 0.8377746939659119 \n",
      " \n",
      "#################### Sampling at Epoch 42449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42449\n",
      "Mean Log Likelihood -- train: -5.375212669372559, -- test: -33.75758361816406 \n",
      "Root Mean Squared Error -- train: 0.36766448616981506, -- test: 0.8383464217185974 \n",
      " \n",
      "#################### Sampling at Epoch 42499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42499\n",
      "Mean Log Likelihood -- train: -5.364850044250488, -- test: -33.4426155090332 \n",
      "Root Mean Squared Error -- train: 0.3673825263977051, -- test: 0.8345808982849121 \n",
      " \n",
      "#################### Sampling at Epoch 42549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42549\n",
      "Mean Log Likelihood -- train: -5.345720291137695, -- test: -33.36992263793945 \n",
      "Root Mean Squared Error -- train: 0.3668614625930786, -- test: 0.8337094187736511 \n",
      " \n",
      "#################### Sampling at Epoch 42599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42599\n",
      "Mean Log Likelihood -- train: -5.382071495056152, -- test: -33.496524810791016 \n",
      "Root Mean Squared Error -- train: 0.36785101890563965, -- test: 0.8352265357971191 \n",
      " \n",
      "#################### Sampling at Epoch 42649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42649\n",
      "Mean Log Likelihood -- train: -5.39680290222168, -- test: -35.81927490234375 \n",
      "Root Mean Squared Error -- train: 0.3682512640953064, -- test: 0.8625881671905518 \n",
      " \n",
      "#################### Sampling at Epoch 42699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42699\n",
      "Mean Log Likelihood -- train: -5.360044956207275, -- test: -34.18779373168945 \n",
      "Root Mean Squared Error -- train: 0.3672517240047455, -- test: 0.8434624075889587 \n",
      " \n",
      "#################### Sampling at Epoch 42749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42749\n",
      "Mean Log Likelihood -- train: -5.3569722175598145, -- test: -31.34238052368164 \n",
      "Root Mean Squared Error -- train: 0.3671680688858032, -- test: 0.809024453163147 \n",
      " \n",
      "#################### Sampling at Epoch 42799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42799\n",
      "Mean Log Likelihood -- train: -5.37905740737915, -- test: -33.45629119873047 \n",
      "Root Mean Squared Error -- train: 0.3677690625190735, -- test: 0.8347446918487549 \n",
      " \n",
      "#################### Sampling at Epoch 42849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42849\n",
      "Mean Log Likelihood -- train: -5.510927677154541, -- test: -32.633358001708984 \n",
      "Root Mean Squared Error -- train: 0.3713374435901642, -- test: 0.8248273134231567 \n",
      " \n",
      "#################### Sampling at Epoch 42899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42899\n",
      "Mean Log Likelihood -- train: -5.359762668609619, -- test: -33.45016860961914 \n",
      "Root Mean Squared Error -- train: 0.36724403500556946, -- test: 0.8346713185310364 \n",
      " \n",
      "#################### Sampling at Epoch 42949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42949\n",
      "Mean Log Likelihood -- train: -5.392465114593506, -- test: -35.07115173339844 \n",
      "Root Mean Squared Error -- train: 0.36813342571258545, -- test: 0.8538711071014404 \n",
      " \n",
      "#################### Sampling at Epoch 42999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 42999\n",
      "Mean Log Likelihood -- train: -5.359504222869873, -- test: -36.46965408325195 \n",
      "Root Mean Squared Error -- train: 0.3672369718551636, -- test: 0.8700953722000122 \n",
      " \n",
      "#################### Sampling at Epoch 43049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43049\n",
      "Mean Log Likelihood -- train: -5.332326412200928, -- test: -38.35030746459961 \n",
      "Root Mean Squared Error -- train: 0.366496205329895, -- test: 0.8914477229118347 \n",
      " \n",
      "#################### Sampling at Epoch 43099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43099\n",
      "Mean Log Likelihood -- train: -5.315680980682373, -- test: -38.956451416015625 \n",
      "Root Mean Squared Error -- train: 0.36604171991348267, -- test: 0.898221492767334 \n",
      " \n",
      "#################### Sampling at Epoch 43149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43149\n",
      "Mean Log Likelihood -- train: -5.343416213989258, -- test: -37.407928466796875 \n",
      "Root Mean Squared Error -- train: 0.36679866909980774, -- test: 0.88081294298172 \n",
      " \n",
      "#################### Sampling at Epoch 43199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43199\n",
      "Mean Log Likelihood -- train: -5.361085891723633, -- test: -34.5054817199707 \n",
      "Root Mean Squared Error -- train: 0.3672800660133362, -- test: 0.8472204804420471 \n",
      " \n",
      "#################### Sampling at Epoch 43249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43249\n",
      "Mean Log Likelihood -- train: -5.3819451332092285, -- test: -33.676822662353516 \n",
      "Root Mean Squared Error -- train: 0.3678475618362427, -- test: 0.837382435798645 \n",
      " \n",
      "#################### Sampling at Epoch 43299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43299\n",
      "Mean Log Likelihood -- train: -5.454067707061768, -- test: -37.64377212524414 \n",
      "Root Mean Squared Error -- train: 0.3698030114173889, -- test: 0.8834865093231201 \n",
      " \n",
      "#################### Sampling at Epoch 43349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43349\n",
      "Mean Log Likelihood -- train: -5.379034519195557, -- test: -35.485740661621094 \n",
      "Root Mean Squared Error -- train: 0.36776843667030334, -- test: 0.8587128520011902 \n",
      " \n",
      "#################### Sampling at Epoch 43399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43399\n",
      "Mean Log Likelihood -- train: -5.4630632400512695, -- test: -36.88200378417969 \n",
      "Root Mean Squared Error -- train: 0.3700461983680725, -- test: 0.874821662902832 \n",
      " \n",
      "#################### Sampling at Epoch 43449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43449\n",
      "Mean Log Likelihood -- train: -5.472146511077881, -- test: -36.262367248535156 \n",
      "Root Mean Squared Error -- train: 0.3702915906906128, -- test: 0.867709755897522 \n",
      " \n",
      "#################### Sampling at Epoch 43499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43499\n",
      "Mean Log Likelihood -- train: -5.471856594085693, -- test: -36.48780059814453 \n",
      "Root Mean Squared Error -- train: 0.37028375267982483, -- test: 0.8703039288520813 \n",
      " \n",
      "#################### Sampling at Epoch 43549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43549\n",
      "Mean Log Likelihood -- train: -5.459740161895752, -- test: -40.545928955078125 \n",
      "Root Mean Squared Error -- train: 0.369956374168396, -- test: 0.9157463908195496 \n",
      " \n",
      "#################### Sampling at Epoch 43599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43599\n",
      "Mean Log Likelihood -- train: -5.454136371612549, -- test: -41.743873596191406 \n",
      "Root Mean Squared Error -- train: 0.36980488896369934, -- test: 0.9287359118461609 \n",
      " \n",
      "#################### Sampling at Epoch 43649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43649\n",
      "Mean Log Likelihood -- train: -5.395401477813721, -- test: -40.59431838989258 \n",
      "Root Mean Squared Error -- train: 0.3682132065296173, -- test: 0.9162746667861938 \n",
      " \n",
      "#################### Sampling at Epoch 43699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43699\n",
      "Mean Log Likelihood -- train: -5.33644962310791, -- test: -38.74766159057617 \n",
      "Root Mean Squared Error -- train: 0.3666086792945862, -- test: 0.8958939909934998 \n",
      " \n",
      "#################### Sampling at Epoch 43749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43749\n",
      "Mean Log Likelihood -- train: -5.4016947746276855, -- test: -39.720523834228516 \n",
      "Root Mean Squared Error -- train: 0.36838406324386597, -- test: 0.9066880941390991 \n",
      " \n",
      "#################### Sampling at Epoch 43799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43799\n",
      "Mean Log Likelihood -- train: -5.355409622192383, -- test: -38.75639724731445 \n",
      "Root Mean Squared Error -- train: 0.3671254813671112, -- test: 0.8959915041923523 \n",
      " \n",
      "#################### Sampling at Epoch 43849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43849\n",
      "Mean Log Likelihood -- train: -5.446438312530518, -- test: -37.93561935424805 \n",
      "Root Mean Squared Error -- train: 0.3695966601371765, -- test: 0.8867836594581604 \n",
      " \n",
      "#################### Sampling at Epoch 43899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43899\n",
      "Mean Log Likelihood -- train: -5.356668949127197, -- test: -39.43141174316406 \n",
      "Root Mean Squared Error -- train: 0.36715978384017944, -- test: 0.9034938812255859 \n",
      " \n",
      "#################### Sampling at Epoch 43949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43949\n",
      "Mean Log Likelihood -- train: -5.360780239105225, -- test: -39.65192794799805 \n",
      "Root Mean Squared Error -- train: 0.3672717213630676, -- test: 0.905931293964386 \n",
      " \n",
      "#################### Sampling at Epoch 43999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 43999\n",
      "Mean Log Likelihood -- train: -5.348289966583252, -- test: -41.785160064697266 \n",
      "Root Mean Squared Error -- train: 0.3669315278530121, -- test: 0.929180383682251 \n",
      " \n",
      "#################### Sampling at Epoch 44049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44049\n",
      "Mean Log Likelihood -- train: -5.363219261169434, -- test: -39.34101486206055 \n",
      "Root Mean Squared Error -- train: 0.3673381209373474, -- test: 0.9024927616119385 \n",
      " \n",
      "#################### Sampling at Epoch 44099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44099\n",
      "Mean Log Likelihood -- train: -5.418478488922119, -- test: -42.36835479736328 \n",
      "Root Mean Squared Error -- train: 0.36883941292762756, -- test: 0.9354357123374939 \n",
      " \n",
      "#################### Sampling at Epoch 44149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44149\n",
      "Mean Log Likelihood -- train: -5.350720405578613, -- test: -37.680274963378906 \n",
      "Root Mean Squared Error -- train: 0.36699771881103516, -- test: 0.8838995099067688 \n",
      " \n",
      "#################### Sampling at Epoch 44199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44199\n",
      "Mean Log Likelihood -- train: -5.40872859954834, -- test: -37.051090240478516 \n",
      "Root Mean Squared Error -- train: 0.36857494711875916, -- test: 0.8767523169517517 \n",
      " \n",
      "#################### Sampling at Epoch 44249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44249\n",
      "Mean Log Likelihood -- train: -5.32307243347168, -- test: -33.71778106689453 \n",
      "Root Mean Squared Error -- train: 0.3662435710430145, -- test: 0.8378714323043823 \n",
      " \n",
      "#################### Sampling at Epoch 44299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44299\n",
      "Mean Log Likelihood -- train: -5.324635028839111, -- test: -34.18423080444336 \n",
      "Root Mean Squared Error -- train: 0.3662862479686737, -- test: 0.843420147895813 \n",
      " \n",
      "#################### Sampling at Epoch 44349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44349\n",
      "Mean Log Likelihood -- train: -5.189403057098389, -- test: -35.94261169433594 \n",
      "Root Mean Squared Error -- train: 0.362575501203537, -- test: 0.8640168309211731 \n",
      " \n",
      "#################### Sampling at Epoch 44399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44399\n",
      "Mean Log Likelihood -- train: -5.079793453216553, -- test: -32.66072082519531 \n",
      "Root Mean Squared Error -- train: 0.3595396876335144, -- test: 0.825158953666687 \n",
      " \n",
      "#################### Sampling at Epoch 44449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44449\n",
      "Mean Log Likelihood -- train: -4.893110752105713, -- test: -36.86263656616211 \n",
      "Root Mean Squared Error -- train: 0.35430940985679626, -- test: 0.8746002912521362 \n",
      " \n",
      "#################### Sampling at Epoch 44499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44499\n",
      "Mean Log Likelihood -- train: -4.831079483032227, -- test: -40.463539123535156 \n",
      "Root Mean Squared Error -- train: 0.3525542616844177, -- test: 0.9148462414741516 \n",
      " \n",
      "#################### Sampling at Epoch 44549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44549\n",
      "Mean Log Likelihood -- train: -4.645835876464844, -- test: -40.099098205566406 \n",
      "Root Mean Squared Error -- train: 0.3472602069377899, -- test: 0.910853922367096 \n",
      " \n",
      "#################### Sampling at Epoch 44599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44599\n",
      "Mean Log Likelihood -- train: -4.45347261428833, -- test: -41.724830627441406 \n",
      "Root Mean Squared Error -- train: 0.34167584776878357, -- test: 0.9285308122634888 \n",
      " \n",
      "#################### Sampling at Epoch 44649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44649\n",
      "Mean Log Likelihood -- train: -4.323614597320557, -- test: -44.923095703125 \n",
      "Root Mean Squared Error -- train: 0.3378538191318512, -- test: 0.9623590111732483 \n",
      " \n",
      "#################### Sampling at Epoch 44699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44699\n",
      "Mean Log Likelihood -- train: -4.1699113845825195, -- test: -46.8306999206543 \n",
      "Root Mean Squared Error -- train: 0.33327338099479675, -- test: 0.9819811582565308 \n",
      " \n",
      "#################### Sampling at Epoch 44749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44749\n",
      "Mean Log Likelihood -- train: -3.9171688556671143, -- test: -46.44688415527344 \n",
      "Root Mean Squared Error -- train: 0.3256014585494995, -- test: 0.9780648350715637 \n",
      " \n",
      "#################### Sampling at Epoch 44799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44799\n",
      "Mean Log Likelihood -- train: -3.571774959564209, -- test: -49.05915451049805 \n",
      "Root Mean Squared Error -- train: 0.31481489539146423, -- test: 1.0044182538986206 \n",
      " \n",
      "#################### Sampling at Epoch 44849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44849\n",
      "Mean Log Likelihood -- train: -3.276332139968872, -- test: -52.76799774169922 \n",
      "Root Mean Squared Error -- train: 0.3052860498428345, -- test: 1.0406886339187622 \n",
      " \n",
      "#################### Sampling at Epoch 44899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44899\n",
      "Mean Log Likelihood -- train: -2.989004611968994, -- test: -56.97359848022461 \n",
      "Root Mean Squared Error -- train: 0.2957245707511902, -- test: 1.080344796180725 \n",
      " \n",
      "#################### Sampling at Epoch 44949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44949\n",
      "Mean Log Likelihood -- train: -2.95558762550354, -- test: -54.992820739746094 \n",
      "Root Mean Squared Error -- train: 0.29459238052368164, -- test: 1.0618518590927124 \n",
      " \n",
      "#################### Sampling at Epoch 44999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 44999\n",
      "Mean Log Likelihood -- train: -2.850878953933716, -- test: -57.6728515625 \n",
      "Root Mean Squared Error -- train: 0.2910163402557373, -- test: 1.086798071861267 \n",
      " \n",
      "#################### Sampling at Epoch 45049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45049\n",
      "Mean Log Likelihood -- train: -2.7725908756256104, -- test: -55.679359436035156 \n",
      "Root Mean Squared Error -- train: 0.288313627243042, -- test: 1.0682977437973022 \n",
      " \n",
      "#################### Sampling at Epoch 45099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45099\n",
      "Mean Log Likelihood -- train: -2.6620900630950928, -- test: -56.35161590576172 \n",
      "Root Mean Squared Error -- train: 0.28445515036582947, -- test: 1.0745720863342285 \n",
      " \n",
      "#################### Sampling at Epoch 45149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45149\n",
      "Mean Log Likelihood -- train: -2.668382167816162, -- test: -56.62824249267578 \n",
      "Root Mean Squared Error -- train: 0.2846762537956238, -- test: 1.0771433115005493 \n",
      " \n",
      "#################### Sampling at Epoch 45199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45199\n",
      "Mean Log Likelihood -- train: -2.556307077407837, -- test: -60.304569244384766 \n",
      "Root Mean Squared Error -- train: 0.28071174025535583, -- test: 1.1107494831085205 \n",
      " \n",
      "#################### Sampling at Epoch 45249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45249\n",
      "Mean Log Likelihood -- train: -2.5574722290039062, -- test: -60.693756103515625 \n",
      "Root Mean Squared Error -- train: 0.2807532250881195, -- test: 1.1142476797103882 \n",
      " \n",
      "#################### Sampling at Epoch 45299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45299\n",
      "Mean Log Likelihood -- train: -2.6290297508239746, -- test: -62.85299301147461 \n",
      "Root Mean Squared Error -- train: 0.2832905054092407, -- test: 1.133460521697998 \n",
      " \n",
      "#################### Sampling at Epoch 45349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45349\n",
      "Mean Log Likelihood -- train: -2.5353405475616455, -- test: -64.11552429199219 \n",
      "Root Mean Squared Error -- train: 0.27996382117271423, -- test: 1.144545078277588 \n",
      " \n",
      "#################### Sampling at Epoch 45399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45399\n",
      "Mean Log Likelihood -- train: -2.477983236312866, -- test: -64.4870834350586 \n",
      "Root Mean Squared Error -- train: 0.27790752053260803, -- test: 1.1477868556976318 \n",
      " \n",
      "#################### Sampling at Epoch 45449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45449\n",
      "Mean Log Likelihood -- train: -2.473698377609253, -- test: -66.63676452636719 \n",
      "Root Mean Squared Error -- train: 0.2777532935142517, -- test: 1.166365385055542 \n",
      " \n",
      "#################### Sampling at Epoch 45499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45499\n",
      "Mean Log Likelihood -- train: -2.479031801223755, -- test: -66.15007019042969 \n",
      "Root Mean Squared Error -- train: 0.27794528007507324, -- test: 1.1621851921081543 \n",
      " \n",
      "#################### Sampling at Epoch 45549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45549\n",
      "Mean Log Likelihood -- train: -2.465679407119751, -- test: -64.54336547851562 \n",
      "Root Mean Squared Error -- train: 0.27746444940567017, -- test: 1.1482770442962646 \n",
      " \n",
      "#################### Sampling at Epoch 45599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45599\n",
      "Mean Log Likelihood -- train: -2.4838881492614746, -- test: -63.07145690917969 \n",
      "Root Mean Squared Error -- train: 0.27811992168426514, -- test: 1.135386347770691 \n",
      " \n",
      "#################### Sampling at Epoch 45649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45649\n",
      "Mean Log Likelihood -- train: -2.511533260345459, -- test: -66.24388885498047 \n",
      "Root Mean Squared Error -- train: 0.27911216020584106, -- test: 1.1629921197891235 \n",
      " \n",
      "#################### Sampling at Epoch 45699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45699\n",
      "Mean Log Likelihood -- train: -2.4821367263793945, -- test: -66.97472381591797 \n",
      "Root Mean Squared Error -- train: 0.27805694937705994, -- test: 1.1692593097686768 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 11:32:39.112169: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Sampling at Epoch 45749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45749\n",
      "Mean Log Likelihood -- train: -2.5448145866394043, -- test: -64.65258026123047 \n",
      "Root Mean Squared Error -- train: 0.2803020179271698, -- test: 1.1492277383804321 \n",
      " \n",
      "#################### Sampling at Epoch 45799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45799\n",
      "Mean Log Likelihood -- train: -2.4423208236694336, -- test: -70.07951354980469 \n",
      "Root Mean Squared Error -- train: 0.2766213119029999, -- test: 1.195517897605896 \n",
      " \n",
      "#################### Sampling at Epoch 45849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45849\n",
      "Mean Log Likelihood -- train: -2.4355359077453613, -- test: -66.04693603515625 \n",
      "Root Mean Squared Error -- train: 0.2763758897781372, -- test: 1.16129732131958 \n",
      " \n",
      "#################### Sampling at Epoch 45899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45899\n",
      "Mean Log Likelihood -- train: -2.505213499069214, -- test: -66.07926940917969 \n",
      "Root Mean Squared Error -- train: 0.2788856327533722, -- test: 1.1615757942199707 \n",
      " \n",
      "#################### Sampling at Epoch 45949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45949\n",
      "Mean Log Likelihood -- train: -2.407475233078003, -- test: -65.30595397949219 \n",
      "Root Mean Squared Error -- train: 0.27535873651504517, -- test: 1.1548991203308105 \n",
      " \n",
      "#################### Sampling at Epoch 45999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 45999\n",
      "Mean Log Likelihood -- train: -2.4395477771759033, -- test: -66.19470977783203 \n",
      "Root Mean Squared Error -- train: 0.27652105689048767, -- test: 1.1625690460205078 \n",
      " \n",
      "#################### Sampling at Epoch 46049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46049\n",
      "Mean Log Likelihood -- train: -2.4219934940338135, -- test: -67.00684356689453 \n",
      "Root Mean Squared Error -- train: 0.2758854627609253, -- test: 1.1695339679718018 \n",
      " \n",
      "#################### Sampling at Epoch 46099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46099\n",
      "Mean Log Likelihood -- train: -2.4530551433563232, -- test: -67.9937973022461 \n",
      "Root Mean Squared Error -- train: 0.2770090699195862, -- test: 1.1779426336288452 \n",
      " \n",
      "#################### Sampling at Epoch 46149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46149\n",
      "Mean Log Likelihood -- train: -2.4089741706848145, -- test: -69.16070556640625 \n",
      "Root Mean Squared Error -- train: 0.2754131555557251, -- test: 1.187807559967041 \n",
      " \n",
      "#################### Sampling at Epoch 46199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46199\n",
      "Mean Log Likelihood -- train: -2.465933322906494, -- test: -70.56918334960938 \n",
      "Root Mean Squared Error -- train: 0.2774735987186432, -- test: 1.1996067762374878 \n",
      " \n",
      "#################### Sampling at Epoch 46249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46249\n",
      "Mean Log Likelihood -- train: -2.4084153175354004, -- test: -70.4876937866211 \n",
      "Root Mean Squared Error -- train: 0.2753928601741791, -- test: 1.198927402496338 \n",
      " \n",
      "#################### Sampling at Epoch 46299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46299\n",
      "Mean Log Likelihood -- train: -2.381504774093628, -- test: -67.76834869384766 \n",
      "Root Mean Squared Error -- train: 0.27441397309303284, -- test: 1.1760271787643433 \n",
      " \n",
      "#################### Sampling at Epoch 46349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46349\n",
      "Mean Log Likelihood -- train: -2.5067672729492188, -- test: -69.08102416992188 \n",
      "Root Mean Squared Error -- train: 0.2789413332939148, -- test: 1.1871366500854492 \n",
      " \n",
      "#################### Sampling at Epoch 46399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46399\n",
      "Mean Log Likelihood -- train: -2.538243055343628, -- test: -64.05260467529297 \n",
      "Root Mean Squared Error -- train: 0.28006747364997864, -- test: 1.1439952850341797 \n",
      " \n",
      "#################### Sampling at Epoch 46449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46449\n",
      "Mean Log Likelihood -- train: -2.4114465713500977, -- test: -66.87007904052734 \n",
      "Root Mean Squared Error -- train: 0.27550292015075684, -- test: 1.1683640480041504 \n",
      " \n",
      "#################### Sampling at Epoch 46499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46499\n",
      "Mean Log Likelihood -- train: -2.4798052310943604, -- test: -70.66079711914062 \n",
      "Root Mean Squared Error -- train: 0.27797308564186096, -- test: 1.2003703117370605 \n",
      " \n",
      "#################### Sampling at Epoch 46549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46549\n",
      "Mean Log Likelihood -- train: -2.581113576889038, -- test: -73.2103500366211 \n",
      "Root Mean Squared Error -- train: 0.28159403800964355, -- test: 1.2214252948760986 \n",
      " \n",
      "#################### Sampling at Epoch 46599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46599\n",
      "Mean Log Likelihood -- train: -2.398040294647217, -- test: -67.7344741821289 \n",
      "Root Mean Squared Error -- train: 0.2750158905982971, -- test: 1.175739049911499 \n",
      " \n",
      "#################### Sampling at Epoch 46649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46649\n",
      "Mean Log Likelihood -- train: -2.3981783390045166, -- test: -69.7420883178711 \n",
      "Root Mean Squared Error -- train: 0.27502089738845825, -- test: 1.1926920413970947 \n",
      " \n",
      "#################### Sampling at Epoch 46699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46699\n",
      "Mean Log Likelihood -- train: -2.4278624057769775, -- test: -68.60469818115234 \n",
      "Root Mean Squared Error -- train: 0.2760981321334839, -- test: 1.183117389678955 \n",
      " \n",
      "#################### Sampling at Epoch 46749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46749\n",
      "Mean Log Likelihood -- train: -2.4410080909729004, -- test: -69.51066589355469 \n",
      "Root Mean Squared Error -- train: 0.2765738368034363, -- test: 1.190750241279602 \n",
      " \n",
      "#################### Sampling at Epoch 46799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46799\n",
      "Mean Log Likelihood -- train: -2.4127728939056396, -- test: -71.38243865966797 \n",
      "Root Mean Squared Error -- train: 0.27555105090141296, -- test: 1.2063671350479126 \n",
      " \n",
      "#################### Sampling at Epoch 46849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46849\n",
      "Mean Log Likelihood -- train: -2.435246229171753, -- test: -69.0837173461914 \n",
      "Root Mean Squared Error -- train: 0.2763654291629791, -- test: 1.1871592998504639 \n",
      " \n",
      "#################### Sampling at Epoch 46899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46899\n",
      "Mean Log Likelihood -- train: -2.4239351749420166, -- test: -72.3305892944336 \n",
      "Root Mean Squared Error -- train: 0.27595585584640503, -- test: 1.2142012119293213 \n",
      " \n",
      "#################### Sampling at Epoch 46949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46949\n",
      "Mean Log Likelihood -- train: -2.470165729522705, -- test: -70.9190673828125 \n",
      "Root Mean Squared Error -- train: 0.27762606739997864, -- test: 1.2025198936462402 \n",
      " \n",
      "#################### Sampling at Epoch 46999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 46999\n",
      "Mean Log Likelihood -- train: -2.404107093811035, -- test: -70.54987335205078 \n",
      "Root Mean Squared Error -- train: 0.2752363979816437, -- test: 1.1994458436965942 \n",
      " \n",
      "#################### Sampling at Epoch 47049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47049\n",
      "Mean Log Likelihood -- train: -2.4950780868530273, -- test: -73.31900024414062 \n",
      "Root Mean Squared Error -- train: 0.27852198481559753, -- test: 1.2223145961761475 \n",
      " \n",
      "#################### Sampling at Epoch 47099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47099\n",
      "Mean Log Likelihood -- train: -2.379692316055298, -- test: -69.88943481445312 \n",
      "Root Mean Squared Error -- train: 0.2743479013442993, -- test: 1.1939270496368408 \n",
      " \n",
      "#################### Sampling at Epoch 47149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47149\n",
      "Mean Log Likelihood -- train: -2.414630651473999, -- test: -71.15424346923828 \n",
      "Root Mean Squared Error -- train: 0.27561846375465393, -- test: 1.2044739723205566 \n",
      " \n",
      "#################### Sampling at Epoch 47199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47199\n",
      "Mean Log Likelihood -- train: -2.4333317279815674, -- test: -68.91264343261719 \n",
      "Root Mean Squared Error -- train: 0.2762961685657501, -- test: 1.1857174634933472 \n",
      " \n",
      "#################### Sampling at Epoch 47249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47249\n",
      "Mean Log Likelihood -- train: -2.486205577850342, -- test: -74.2226791381836 \n",
      "Root Mean Squared Error -- train: 0.27820321917533875, -- test: 1.2296855449676514 \n",
      " \n",
      "#################### Sampling at Epoch 47299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47299\n",
      "Mean Log Likelihood -- train: -2.399247884750366, -- test: -69.8338394165039 \n",
      "Root Mean Squared Error -- train: 0.2750597894191742, -- test: 1.1934611797332764 \n",
      " \n",
      "#################### Sampling at Epoch 47349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47349\n",
      "Mean Log Likelihood -- train: -2.3760671615600586, -- test: -68.82038116455078 \n",
      "Root Mean Squared Error -- train: 0.2742157280445099, -- test: 1.1849390268325806 \n",
      " \n",
      "#################### Sampling at Epoch 47399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47399\n",
      "Mean Log Likelihood -- train: -2.451726198196411, -- test: -69.36865997314453 \n",
      "Root Mean Squared Error -- train: 0.276961088180542, -- test: 1.1895570755004883 \n",
      " \n",
      "#################### Sampling at Epoch 47449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47449\n",
      "Mean Log Likelihood -- train: -2.424957036972046, -- test: -66.79055786132812 \n",
      "Root Mean Squared Error -- train: 0.27599287033081055, -- test: 1.1676831245422363 \n",
      " \n",
      "#################### Sampling at Epoch 47499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47499\n",
      "Mean Log Likelihood -- train: -2.408520460128784, -- test: -67.2880630493164 \n",
      "Root Mean Squared Error -- train: 0.2753966748714447, -- test: 1.1719361543655396 \n",
      " \n",
      "#################### Sampling at Epoch 47549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47549\n",
      "Mean Log Likelihood -- train: -2.3967833518981934, -- test: -67.78359985351562 \n",
      "Root Mean Squared Error -- train: 0.2749701738357544, -- test: 1.176156759262085 \n",
      " \n",
      "#################### Sampling at Epoch 47599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47599\n",
      "Mean Log Likelihood -- train: -2.432682991027832, -- test: -67.80976104736328 \n",
      "Root Mean Squared Error -- train: 0.27627265453338623, -- test: 1.1763792037963867 \n",
      " \n",
      "#################### Sampling at Epoch 47649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47649\n",
      "Mean Log Likelihood -- train: -2.4537529945373535, -- test: -67.89777374267578 \n",
      "Root Mean Squared Error -- train: 0.27703428268432617, -- test: 1.1771271228790283 \n",
      " \n",
      "#################### Sampling at Epoch 47699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47699\n",
      "Mean Log Likelihood -- train: -2.463137626647949, -- test: -70.69168853759766 \n",
      "Root Mean Squared Error -- train: 0.2773728370666504, -- test: 1.2006275653839111 \n",
      " \n",
      "#################### Sampling at Epoch 47749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47749\n",
      "Mean Log Likelihood -- train: -2.467230796813965, -- test: -70.7962646484375 \n",
      "Root Mean Squared Error -- train: 0.2775203585624695, -- test: 1.20149827003479 \n",
      " \n",
      "#################### Sampling at Epoch 47799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47799\n",
      "Mean Log Likelihood -- train: -2.423170804977417, -- test: -70.72936248779297 \n",
      "Root Mean Squared Error -- train: 0.27592816948890686, -- test: 1.2009413242340088 \n",
      " \n",
      "#################### Sampling at Epoch 47849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47849\n",
      "Mean Log Likelihood -- train: -2.4364097118377686, -- test: -67.16801452636719 \n",
      "Root Mean Squared Error -- train: 0.27640751004219055, -- test: 1.1709113121032715 \n",
      " \n",
      "#################### Sampling at Epoch 47899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47899\n",
      "Mean Log Likelihood -- train: -2.5075535774230957, -- test: -69.0159683227539 \n",
      "Root Mean Squared Error -- train: 0.27896955609321594, -- test: 1.1865885257720947 \n",
      " \n",
      "#################### Sampling at Epoch 47949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47949\n",
      "Mean Log Likelihood -- train: -2.492231845855713, -- test: -67.83049011230469 \n",
      "Root Mean Squared Error -- train: 0.27841976284980774, -- test: 1.1765553951263428 \n",
      " \n",
      "#################### Sampling at Epoch 47999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 47999\n",
      "Mean Log Likelihood -- train: -2.4134888648986816, -- test: -68.65896606445312 \n",
      "Root Mean Squared Error -- train: 0.27557703852653503, -- test: 1.183575987815857 \n",
      " \n",
      "#################### Sampling at Epoch 48049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48049\n",
      "Mean Log Likelihood -- train: -2.4243454933166504, -- test: -72.05870819091797 \n",
      "Root Mean Squared Error -- train: 0.2759706974029541, -- test: 1.211959958076477 \n",
      " \n",
      "#################### Sampling at Epoch 48099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48099\n",
      "Mean Log Likelihood -- train: -2.517627000808716, -- test: -71.57489776611328 \n",
      "Root Mean Squared Error -- train: 0.27933040261268616, -- test: 1.2079614400863647 \n",
      " \n",
      "#################### Sampling at Epoch 48149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48149\n",
      "Mean Log Likelihood -- train: -2.457982063293457, -- test: -71.07044219970703 \n",
      "Root Mean Squared Error -- train: 0.27718690037727356, -- test: 1.2037781476974487 \n",
      " \n",
      "#################### Sampling at Epoch 48199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48199\n",
      "Mean Log Likelihood -- train: -2.4177260398864746, -- test: -67.93639373779297 \n",
      "Root Mean Squared Error -- train: 0.27573075890541077, -- test: 1.1774553060531616 \n",
      " \n",
      "#################### Sampling at Epoch 48249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48249\n",
      "Mean Log Likelihood -- train: -2.423859119415283, -- test: -70.45159912109375 \n",
      "Root Mean Squared Error -- train: 0.275953084230423, -- test: 1.1986262798309326 \n",
      " \n",
      "#################### Sampling at Epoch 48299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48299\n",
      "Mean Log Likelihood -- train: -2.4632976055145264, -- test: -70.40093994140625 \n",
      "Root Mean Squared Error -- train: 0.2773785889148712, -- test: 1.1982035636901855 \n",
      " \n",
      "#################### Sampling at Epoch 48349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48349\n",
      "Mean Log Likelihood -- train: -2.4422318935394287, -- test: -70.21317291259766 \n",
      "Root Mean Squared Error -- train: 0.276618093252182, -- test: 1.1966354846954346 \n",
      " \n",
      "#################### Sampling at Epoch 48399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48399\n",
      "Mean Log Likelihood -- train: -2.4284627437591553, -- test: -72.83183288574219 \n",
      "Root Mean Squared Error -- train: 0.2761198580265045, -- test: 1.218322515487671 \n",
      " \n",
      "#################### Sampling at Epoch 48449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48449\n",
      "Mean Log Likelihood -- train: -2.4704129695892334, -- test: -67.16243743896484 \n",
      "Root Mean Squared Error -- train: 0.27763497829437256, -- test: 1.1708636283874512 \n",
      " \n",
      "#################### Sampling at Epoch 48499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48499\n",
      "Mean Log Likelihood -- train: -2.4809417724609375, -- test: -67.48250579833984 \n",
      "Root Mean Squared Error -- train: 0.2780139744281769, -- test: 1.1735939979553223 \n",
      " \n",
      "#################### Sampling at Epoch 48549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48549\n",
      "Mean Log Likelihood -- train: -2.4183130264282227, -- test: -69.15541076660156 \n",
      "Root Mean Squared Error -- train: 0.27575206756591797, -- test: 1.1877630949020386 \n",
      " \n",
      "#################### Sampling at Epoch 48599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48599\n",
      "Mean Log Likelihood -- train: -2.4764914512634277, -- test: -66.40483856201172 \n",
      "Root Mean Squared Error -- train: 0.2778538465499878, -- test: 1.1643753051757812 \n",
      " \n",
      "#################### Sampling at Epoch 48649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48649\n",
      "Mean Log Likelihood -- train: -2.430554151535034, -- test: -66.01385498046875 \n",
      "Root Mean Squared Error -- train: 0.27619558572769165, -- test: 1.1610124111175537 \n",
      " \n",
      "#################### Sampling at Epoch 48699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48699\n",
      "Mean Log Likelihood -- train: -2.439746141433716, -- test: -64.96861267089844 \n",
      "Root Mean Squared Error -- train: 0.2765282094478607, -- test: 1.1519744396209717 \n",
      " \n",
      "#################### Sampling at Epoch 48749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48749\n",
      "Mean Log Likelihood -- train: -2.460127830505371, -- test: -65.53730773925781 \n",
      "Root Mean Squared Error -- train: 0.277264267206192, -- test: 1.1569006443023682 \n",
      " \n",
      "#################### Sampling at Epoch 48799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48799\n",
      "Mean Log Likelihood -- train: -2.4826202392578125, -- test: -60.78605651855469 \n",
      "Root Mean Squared Error -- train: 0.27807432413101196, -- test: 1.1150758266448975 \n",
      " \n",
      "#################### Sampling at Epoch 48849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48849\n",
      "Mean Log Likelihood -- train: -2.4765231609344482, -- test: -61.29560470581055 \n",
      "Root Mean Squared Error -- train: 0.2778549790382385, -- test: 1.119636058807373 \n",
      " \n",
      "#################### Sampling at Epoch 48899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48899\n",
      "Mean Log Likelihood -- train: -2.4551193714141846, -- test: -62.60955047607422 \n",
      "Root Mean Squared Error -- train: 0.2770835757255554, -- test: 1.1313107013702393 \n",
      " \n",
      "#################### Sampling at Epoch 48949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48949\n",
      "Mean Log Likelihood -- train: -2.4362945556640625, -- test: -62.700923919677734 \n",
      "Root Mean Squared Error -- train: 0.27640336751937866, -- test: 1.1321181058883667 \n",
      " \n",
      "#################### Sampling at Epoch 48999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 48999\n",
      "Mean Log Likelihood -- train: -2.456514596939087, -- test: -63.10285186767578 \n",
      "Root Mean Squared Error -- train: 0.27713391184806824, -- test: 1.1356627941131592 \n",
      " \n",
      "#################### Sampling at Epoch 49049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49049\n",
      "Mean Log Likelihood -- train: -2.5242950916290283, -- test: -64.94168853759766 \n",
      "Root Mean Squared Error -- train: 0.27956902980804443, -- test: 1.1517407894134521 \n",
      " \n",
      "#################### Sampling at Epoch 49099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49099\n",
      "Mean Log Likelihood -- train: -2.470515489578247, -- test: -63.84284210205078 \n",
      "Root Mean Squared Error -- train: 0.27763867378234863, -- test: 1.1421600580215454 \n",
      " \n",
      "#################### Sampling at Epoch 49149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49149\n",
      "Mean Log Likelihood -- train: -2.465296506881714, -- test: -65.96041870117188 \n",
      "Root Mean Squared Error -- train: 0.2774506211280823, -- test: 1.1605521440505981 \n",
      " \n",
      "#################### Sampling at Epoch 49199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49199\n",
      "Mean Log Likelihood -- train: -2.4391896724700928, -- test: -64.07341766357422 \n",
      "Root Mean Squared Error -- train: 0.276508092880249, -- test: 1.1441770792007446 \n",
      " \n",
      "#################### Sampling at Epoch 49249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49249\n",
      "Mean Log Likelihood -- train: -2.480388879776001, -- test: -65.20287322998047 \n",
      "Root Mean Squared Error -- train: 0.2779940962791443, -- test: 1.1540062427520752 \n",
      " \n",
      "#################### Sampling at Epoch 49299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49299\n",
      "Mean Log Likelihood -- train: -2.498365879058838, -- test: -61.75725555419922 \n",
      "Root Mean Squared Error -- train: 0.2786400020122528, -- test: 1.1237517595291138 \n",
      " \n",
      "#################### Sampling at Epoch 49349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49349\n",
      "Mean Log Likelihood -- train: -2.421452760696411, -- test: -63.732479095458984 \n",
      "Root Mean Squared Error -- train: 0.2758658826351166, -- test: 1.1411933898925781 \n",
      " \n",
      "#################### Sampling at Epoch 49399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49399\n",
      "Mean Log Likelihood -- train: -2.4963419437408447, -- test: -64.35861206054688 \n",
      "Root Mean Squared Error -- train: 0.2785673439502716, -- test: 1.1466668844223022 \n",
      " \n",
      "#################### Sampling at Epoch 49449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49449\n",
      "Mean Log Likelihood -- train: -2.490476131439209, -- test: -65.03726196289062 \n",
      "Root Mean Squared Error -- train: 0.2783567011356354, -- test: 1.1525702476501465 \n",
      " \n",
      "#################### Sampling at Epoch 49499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49499\n",
      "Mean Log Likelihood -- train: -2.463925838470459, -- test: -67.20770263671875 \n",
      "Root Mean Squared Error -- train: 0.27740126848220825, -- test: 1.1712501049041748 \n",
      " \n",
      "#################### Sampling at Epoch 49549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49549\n",
      "Mean Log Likelihood -- train: -2.460702419281006, -- test: -67.9350814819336 \n",
      "Root Mean Squared Error -- train: 0.27728503942489624, -- test: 1.1774441003799438 \n",
      " \n",
      "#################### Sampling at Epoch 49599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49599\n",
      "Mean Log Likelihood -- train: -2.4236667156219482, -- test: -65.97360229492188 \n",
      "Root Mean Squared Error -- train: 0.27594611048698425, -- test: 1.16066575050354 \n",
      " \n",
      "#################### Sampling at Epoch 49649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49649\n",
      "Mean Log Likelihood -- train: -2.5079050064086914, -- test: -63.120792388916016 \n",
      "Root Mean Squared Error -- train: 0.27898213267326355, -- test: 1.1358208656311035 \n",
      " \n",
      "#################### Sampling at Epoch 49699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49699\n",
      "Mean Log Likelihood -- train: -2.493931770324707, -- test: -65.84625244140625 \n",
      "Root Mean Squared Error -- train: 0.2784808278083801, -- test: 1.159567952156067 \n",
      " \n",
      "#################### Sampling at Epoch 49749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49749\n",
      "Mean Log Likelihood -- train: -2.4356160163879395, -- test: -68.23847198486328 \n",
      "Root Mean Squared Error -- train: 0.2763788104057312, -- test: 1.1800179481506348 \n",
      " \n",
      "#################### Sampling at Epoch 49799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49799\n",
      "Mean Log Likelihood -- train: -2.4803059101104736, -- test: -69.59513854980469 \n",
      "Root Mean Squared Error -- train: 0.2779911160469055, -- test: 1.1914595365524292 \n",
      " \n",
      "#################### Sampling at Epoch 49849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49849\n",
      "Mean Log Likelihood -- train: -2.464520215988159, -- test: -67.9870376586914 \n",
      "Root Mean Squared Error -- train: 0.27742263674736023, -- test: 1.1778852939605713 \n",
      " \n",
      "#################### Sampling at Epoch 49899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49899\n",
      "Mean Log Likelihood -- train: -2.474017381668091, -- test: -69.81739044189453 \n",
      "Root Mean Squared Error -- train: 0.27776479721069336, -- test: 1.1933233737945557 \n",
      " \n",
      "#################### Sampling at Epoch 49949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49949\n",
      "Mean Log Likelihood -- train: -2.4442508220672607, -- test: -72.37354278564453 \n",
      "Root Mean Squared Error -- train: 0.2766910493373871, -- test: 1.2145549058914185 \n",
      " \n",
      "#################### Sampling at Epoch 49999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 49999\n",
      "Mean Log Likelihood -- train: -2.4619979858398438, -- test: -69.52238464355469 \n",
      "Root Mean Squared Error -- train: 0.27733170986175537, -- test: 1.190848708152771 \n",
      " \n",
      "#################### Sampling at Epoch 50049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50049\n",
      "Mean Log Likelihood -- train: -2.468214511871338, -- test: -65.31517791748047 \n",
      "Root Mean Squared Error -- train: 0.27755579352378845, -- test: 1.1549789905548096 \n",
      " \n",
      "#################### Sampling at Epoch 50099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50099\n",
      "Mean Log Likelihood -- train: -2.428967237472534, -- test: -65.63854217529297 \n",
      "Root Mean Squared Error -- train: 0.27613815665245056, -- test: 1.1577752828598022 \n",
      " \n",
      "#################### Sampling at Epoch 50149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50149\n",
      "Mean Log Likelihood -- train: -2.431777238845825, -- test: -63.3563232421875 \n",
      "Root Mean Squared Error -- train: 0.27623987197875977, -- test: 1.137892484664917 \n",
      " \n",
      "#################### Sampling at Epoch 50199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50199\n",
      "Mean Log Likelihood -- train: -2.4100325107574463, -- test: -63.641902923583984 \n",
      "Root Mean Squared Error -- train: 0.2754516005516052, -- test: 1.14039945602417 \n",
      " \n",
      "#################### Sampling at Epoch 50249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50249\n",
      "Mean Log Likelihood -- train: -2.4887781143188477, -- test: -65.57313537597656 \n",
      "Root Mean Squared Error -- train: 0.27829569578170776, -- test: 1.1572102308273315 \n",
      " \n",
      "#################### Sampling at Epoch 50299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50299\n",
      "Mean Log Likelihood -- train: -2.4594242572784424, -- test: -64.46134948730469 \n",
      "Root Mean Squared Error -- train: 0.2772389054298401, -- test: 1.1475625038146973 \n",
      " \n",
      "#################### Sampling at Epoch 50349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50349\n",
      "Mean Log Likelihood -- train: -2.48244047164917, -- test: -67.0180435180664 \n",
      "Root Mean Squared Error -- train: 0.27806785702705383, -- test: 1.169629693031311 \n",
      " \n",
      "#################### Sampling at Epoch 50399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50399\n",
      "Mean Log Likelihood -- train: -2.4348151683807373, -- test: -67.79045104980469 \n",
      "Root Mean Squared Error -- train: 0.27634984254837036, -- test: 1.1762150526046753 \n",
      " \n",
      "#################### Sampling at Epoch 50449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50449\n",
      "Mean Log Likelihood -- train: -2.568877696990967, -- test: -68.41790771484375 \n",
      "Root Mean Squared Error -- train: 0.2811591923236847, -- test: 1.1815375089645386 \n",
      " \n",
      "#################### Sampling at Epoch 50499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50499\n",
      "Mean Log Likelihood -- train: -2.43552303314209, -- test: -67.41032409667969 \n",
      "Root Mean Squared Error -- train: 0.2763754427433014, -- test: 1.1729788780212402 \n",
      " \n",
      "#################### Sampling at Epoch 50549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50549\n",
      "Mean Log Likelihood -- train: -2.4377191066741943, -- test: -67.00706481933594 \n",
      "Root Mean Squared Error -- train: 0.276454895734787, -- test: 1.1695358753204346 \n",
      " \n",
      "#################### Sampling at Epoch 50599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50599\n",
      "Mean Log Likelihood -- train: -2.4593634605407715, -- test: -64.98795318603516 \n",
      "Root Mean Squared Error -- train: 0.2772367298603058, -- test: 1.1521422863006592 \n",
      " \n",
      "#################### Sampling at Epoch 50649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50649\n",
      "Mean Log Likelihood -- train: -2.452634572982788, -- test: -64.7170181274414 \n",
      "Root Mean Squared Error -- train: 0.27699390053749084, -- test: 1.1497883796691895 \n",
      " \n",
      "#################### Sampling at Epoch 50699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50699\n",
      "Mean Log Likelihood -- train: -2.4413132667541504, -- test: -65.75711059570312 \n",
      "Root Mean Squared Error -- train: 0.2765848636627197, -- test: 1.1587990522384644 \n",
      " \n",
      "#################### Sampling at Epoch 50749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50749\n",
      "Mean Log Likelihood -- train: -2.4865667819976807, -- test: -66.77546691894531 \n",
      "Root Mean Squared Error -- train: 0.2782162129878998, -- test: 1.1675540208816528 \n",
      " \n",
      "#################### Sampling at Epoch 50799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50799\n",
      "Mean Log Likelihood -- train: -2.4223580360412598, -- test: -67.03062438964844 \n",
      "Root Mean Squared Error -- train: 0.27589869499206543, -- test: 1.1697373390197754 \n",
      " \n",
      "#################### Sampling at Epoch 50849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50849\n",
      "Mean Log Likelihood -- train: -2.4352822303771973, -- test: -65.53460693359375 \n",
      "Root Mean Squared Error -- train: 0.2763667404651642, -- test: 1.1568772792816162 \n",
      " \n",
      "#################### Sampling at Epoch 50899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50899\n",
      "Mean Log Likelihood -- train: -2.4059031009674072, -- test: -67.67987060546875 \n",
      "Root Mean Squared Error -- train: 0.27530163526535034, -- test: 1.1752744913101196 \n",
      " \n",
      "#################### Sampling at Epoch 50949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50949\n",
      "Mean Log Likelihood -- train: -2.4445173740386963, -- test: -66.0484390258789 \n",
      "Root Mean Squared Error -- train: 0.2767006754875183, -- test: 1.1613104343414307 \n",
      " \n",
      "#################### Sampling at Epoch 50999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 50999\n",
      "Mean Log Likelihood -- train: -2.4915106296539307, -- test: -65.85248565673828 \n",
      "Root Mean Squared Error -- train: 0.27839383482933044, -- test: 1.1596217155456543 \n",
      " \n",
      "#################### Sampling at Epoch 51049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51049\n",
      "Mean Log Likelihood -- train: -2.3997087478637695, -- test: -64.32978820800781 \n",
      "Root Mean Squared Error -- train: 0.27507656812667847, -- test: 1.1464155912399292 \n",
      " \n",
      "#################### Sampling at Epoch 51099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51099\n",
      "Mean Log Likelihood -- train: -2.4454331398010254, -- test: -67.38709259033203 \n",
      "Root Mean Squared Error -- train: 0.27673378586769104, -- test: 1.1727807521820068 \n",
      " \n",
      "#################### Sampling at Epoch 51149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51149\n",
      "Mean Log Likelihood -- train: -2.41133189201355, -- test: -63.715965270996094 \n",
      "Root Mean Squared Error -- train: 0.27549877762794495, -- test: 1.141048789024353 \n",
      " \n",
      "#################### Sampling at Epoch 51199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51199\n",
      "Mean Log Likelihood -- train: -2.4572501182556152, -- test: -64.41343688964844 \n",
      "Root Mean Squared Error -- train: 0.27716049551963806, -- test: 1.1471450328826904 \n",
      " \n",
      "#################### Sampling at Epoch 51249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51249\n",
      "Mean Log Likelihood -- train: -2.5446791648864746, -- test: -62.225685119628906 \n",
      "Root Mean Squared Error -- train: 0.280297189950943, -- test: 1.1279125213623047 \n",
      " \n",
      "#################### Sampling at Epoch 51299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51299\n",
      "Mean Log Likelihood -- train: -2.478519916534424, -- test: -61.195716857910156 \n",
      "Root Mean Squared Error -- train: 0.27792683243751526, -- test: 1.118743658065796 \n",
      " \n",
      "#################### Sampling at Epoch 51349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51349\n",
      "Mean Log Likelihood -- train: -2.4397261142730713, -- test: -62.577693939208984 \n",
      "Root Mean Squared Error -- train: 0.276527464389801, -- test: 1.1310290098190308 \n",
      " \n",
      "#################### Sampling at Epoch 51399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51399\n",
      "Mean Log Likelihood -- train: -2.4920973777770996, -- test: -63.66908645629883 \n",
      "Root Mean Squared Error -- train: 0.27841493487358093, -- test: 1.1406378746032715 \n",
      " \n",
      "#################### Sampling at Epoch 51449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51449\n",
      "Mean Log Likelihood -- train: -2.4500715732574463, -- test: -59.316307067871094 \n",
      "Root Mean Squared Error -- train: 0.27690133452415466, -- test: 1.1018162965774536 \n",
      " \n",
      "#################### Sampling at Epoch 51499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51499\n",
      "Mean Log Likelihood -- train: -2.4634482860565186, -- test: -58.14911651611328 \n",
      "Root Mean Squared Error -- train: 0.2773840129375458, -- test: 1.0911715030670166 \n",
      " \n",
      "#################### Sampling at Epoch 51549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51549\n",
      "Mean Log Likelihood -- train: -2.4950833320617676, -- test: -56.84359359741211 \n",
      "Root Mean Squared Error -- train: 0.27852216362953186, -- test: 1.0791406631469727 \n",
      " \n",
      "#################### Sampling at Epoch 51599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51599\n",
      "Mean Log Likelihood -- train: -2.5098090171813965, -- test: -58.065914154052734 \n",
      "Root Mean Squared Error -- train: 0.27905037999153137, -- test: 1.0904086828231812 \n",
      " \n",
      "#################### Sampling at Epoch 51649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51649\n",
      "Mean Log Likelihood -- train: -2.499199867248535, -- test: -52.949153900146484 \n",
      "Root Mean Squared Error -- train: 0.27866995334625244, -- test: 1.0424280166625977 \n",
      " \n",
      "#################### Sampling at Epoch 51699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51699\n",
      "Mean Log Likelihood -- train: -2.490035057067871, -- test: -52.41258239746094 \n",
      "Root Mean Squared Error -- train: 0.2783408463001251, -- test: 1.0372679233551025 \n",
      " \n",
      "#################### Sampling at Epoch 51749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51749\n",
      "Mean Log Likelihood -- train: -2.492697238922119, -- test: -54.509586334228516 \n",
      "Root Mean Squared Error -- train: 0.27843648195266724, -- test: 1.0572911500930786 \n",
      " \n",
      "#################### Sampling at Epoch 51799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51799\n",
      "Mean Log Likelihood -- train: -2.442711591720581, -- test: -58.03670883178711 \n",
      "Root Mean Squared Error -- train: 0.27663543820381165, -- test: 1.09014093875885 \n",
      " \n",
      "#################### Sampling at Epoch 51849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51849\n",
      "Mean Log Likelihood -- train: -2.478938579559326, -- test: -55.997623443603516 \n",
      "Root Mean Squared Error -- train: 0.27794188261032104, -- test: 1.071272850036621 \n",
      " \n",
      "#################### Sampling at Epoch 51899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51899\n",
      "Mean Log Likelihood -- train: -2.552581310272217, -- test: -57.961402893066406 \n",
      "Root Mean Squared Error -- train: 0.28057894110679626, -- test: 1.0894498825073242 \n",
      " \n",
      "#################### Sampling at Epoch 51949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51949\n",
      "Mean Log Likelihood -- train: -2.4500510692596436, -- test: -59.420616149902344 \n",
      "Root Mean Squared Error -- train: 0.27690061926841736, -- test: 1.1027624607086182 \n",
      " \n",
      "#################### Sampling at Epoch 51999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 51999\n",
      "Mean Log Likelihood -- train: -2.405085802078247, -- test: -61.32624816894531 \n",
      "Root Mean Squared Error -- train: 0.2752719521522522, -- test: 1.119909644126892 \n",
      " \n",
      "#################### Sampling at Epoch 52049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52049\n",
      "Mean Log Likelihood -- train: -2.4517593383789062, -- test: -64.36884307861328 \n",
      "Root Mean Squared Error -- train: 0.2769623100757599, -- test: 1.1467561721801758 \n",
      " \n",
      "#################### Sampling at Epoch 52099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52099\n",
      "Mean Log Likelihood -- train: -2.3795244693756104, -- test: -63.57072448730469 \n",
      "Root Mean Squared Error -- train: 0.27434179186820984, -- test: 1.1397751569747925 \n",
      " \n",
      "#################### Sampling at Epoch 52149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52149\n",
      "Mean Log Likelihood -- train: -2.4074788093566895, -- test: -65.71154022216797 \n",
      "Root Mean Squared Error -- train: 0.2753588557243347, -- test: 1.1584056615829468 \n",
      " \n",
      "#################### Sampling at Epoch 52199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52199\n",
      "Mean Log Likelihood -- train: -2.377115488052368, -- test: -63.63275909423828 \n",
      "Root Mean Squared Error -- train: 0.2742539644241333, -- test: 1.1403192281723022 \n",
      " \n",
      "#################### Sampling at Epoch 52249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52249\n",
      "Mean Log Likelihood -- train: -2.417212963104248, -- test: -64.45658874511719 \n",
      "Root Mean Squared Error -- train: 0.27571213245391846, -- test: 1.1475211381912231 \n",
      " \n",
      "#################### Sampling at Epoch 52299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52299\n",
      "Mean Log Likelihood -- train: -2.409071207046509, -- test: -63.24558639526367 \n",
      "Root Mean Squared Error -- train: 0.27541670203208923, -- test: 1.1369189023971558 \n",
      " \n",
      "#################### Sampling at Epoch 52349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52349\n",
      "Mean Log Likelihood -- train: -2.5039565563201904, -- test: -60.405330657958984 \n",
      "Root Mean Squared Error -- train: 0.278840571641922, -- test: 1.1116563081741333 \n",
      " \n",
      "#################### Sampling at Epoch 52399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52399\n",
      "Mean Log Likelihood -- train: -2.4165258407592773, -- test: -64.51502227783203 \n",
      "Root Mean Squared Error -- train: 0.27568721771240234, -- test: 1.148030161857605 \n",
      " \n",
      "#################### Sampling at Epoch 52449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52449\n",
      "Mean Log Likelihood -- train: -2.4600439071655273, -- test: -70.97322082519531 \n",
      "Root Mean Squared Error -- train: 0.27726125717163086, -- test: 1.202970266342163 \n",
      " \n",
      "#################### Sampling at Epoch 52499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52499\n",
      "Mean Log Likelihood -- train: -2.4203898906707764, -- test: -69.83487701416016 \n",
      "Root Mean Squared Error -- train: 0.2758273482322693, -- test: 1.1934698820114136 \n",
      " \n",
      "#################### Sampling at Epoch 52549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52549\n",
      "Mean Log Likelihood -- train: -2.4661636352539062, -- test: -72.95667266845703 \n",
      "Root Mean Squared Error -- train: 0.27748191356658936, -- test: 1.2193466424942017 \n",
      " \n",
      "#################### Sampling at Epoch 52599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52599\n",
      "Mean Log Likelihood -- train: -2.430523157119751, -- test: -71.95573425292969 \n",
      "Root Mean Squared Error -- train: 0.2761944532394409, -- test: 1.2111101150512695 \n",
      " \n",
      "#################### Sampling at Epoch 52649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52649\n",
      "Mean Log Likelihood -- train: -2.449392795562744, -- test: -72.7745590209961 \n",
      "Root Mean Squared Error -- train: 0.276876837015152, -- test: 1.217852234840393 \n",
      " \n",
      "#################### Sampling at Epoch 52699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52699\n",
      "Mean Log Likelihood -- train: -2.4498651027679443, -- test: -69.50074005126953 \n",
      "Root Mean Squared Error -- train: 0.2768939137458801, -- test: 1.190666913986206 \n",
      " \n",
      "#################### Sampling at Epoch 52749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52749\n",
      "Mean Log Likelihood -- train: -2.4769113063812256, -- test: -71.44673919677734 \n",
      "Root Mean Squared Error -- train: 0.27786895632743835, -- test: 1.206899881362915 \n",
      " \n",
      "#################### Sampling at Epoch 52799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52799\n",
      "Mean Log Likelihood -- train: -2.5227458477020264, -- test: -70.33675384521484 \n",
      "Root Mean Squared Error -- train: 0.2795135974884033, -- test: 1.1976677179336548 \n",
      " \n",
      "#################### Sampling at Epoch 52849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52849\n",
      "Mean Log Likelihood -- train: -2.5332887172698975, -- test: -70.46209716796875 \n",
      "Root Mean Squared Error -- train: 0.2798905372619629, -- test: 1.198713779449463 \n",
      " \n",
      "#################### Sampling at Epoch 52899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52899\n",
      "Mean Log Likelihood -- train: -2.465554714202881, -- test: -66.17572021484375 \n",
      "Root Mean Squared Error -- train: 0.2774599492549896, -- test: 1.1624057292938232 \n",
      " \n",
      "#################### Sampling at Epoch 52949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52949\n",
      "Mean Log Likelihood -- train: -2.515610456466675, -- test: -67.50090026855469 \n",
      "Root Mean Squared Error -- train: 0.27925822138786316, -- test: 1.1737507581710815 \n",
      " \n",
      "#################### Sampling at Epoch 52999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 52999\n",
      "Mean Log Likelihood -- train: -2.5734732151031494, -- test: -69.9178237915039 \n",
      "Root Mean Squared Error -- train: 0.28132256865501404, -- test: 1.1941646337509155 \n",
      " \n",
      "#################### Sampling at Epoch 53049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53049\n",
      "Mean Log Likelihood -- train: -2.5489792823791504, -- test: -76.83308410644531 \n",
      "Root Mean Squared Error -- train: 0.2804505527019501, -- test: 1.2507336139678955 \n",
      " \n",
      "#################### Sampling at Epoch 53099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53099\n",
      "Mean Log Likelihood -- train: -2.4903910160064697, -- test: -72.68692016601562 \n",
      "Root Mean Squared Error -- train: 0.27835366129875183, -- test: 1.2171324491500854 \n",
      " \n",
      "#################### Sampling at Epoch 53149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53149\n",
      "Mean Log Likelihood -- train: -2.4714784622192383, -- test: -71.47447204589844 \n",
      "Root Mean Squared Error -- train: 0.2776733636856079, -- test: 1.2071298360824585 \n",
      " \n",
      "#################### Sampling at Epoch 53199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53199\n",
      "Mean Log Likelihood -- train: -2.5084409713745117, -- test: -72.66510009765625 \n",
      "Root Mean Squared Error -- train: 0.2790013551712036, -- test: 1.216953158378601 \n",
      " \n",
      "#################### Sampling at Epoch 53249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53249\n",
      "Mean Log Likelihood -- train: -2.458392858505249, -- test: -73.29866790771484 \n",
      "Root Mean Squared Error -- train: 0.27720168232917786, -- test: 1.2221481800079346 \n",
      " \n",
      "#################### Sampling at Epoch 53299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53299\n",
      "Mean Log Likelihood -- train: -2.5292258262634277, -- test: -68.47059631347656 \n",
      "Root Mean Squared Error -- train: 0.27974531054496765, -- test: 1.181983470916748 \n",
      " \n",
      "#################### Sampling at Epoch 53349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53349\n",
      "Mean Log Likelihood -- train: -2.5038390159606934, -- test: -69.93651580810547 \n",
      "Root Mean Squared Error -- train: 0.27883636951446533, -- test: 1.1943212747573853 \n",
      " \n",
      "#################### Sampling at Epoch 53399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53399\n",
      "Mean Log Likelihood -- train: -2.4993937015533447, -- test: -68.74357604980469 \n",
      "Root Mean Squared Error -- train: 0.2786768972873688, -- test: 1.1842907667160034 \n",
      " \n",
      "#################### Sampling at Epoch 53449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53449\n",
      "Mean Log Likelihood -- train: -2.530884265899658, -- test: -71.80419158935547 \n",
      "Root Mean Squared Error -- train: 0.2798045873641968, -- test: 1.2098581790924072 \n",
      " \n",
      "#################### Sampling at Epoch 53499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53499\n",
      "Mean Log Likelihood -- train: -2.5007543563842773, -- test: -70.2799301147461 \n",
      "Root Mean Squared Error -- train: 0.27872568368911743, -- test: 1.1971931457519531 \n",
      " \n",
      "#################### Sampling at Epoch 53549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53549\n",
      "Mean Log Likelihood -- train: -2.448958396911621, -- test: -73.18745422363281 \n",
      "Root Mean Squared Error -- train: 0.27686113119125366, -- test: 1.2212378978729248 \n",
      " \n",
      "#################### Sampling at Epoch 53599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53599\n",
      "Mean Log Likelihood -- train: -2.474128007888794, -- test: -71.50914001464844 \n",
      "Root Mean Squared Error -- train: 0.2777687609195709, -- test: 1.2074168920516968 \n",
      " \n",
      "#################### Sampling at Epoch 53649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53649\n",
      "Mean Log Likelihood -- train: -2.4293315410614014, -- test: -70.45526123046875 \n",
      "Root Mean Squared Error -- train: 0.2761513292789459, -- test: 1.1986569166183472 \n",
      " \n",
      "#################### Sampling at Epoch 53699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53699\n",
      "Mean Log Likelihood -- train: -2.421149969100952, -- test: -68.10392761230469 \n",
      "Root Mean Squared Error -- train: 0.2758549153804779, -- test: 1.1788771152496338 \n",
      " \n",
      "#################### Sampling at Epoch 53749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53749\n",
      "Mean Log Likelihood -- train: -2.3823978900909424, -- test: -65.085693359375 \n",
      "Root Mean Squared Error -- train: 0.2744465172290802, -- test: 1.1529903411865234 \n",
      " \n",
      "#################### Sampling at Epoch 53799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53799\n",
      "Mean Log Likelihood -- train: -2.4411118030548096, -- test: -63.880802154541016 \n",
      "Root Mean Squared Error -- train: 0.27657759189605713, -- test: 1.1424922943115234 \n",
      " \n",
      "#################### Sampling at Epoch 53849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53849\n",
      "Mean Log Likelihood -- train: -2.43023419380188, -- test: -63.53938293457031 \n",
      "Root Mean Squared Error -- train: 0.2761840224266052, -- test: 1.1395000219345093 \n",
      " \n",
      "#################### Sampling at Epoch 53899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53899\n",
      "Mean Log Likelihood -- train: -2.4217123985290527, -- test: -64.55551147460938 \n",
      "Root Mean Squared Error -- train: 0.2758753001689911, -- test: 1.1483829021453857 \n",
      " \n",
      "#################### Sampling at Epoch 53949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53949\n",
      "Mean Log Likelihood -- train: -2.403172254562378, -- test: -62.06781768798828 \n",
      "Root Mean Squared Error -- train: 0.2752024233341217, -- test: 1.1265119314193726 \n",
      " \n",
      "#################### Sampling at Epoch 53999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 53999\n",
      "Mean Log Likelihood -- train: -2.52077054977417, -- test: -63.9155387878418 \n",
      "Root Mean Squared Error -- train: 0.2794429361820221, -- test: 1.142796516418457 \n",
      " \n",
      "#################### Sampling at Epoch 54049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54049\n",
      "Mean Log Likelihood -- train: -2.4464364051818848, -- test: -62.2852783203125 \n",
      "Root Mean Squared Error -- train: 0.2767700254917145, -- test: 1.1284407377243042 \n",
      " \n",
      "#################### Sampling at Epoch 54099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54099\n",
      "Mean Log Likelihood -- train: -2.5140960216522217, -- test: -63.04167556762695 \n",
      "Root Mean Squared Error -- train: 0.27920395135879517, -- test: 1.1351239681243896 \n",
      " \n",
      "#################### Sampling at Epoch 54149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54149\n",
      "Mean Log Likelihood -- train: -2.4386587142944336, -- test: -64.53478240966797 \n",
      "Root Mean Squared Error -- train: 0.27648887038230896, -- test: 1.1482023000717163 \n",
      " \n",
      "#################### Sampling at Epoch 54199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54199\n",
      "Mean Log Likelihood -- train: -2.4077835083007812, -- test: -61.36697769165039 \n",
      "Root Mean Squared Error -- train: 0.27536991238594055, -- test: 1.1202733516693115 \n",
      " \n",
      "#################### Sampling at Epoch 54249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54249\n",
      "Mean Log Likelihood -- train: -2.539802074432373, -- test: -62.46290969848633 \n",
      "Root Mean Squared Error -- train: 0.28012311458587646, -- test: 1.1300137042999268 \n",
      " \n",
      "#################### Sampling at Epoch 54299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54299\n",
      "Mean Log Likelihood -- train: -2.4632444381713867, -- test: -61.98982238769531 \n",
      "Root Mean Squared Error -- train: 0.277376651763916, -- test: 1.125819444656372 \n",
      " \n",
      "#################### Sampling at Epoch 54349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54349\n",
      "Mean Log Likelihood -- train: -2.4775328636169434, -- test: -64.25415802001953 \n",
      "Root Mean Squared Error -- train: 0.2778913080692291, -- test: 1.145755648612976 \n",
      " \n",
      "#################### Sampling at Epoch 54399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54399\n",
      "Mean Log Likelihood -- train: -2.446347713470459, -- test: -63.13121032714844 \n",
      "Root Mean Squared Error -- train: 0.276766836643219, -- test: 1.135912537574768 \n",
      " \n",
      "#################### Sampling at Epoch 54449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54449\n",
      "Mean Log Likelihood -- train: -2.5232748985290527, -- test: -64.89122772216797 \n",
      "Root Mean Squared Error -- train: 0.2795325219631195, -- test: 1.151302456855774 \n",
      " \n",
      "#################### Sampling at Epoch 54499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54499\n",
      "Mean Log Likelihood -- train: -2.47019624710083, -- test: -67.56092834472656 \n",
      "Root Mean Squared Error -- train: 0.277627170085907, -- test: 1.1742621660232544 \n",
      " \n",
      "#################### Sampling at Epoch 54549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54549\n",
      "Mean Log Likelihood -- train: -2.459700345993042, -- test: -65.96582794189453 \n",
      "Root Mean Squared Error -- train: 0.2772488594055176, -- test: 1.160598635673523 \n",
      " \n",
      "#################### Sampling at Epoch 54599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54599\n",
      "Mean Log Likelihood -- train: -2.423994779586792, -- test: -64.36912536621094 \n",
      "Root Mean Squared Error -- train: 0.27595800161361694, -- test: 1.1467585563659668 \n",
      " \n",
      "#################### Sampling at Epoch 54649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54649\n",
      "Mean Log Likelihood -- train: -2.452483654022217, -- test: -63.66719055175781 \n",
      "Root Mean Squared Error -- train: 0.2769884467124939, -- test: 1.1406211853027344 \n",
      " \n",
      "#################### Sampling at Epoch 54699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54699\n",
      "Mean Log Likelihood -- train: -2.439596652984619, -- test: -63.65248489379883 \n",
      "Root Mean Squared Error -- train: 0.27652278542518616, -- test: 1.1404922008514404 \n",
      " \n",
      "#################### Sampling at Epoch 54749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54749\n",
      "Mean Log Likelihood -- train: -2.533083200454712, -- test: -62.9835205078125 \n",
      "Root Mean Squared Error -- train: 0.27988314628601074, -- test: 1.1346114873886108 \n",
      " \n",
      "#################### Sampling at Epoch 54799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54799\n",
      "Mean Log Likelihood -- train: -2.4856057167053223, -- test: -63.59910202026367 \n",
      "Root Mean Squared Error -- train: 0.27818167209625244, -- test: 1.140024185180664 \n",
      " \n",
      "#################### Sampling at Epoch 54849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54849\n",
      "Mean Log Likelihood -- train: -2.5630290508270264, -- test: -65.56011962890625 \n",
      "Root Mean Squared Error -- train: 0.2809510827064514, -- test: 1.1570978164672852 \n",
      " \n",
      "#################### Sampling at Epoch 54899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54899\n",
      "Mean Log Likelihood -- train: -2.5709712505340576, -- test: -70.62023162841797 \n",
      "Root Mean Squared Error -- train: 0.28123363852500916, -- test: 1.2000322341918945 \n",
      " \n",
      "#################### Sampling at Epoch 54949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54949\n",
      "Mean Log Likelihood -- train: -2.50034236907959, -- test: -66.70487976074219 \n",
      "Root Mean Squared Error -- train: 0.2787109315395355, -- test: 1.1669491529464722 \n",
      " \n",
      "#################### Sampling at Epoch 54999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 54999\n",
      "Mean Log Likelihood -- train: -2.430023670196533, -- test: -63.117488861083984 \n",
      "Root Mean Squared Error -- train: 0.276176393032074, -- test: 1.1357916593551636 \n",
      " \n",
      "#################### Sampling at Epoch 55049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55049\n",
      "Mean Log Likelihood -- train: -2.452239990234375, -- test: -62.66031265258789 \n",
      "Root Mean Squared Error -- train: 0.2769796550273895, -- test: 1.1317592859268188 \n",
      " \n",
      "#################### Sampling at Epoch 55099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55099\n",
      "Mean Log Likelihood -- train: -2.4209413528442383, -- test: -66.47753143310547 \n",
      "Root Mean Squared Error -- train: 0.27584734559059143, -- test: 1.1649993658065796 \n",
      " \n",
      "#################### Sampling at Epoch 55149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55149\n",
      "Mean Log Likelihood -- train: -2.441293478012085, -- test: -66.21890258789062 \n",
      "Root Mean Squared Error -- train: 0.2765841484069824, -- test: 1.162777304649353 \n",
      " \n",
      "#################### Sampling at Epoch 55199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55199\n",
      "Mean Log Likelihood -- train: -2.3947930335998535, -- test: -66.60608673095703 \n",
      "Root Mean Squared Error -- train: 0.2748977839946747, -- test: 1.1661021709442139 \n",
      " \n",
      "#################### Sampling at Epoch 55249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55249\n",
      "Mean Log Likelihood -- train: -2.399775981903076, -- test: -67.25802612304688 \n",
      "Root Mean Squared Error -- train: 0.27507898211479187, -- test: 1.1716797351837158 \n",
      " \n",
      "#################### Sampling at Epoch 55299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55299\n",
      "Mean Log Likelihood -- train: -2.3937857151031494, -- test: -68.44718933105469 \n",
      "Root Mean Squared Error -- train: 0.2748611271381378, -- test: 1.1817854642868042 \n",
      " \n",
      "#################### Sampling at Epoch 55349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55349\n",
      "Mean Log Likelihood -- train: -2.4221696853637695, -- test: -69.56925964355469 \n",
      "Root Mean Squared Error -- train: 0.27589187026023865, -- test: 1.1912422180175781 \n",
      " \n",
      "#################### Sampling at Epoch 55399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55399\n",
      "Mean Log Likelihood -- train: -2.440483570098877, -- test: -66.8399429321289 \n",
      "Root Mean Squared Error -- train: 0.2765548825263977, -- test: 1.1681060791015625 \n",
      " \n",
      "#################### Sampling at Epoch 55449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55449\n",
      "Mean Log Likelihood -- train: -2.441521167755127, -- test: -68.56441497802734 \n",
      "Root Mean Squared Error -- train: 0.2765924036502838, -- test: 1.182776927947998 \n",
      " \n",
      "#################### Sampling at Epoch 55499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55499\n",
      "Mean Log Likelihood -- train: -2.423468589782715, -- test: -68.8086929321289 \n",
      "Root Mean Squared Error -- train: 0.2759389579296112, -- test: 1.184840440750122 \n",
      " \n",
      "#################### Sampling at Epoch 55549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55549\n",
      "Mean Log Likelihood -- train: -2.4921202659606934, -- test: -74.21434783935547 \n",
      "Root Mean Squared Error -- train: 0.2784157395362854, -- test: 1.229617714881897 \n",
      " \n",
      "#################### Sampling at Epoch 55599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55599\n",
      "Mean Log Likelihood -- train: -2.4923486709594727, -- test: -69.69173431396484 \n",
      "Root Mean Squared Error -- train: 0.2784239649772644, -- test: 1.1922698020935059 \n",
      " \n",
      "#################### Sampling at Epoch 55649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55649\n",
      "Mean Log Likelihood -- train: -2.4237186908721924, -- test: -74.55860137939453 \n",
      "Root Mean Squared Error -- train: 0.2759479880332947, -- test: 1.2324143648147583 \n",
      " \n",
      "#################### Sampling at Epoch 55699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55699\n",
      "Mean Log Likelihood -- train: -2.4167072772979736, -- test: -75.38140869140625 \n",
      "Root Mean Squared Error -- train: 0.27569380402565, -- test: 1.2390726804733276 \n",
      " \n",
      "#################### Sampling at Epoch 55749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55749\n",
      "Mean Log Likelihood -- train: -2.422450065612793, -- test: -73.43595886230469 \n",
      "Root Mean Squared Error -- train: 0.27590200304985046, -- test: 1.2232710123062134 \n",
      " \n",
      "#################### Sampling at Epoch 55799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55799\n",
      "Mean Log Likelihood -- train: -2.4328503608703613, -- test: -72.7120132446289 \n",
      "Root Mean Squared Error -- train: 0.2762787342071533, -- test: 1.2173386812210083 \n",
      " \n",
      "#################### Sampling at Epoch 55849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55849\n",
      "Mean Log Likelihood -- train: -2.4324796199798584, -- test: -73.92267608642578 \n",
      "Root Mean Squared Error -- train: 0.27626532316207886, -- test: 1.227243423461914 \n",
      " \n",
      "#################### Sampling at Epoch 55899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55899\n",
      "Mean Log Likelihood -- train: -2.4223573207855225, -- test: -72.40281677246094 \n",
      "Root Mean Squared Error -- train: 0.27589866518974304, -- test: 1.2147959470748901 \n",
      " \n",
      "#################### Sampling at Epoch 55949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55949\n",
      "Mean Log Likelihood -- train: -2.456620693206787, -- test: -69.72193908691406 \n",
      "Root Mean Squared Error -- train: 0.27713775634765625, -- test: 1.1925232410430908 \n",
      " \n",
      "#################### Sampling at Epoch 55999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 55999\n",
      "Mean Log Likelihood -- train: -2.4351627826690674, -- test: -72.16327667236328 \n",
      "Root Mean Squared Error -- train: 0.27636241912841797, -- test: 1.212822437286377 \n",
      " \n",
      "#################### Sampling at Epoch 56049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56049\n",
      "Mean Log Likelihood -- train: -2.429630756378174, -- test: -70.68550109863281 \n",
      "Root Mean Squared Error -- train: 0.27616214752197266, -- test: 1.2005760669708252 \n",
      " \n",
      "#################### Sampling at Epoch 56099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56099\n",
      "Mean Log Likelihood -- train: -2.4711310863494873, -- test: -66.48495483398438 \n",
      "Root Mean Squared Error -- train: 0.2776608467102051, -- test: 1.1650630235671997 \n",
      " \n",
      "#################### Sampling at Epoch 56149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56149\n",
      "Mean Log Likelihood -- train: -2.507058620452881, -- test: -65.82760620117188 \n",
      "Root Mean Squared Error -- train: 0.2789517939090729, -- test: 1.159407138824463 \n",
      " \n",
      "#################### Sampling at Epoch 56199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56199\n",
      "Mean Log Likelihood -- train: -2.4343173503875732, -- test: -67.85535430908203 \n",
      "Root Mean Squared Error -- train: 0.2763318121433258, -- test: 1.1767667531967163 \n",
      " \n",
      "#################### Sampling at Epoch 56249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56249\n",
      "Mean Log Likelihood -- train: -2.4523706436157227, -- test: -65.3021240234375 \n",
      "Root Mean Squared Error -- train: 0.2769843637943268, -- test: 1.1548659801483154 \n",
      " \n",
      "#################### Sampling at Epoch 56299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56299\n",
      "Mean Log Likelihood -- train: -2.412905216217041, -- test: -69.48516845703125 \n",
      "Root Mean Squared Error -- train: 0.2755558490753174, -- test: 1.1905361413955688 \n",
      " \n",
      "#################### Sampling at Epoch 56349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56349\n",
      "Mean Log Likelihood -- train: -2.401207447052002, -- test: -69.8255844116211 \n",
      "Root Mean Squared Error -- train: 0.2751310169696808, -- test: 1.193392038345337 \n",
      " \n",
      "#################### Sampling at Epoch 56399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56399\n",
      "Mean Log Likelihood -- train: -2.4289796352386475, -- test: -66.76136016845703 \n",
      "Root Mean Squared Error -- train: 0.2761386036872864, -- test: 1.1674331426620483 \n",
      " \n",
      "#################### Sampling at Epoch 56449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56449\n",
      "Mean Log Likelihood -- train: -2.4376168251037598, -- test: -67.21776580810547 \n",
      "Root Mean Squared Error -- train: 0.2764512002468109, -- test: 1.171336054801941 \n",
      " \n",
      "#################### Sampling at Epoch 56499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56499\n",
      "Mean Log Likelihood -- train: -2.4507410526275635, -- test: -68.07229614257812 \n",
      "Root Mean Squared Error -- train: 0.2769255042076111, -- test: 1.178608775138855 \n",
      " \n",
      "#################### Sampling at Epoch 56549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56549\n",
      "Mean Log Likelihood -- train: -2.4472923278808594, -- test: -68.62248992919922 \n",
      "Root Mean Squared Error -- train: 0.2768009603023529, -- test: 1.1832678318023682 \n",
      " \n",
      "#################### Sampling at Epoch 56599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56599\n",
      "Mean Log Likelihood -- train: -2.4717981815338135, -- test: -70.47964477539062 \n",
      "Root Mean Squared Error -- train: 0.27768486738204956, -- test: 1.1988601684570312 \n",
      " \n",
      "#################### Sampling at Epoch 56649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56649\n",
      "Mean Log Likelihood -- train: -2.490771532058716, -- test: -64.06193542480469 \n",
      "Root Mean Squared Error -- train: 0.2783673107624054, -- test: 1.1440768241882324 \n",
      " \n",
      "#################### Sampling at Epoch 56699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56699\n",
      "Mean Log Likelihood -- train: -2.466360569000244, -- test: -68.04190826416016 \n",
      "Root Mean Squared Error -- train: 0.27748897671699524, -- test: 1.1783509254455566 \n",
      " \n",
      "#################### Sampling at Epoch 56749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56749\n",
      "Mean Log Likelihood -- train: -2.410299062728882, -- test: -66.07550048828125 \n",
      "Root Mean Squared Error -- train: 0.27546125650405884, -- test: 1.161543369293213 \n",
      " \n",
      "#################### Sampling at Epoch 56799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56799\n",
      "Mean Log Likelihood -- train: -2.4974396228790283, -- test: -67.83910369873047 \n",
      "Root Mean Squared Error -- train: 0.27860674262046814, -- test: 1.1766287088394165 \n",
      " \n",
      "#################### Sampling at Epoch 56849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56849\n",
      "Mean Log Likelihood -- train: -2.5527167320251465, -- test: -66.40594482421875 \n",
      "Root Mean Squared Error -- train: 0.28058376908302307, -- test: 1.1643848419189453 \n",
      " \n",
      "#################### Sampling at Epoch 56899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56899\n",
      "Mean Log Likelihood -- train: -2.4591400623321533, -- test: -66.00070190429688 \n",
      "Root Mean Squared Error -- train: 0.2772286534309387, -- test: 1.16089928150177 \n",
      " \n",
      "#################### Sampling at Epoch 56949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56949\n",
      "Mean Log Likelihood -- train: -2.4577620029449463, -- test: -65.92607879638672 \n",
      "Root Mean Squared Error -- train: 0.27717894315719604, -- test: 1.1602561473846436 \n",
      " \n",
      "#################### Sampling at Epoch 56999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 56999\n",
      "Mean Log Likelihood -- train: -2.466411828994751, -- test: -68.7093734741211 \n",
      "Root Mean Squared Error -- train: 0.27749085426330566, -- test: 1.1840018033981323 \n",
      " \n",
      "#################### Sampling at Epoch 57049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57049\n",
      "Mean Log Likelihood -- train: -2.395129680633545, -- test: -66.81816864013672 \n",
      "Root Mean Squared Error -- train: 0.274910032749176, -- test: 1.1679195165634155 \n",
      " \n",
      "#################### Sampling at Epoch 57099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57099\n",
      "Mean Log Likelihood -- train: -2.462188959121704, -- test: -68.80742645263672 \n",
      "Root Mean Squared Error -- train: 0.2773386240005493, -- test: 1.1848297119140625 \n",
      " \n",
      "#################### Sampling at Epoch 57149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57149\n",
      "Mean Log Likelihood -- train: -2.4564969539642334, -- test: -66.72978210449219 \n",
      "Root Mean Squared Error -- train: 0.2771332859992981, -- test: 1.167162537574768 \n",
      " \n",
      "#################### Sampling at Epoch 57199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57199\n",
      "Mean Log Likelihood -- train: -2.4220564365386963, -- test: -67.5652847290039 \n",
      "Root Mean Squared Error -- train: 0.27588775753974915, -- test: 1.1742991209030151 \n",
      " \n",
      "#################### Sampling at Epoch 57249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57249\n",
      "Mean Log Likelihood -- train: -2.479700803756714, -- test: -67.73773956298828 \n",
      "Root Mean Squared Error -- train: 0.2779693305492401, -- test: 1.1757668256759644 \n",
      " \n",
      "#################### Sampling at Epoch 57299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57299\n",
      "Mean Log Likelihood -- train: -2.4345784187316895, -- test: -66.21143341064453 \n",
      "Root Mean Squared Error -- train: 0.2763412594795227, -- test: 1.1627129316329956 \n",
      " \n",
      "#################### Sampling at Epoch 57349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57349\n",
      "Mean Log Likelihood -- train: -2.5039987564086914, -- test: -68.29097747802734 \n",
      "Root Mean Squared Error -- train: 0.27884209156036377, -- test: 1.1804628372192383 \n",
      " \n",
      "#################### Sampling at Epoch 57399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57399\n",
      "Mean Log Likelihood -- train: -2.437861919403076, -- test: -70.49784088134766 \n",
      "Root Mean Squared Error -- train: 0.27646005153656006, -- test: 1.1990119218826294 \n",
      " \n",
      "#################### Sampling at Epoch 57449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57449\n",
      "Mean Log Likelihood -- train: -2.4267237186431885, -- test: -73.9256362915039 \n",
      "Root Mean Squared Error -- train: 0.2760568857192993, -- test: 1.2272675037384033 \n",
      " \n",
      "#################### Sampling at Epoch 57499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57499\n",
      "Mean Log Likelihood -- train: -2.5272865295410156, -- test: -70.7295913696289 \n",
      "Root Mean Squared Error -- train: 0.27967599034309387, -- test: 1.2009432315826416 \n",
      " \n",
      "#################### Sampling at Epoch 57549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57549\n",
      "Mean Log Likelihood -- train: -2.4152331352233887, -- test: -70.9269027709961 \n",
      "Root Mean Squared Error -- train: 0.2756403386592865, -- test: 1.202584981918335 \n",
      " \n",
      "#################### Sampling at Epoch 57599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57599\n",
      "Mean Log Likelihood -- train: -2.423990488052368, -- test: -68.19381713867188 \n",
      "Root Mean Squared Error -- train: 0.275957852602005, -- test: 1.179639458656311 \n",
      " \n",
      "#################### Sampling at Epoch 57649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57649\n",
      "Mean Log Likelihood -- train: -2.437666177749634, -- test: -71.6412124633789 \n",
      "Root Mean Squared Error -- train: 0.2764529883861542, -- test: 1.2085102796554565 \n",
      " \n",
      "#################### Sampling at Epoch 57699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57699\n",
      "Mean Log Likelihood -- train: -2.3914730548858643, -- test: -69.66078186035156 \n",
      "Root Mean Squared Error -- train: 0.27477699518203735, -- test: 1.1920102834701538 \n",
      " \n",
      "#################### Sampling at Epoch 57749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57749\n",
      "Mean Log Likelihood -- train: -2.38073992729187, -- test: -68.21279907226562 \n",
      "Root Mean Squared Error -- train: 0.27438607811927795, -- test: 1.1798003911972046 \n",
      " \n",
      "#################### Sampling at Epoch 57799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57799\n",
      "Mean Log Likelihood -- train: -2.4255895614624023, -- test: -68.98457336425781 \n",
      "Root Mean Squared Error -- train: 0.2760157883167267, -- test: 1.186323881149292 \n",
      " \n",
      "#################### Sampling at Epoch 57849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57849\n",
      "Mean Log Likelihood -- train: -2.505507707595825, -- test: -70.36126708984375 \n",
      "Root Mean Squared Error -- train: 0.2788962125778198, -- test: 1.1978724002838135 \n",
      " \n",
      "#################### Sampling at Epoch 57899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57899\n",
      "Mean Log Likelihood -- train: -2.4396214485168457, -- test: -70.93913269042969 \n",
      "Root Mean Squared Error -- train: 0.2765237092971802, -- test: 1.2026867866516113 \n",
      " \n",
      "#################### Sampling at Epoch 57949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57949\n",
      "Mean Log Likelihood -- train: -2.4339165687561035, -- test: -67.8185043334961 \n",
      "Root Mean Squared Error -- train: 0.276317298412323, -- test: 1.1764534711837769 \n",
      " \n",
      "#################### Sampling at Epoch 57999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 57999\n",
      "Mean Log Likelihood -- train: -2.479200839996338, -- test: -67.4773178100586 \n",
      "Root Mean Squared Error -- train: 0.27795132994651794, -- test: 1.173549771308899 \n",
      " \n",
      "#################### Sampling at Epoch 58049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58049\n",
      "Mean Log Likelihood -- train: -2.429429054260254, -- test: -69.35986328125 \n",
      "Root Mean Squared Error -- train: 0.27615484595298767, -- test: 1.1894831657409668 \n",
      " \n",
      "#################### Sampling at Epoch 58099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58099\n",
      "Mean Log Likelihood -- train: -2.4420809745788574, -- test: -65.64794158935547 \n",
      "Root Mean Squared Error -- train: 0.27661263942718506, -- test: 1.1578564643859863 \n",
      " \n",
      "#################### Sampling at Epoch 58149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58149\n",
      "Mean Log Likelihood -- train: -2.467291831970215, -- test: -64.76306915283203 \n",
      "Root Mean Squared Error -- train: 0.27752256393432617, -- test: 1.1501888036727905 \n",
      " \n",
      "#################### Sampling at Epoch 58199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58199\n",
      "Mean Log Likelihood -- train: -2.4754629135131836, -- test: -63.482051849365234 \n",
      "Root Mean Squared Error -- train: 0.2778168022632599, -- test: 1.1389968395233154 \n",
      " \n",
      "#################### Sampling at Epoch 58249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58249\n",
      "Mean Log Likelihood -- train: -2.4283087253570557, -- test: -62.73346710205078 \n",
      "Root Mean Squared Error -- train: 0.276114284992218, -- test: 1.1324055194854736 \n",
      " \n",
      "#################### Sampling at Epoch 58299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58299\n",
      "Mean Log Likelihood -- train: -2.455956220626831, -- test: -63.40992736816406 \n",
      "Root Mean Squared Error -- train: 0.27711379528045654, -- test: 1.1383635997772217 \n",
      " \n",
      "#################### Sampling at Epoch 58349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58349\n",
      "Mean Log Likelihood -- train: -2.4261550903320312, -- test: -64.81695556640625 \n",
      "Root Mean Squared Error -- train: 0.2760362923145294, -- test: 1.1506571769714355 \n",
      " \n",
      "#################### Sampling at Epoch 58399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58399\n",
      "Mean Log Likelihood -- train: -2.4238245487213135, -- test: -64.88360595703125 \n",
      "Root Mean Squared Error -- train: 0.2759518325328827, -- test: 1.1512362957000732 \n",
      " \n",
      "#################### Sampling at Epoch 58449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58449\n",
      "Mean Log Likelihood -- train: -2.452296257019043, -- test: -62.784690856933594 \n",
      "Root Mean Squared Error -- train: 0.2769816815853119, -- test: 1.1328577995300293 \n",
      " \n",
      "#################### Sampling at Epoch 58499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58499\n",
      "Mean Log Likelihood -- train: -2.4633941650390625, -- test: -62.41151809692383 \n",
      "Root Mean Squared Error -- train: 0.2773820459842682, -- test: 1.1295589208602905 \n",
      " \n",
      "#################### Sampling at Epoch 58549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58549\n",
      "Mean Log Likelihood -- train: -2.4460489749908447, -- test: -61.68165588378906 \n",
      "Root Mean Squared Error -- train: 0.27675604820251465, -- test: 1.1230788230895996 \n",
      " \n",
      "#################### Sampling at Epoch 58599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58599\n",
      "Mean Log Likelihood -- train: -2.4447624683380127, -- test: -62.428916931152344 \n",
      "Root Mean Squared Error -- train: 0.27670952677726746, -- test: 1.1297128200531006 \n",
      " \n",
      "#################### Sampling at Epoch 58649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58649\n",
      "Mean Log Likelihood -- train: -2.511096954345703, -- test: -60.50538635253906 \n",
      "Root Mean Squared Error -- train: 0.2790965437889099, -- test: 1.1125558614730835 \n",
      " \n",
      "#################### Sampling at Epoch 58699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58699\n",
      "Mean Log Likelihood -- train: -2.465155601501465, -- test: -61.683433532714844 \n",
      "Root Mean Squared Error -- train: 0.27744555473327637, -- test: 1.1230946779251099 \n",
      " \n",
      "#################### Sampling at Epoch 58749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58749\n",
      "Mean Log Likelihood -- train: -2.446153163909912, -- test: -59.914249420166016 \n",
      "Root Mean Squared Error -- train: 0.2767598330974579, -- test: 1.1072298288345337 \n",
      " \n",
      "#################### Sampling at Epoch 58799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58799\n",
      "Mean Log Likelihood -- train: -2.4437944889068604, -- test: -60.59843444824219 \n",
      "Root Mean Squared Error -- train: 0.2766745686531067, -- test: 1.1133918762207031 \n",
      " \n",
      "#################### Sampling at Epoch 58849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58849\n",
      "Mean Log Likelihood -- train: -2.4276466369628906, -- test: -60.01459503173828 \n",
      "Root Mean Squared Error -- train: 0.2760902941226959, -- test: 1.10813570022583 \n",
      " \n",
      "#################### Sampling at Epoch 58899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58899\n",
      "Mean Log Likelihood -- train: -2.442765474319458, -- test: -60.40385437011719 \n",
      "Root Mean Squared Error -- train: 0.27663737535476685, -- test: 1.1116429567337036 \n",
      " \n",
      "#################### Sampling at Epoch 58949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58949\n",
      "Mean Log Likelihood -- train: -2.472688913345337, -- test: -62.061798095703125 \n",
      "Root Mean Squared Error -- train: 0.2777169346809387, -- test: 1.1264585256576538 \n",
      " \n",
      "#################### Sampling at Epoch 58999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 58999\n",
      "Mean Log Likelihood -- train: -2.4457318782806396, -- test: -61.32404327392578 \n",
      "Root Mean Squared Error -- train: 0.2767445743083954, -- test: 1.1198899745941162 \n",
      " \n",
      "#################### Sampling at Epoch 59049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59049\n",
      "Mean Log Likelihood -- train: -2.4405717849731445, -- test: -63.446372985839844 \n",
      "Root Mean Squared Error -- train: 0.2765580415725708, -- test: 1.138683557510376 \n",
      " \n",
      "#################### Sampling at Epoch 59099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59099\n",
      "Mean Log Likelihood -- train: -2.434408664703369, -- test: -63.38968276977539 \n",
      "Root Mean Squared Error -- train: 0.27633512020111084, -- test: 1.1381856203079224 \n",
      " \n",
      "#################### Sampling at Epoch 59149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59149\n",
      "Mean Log Likelihood -- train: -2.433145046234131, -- test: -67.89202880859375 \n",
      "Root Mean Squared Error -- train: 0.2762893736362457, -- test: 1.177078366279602 \n",
      " \n",
      "#################### Sampling at Epoch 59199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59199\n",
      "Mean Log Likelihood -- train: -2.4791259765625, -- test: -65.44796752929688 \n",
      "Root Mean Squared Error -- train: 0.27794864773750305, -- test: 1.156128168106079 \n",
      " \n",
      "#################### Sampling at Epoch 59249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59249\n",
      "Mean Log Likelihood -- train: -2.4466726779937744, -- test: -67.90573120117188 \n",
      "Root Mean Squared Error -- train: 0.27677857875823975, -- test: 1.1771947145462036 \n",
      " \n",
      "#################### Sampling at Epoch 59299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59299\n",
      "Mean Log Likelihood -- train: -2.4975407123565674, -- test: -69.0908432006836 \n",
      "Root Mean Squared Error -- train: 0.27861037850379944, -- test: 1.187219262123108 \n",
      " \n",
      "#################### Sampling at Epoch 59349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59349\n",
      "Mean Log Likelihood -- train: -2.4242255687713623, -- test: -63.003177642822266 \n",
      "Root Mean Squared Error -- train: 0.2759663760662079, -- test: 1.1347846984863281 \n",
      " \n",
      "#################### Sampling at Epoch 59399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59399\n",
      "Mean Log Likelihood -- train: -2.4443399906158447, -- test: -66.51014709472656 \n",
      "Root Mean Squared Error -- train: 0.27669426798820496, -- test: 1.1652792692184448 \n",
      " \n",
      "#################### Sampling at Epoch 59449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59449\n",
      "Mean Log Likelihood -- train: -2.52490234375, -- test: -65.12788391113281 \n",
      "Root Mean Squared Error -- train: 0.2795907258987427, -- test: 1.1533561944961548 \n",
      " \n",
      "#################### Sampling at Epoch 59499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59499\n",
      "Mean Log Likelihood -- train: -2.415139675140381, -- test: -66.01840209960938 \n",
      "Root Mean Squared Error -- train: 0.2756369411945343, -- test: 1.1610515117645264 \n",
      " \n",
      "#################### Sampling at Epoch 59549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59549\n",
      "Mean Log Likelihood -- train: -2.4308886528015137, -- test: -61.706817626953125 \n",
      "Root Mean Squared Error -- train: 0.27620771527290344, -- test: 1.1233028173446655 \n",
      " \n",
      "#################### Sampling at Epoch 59599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59599\n",
      "Mean Log Likelihood -- train: -2.4753875732421875, -- test: -63.19635772705078 \n",
      "Root Mean Squared Error -- train: 0.277814120054245, -- test: 1.1364858150482178 \n",
      " \n",
      "#################### Sampling at Epoch 59649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59649\n",
      "Mean Log Likelihood -- train: -2.4858295917510986, -- test: -64.87043762207031 \n",
      "Root Mean Squared Error -- train: 0.2781897187232971, -- test: 1.1511218547821045 \n",
      " \n",
      "#################### Sampling at Epoch 59699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59699\n",
      "Mean Log Likelihood -- train: -2.4203298091888428, -- test: -65.69799041748047 \n",
      "Root Mean Squared Error -- train: 0.275825172662735, -- test: 1.1582887172698975 \n",
      " \n",
      "#################### Sampling at Epoch 59749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59749\n",
      "Mean Log Likelihood -- train: -2.466301441192627, -- test: -65.34959411621094 \n",
      "Root Mean Squared Error -- train: 0.2774868607521057, -- test: 1.1552770137786865 \n",
      " \n",
      "#################### Sampling at Epoch 59799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59799\n",
      "Mean Log Likelihood -- train: -2.435500383377075, -- test: -64.82543182373047 \n",
      "Root Mean Squared Error -- train: 0.2763746380805969, -- test: 1.150730848312378 \n",
      " \n",
      "#################### Sampling at Epoch 59849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59849\n",
      "Mean Log Likelihood -- train: -2.44064998626709, -- test: -63.149314880371094 \n",
      "Root Mean Squared Error -- train: 0.27656087279319763, -- test: 1.1360719203948975 \n",
      " \n",
      "#################### Sampling at Epoch 59899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59899\n",
      "Mean Log Likelihood -- train: -2.460033655166626, -- test: -62.590087890625 \n",
      "Root Mean Squared Error -- train: 0.2772608995437622, -- test: 1.131138563156128 \n",
      " \n",
      "#################### Sampling at Epoch 59949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59949\n",
      "Mean Log Likelihood -- train: -2.4469306468963623, -- test: -62.26643371582031 \n",
      "Root Mean Squared Error -- train: 0.2767879068851471, -- test: 1.1282737255096436 \n",
      " \n",
      "#################### Sampling at Epoch 59999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 59999\n",
      "Mean Log Likelihood -- train: -2.4230051040649414, -- test: -65.32759094238281 \n",
      "Root Mean Squared Error -- train: 0.27592214941978455, -- test: 1.1550863981246948 \n",
      " \n",
      "#################### Sampling at Epoch 60049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60049\n",
      "Mean Log Likelihood -- train: -2.412315845489502, -- test: -65.7522201538086 \n",
      "Root Mean Squared Error -- train: 0.2755344808101654, -- test: 1.1587567329406738 \n",
      " \n",
      "#################### Sampling at Epoch 60099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60099\n",
      "Mean Log Likelihood -- train: -2.38922381401062, -- test: -65.97653198242188 \n",
      "Root Mean Squared Error -- train: 0.27469512820243835, -- test: 1.1606910228729248 \n",
      " \n",
      "#################### Sampling at Epoch 60149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60149\n",
      "Mean Log Likelihood -- train: -2.4850544929504395, -- test: -67.06824493408203 \n",
      "Root Mean Squared Error -- train: 0.2781618535518646, -- test: 1.1700588464736938 \n",
      " \n",
      "#################### Sampling at Epoch 60199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60199\n",
      "Mean Log Likelihood -- train: -2.4743311405181885, -- test: -63.38595199584961 \n",
      "Root Mean Squared Error -- train: 0.2777760624885559, -- test: 1.138152837753296 \n",
      " \n",
      "#################### Sampling at Epoch 60249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60249\n",
      "Mean Log Likelihood -- train: -2.469881772994995, -- test: -64.05546569824219 \n",
      "Root Mean Squared Error -- train: 0.27761584520339966, -- test: 1.1440201997756958 \n",
      " \n",
      "#################### Sampling at Epoch 60299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60299\n",
      "Mean Log Likelihood -- train: -2.4466841220855713, -- test: -66.61497497558594 \n",
      "Root Mean Squared Error -- train: 0.2767789959907532, -- test: 1.1661784648895264 \n",
      " \n",
      "#################### Sampling at Epoch 60349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60349\n",
      "Mean Log Likelihood -- train: -2.406604051589966, -- test: -67.16161346435547 \n",
      "Root Mean Squared Error -- train: 0.2753271162509918, -- test: 1.1708565950393677 \n",
      " \n",
      "#################### Sampling at Epoch 60399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60399\n",
      "Mean Log Likelihood -- train: -2.450814723968506, -- test: -66.44977569580078 \n",
      "Root Mean Squared Error -- train: 0.276928186416626, -- test: 1.1647610664367676 \n",
      " \n",
      "#################### Sampling at Epoch 60449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60449\n",
      "Mean Log Likelihood -- train: -2.413609266281128, -- test: -65.82119750976562 \n",
      "Root Mean Squared Error -- train: 0.275581419467926, -- test: 1.1593518257141113 \n",
      " \n",
      "#################### Sampling at Epoch 60499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60499\n",
      "Mean Log Likelihood -- train: -2.4616622924804688, -- test: -63.13982391357422 \n",
      "Root Mean Squared Error -- train: 0.27731963992118835, -- test: 1.1359882354736328 \n",
      " \n",
      "#################### Sampling at Epoch 60549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60549\n",
      "Mean Log Likelihood -- train: -2.4612910747528076, -- test: -62.38441467285156 \n",
      "Root Mean Squared Error -- train: 0.2773062288761139, -- test: 1.1293188333511353 \n",
      " \n",
      "#################### Sampling at Epoch 60599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60599\n",
      "Mean Log Likelihood -- train: -2.481217622756958, -- test: -66.1865005493164 \n",
      "Root Mean Squared Error -- train: 0.278023898601532, -- test: 1.1624985933303833 \n",
      " \n",
      "#################### Sampling at Epoch 60649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60649\n",
      "Mean Log Likelihood -- train: -2.4684793949127197, -- test: -62.93229675292969 \n",
      "Root Mean Squared Error -- train: 0.2775653600692749, -- test: 1.1341599225997925 \n",
      " \n",
      "#################### Sampling at Epoch 60699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60699\n",
      "Mean Log Likelihood -- train: -2.4748830795288086, -- test: -61.40848159790039 \n",
      "Root Mean Squared Error -- train: 0.2777959406375885, -- test: 1.1206438541412354 \n",
      " \n",
      "#################### Sampling at Epoch 60749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60749\n",
      "Mean Log Likelihood -- train: -2.430279016494751, -- test: -65.24336242675781 \n",
      "Root Mean Squared Error -- train: 0.27618563175201416, -- test: 1.1543570756912231 \n",
      " \n",
      "#################### Sampling at Epoch 60799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60799\n",
      "Mean Log Likelihood -- train: -2.3859689235687256, -- test: -64.06780242919922 \n",
      "Root Mean Squared Error -- train: 0.2745766043663025, -- test: 1.1441280841827393 \n",
      " \n",
      "#################### Sampling at Epoch 60849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60849\n",
      "Mean Log Likelihood -- train: -2.446411609649658, -- test: -63.492576599121094 \n",
      "Root Mean Squared Error -- train: 0.27676913142204285, -- test: 1.1390892267227173 \n",
      " \n",
      "#################### Sampling at Epoch 60899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60899\n",
      "Mean Log Likelihood -- train: -2.473365306854248, -- test: -63.354217529296875 \n",
      "Root Mean Squared Error -- train: 0.27774131298065186, -- test: 1.1378740072250366 \n",
      " \n",
      "#################### Sampling at Epoch 60949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60949\n",
      "Mean Log Likelihood -- train: -2.424443244934082, -- test: -63.76838684082031 \n",
      "Root Mean Squared Error -- train: 0.2759742736816406, -- test: 1.1415079832077026 \n",
      " \n",
      "#################### Sampling at Epoch 60999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 60999\n",
      "Mean Log Likelihood -- train: -2.4573569297790527, -- test: -65.95321655273438 \n",
      "Root Mean Squared Error -- train: 0.27716436982154846, -- test: 1.1604899168014526 \n",
      " \n",
      "#################### Sampling at Epoch 61049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61049\n",
      "Mean Log Likelihood -- train: -2.4075307846069336, -- test: -61.52973937988281 \n",
      "Root Mean Squared Error -- train: 0.27536076307296753, -- test: 1.12172532081604 \n",
      " \n",
      "#################### Sampling at Epoch 61099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61099\n",
      "Mean Log Likelihood -- train: -2.4048235416412354, -- test: -62.16651916503906 \n",
      "Root Mean Squared Error -- train: 0.2752624452114105, -- test: 1.1273877620697021 \n",
      " \n",
      "#################### Sampling at Epoch 61149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61149\n",
      "Mean Log Likelihood -- train: -2.537241220474243, -- test: -59.926414489746094 \n",
      "Root Mean Squared Error -- train: 0.2800317108631134, -- test: 1.1073397397994995 \n",
      " \n",
      "#################### Sampling at Epoch 61199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61199\n",
      "Mean Log Likelihood -- train: -2.445380687713623, -- test: -65.29383087158203 \n",
      "Root Mean Squared Error -- train: 0.2767318785190582, -- test: 1.1547940969467163 \n",
      " \n",
      "#################### Sampling at Epoch 61249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61249\n",
      "Mean Log Likelihood -- train: -2.452970266342163, -- test: -65.08418273925781 \n",
      "Root Mean Squared Error -- train: 0.27700600028038025, -- test: 1.1529772281646729 \n",
      " \n",
      "#################### Sampling at Epoch 61299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61299\n",
      "Mean Log Likelihood -- train: -2.576934337615967, -- test: -62.24728012084961 \n",
      "Root Mean Squared Error -- train: 0.28144559264183044, -- test: 1.1281039714813232 \n",
      " \n",
      "#################### Sampling at Epoch 61349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61349\n",
      "Mean Log Likelihood -- train: -2.4345383644104004, -- test: -61.45896530151367 \n",
      "Root Mean Squared Error -- train: 0.2763397991657257, -- test: 1.1210941076278687 \n",
      " \n",
      "#################### Sampling at Epoch 61399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61399\n",
      "Mean Log Likelihood -- train: -2.4696710109710693, -- test: -59.683929443359375 \n",
      "Root Mean Squared Error -- train: 0.27760830521583557, -- test: 1.1051477193832397 \n",
      " \n",
      "#################### Sampling at Epoch 61449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61449\n",
      "Mean Log Likelihood -- train: -2.4132983684539795, -- test: -58.88556671142578 \n",
      "Root Mean Squared Error -- train: 0.2755701243877411, -- test: 1.0978999137878418 \n",
      " \n",
      "#################### Sampling at Epoch 61499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61499\n",
      "Mean Log Likelihood -- train: -2.421727418899536, -- test: -59.29240417480469 \n",
      "Root Mean Squared Error -- train: 0.27587583661079407, -- test: 1.1015993356704712 \n",
      " \n",
      "#################### Sampling at Epoch 61549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61549\n",
      "Mean Log Likelihood -- train: -2.398984670639038, -- test: -61.27442932128906 \n",
      "Root Mean Squared Error -- train: 0.27505022287368774, -- test: 1.119446873664856 \n",
      " \n",
      "#################### Sampling at Epoch 61599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61599\n",
      "Mean Log Likelihood -- train: -2.5184638500213623, -- test: -62.070438385009766 \n",
      "Root Mean Squared Error -- train: 0.2793603837490082, -- test: 1.126535177230835 \n",
      " \n",
      "#################### Sampling at Epoch 61649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61649\n",
      "Mean Log Likelihood -- train: -2.4493634700775146, -- test: -64.04068756103516 \n",
      "Root Mean Squared Error -- train: 0.276875764131546, -- test: 1.1438909769058228 \n",
      " \n",
      "#################### Sampling at Epoch 61699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61699\n",
      "Mean Log Likelihood -- train: -2.4929487705230713, -- test: -64.8186264038086 \n",
      "Root Mean Squared Error -- train: 0.2784455120563507, -- test: 1.1506717205047607 \n",
      " \n",
      "#################### Sampling at Epoch 61749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61749\n",
      "Mean Log Likelihood -- train: -2.439643383026123, -- test: -60.965599060058594 \n",
      "Root Mean Squared Error -- train: 0.27652448415756226, -- test: 1.116684913635254 \n",
      " \n",
      "#################### Sampling at Epoch 61799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61799\n",
      "Mean Log Likelihood -- train: -2.504793405532837, -- test: -65.5379867553711 \n",
      "Root Mean Squared Error -- train: 0.2788705825805664, -- test: 1.1569064855575562 \n",
      " \n",
      "#################### Sampling at Epoch 61849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61849\n",
      "Mean Log Likelihood -- train: -2.472787618637085, -- test: -66.41991424560547 \n",
      "Root Mean Squared Error -- train: 0.27772051095962524, -- test: 1.1645047664642334 \n",
      " \n",
      "#################### Sampling at Epoch 61899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61899\n",
      "Mean Log Likelihood -- train: -2.4221954345703125, -- test: -65.65901184082031 \n",
      "Root Mean Squared Error -- train: 0.27589279413223267, -- test: 1.157952070236206 \n",
      " \n",
      "#################### Sampling at Epoch 61949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61949\n",
      "Mean Log Likelihood -- train: -2.5000457763671875, -- test: -63.11977005004883 \n",
      "Root Mean Squared Error -- train: 0.2787002623081207, -- test: 1.135811686515808 \n",
      " \n",
      "#################### Sampling at Epoch 61999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 61999\n",
      "Mean Log Likelihood -- train: -2.456557035446167, -- test: -63.39726638793945 \n",
      "Root Mean Squared Error -- train: 0.2771354615688324, -- test: 1.1382522583007812 \n",
      " \n",
      "#################### Sampling at Epoch 62049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62049\n",
      "Mean Log Likelihood -- train: -2.525265693664551, -- test: -65.34356689453125 \n",
      "Root Mean Squared Error -- train: 0.2796037197113037, -- test: 1.1552246809005737 \n",
      " \n",
      "#################### Sampling at Epoch 62099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62099\n",
      "Mean Log Likelihood -- train: -2.498980760574341, -- test: -65.1863784790039 \n",
      "Root Mean Squared Error -- train: 0.2786620855331421, -- test: 1.1538631916046143 \n",
      " \n",
      "#################### Sampling at Epoch 62149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62149\n",
      "Mean Log Likelihood -- train: -2.502915382385254, -- test: -69.37564086914062 \n",
      "Root Mean Squared Error -- train: 0.2788032293319702, -- test: 1.1896158456802368 \n",
      " \n",
      "#################### Sampling at Epoch 62199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62199\n",
      "Mean Log Likelihood -- train: -2.456289529800415, -- test: -67.29301452636719 \n",
      "Root Mean Squared Error -- train: 0.2771258056163788, -- test: 1.17197847366333 \n",
      " \n",
      "#################### Sampling at Epoch 62249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62249\n",
      "Mean Log Likelihood -- train: -2.463651180267334, -- test: -64.87117004394531 \n",
      "Root Mean Squared Error -- train: 0.27739134430885315, -- test: 1.1511282920837402 \n",
      " \n",
      "#################### Sampling at Epoch 62299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62299\n",
      "Mean Log Likelihood -- train: -2.463796377182007, -- test: -67.70065307617188 \n",
      "Root Mean Squared Error -- train: 0.2773965895175934, -- test: 1.175451397895813 \n",
      " \n",
      "#################### Sampling at Epoch 62349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62349\n",
      "Mean Log Likelihood -- train: -2.437592029571533, -- test: -63.481109619140625 \n",
      "Root Mean Squared Error -- train: 0.2764503061771393, -- test: 1.1389886140823364 \n",
      " \n",
      "#################### Sampling at Epoch 62399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62399\n",
      "Mean Log Likelihood -- train: -2.4332172870635986, -- test: -64.93511199951172 \n",
      "Root Mean Squared Error -- train: 0.27629199624061584, -- test: 1.1516835689544678 \n",
      " \n",
      "#################### Sampling at Epoch 62449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62449\n",
      "Mean Log Likelihood -- train: -2.430025815963745, -- test: -65.07807922363281 \n",
      "Root Mean Squared Error -- train: 0.27617645263671875, -- test: 1.1529242992401123 \n",
      " \n",
      "#################### Sampling at Epoch 62499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62499\n",
      "Mean Log Likelihood -- train: -2.524273633956909, -- test: -63.7215690612793 \n",
      "Root Mean Squared Error -- train: 0.27956822514533997, -- test: 1.141097903251648 \n",
      " \n",
      "#################### Sampling at Epoch 62549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62549\n",
      "Mean Log Likelihood -- train: -2.4764835834503174, -- test: -63.087772369384766 \n",
      "Root Mean Squared Error -- train: 0.2778535485267639, -- test: 1.1355299949645996 \n",
      " \n",
      "#################### Sampling at Epoch 62599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62599\n",
      "Mean Log Likelihood -- train: -2.5935158729553223, -- test: -64.03211212158203 \n",
      "Root Mean Squared Error -- train: 0.28203412890434265, -- test: 1.1438159942626953 \n",
      " \n",
      "#################### Sampling at Epoch 62649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62649\n",
      "Mean Log Likelihood -- train: -2.5336456298828125, -- test: -64.91869354248047 \n",
      "Root Mean Squared Error -- train: 0.27990326285362244, -- test: 1.1515411138534546 \n",
      " \n",
      "#################### Sampling at Epoch 62699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62699\n",
      "Mean Log Likelihood -- train: -2.4856276512145996, -- test: -65.6318588256836 \n",
      "Root Mean Squared Error -- train: 0.2781824767589569, -- test: 1.1577175855636597 \n",
      " \n",
      "#################### Sampling at Epoch 62749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62749\n",
      "Mean Log Likelihood -- train: -2.557427167892456, -- test: -67.38904571533203 \n",
      "Root Mean Squared Error -- train: 0.28075161576271057, -- test: 1.172797441482544 \n",
      " \n",
      "#################### Sampling at Epoch 62799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62799\n",
      "Mean Log Likelihood -- train: -2.4683709144592285, -- test: -66.58882141113281 \n",
      "Root Mean Squared Error -- train: 0.2775614261627197, -- test: 1.1659541130065918 \n",
      " \n",
      "#################### Sampling at Epoch 62849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62849\n",
      "Mean Log Likelihood -- train: -2.455914258956909, -- test: -62.12264633178711 \n",
      "Root Mean Squared Error -- train: 0.27711227536201477, -- test: 1.1269986629486084 \n",
      " \n",
      "#################### Sampling at Epoch 62899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62899\n",
      "Mean Log Likelihood -- train: -2.4703192710876465, -- test: -62.63484191894531 \n",
      "Root Mean Squared Error -- train: 0.27763161063194275, -- test: 1.131534218788147 \n",
      " \n",
      "#################### Sampling at Epoch 62949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62949\n",
      "Mean Log Likelihood -- train: -2.494499921798706, -- test: -67.56732940673828 \n",
      "Root Mean Squared Error -- train: 0.2785012125968933, -- test: 1.1743165254592896 \n",
      " \n",
      "#################### Sampling at Epoch 62999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 62999\n",
      "Mean Log Likelihood -- train: -2.5183730125427246, -- test: -63.981651306152344 \n",
      "Root Mean Squared Error -- train: 0.27935710549354553, -- test: 1.1433748006820679 \n",
      " \n",
      "#################### Sampling at Epoch 63049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63049\n",
      "Mean Log Likelihood -- train: -2.484071969985962, -- test: -62.220890045166016 \n",
      "Root Mean Squared Error -- train: 0.2781265079975128, -- test: 1.127869963645935 \n",
      " \n",
      "#################### Sampling at Epoch 63099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63099\n",
      "Mean Log Likelihood -- train: -2.5939180850982666, -- test: -65.74418640136719 \n",
      "Root Mean Squared Error -- train: 0.28204840421676636, -- test: 1.1586874723434448 \n",
      " \n",
      "#################### Sampling at Epoch 63149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63149\n",
      "Mean Log Likelihood -- train: -2.483628273010254, -- test: -67.53683471679688 \n",
      "Root Mean Squared Error -- train: 0.2781105637550354, -- test: 1.174056887626648 \n",
      " \n",
      "#################### Sampling at Epoch 63199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63199\n",
      "Mean Log Likelihood -- train: -2.4317219257354736, -- test: -63.47575378417969 \n",
      "Root Mean Squared Error -- train: 0.2762378752231598, -- test: 1.1389415264129639 \n",
      " \n",
      "#################### Sampling at Epoch 63249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63249\n",
      "Mean Log Likelihood -- train: -2.412633180618286, -- test: -63.6158447265625 \n",
      "Root Mean Squared Error -- train: 0.27554601430892944, -- test: 1.140170931816101 \n",
      " \n",
      "#################### Sampling at Epoch 63299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63299\n",
      "Mean Log Likelihood -- train: -2.536409854888916, -- test: -63.646114349365234 \n",
      "Root Mean Squared Error -- train: 0.28000199794769287, -- test: 1.1404364109039307 \n",
      " \n",
      "#################### Sampling at Epoch 63349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63349\n",
      "Mean Log Likelihood -- train: -2.5004258155822754, -- test: -62.384307861328125 \n",
      "Root Mean Squared Error -- train: 0.2787139117717743, -- test: 1.1293179988861084 \n",
      " \n",
      "#################### Sampling at Epoch 63399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63399\n",
      "Mean Log Likelihood -- train: -2.428696632385254, -- test: -59.271080017089844 \n",
      "Root Mean Squared Error -- train: 0.276128351688385, -- test: 1.1014056205749512 \n",
      " \n",
      "#################### Sampling at Epoch 63449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63449\n",
      "Mean Log Likelihood -- train: -2.4728658199310303, -- test: -64.17388153076172 \n",
      "Root Mean Squared Error -- train: 0.2777233123779297, -- test: 1.1450549364089966 \n",
      " \n",
      "#################### Sampling at Epoch 63499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63499\n",
      "Mean Log Likelihood -- train: -2.411752462387085, -- test: -62.8074836730957 \n",
      "Root Mean Squared Error -- train: 0.27551403641700745, -- test: 1.1330589056015015 \n",
      " \n",
      "#################### Sampling at Epoch 63549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63549\n",
      "Mean Log Likelihood -- train: -2.451556444168091, -- test: -60.567840576171875 \n",
      "Root Mean Squared Error -- train: 0.2769549489021301, -- test: 1.1131172180175781 \n",
      " \n",
      "#################### Sampling at Epoch 63599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63599\n",
      "Mean Log Likelihood -- train: -2.456101417541504, -- test: -61.23198318481445 \n",
      "Root Mean Squared Error -- train: 0.2771190404891968, -- test: 1.119067668914795 \n",
      " \n",
      "#################### Sampling at Epoch 63649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63649\n",
      "Mean Log Likelihood -- train: -2.4907076358795166, -- test: -65.94033813476562 \n",
      "Root Mean Squared Error -- train: 0.27836501598358154, -- test: 1.16037917137146 \n",
      " \n",
      "#################### Sampling at Epoch 63699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63699\n",
      "Mean Log Likelihood -- train: -2.4783449172973633, -- test: -59.66142654418945 \n",
      "Root Mean Squared Error -- train: 0.27792054414749146, -- test: 1.104944109916687 \n",
      " \n",
      "#################### Sampling at Epoch 63749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63749\n",
      "Mean Log Likelihood -- train: -2.3998863697052, -- test: -61.2779655456543 \n",
      "Root Mean Squared Error -- train: 0.2750829756259918, -- test: 1.119478464126587 \n",
      " \n",
      "#################### Sampling at Epoch 63799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63799\n",
      "Mean Log Likelihood -- train: -2.4249627590179443, -- test: -63.07331848144531 \n",
      "Root Mean Squared Error -- train: 0.27599307894706726, -- test: 1.1354026794433594 \n",
      " \n",
      "#################### Sampling at Epoch 63849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63849\n",
      "Mean Log Likelihood -- train: -2.434495210647583, -- test: -59.9749641418457 \n",
      "Root Mean Squared Error -- train: 0.27633824944496155, -- test: 1.1077780723571777 \n",
      " \n",
      "#################### Sampling at Epoch 63899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63899\n",
      "Mean Log Likelihood -- train: -2.392625570297241, -- test: -61.712276458740234 \n",
      "Root Mean Squared Error -- train: 0.27481892704963684, -- test: 1.1233514547348022 \n",
      " \n",
      "#################### Sampling at Epoch 63949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63949\n",
      "Mean Log Likelihood -- train: -2.446234703063965, -- test: -60.16889190673828 \n",
      "Root Mean Squared Error -- train: 0.2767627537250519, -- test: 1.109527349472046 \n",
      " \n",
      "#################### Sampling at Epoch 63999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 63999\n",
      "Mean Log Likelihood -- train: -2.431823253631592, -- test: -60.8340950012207 \n",
      "Root Mean Squared Error -- train: 0.2762415409088135, -- test: 1.1155065298080444 \n",
      " \n",
      "#################### Sampling at Epoch 64049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64049\n",
      "Mean Log Likelihood -- train: -2.4314775466918945, -- test: -61.30543899536133 \n",
      "Root Mean Squared Error -- train: 0.27622905373573303, -- test: 1.119723916053772 \n",
      " \n",
      "#################### Sampling at Epoch 64099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64099\n",
      "Mean Log Likelihood -- train: -2.413945436477661, -- test: -61.64704513549805 \n",
      "Root Mean Squared Error -- train: 0.2755936086177826, -- test: 1.1227706670761108 \n",
      " \n",
      "#################### Sampling at Epoch 64149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64149\n",
      "Mean Log Likelihood -- train: -2.4683918952941895, -- test: -62.43087387084961 \n",
      "Root Mean Squared Error -- train: 0.2775622010231018, -- test: 1.129730224609375 \n",
      " \n",
      "#################### Sampling at Epoch 64199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64199\n",
      "Mean Log Likelihood -- train: -2.439685583114624, -- test: -63.17416000366211 \n",
      "Root Mean Squared Error -- train: 0.27652600407600403, -- test: 1.1362905502319336 \n",
      " \n",
      "#################### Sampling at Epoch 64249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64249\n",
      "Mean Log Likelihood -- train: -2.4333322048187256, -- test: -60.948829650878906 \n",
      "Root Mean Squared Error -- train: 0.2762961685657501, -- test: 1.1165345907211304 \n",
      " \n",
      "#################### Sampling at Epoch 64299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64299\n",
      "Mean Log Likelihood -- train: -2.4839372634887695, -- test: -65.81456756591797 \n",
      "Root Mean Squared Error -- train: 0.278121680021286, -- test: 1.1592947244644165 \n",
      " \n",
      "#################### Sampling at Epoch 64349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64349\n",
      "Mean Log Likelihood -- train: -2.411363363265991, -- test: -65.16242980957031 \n",
      "Root Mean Squared Error -- train: 0.2754999101161957, -- test: 1.1536556482315063 \n",
      " \n",
      "#################### Sampling at Epoch 64399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64399\n",
      "Mean Log Likelihood -- train: -2.552290678024292, -- test: -66.2859115600586 \n",
      "Root Mean Squared Error -- train: 0.28056859970092773, -- test: 1.163353443145752 \n",
      " \n",
      "#################### Sampling at Epoch 64449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64449\n",
      "Mean Log Likelihood -- train: -2.3853774070739746, -- test: -65.43152618408203 \n",
      "Root Mean Squared Error -- train: 0.2745550572872162, -- test: 1.1559858322143555 \n",
      " \n",
      "#################### Sampling at Epoch 64499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64499\n",
      "Mean Log Likelihood -- train: -2.4278528690338135, -- test: -59.4901008605957 \n",
      "Root Mean Squared Error -- train: 0.27609777450561523, -- test: 1.103392481803894 \n",
      " \n",
      "#################### Sampling at Epoch 64549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64549\n",
      "Mean Log Likelihood -- train: -2.488152265548706, -- test: -62.37416458129883 \n",
      "Root Mean Squared Error -- train: 0.27827319502830505, -- test: 1.129228115081787 \n",
      " \n",
      "#################### Sampling at Epoch 64599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64599\n",
      "Mean Log Likelihood -- train: -2.4284555912017822, -- test: -61.0731086730957 \n",
      "Root Mean Squared Error -- train: 0.2761196196079254, -- test: 1.1176471710205078 \n",
      " \n",
      "#################### Sampling at Epoch 64649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64649\n",
      "Mean Log Likelihood -- train: -2.459749937057495, -- test: -62.50584030151367 \n",
      "Root Mean Squared Error -- train: 0.27725064754486084, -- test: 1.130393624305725 \n",
      " \n",
      "#################### Sampling at Epoch 64699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64699\n",
      "Mean Log Likelihood -- train: -2.462005138397217, -- test: -61.7333984375 \n",
      "Root Mean Squared Error -- train: 0.27733197808265686, -- test: 1.1235394477844238 \n",
      " \n",
      "#################### Sampling at Epoch 64749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64749\n",
      "Mean Log Likelihood -- train: -2.4103283882141113, -- test: -62.94416809082031 \n",
      "Root Mean Squared Error -- train: 0.2754623293876648, -- test: 1.1342647075653076 \n",
      " \n",
      "#################### Sampling at Epoch 64799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64799\n",
      "Mean Log Likelihood -- train: -2.4482028484344482, -- test: -62.764991760253906 \n",
      "Root Mean Squared Error -- train: 0.2768338918685913, -- test: 1.1326838731765747 \n",
      " \n",
      "#################### Sampling at Epoch 64849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64849\n",
      "Mean Log Likelihood -- train: -2.4728574752807617, -- test: -60.98379898071289 \n",
      "Root Mean Squared Error -- train: 0.2777230143547058, -- test: 1.1168478727340698 \n",
      " \n",
      "#################### Sampling at Epoch 64899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64899\n",
      "Mean Log Likelihood -- train: -2.4918267726898193, -- test: -63.33607482910156 \n",
      "Root Mean Squared Error -- train: 0.27840521931648254, -- test: 1.1377145051956177 \n",
      " \n",
      "#################### Sampling at Epoch 64949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64949\n",
      "Mean Log Likelihood -- train: -2.5007379055023193, -- test: -63.541534423828125 \n",
      "Root Mean Squared Error -- train: 0.27872511744499207, -- test: 1.1395188570022583 \n",
      " \n",
      "#################### Sampling at Epoch 64999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 64999\n",
      "Mean Log Likelihood -- train: -2.397505521774292, -- test: -65.80491638183594 \n",
      "Root Mean Squared Error -- train: 0.27499642968177795, -- test: 1.1592113971710205 \n",
      " \n",
      "#################### Sampling at Epoch 65049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65049\n",
      "Mean Log Likelihood -- train: -2.4330430030822754, -- test: -62.000701904296875 \n",
      "Root Mean Squared Error -- train: 0.27628570795059204, -- test: 1.1259160041809082 \n",
      " \n",
      "#################### Sampling at Epoch 65099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65099\n",
      "Mean Log Likelihood -- train: -2.456186532974243, -- test: -60.961524963378906 \n",
      "Root Mean Squared Error -- train: 0.2771220803260803, -- test: 1.1166483163833618 \n",
      " \n",
      "#################### Sampling at Epoch 65149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65149\n",
      "Mean Log Likelihood -- train: -2.491501808166504, -- test: -63.68073272705078 \n",
      "Root Mean Squared Error -- train: 0.27839356660842896, -- test: 1.140739917755127 \n",
      " \n",
      "#################### Sampling at Epoch 65199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65199\n",
      "Mean Log Likelihood -- train: -2.4369795322418213, -- test: -61.18392562866211 \n",
      "Root Mean Squared Error -- train: 0.27642813324928284, -- test: 1.1186381578445435 \n",
      " \n",
      "#################### Sampling at Epoch 65249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65249\n",
      "Mean Log Likelihood -- train: -2.4601852893829346, -- test: -60.58827209472656 \n",
      "Root Mean Squared Error -- train: 0.27726635336875916, -- test: 1.1133006811141968 \n",
      " \n",
      "#################### Sampling at Epoch 65299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65299\n",
      "Mean Log Likelihood -- train: -2.4454920291900635, -- test: -57.33906173706055 \n",
      "Root Mean Squared Error -- train: 0.27673593163490295, -- test: 1.0837223529815674 \n",
      " \n",
      "#################### Sampling at Epoch 65349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65349\n",
      "Mean Log Likelihood -- train: -2.4389853477478027, -- test: -56.1500358581543 \n",
      "Root Mean Squared Error -- train: 0.2765006721019745, -- test: 1.0726945400238037 \n",
      " \n",
      "#################### Sampling at Epoch 65399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65399\n",
      "Mean Log Likelihood -- train: -2.4851784706115723, -- test: -62.123104095458984 \n",
      "Root Mean Squared Error -- train: 0.2781662940979004, -- test: 1.1270025968551636 \n",
      " \n",
      "#################### Sampling at Epoch 65449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65449\n",
      "Mean Log Likelihood -- train: -2.4386537075042725, -- test: -59.81649398803711 \n",
      "Root Mean Squared Error -- train: 0.276488721370697, -- test: 1.106346607208252 \n",
      " \n",
      "#################### Sampling at Epoch 65499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65499\n",
      "Mean Log Likelihood -- train: -2.4100341796875, -- test: -57.66209411621094 \n",
      "Root Mean Squared Error -- train: 0.27545166015625, -- test: 1.0866990089416504 \n",
      " \n",
      "#################### Sampling at Epoch 65549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65549\n",
      "Mean Log Likelihood -- train: -2.444232702255249, -- test: -57.305824279785156 \n",
      "Root Mean Squared Error -- train: 0.27669042348861694, -- test: 1.0834156274795532 \n",
      " \n",
      "#################### Sampling at Epoch 65599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65599\n",
      "Mean Log Likelihood -- train: -2.3913886547088623, -- test: -57.95991134643555 \n",
      "Root Mean Squared Error -- train: 0.2747739255428314, -- test: 1.0894361734390259 \n",
      " \n",
      "#################### Sampling at Epoch 65649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65649\n",
      "Mean Log Likelihood -- train: -2.468801259994507, -- test: -60.95439529418945 \n",
      "Root Mean Squared Error -- train: 0.27757692337036133, -- test: 1.1165845394134521 \n",
      " \n",
      "#################### Sampling at Epoch 65699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65699\n",
      "Mean Log Likelihood -- train: -2.5025079250335693, -- test: -58.93007278442383 \n",
      "Root Mean Squared Error -- train: 0.27878862619400024, -- test: 1.0983052253723145 \n",
      " \n",
      "#################### Sampling at Epoch 65749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65749\n",
      "Mean Log Likelihood -- train: -2.448490858078003, -- test: -57.728965759277344 \n",
      "Root Mean Squared Error -- train: 0.2768442630767822, -- test: 1.087314248085022 \n",
      " \n",
      "#################### Sampling at Epoch 65799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65799\n",
      "Mean Log Likelihood -- train: -2.4779412746429443, -- test: -56.10873031616211 \n",
      "Root Mean Squared Error -- train: 0.27790600061416626, -- test: 1.0723094940185547 \n",
      " \n",
      "#################### Sampling at Epoch 65849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65849\n",
      "Mean Log Likelihood -- train: -2.436267137527466, -- test: -58.68281555175781 \n",
      "Root Mean Squared Error -- train: 0.27640238404273987, -- test: 1.0960516929626465 \n",
      " \n",
      "#################### Sampling at Epoch 65899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65899\n",
      "Mean Log Likelihood -- train: -2.4707071781158447, -- test: -57.792144775390625 \n",
      "Root Mean Squared Error -- train: 0.2776455879211426, -- test: 1.087895154953003 \n",
      " \n",
      "#################### Sampling at Epoch 65949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65949\n",
      "Mean Log Likelihood -- train: -2.429243326187134, -- test: -57.4249382019043 \n",
      "Root Mean Squared Error -- train: 0.27614811062812805, -- test: 1.0845144987106323 \n",
      " \n",
      "#################### Sampling at Epoch 65999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 65999\n",
      "Mean Log Likelihood -- train: -2.4566562175750732, -- test: -56.93061447143555 \n",
      "Root Mean Squared Error -- train: 0.2771390378475189, -- test: 1.0799468755722046 \n",
      " \n",
      "#################### Sampling at Epoch 66049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66049\n",
      "Mean Log Likelihood -- train: -2.4068715572357178, -- test: -57.17564392089844 \n",
      "Root Mean Squared Error -- train: 0.2753368020057678, -- test: 1.0822134017944336 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 11:43:36.677706: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Sampling at Epoch 66099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66099\n",
      "Mean Log Likelihood -- train: -2.4571874141693115, -- test: -60.128074645996094 \n",
      "Root Mean Squared Error -- train: 0.2771582007408142, -- test: 1.1091593503952026 \n",
      " \n",
      "#################### Sampling at Epoch 66149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66149\n",
      "Mean Log Likelihood -- train: -2.464543104171753, -- test: -57.77714538574219 \n",
      "Root Mean Squared Error -- train: 0.2774234712123871, -- test: 1.0877572298049927 \n",
      " \n",
      "#################### Sampling at Epoch 66199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66199\n",
      "Mean Log Likelihood -- train: -2.47216796875, -- test: -57.68256378173828 \n",
      "Root Mean Squared Error -- train: 0.27769818902015686, -- test: 1.0868873596191406 \n",
      " \n",
      "#################### Sampling at Epoch 66249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66249\n",
      "Mean Log Likelihood -- train: -2.521000385284424, -- test: -60.12822341918945 \n",
      "Root Mean Squared Error -- train: 0.2794511318206787, -- test: 1.1091606616973877 \n",
      " \n",
      "#################### Sampling at Epoch 66299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66299\n",
      "Mean Log Likelihood -- train: -2.4750051498413086, -- test: -61.146812438964844 \n",
      "Root Mean Squared Error -- train: 0.2778003215789795, -- test: 1.118306279182434 \n",
      " \n",
      "#################### Sampling at Epoch 66349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66349\n",
      "Mean Log Likelihood -- train: -2.461634874343872, -- test: -60.20518493652344 \n",
      "Root Mean Squared Error -- train: 0.2773186266422272, -- test: 1.1098543405532837 \n",
      " \n",
      "#################### Sampling at Epoch 66399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66399\n",
      "Mean Log Likelihood -- train: -2.425139904022217, -- test: -60.93875503540039 \n",
      "Root Mean Squared Error -- train: 0.275999516248703, -- test: 1.1164443492889404 \n",
      " \n",
      "#################### Sampling at Epoch 66449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66449\n",
      "Mean Log Likelihood -- train: -2.4489314556121826, -- test: -62.391109466552734 \n",
      "Root Mean Squared Error -- train: 0.27686017751693726, -- test: 1.1293781995773315 \n",
      " \n",
      "#################### Sampling at Epoch 66499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66499\n",
      "Mean Log Likelihood -- train: -2.384153127670288, -- test: -65.18133544921875 \n",
      "Root Mean Squared Error -- train: 0.2745104730129242, -- test: 1.1538195610046387 \n",
      " \n",
      "#################### Sampling at Epoch 66549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66549\n",
      "Mean Log Likelihood -- train: -2.427814483642578, -- test: -66.6572494506836 \n",
      "Root Mean Squared Error -- train: 0.2760964035987854, -- test: 1.1665409803390503 \n",
      " \n",
      "#################### Sampling at Epoch 66599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66599\n",
      "Mean Log Likelihood -- train: -2.4034180641174316, -- test: -65.02066040039062 \n",
      "Root Mean Squared Error -- train: 0.275211364030838, -- test: 1.1524262428283691 \n",
      " \n",
      "#################### Sampling at Epoch 66649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66649\n",
      "Mean Log Likelihood -- train: -2.403576135635376, -- test: -63.378883361816406 \n",
      "Root Mean Squared Error -- train: 0.27521711587905884, -- test: 1.13809072971344 \n",
      " \n",
      "#################### Sampling at Epoch 66699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66699\n",
      "Mean Log Likelihood -- train: -2.415287494659424, -- test: -61.04525375366211 \n",
      "Root Mean Squared Error -- train: 0.2756422758102417, -- test: 1.1173979043960571 \n",
      " \n",
      "#################### Sampling at Epoch 66749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66749\n",
      "Mean Log Likelihood -- train: -2.4486305713653564, -- test: -60.453189849853516 \n",
      "Root Mean Squared Error -- train: 0.27684929966926575, -- test: 1.112086534500122 \n",
      " \n",
      "#################### Sampling at Epoch 66799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66799\n",
      "Mean Log Likelihood -- train: -2.385867118835449, -- test: -61.30613327026367 \n",
      "Root Mean Squared Error -- train: 0.27457287907600403, -- test: 1.1197301149368286 \n",
      " \n",
      "#################### Sampling at Epoch 66849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66849\n",
      "Mean Log Likelihood -- train: -2.4283981323242188, -- test: -64.30912017822266 \n",
      "Root Mean Squared Error -- train: 0.2761175334453583, -- test: 1.1462352275848389 \n",
      " \n",
      "#################### Sampling at Epoch 66899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66899\n",
      "Mean Log Likelihood -- train: -2.409186840057373, -- test: -63.85652160644531 \n",
      "Root Mean Squared Error -- train: 0.2754209041595459, -- test: 1.142279863357544 \n",
      " \n",
      "#################### Sampling at Epoch 66949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66949\n",
      "Mean Log Likelihood -- train: -2.370405912399292, -- test: -62.81513595581055 \n",
      "Root Mean Squared Error -- train: 0.27400919795036316, -- test: 1.1331263780593872 \n",
      " \n",
      "#################### Sampling at Epoch 66999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 66999\n",
      "Mean Log Likelihood -- train: -2.3956353664398193, -- test: -60.824737548828125 \n",
      "Root Mean Squared Error -- train: 0.27492842078208923, -- test: 1.1154226064682007 \n",
      " \n",
      "#################### Sampling at Epoch 67049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67049\n",
      "Mean Log Likelihood -- train: -2.413959264755249, -- test: -59.41728210449219 \n",
      "Root Mean Squared Error -- train: 0.2755940854549408, -- test: 1.1027323007583618 \n",
      " \n",
      "#################### Sampling at Epoch 67099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67099\n",
      "Mean Log Likelihood -- train: -2.3817837238311768, -- test: -58.80637741088867 \n",
      "Root Mean Squared Error -- train: 0.27442413568496704, -- test: 1.0971784591674805 \n",
      " \n",
      "#################### Sampling at Epoch 67149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67149\n",
      "Mean Log Likelihood -- train: -2.3905088901519775, -- test: -60.582733154296875 \n",
      "Root Mean Squared Error -- train: 0.27474185824394226, -- test: 1.1132508516311646 \n",
      " \n",
      "#################### Sampling at Epoch 67199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67199\n",
      "Mean Log Likelihood -- train: -2.398231029510498, -- test: -61.19828796386719 \n",
      "Root Mean Squared Error -- train: 0.27502280473709106, -- test: 1.1187665462493896 \n",
      " \n",
      "#################### Sampling at Epoch 67249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67249\n",
      "Mean Log Likelihood -- train: -2.390777587890625, -- test: -59.08225631713867 \n",
      "Root Mean Squared Error -- train: 0.2747516632080078, -- test: 1.0996899604797363 \n",
      " \n",
      "#################### Sampling at Epoch 67299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67299\n",
      "Mean Log Likelihood -- train: -2.4331743717193604, -- test: -61.921749114990234 \n",
      "Root Mean Squared Error -- train: 0.2762904465198517, -- test: 1.1252145767211914 \n",
      " \n",
      "#################### Sampling at Epoch 67349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67349\n",
      "Mean Log Likelihood -- train: -2.441277503967285, -- test: -60.9430046081543 \n",
      "Root Mean Squared Error -- train: 0.27658358216285706, -- test: 1.1164823770523071 \n",
      " \n",
      "#################### Sampling at Epoch 67399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67399\n",
      "Mean Log Likelihood -- train: -2.440749168395996, -- test: -56.64631652832031 \n",
      "Root Mean Squared Error -- train: 0.27656447887420654, -- test: 1.0773110389709473 \n",
      " \n",
      "#################### Sampling at Epoch 67449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67449\n",
      "Mean Log Likelihood -- train: -2.523695707321167, -- test: -59.55866622924805 \n",
      "Root Mean Squared Error -- train: 0.2795475423336029, -- test: 1.1040138006210327 \n",
      " \n",
      "#################### Sampling at Epoch 67499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67499\n",
      "Mean Log Likelihood -- train: -2.452991247177124, -- test: -59.08604049682617 \n",
      "Root Mean Squared Error -- train: 0.27700677514076233, -- test: 1.0997244119644165 \n",
      " \n",
      "#################### Sampling at Epoch 67549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67549\n",
      "Mean Log Likelihood -- train: -2.379067897796631, -- test: -58.801910400390625 \n",
      "Root Mean Squared Error -- train: 0.2743251323699951, -- test: 1.0971375703811646 \n",
      " \n",
      "#################### Sampling at Epoch 67599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67599\n",
      "Mean Log Likelihood -- train: -2.394996166229248, -- test: -58.63152313232422 \n",
      "Root Mean Squared Error -- train: 0.27490514516830444, -- test: 1.0955835580825806 \n",
      " \n",
      "#################### Sampling at Epoch 67649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67649\n",
      "Mean Log Likelihood -- train: -2.3781585693359375, -- test: -57.3288688659668 \n",
      "Root Mean Squared Error -- train: 0.2742919921875, -- test: 1.0836282968521118 \n",
      " \n",
      "#################### Sampling at Epoch 67699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67699\n",
      "Mean Log Likelihood -- train: -2.436222791671753, -- test: -57.9791145324707 \n",
      "Root Mean Squared Error -- train: 0.27640077471733093, -- test: 1.0896124839782715 \n",
      " \n",
      "#################### Sampling at Epoch 67749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67749\n",
      "Mean Log Likelihood -- train: -2.45059871673584, -- test: -57.14371109008789 \n",
      "Root Mean Squared Error -- train: 0.2769203782081604, -- test: 1.0819183588027954 \n",
      " \n",
      "#################### Sampling at Epoch 67799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67799\n",
      "Mean Log Likelihood -- train: -2.505181074142456, -- test: -57.023040771484375 \n",
      "Root Mean Squared Error -- train: 0.2788844704627991, -- test: 1.0808024406433105 \n",
      " \n",
      "#################### Sampling at Epoch 67849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67849\n",
      "Mean Log Likelihood -- train: -2.481729030609131, -- test: -58.90748596191406 \n",
      "Root Mean Squared Error -- train: 0.2780422866344452, -- test: 1.0980994701385498 \n",
      " \n",
      "#################### Sampling at Epoch 67899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67899\n",
      "Mean Log Likelihood -- train: -2.396955728530884, -- test: -58.10555648803711 \n",
      "Root Mean Squared Error -- train: 0.2749764323234558, -- test: 1.090772271156311 \n",
      " \n",
      "#################### Sampling at Epoch 67949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67949\n",
      "Mean Log Likelihood -- train: -2.4243931770324707, -- test: -58.58329772949219 \n",
      "Root Mean Squared Error -- train: 0.275972455739975, -- test: 1.0951433181762695 \n",
      " \n",
      "#################### Sampling at Epoch 67999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 67999\n",
      "Mean Log Likelihood -- train: -2.4149062633514404, -- test: -57.889766693115234 \n",
      "Root Mean Squared Error -- train: 0.2756284773349762, -- test: 1.088792085647583 \n",
      " \n",
      "#################### Sampling at Epoch 68049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68049\n",
      "Mean Log Likelihood -- train: -2.448849678039551, -- test: -59.05203628540039 \n",
      "Root Mean Squared Error -- train: 0.2768571972846985, -- test: 1.0994150638580322 \n",
      " \n",
      "#################### Sampling at Epoch 68099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68099\n",
      "Mean Log Likelihood -- train: -2.5313847064971924, -- test: -60.398048400878906 \n",
      "Root Mean Squared Error -- train: 0.2798224687576294, -- test: 1.1115906238555908 \n",
      " \n",
      "#################### Sampling at Epoch 68149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68149\n",
      "Mean Log Likelihood -- train: -2.4113073348999023, -- test: -61.70964813232422 \n",
      "Root Mean Squared Error -- train: 0.2754978835582733, -- test: 1.1233280897140503 \n",
      " \n",
      "#################### Sampling at Epoch 68199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68199\n",
      "Mean Log Likelihood -- train: -2.44496488571167, -- test: -64.11719512939453 \n",
      "Root Mean Squared Error -- train: 0.27671685814857483, -- test: 1.144559621810913 \n",
      " \n",
      "#################### Sampling at Epoch 68249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68249\n",
      "Mean Log Likelihood -- train: -2.4460744857788086, -- test: -64.50372314453125 \n",
      "Root Mean Squared Error -- train: 0.27675697207450867, -- test: 1.1479318141937256 \n",
      " \n",
      "#################### Sampling at Epoch 68299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68299\n",
      "Mean Log Likelihood -- train: -2.4348411560058594, -- test: -66.86949920654297 \n",
      "Root Mean Squared Error -- train: 0.2763507664203644, -- test: 1.1683591604232788 \n",
      " \n",
      "#################### Sampling at Epoch 68349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68349\n",
      "Mean Log Likelihood -- train: -2.411567211151123, -- test: -67.16222381591797 \n",
      "Root Mean Squared Error -- train: 0.2755073010921478, -- test: 1.1708619594573975 \n",
      " \n",
      "#################### Sampling at Epoch 68399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68399\n",
      "Mean Log Likelihood -- train: -2.4071924686431885, -- test: -67.62427520751953 \n",
      "Root Mean Squared Error -- train: 0.2753484547138214, -- test: 1.1748013496398926 \n",
      " \n",
      "#################### Sampling at Epoch 68449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68449\n",
      "Mean Log Likelihood -- train: -2.452817678451538, -- test: -67.09895324707031 \n",
      "Root Mean Squared Error -- train: 0.2770005166530609, -- test: 1.1703212261199951 \n",
      " \n",
      "#################### Sampling at Epoch 68499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68499\n",
      "Mean Log Likelihood -- train: -2.3859448432922363, -- test: -66.78044128417969 \n",
      "Root Mean Squared Error -- train: 0.27457574009895325, -- test: 1.167596459388733 \n",
      " \n",
      "#################### Sampling at Epoch 68549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68549\n",
      "Mean Log Likelihood -- train: -2.49607515335083, -- test: -65.79708099365234 \n",
      "Root Mean Squared Error -- train: 0.27855777740478516, -- test: 1.1591439247131348 \n",
      " \n",
      "#################### Sampling at Epoch 68599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68599\n",
      "Mean Log Likelihood -- train: -2.431826114654541, -- test: -63.7692985534668 \n",
      "Root Mean Squared Error -- train: 0.27624163031578064, -- test: 1.141516089439392 \n",
      " \n",
      "#################### Sampling at Epoch 68649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68649\n",
      "Mean Log Likelihood -- train: -2.3738198280334473, -- test: -64.64764404296875 \n",
      "Root Mean Squared Error -- train: 0.2741337716579437, -- test: 1.1491848230361938 \n",
      " \n",
      "#################### Sampling at Epoch 68699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68699\n",
      "Mean Log Likelihood -- train: -2.4071478843688965, -- test: -64.3314208984375 \n",
      "Root Mean Squared Error -- train: 0.2753468453884125, -- test: 1.1464297771453857 \n",
      " \n",
      "#################### Sampling at Epoch 68749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68749\n",
      "Mean Log Likelihood -- train: -2.47128963470459, -- test: -65.07808685302734 \n",
      "Root Mean Squared Error -- train: 0.2776665687561035, -- test: 1.1529244184494019 \n",
      " \n",
      "#################### Sampling at Epoch 68799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68799\n",
      "Mean Log Likelihood -- train: -2.4759528636932373, -- test: -64.19298553466797 \n",
      "Root Mean Squared Error -- train: 0.2778344452381134, -- test: 1.1452217102050781 \n",
      " \n",
      "#################### Sampling at Epoch 68849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68849\n",
      "Mean Log Likelihood -- train: -2.478863477706909, -- test: -65.58948516845703 \n",
      "Root Mean Squared Error -- train: 0.27793920040130615, -- test: 1.1573516130447388 \n",
      " \n",
      "#################### Sampling at Epoch 68899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68899\n",
      "Mean Log Likelihood -- train: -2.434408664703369, -- test: -67.94603729248047 \n",
      "Root Mean Squared Error -- train: 0.27633512020111084, -- test: 1.1775370836257935 \n",
      " \n",
      "#################### Sampling at Epoch 68949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68949\n",
      "Mean Log Likelihood -- train: -2.5020430088043213, -- test: -65.03475952148438 \n",
      "Root Mean Squared Error -- train: 0.27877193689346313, -- test: 1.1525485515594482 \n",
      " \n",
      "#################### Sampling at Epoch 68999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 68999\n",
      "Mean Log Likelihood -- train: -2.4182424545288086, -- test: -64.97099304199219 \n",
      "Root Mean Squared Error -- train: 0.27574947476387024, -- test: 1.1519951820373535 \n",
      " \n",
      "#################### Sampling at Epoch 69049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69049\n",
      "Mean Log Likelihood -- train: -2.459000587463379, -- test: -66.24357604980469 \n",
      "Root Mean Squared Error -- train: 0.2772236168384552, -- test: 1.1629894971847534 \n",
      " \n",
      "#################### Sampling at Epoch 69099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69099\n",
      "Mean Log Likelihood -- train: -2.449493885040283, -- test: -64.4671859741211 \n",
      "Root Mean Squared Error -- train: 0.2768804728984833, -- test: 1.1476134061813354 \n",
      " \n",
      "#################### Sampling at Epoch 69149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69149\n",
      "Mean Log Likelihood -- train: -2.454223155975342, -- test: -64.77043151855469 \n",
      "Root Mean Squared Error -- train: 0.27705124020576477, -- test: 1.1502528190612793 \n",
      " \n",
      "#################### Sampling at Epoch 69199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69199\n",
      "Mean Log Likelihood -- train: -2.425013780593872, -- test: -66.23982238769531 \n",
      "Root Mean Squared Error -- train: 0.2759949266910553, -- test: 1.1629571914672852 \n",
      " \n",
      "#################### Sampling at Epoch 69249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69249\n",
      "Mean Log Likelihood -- train: -2.500739812850952, -- test: -63.752113342285156 \n",
      "Root Mean Squared Error -- train: 0.27872517704963684, -- test: 1.1413655281066895 \n",
      " \n",
      "#################### Sampling at Epoch 69299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69299\n",
      "Mean Log Likelihood -- train: -2.621150493621826, -- test: -65.44243621826172 \n",
      "Root Mean Squared Error -- train: 0.2830122411251068, -- test: 1.1560802459716797 \n",
      " \n",
      "#################### Sampling at Epoch 69349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69349\n",
      "Mean Log Likelihood -- train: -2.5971686840057373, -- test: -63.15902328491211 \n",
      "Root Mean Squared Error -- train: 0.2821636199951172, -- test: 1.1361572742462158 \n",
      " \n",
      "#################### Sampling at Epoch 69399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69399\n",
      "Mean Log Likelihood -- train: -2.477632999420166, -- test: -64.4248275756836 \n",
      "Root Mean Squared Error -- train: 0.27789491415023804, -- test: 1.1472443342208862 \n",
      " \n",
      "#################### Sampling at Epoch 69449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69449\n",
      "Mean Log Likelihood -- train: -2.4916329383850098, -- test: -67.62568664550781 \n",
      "Root Mean Squared Error -- train: 0.2783982455730438, -- test: 1.1748133897781372 \n",
      " \n",
      "#################### Sampling at Epoch 69499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69499\n",
      "Mean Log Likelihood -- train: -2.4499876499176025, -- test: -67.31085205078125 \n",
      "Root Mean Squared Error -- train: 0.2768983244895935, -- test: 1.1721305847167969 \n",
      " \n",
      "#################### Sampling at Epoch 69549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69549\n",
      "Mean Log Likelihood -- train: -2.4335570335388184, -- test: -65.46366119384766 \n",
      "Root Mean Squared Error -- train: 0.27630430459976196, -- test: 1.1562639474868774 \n",
      " \n",
      "#################### Sampling at Epoch 69599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69599\n",
      "Mean Log Likelihood -- train: -2.4102985858917236, -- test: -63.687225341796875 \n",
      "Root Mean Squared Error -- train: 0.27546125650405884, -- test: 1.1407967805862427 \n",
      " \n",
      "#################### Sampling at Epoch 69649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69649\n",
      "Mean Log Likelihood -- train: -2.4861040115356445, -- test: -62.85529708862305 \n",
      "Root Mean Squared Error -- train: 0.27819958329200745, -- test: 1.1334807872772217 \n",
      " \n",
      "#################### Sampling at Epoch 69699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69699\n",
      "Mean Log Likelihood -- train: -2.445639133453369, -- test: -62.385276794433594 \n",
      "Root Mean Squared Error -- train: 0.2767412066459656, -- test: 1.129326581954956 \n",
      " \n",
      "#################### Sampling at Epoch 69749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69749\n",
      "Mean Log Likelihood -- train: -2.469525098800659, -- test: -65.07563018798828 \n",
      "Root Mean Squared Error -- train: 0.27760300040245056, -- test: 1.1529030799865723 \n",
      " \n",
      "#################### Sampling at Epoch 69799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69799\n",
      "Mean Log Likelihood -- train: -2.4100914001464844, -- test: -66.40643310546875 \n",
      "Root Mean Squared Error -- train: 0.27545374631881714, -- test: 1.16438889503479 \n",
      " \n",
      "#################### Sampling at Epoch 69849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69849\n",
      "Mean Log Likelihood -- train: -2.421900987625122, -- test: -63.81952667236328 \n",
      "Root Mean Squared Error -- train: 0.27588212490081787, -- test: 1.1419559717178345 \n",
      " \n",
      "#################### Sampling at Epoch 69899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69899\n",
      "Mean Log Likelihood -- train: -2.4140782356262207, -- test: -63.84029769897461 \n",
      "Root Mean Squared Error -- train: 0.2755984365940094, -- test: 1.1421377658843994 \n",
      " \n",
      "#################### Sampling at Epoch 69949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69949\n",
      "Mean Log Likelihood -- train: -2.4133365154266357, -- test: -64.65792846679688 \n",
      "Root Mean Squared Error -- train: 0.2755715250968933, -- test: 1.149274230003357 \n",
      " \n",
      "#################### Sampling at Epoch 69999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 69999\n",
      "Mean Log Likelihood -- train: -2.4083445072174072, -- test: -63.394779205322266 \n",
      "Root Mean Squared Error -- train: 0.27539029717445374, -- test: 1.1382304430007935 \n",
      " \n",
      "#################### Sampling at Epoch 70049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70049\n",
      "Mean Log Likelihood -- train: -2.4161946773529053, -- test: -67.6296615600586 \n",
      "Root Mean Squared Error -- train: 0.2756751775741577, -- test: 1.1748472452163696 \n",
      " \n",
      "#################### Sampling at Epoch 70099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70099\n",
      "Mean Log Likelihood -- train: -2.3991122245788574, -- test: -65.42459106445312 \n",
      "Root Mean Squared Error -- train: 0.27505484223365784, -- test: 1.155925989151001 \n",
      " \n",
      "#################### Sampling at Epoch 70149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70149\n",
      "Mean Log Likelihood -- train: -2.5096969604492188, -- test: -66.32601928710938 \n",
      "Root Mean Squared Error -- train: 0.27904635667800903, -- test: 1.1636980772018433 \n",
      " \n",
      "#################### Sampling at Epoch 70199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70199\n",
      "Mean Log Likelihood -- train: -2.430203914642334, -- test: -64.91197204589844 \n",
      "Root Mean Squared Error -- train: 0.2761829197406769, -- test: 1.1514827013015747 \n",
      " \n",
      "#################### Sampling at Epoch 70249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70249\n",
      "Mean Log Likelihood -- train: -2.481201410293579, -- test: -67.17485046386719 \n",
      "Root Mean Squared Error -- train: 0.2780233323574066, -- test: 1.1709697246551514 \n",
      " \n",
      "#################### Sampling at Epoch 70299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70299\n",
      "Mean Log Likelihood -- train: -2.4268407821655273, -- test: -67.26339721679688 \n",
      "Root Mean Squared Error -- train: 0.27606111764907837, -- test: 1.1717255115509033 \n",
      " \n",
      "#################### Sampling at Epoch 70349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70349\n",
      "Mean Log Likelihood -- train: -2.518178701400757, -- test: -69.76425170898438 \n",
      "Root Mean Squared Error -- train: 0.2793501615524292, -- test: 1.192878007888794 \n",
      " \n",
      "#################### Sampling at Epoch 70399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70399\n",
      "Mean Log Likelihood -- train: -2.4824750423431396, -- test: -70.29196166992188 \n",
      "Root Mean Squared Error -- train: 0.2780691087245941, -- test: 1.1972936391830444 \n",
      " \n",
      "#################### Sampling at Epoch 70449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70449\n",
      "Mean Log Likelihood -- train: -2.4210121631622314, -- test: -69.9498519897461 \n",
      "Root Mean Squared Error -- train: 0.2758499085903168, -- test: 1.1944329738616943 \n",
      " \n",
      "#################### Sampling at Epoch 70499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70499\n",
      "Mean Log Likelihood -- train: -2.4084694385528564, -- test: -69.0662612915039 \n",
      "Root Mean Squared Error -- train: 0.27539482712745667, -- test: 1.1870121955871582 \n",
      " \n",
      "#################### Sampling at Epoch 70549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70549\n",
      "Mean Log Likelihood -- train: -2.4518320560455322, -- test: -66.39767456054688 \n",
      "Root Mean Squared Error -- train: 0.27696493268013, -- test: 1.164313793182373 \n",
      " \n",
      "#################### Sampling at Epoch 70599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70599\n",
      "Mean Log Likelihood -- train: -2.4066965579986572, -- test: -68.4684829711914 \n",
      "Root Mean Squared Error -- train: 0.27533045411109924, -- test: 1.1819654703140259 \n",
      " \n",
      "#################### Sampling at Epoch 70649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70649\n",
      "Mean Log Likelihood -- train: -2.4432308673858643, -- test: -68.78326416015625 \n",
      "Root Mean Squared Error -- train: 0.2766541838645935, -- test: 1.1846257448196411 \n",
      " \n",
      "#################### Sampling at Epoch 70699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70699\n",
      "Mean Log Likelihood -- train: -2.4595534801483154, -- test: -66.23371124267578 \n",
      "Root Mean Squared Error -- train: 0.27724358439445496, -- test: 1.1629046201705933 \n",
      " \n",
      "#################### Sampling at Epoch 70749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70749\n",
      "Mean Log Likelihood -- train: -2.465331792831421, -- test: -65.79989624023438 \n",
      "Root Mean Squared Error -- train: 0.27745193243026733, -- test: 1.1591682434082031 \n",
      " \n",
      "#################### Sampling at Epoch 70799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70799\n",
      "Mean Log Likelihood -- train: -2.4383020401000977, -- test: -66.65029907226562 \n",
      "Root Mean Squared Error -- train: 0.2764759659767151, -- test: 1.166481375694275 \n",
      " \n",
      "#################### Sampling at Epoch 70849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70849\n",
      "Mean Log Likelihood -- train: -2.4010276794433594, -- test: -67.36907196044922 \n",
      "Root Mean Squared Error -- train: 0.2751244902610779, -- test: 1.1726270914077759 \n",
      " \n",
      "#################### Sampling at Epoch 70899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70899\n",
      "Mean Log Likelihood -- train: -2.4281387329101562, -- test: -72.19888305664062 \n",
      "Root Mean Squared Error -- train: 0.27610811591148376, -- test: 1.2131160497665405 \n",
      " \n",
      "#################### Sampling at Epoch 70949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70949\n",
      "Mean Log Likelihood -- train: -2.4722721576690674, -- test: -69.68045806884766 \n",
      "Root Mean Squared Error -- train: 0.2777019441127777, -- test: 1.1921753883361816 \n",
      " \n",
      "#################### Sampling at Epoch 70999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 70999\n",
      "Mean Log Likelihood -- train: -2.461552381515503, -- test: -70.36972045898438 \n",
      "Root Mean Squared Error -- train: 0.2773156464099884, -- test: 1.1979429721832275 \n",
      " \n",
      "#################### Sampling at Epoch 71049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71049\n",
      "Mean Log Likelihood -- train: -2.435398817062378, -- test: -70.28167724609375 \n",
      "Root Mean Squared Error -- train: 0.27637094259262085, -- test: 1.1972078084945679 \n",
      " \n",
      "#################### Sampling at Epoch 71099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71099\n",
      "Mean Log Likelihood -- train: -2.4246058464050293, -- test: -67.73236083984375 \n",
      "Root Mean Squared Error -- train: 0.275980144739151, -- test: 1.1757210493087769 \n",
      " \n",
      "#################### Sampling at Epoch 71149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71149\n",
      "Mean Log Likelihood -- train: -2.4284300804138184, -- test: -68.32150268554688 \n",
      "Root Mean Squared Error -- train: 0.276118665933609, -- test: 1.1807212829589844 \n",
      " \n",
      "#################### Sampling at Epoch 71199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71199\n",
      "Mean Log Likelihood -- train: -2.406536817550659, -- test: -67.11968994140625 \n",
      "Root Mean Squared Error -- train: 0.27532464265823364, -- test: 1.1704984903335571 \n",
      " \n",
      "#################### Sampling at Epoch 71249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71249\n",
      "Mean Log Likelihood -- train: -2.4142324924468994, -- test: -68.25238037109375 \n",
      "Root Mean Squared Error -- train: 0.2756040096282959, -- test: 1.1801358461380005 \n",
      " \n",
      "#################### Sampling at Epoch 71299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71299\n",
      "Mean Log Likelihood -- train: -2.387833595275879, -- test: -66.44876861572266 \n",
      "Root Mean Squared Error -- train: 0.27464449405670166, -- test: 1.16475248336792 \n",
      " \n",
      "#################### Sampling at Epoch 71349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71349\n",
      "Mean Log Likelihood -- train: -2.5167791843414307, -- test: -63.68254089355469 \n",
      "Root Mean Squared Error -- train: 0.2793000340461731, -- test: 1.1407557725906372 \n",
      " \n",
      "#################### Sampling at Epoch 71399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71399\n",
      "Mean Log Likelihood -- train: -2.4797251224517822, -- test: -68.16255950927734 \n",
      "Root Mean Squared Error -- train: 0.27797019481658936, -- test: 1.1793744564056396 \n",
      " \n",
      "#################### Sampling at Epoch 71449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71449\n",
      "Mean Log Likelihood -- train: -2.4689977169036865, -- test: -66.29556274414062 \n",
      "Root Mean Squared Error -- train: 0.2775840163230896, -- test: 1.1634364128112793 \n",
      " \n",
      "#################### Sampling at Epoch 71499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71499\n",
      "Mean Log Likelihood -- train: -2.5103256702423096, -- test: -64.73973846435547 \n",
      "Root Mean Squared Error -- train: 0.27906888723373413, -- test: 1.149985909461975 \n",
      " \n",
      "#################### Sampling at Epoch 71549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71549\n",
      "Mean Log Likelihood -- train: -2.458083391189575, -- test: -64.70846557617188 \n",
      "Root Mean Squared Error -- train: 0.27719053626060486, -- test: 1.1497139930725098 \n",
      " \n",
      "#################### Sampling at Epoch 71599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71599\n",
      "Mean Log Likelihood -- train: -2.446744680404663, -- test: -65.76671600341797 \n",
      "Root Mean Squared Error -- train: 0.27678120136260986, -- test: 1.1588819026947021 \n",
      " \n",
      "#################### Sampling at Epoch 71649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71649\n",
      "Mean Log Likelihood -- train: -2.4870545864105225, -- test: -64.48236846923828 \n",
      "Root Mean Squared Error -- train: 0.27823373675346375, -- test: 1.1477457284927368 \n",
      " \n",
      "#################### Sampling at Epoch 71699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71699\n",
      "Mean Log Likelihood -- train: -2.40476655960083, -- test: -63.61857604980469 \n",
      "Root Mean Squared Error -- train: 0.2752603590488434, -- test: 1.1401948928833008 \n",
      " \n",
      "#################### Sampling at Epoch 71749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71749\n",
      "Mean Log Likelihood -- train: -2.4274404048919678, -- test: -62.900455474853516 \n",
      "Root Mean Squared Error -- train: 0.276082843542099, -- test: 1.1338791847229004 \n",
      " \n",
      "#################### Sampling at Epoch 71799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71799\n",
      "Mean Log Likelihood -- train: -2.409430980682373, -- test: -64.46878814697266 \n",
      "Root Mean Squared Error -- train: 0.27542975544929504, -- test: 1.1476274728775024 \n",
      " \n",
      "#################### Sampling at Epoch 71849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71849\n",
      "Mean Log Likelihood -- train: -2.387016773223877, -- test: -63.015403747558594 \n",
      "Root Mean Squared Error -- train: 0.27461475133895874, -- test: 1.1348925828933716 \n",
      " \n",
      "#################### Sampling at Epoch 71899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71899\n",
      "Mean Log Likelihood -- train: -2.4230895042419434, -- test: -62.14289474487305 \n",
      "Root Mean Squared Error -- train: 0.2759252190589905, -- test: 1.1271783113479614 \n",
      " \n",
      "#################### Sampling at Epoch 71949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71949\n",
      "Mean Log Likelihood -- train: -2.419757127761841, -- test: -63.39960479736328 \n",
      "Root Mean Squared Error -- train: 0.27580440044403076, -- test: 1.1382728815078735 \n",
      " \n",
      "#################### Sampling at Epoch 71999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 71999\n",
      "Mean Log Likelihood -- train: -2.3867406845092773, -- test: -62.238319396972656 \n",
      "Root Mean Squared Error -- train: 0.2746047079563141, -- test: 1.1280244588851929 \n",
      " \n",
      "#################### Sampling at Epoch 72049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72049\n",
      "Mean Log Likelihood -- train: -2.423798084259033, -- test: -62.755088806152344 \n",
      "Root Mean Squared Error -- train: 0.2759508788585663, -- test: 1.1325963735580444 \n",
      " \n",
      "#################### Sampling at Epoch 72099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72099\n",
      "Mean Log Likelihood -- train: -2.475311279296875, -- test: -64.07244873046875 \n",
      "Root Mean Squared Error -- train: 0.27781134843826294, -- test: 1.144168734550476 \n",
      " \n",
      "#################### Sampling at Epoch 72149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72149\n",
      "Mean Log Likelihood -- train: -2.415252685546875, -- test: -63.02964782714844 \n",
      "Root Mean Squared Error -- train: 0.2756410539150238, -- test: 1.135017991065979 \n",
      " \n",
      "#################### Sampling at Epoch 72199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72199\n",
      "Mean Log Likelihood -- train: -2.432896852493286, -- test: -62.47431945800781 \n",
      "Root Mean Squared Error -- train: 0.27628040313720703, -- test: 1.1301147937774658 \n",
      " \n",
      "#################### Sampling at Epoch 72249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72249\n",
      "Mean Log Likelihood -- train: -2.4786298274993896, -- test: -61.30744552612305 \n",
      "Root Mean Squared Error -- train: 0.2779307961463928, -- test: 1.1197417974472046 \n",
      " \n",
      "#################### Sampling at Epoch 72299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72299\n",
      "Mean Log Likelihood -- train: -2.416431188583374, -- test: -60.16984558105469 \n",
      "Root Mean Squared Error -- train: 0.27568379044532776, -- test: 1.1095359325408936 \n",
      " \n",
      "#################### Sampling at Epoch 72349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72349\n",
      "Mean Log Likelihood -- train: -2.5467782020568848, -- test: -61.588645935058594 \n",
      "Root Mean Squared Error -- train: 0.2803720533847809, -- test: 1.1222503185272217 \n",
      " \n",
      "#################### Sampling at Epoch 72399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72399\n",
      "Mean Log Likelihood -- train: -2.459923028945923, -- test: -62.484466552734375 \n",
      "Root Mean Squared Error -- train: 0.27725690603256226, -- test: 1.1302045583724976 \n",
      " \n",
      "#################### Sampling at Epoch 72449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72449\n",
      "Mean Log Likelihood -- train: -2.4460325241088867, -- test: -61.124229431152344 \n",
      "Root Mean Squared Error -- train: 0.2767554223537445, -- test: 1.118104338645935 \n",
      " \n",
      "#################### Sampling at Epoch 72499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72499\n",
      "Mean Log Likelihood -- train: -2.436932325363159, -- test: -59.0931510925293 \n",
      "Root Mean Squared Error -- train: 0.27642643451690674, -- test: 1.099789023399353 \n",
      " \n",
      "#################### Sampling at Epoch 72549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72549\n",
      "Mean Log Likelihood -- train: -2.504793405532837, -- test: -60.49177551269531 \n",
      "Root Mean Squared Error -- train: 0.2788705825805664, -- test: 1.1124335527420044 \n",
      " \n",
      "#################### Sampling at Epoch 72599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72599\n",
      "Mean Log Likelihood -- train: -2.5585827827453613, -- test: -62.153690338134766 \n",
      "Root Mean Squared Error -- train: 0.28079280257225037, -- test: 1.1272739171981812 \n",
      " \n",
      "#################### Sampling at Epoch 72649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72649\n",
      "Mean Log Likelihood -- train: -2.4413294792175293, -- test: -60.88851547241211 \n",
      "Root Mean Squared Error -- train: 0.2765854597091675, -- test: 1.1159943342208862 \n",
      " \n",
      "#################### Sampling at Epoch 72699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72699\n",
      "Mean Log Likelihood -- train: -2.419886589050293, -- test: -62.595001220703125 \n",
      "Root Mean Squared Error -- train: 0.275809109210968, -- test: 1.131182074546814 \n",
      " \n",
      "#################### Sampling at Epoch 72749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72749\n",
      "Mean Log Likelihood -- train: -2.413177013397217, -- test: -63.04386901855469 \n",
      "Root Mean Squared Error -- train: 0.2755657136440277, -- test: 1.1351432800292969 \n",
      " \n",
      "#################### Sampling at Epoch 72799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72799\n",
      "Mean Log Likelihood -- train: -2.407269239425659, -- test: -61.255191802978516 \n",
      "Root Mean Squared Error -- train: 0.27535125613212585, -- test: 1.1192750930786133 \n",
      " \n",
      "#################### Sampling at Epoch 72849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72849\n",
      "Mean Log Likelihood -- train: -2.4353835582733154, -- test: -60.494972229003906 \n",
      "Root Mean Squared Error -- train: 0.27637040615081787, -- test: 1.1124622821807861 \n",
      " \n",
      "#################### Sampling at Epoch 72899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72899\n",
      "Mean Log Likelihood -- train: -2.4454233646392822, -- test: -59.45497131347656 \n",
      "Root Mean Squared Error -- train: 0.2767334282398224, -- test: 1.103074073791504 \n",
      " \n",
      "#################### Sampling at Epoch 72949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72949\n",
      "Mean Log Likelihood -- train: -2.522864818572998, -- test: -60.170005798339844 \n",
      "Root Mean Squared Error -- train: 0.27951785922050476, -- test: 1.1095372438430786 \n",
      " \n",
      "#################### Sampling at Epoch 72999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 72999\n",
      "Mean Log Likelihood -- train: -2.4024910926818848, -- test: -59.94402313232422 \n",
      "Root Mean Squared Error -- train: 0.27517765760421753, -- test: 1.1074986457824707 \n",
      " \n",
      "#################### Sampling at Epoch 73049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73049\n",
      "Mean Log Likelihood -- train: -2.361931324005127, -- test: -59.273136138916016 \n",
      "Root Mean Squared Error -- train: 0.2736997604370117, -- test: 1.1014243364334106 \n",
      " \n",
      "#################### Sampling at Epoch 73099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73099\n",
      "Mean Log Likelihood -- train: -2.3727686405181885, -- test: -60.021366119384766 \n",
      "Root Mean Squared Error -- train: 0.27409541606903076, -- test: 1.1081968545913696 \n",
      " \n",
      "#################### Sampling at Epoch 73149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73149\n",
      "Mean Log Likelihood -- train: -2.4101126194000244, -- test: -63.461036682128906 \n",
      "Root Mean Squared Error -- train: 0.27545449137687683, -- test: 1.1388123035430908 \n",
      " \n",
      "#################### Sampling at Epoch 73199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73199\n",
      "Mean Log Likelihood -- train: -2.4136781692504883, -- test: -60.99754333496094 \n",
      "Root Mean Squared Error -- train: 0.2755839228630066, -- test: 1.1169707775115967 \n",
      " \n",
      "#################### Sampling at Epoch 73249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73249\n",
      "Mean Log Likelihood -- train: -2.385479211807251, -- test: -62.023719787597656 \n",
      "Root Mean Squared Error -- train: 0.27455875277519226, -- test: 1.1261204481124878 \n",
      " \n",
      "#################### Sampling at Epoch 73299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73299\n",
      "Mean Log Likelihood -- train: -2.4705114364624023, -- test: -60.56929016113281 \n",
      "Root Mean Squared Error -- train: 0.2776385247707367, -- test: 1.1131300926208496 \n",
      " \n",
      "#################### Sampling at Epoch 73349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73349\n",
      "Mean Log Likelihood -- train: -2.4883742332458496, -- test: -62.42276382446289 \n",
      "Root Mean Squared Error -- train: 0.27828118205070496, -- test: 1.1296584606170654 \n",
      " \n",
      "#################### Sampling at Epoch 73399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73399\n",
      "Mean Log Likelihood -- train: -2.463348627090454, -- test: -60.797454833984375 \n",
      "Root Mean Squared Error -- train: 0.27738043665885925, -- test: 1.1151779890060425 \n",
      " \n",
      "#################### Sampling at Epoch 73449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73449\n",
      "Mean Log Likelihood -- train: -2.4695537090301514, -- test: -55.80193328857422 \n",
      "Root Mean Squared Error -- train: 0.27760404348373413, -- test: 1.0694445371627808 \n",
      " \n",
      "#################### Sampling at Epoch 73499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73499\n",
      "Mean Log Likelihood -- train: -2.540097236633301, -- test: -54.62705993652344 \n",
      "Root Mean Squared Error -- train: 0.2801336646080017, -- test: 1.0584017038345337 \n",
      " \n",
      "#################### Sampling at Epoch 73549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73549\n",
      "Mean Log Likelihood -- train: -2.5103392601013184, -- test: -55.84488296508789 \n",
      "Root Mean Squared Error -- train: 0.2790693938732147, -- test: 1.0698460340499878 \n",
      " \n",
      "#################### Sampling at Epoch 73599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73599\n",
      "Mean Log Likelihood -- train: -2.40205979347229, -- test: -58.491004943847656 \n",
      "Root Mean Squared Error -- train: 0.2751619815826416, -- test: 1.0943002700805664 \n",
      " \n",
      "#################### Sampling at Epoch 73649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73649\n",
      "Mean Log Likelihood -- train: -2.405818462371826, -- test: -54.3320198059082 \n",
      "Root Mean Squared Error -- train: 0.2752985656261444, -- test: 1.0556104183197021 \n",
      " \n",
      "#################### Sampling at Epoch 73699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73699\n",
      "Mean Log Likelihood -- train: -2.4567251205444336, -- test: -57.604576110839844 \n",
      "Root Mean Squared Error -- train: 0.2771415412425995, -- test: 1.0861696004867554 \n",
      " \n",
      "#################### Sampling at Epoch 73749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73749\n",
      "Mean Log Likelihood -- train: -2.466386318206787, -- test: -60.19569396972656 \n",
      "Root Mean Squared Error -- train: 0.27748993039131165, -- test: 1.1097687482833862 \n",
      " \n",
      "#################### Sampling at Epoch 73799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73799\n",
      "Mean Log Likelihood -- train: -2.445855140686035, -- test: -58.67027282714844 \n",
      "Root Mean Squared Error -- train: 0.27674904465675354, -- test: 1.0959371328353882 \n",
      " \n",
      "#################### Sampling at Epoch 73849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73849\n",
      "Mean Log Likelihood -- train: -2.4463326930999756, -- test: -57.38188171386719 \n",
      "Root Mean Squared Error -- train: 0.276766300201416, -- test: 1.0841172933578491 \n",
      " \n",
      "#################### Sampling at Epoch 73899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73899\n",
      "Mean Log Likelihood -- train: -2.393563747406006, -- test: -59.32177734375 \n",
      "Root Mean Squared Error -- train: 0.27485308051109314, -- test: 1.1018658876419067 \n",
      " \n",
      "#################### Sampling at Epoch 73949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73949\n",
      "Mean Log Likelihood -- train: -2.4309794902801514, -- test: -58.5744514465332 \n",
      "Root Mean Squared Error -- train: 0.2762109935283661, -- test: 1.095062494277954 \n",
      " \n",
      "#################### Sampling at Epoch 73999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 73999\n",
      "Mean Log Likelihood -- train: -2.50838303565979, -- test: -58.12520980834961 \n",
      "Root Mean Squared Error -- train: 0.2789992690086365, -- test: 1.0909523963928223 \n",
      " \n",
      "#################### Sampling at Epoch 74049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74049\n",
      "Mean Log Likelihood -- train: -2.531477212905884, -- test: -56.831172943115234 \n",
      "Root Mean Squared Error -- train: 0.27982577681541443, -- test: 1.0790256261825562 \n",
      " \n",
      "#################### Sampling at Epoch 74099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74099\n",
      "Mean Log Likelihood -- train: -2.4850728511810303, -- test: -58.48262023925781 \n",
      "Root Mean Squared Error -- train: 0.27816250920295715, -- test: 1.0942236185073853 \n",
      " \n",
      "#################### Sampling at Epoch 74149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74149\n",
      "Mean Log Likelihood -- train: -2.39858341217041, -- test: -62.236881256103516 \n",
      "Root Mean Squared Error -- train: 0.27503564953804016, -- test: 1.1280118227005005 \n",
      " \n",
      "#################### Sampling at Epoch 74199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74199\n",
      "Mean Log Likelihood -- train: -2.4519379138946533, -- test: -60.250457763671875 \n",
      "Root Mean Squared Error -- train: 0.27696874737739563, -- test: 1.110262155532837 \n",
      " \n",
      "#################### Sampling at Epoch 74249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74249\n",
      "Mean Log Likelihood -- train: -2.4289748668670654, -- test: -63.29251480102539 \n",
      "Root Mean Squared Error -- train: 0.27613842487335205, -- test: 1.1373316049575806 \n",
      " \n",
      "#################### Sampling at Epoch 74299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74299\n",
      "Mean Log Likelihood -- train: -2.4483871459960938, -- test: -63.164588928222656 \n",
      "Root Mean Squared Error -- train: 0.2768405079841614, -- test: 1.1362063884735107 \n",
      " \n",
      "#################### Sampling at Epoch 74349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74349\n",
      "Mean Log Likelihood -- train: -2.4069786071777344, -- test: -59.1269645690918 \n",
      "Root Mean Squared Error -- train: 0.2753406763076782, -- test: 1.100096344947815 \n",
      " \n",
      "#################### Sampling at Epoch 74399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74399\n",
      "Mean Log Likelihood -- train: -2.534581422805786, -- test: -60.80266189575195 \n",
      "Root Mean Squared Error -- train: 0.27993670105934143, -- test: 1.1152247190475464 \n",
      " \n",
      "#################### Sampling at Epoch 74449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74449\n",
      "Mean Log Likelihood -- train: -2.4435932636260986, -- test: -62.86685562133789 \n",
      "Root Mean Squared Error -- train: 0.2766672968864441, -- test: 1.1335828304290771 \n",
      " \n",
      "#################### Sampling at Epoch 74499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74499\n",
      "Mean Log Likelihood -- train: -2.3802993297576904, -- test: -62.138572692871094 \n",
      "Root Mean Squared Error -- train: 0.274370014667511, -- test: 1.1271398067474365 \n",
      " \n",
      "#################### Sampling at Epoch 74549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74549\n",
      "Mean Log Likelihood -- train: -2.4163568019866943, -- test: -64.2256088256836 \n",
      "Root Mean Squared Error -- train: 0.27568110823631287, -- test: 1.145506501197815 \n",
      " \n",
      "#################### Sampling at Epoch 74599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74599\n",
      "Mean Log Likelihood -- train: -2.46575665473938, -- test: -63.47377014160156 \n",
      "Root Mean Squared Error -- train: 0.2774672508239746, -- test: 1.1389241218566895 \n",
      " \n",
      "#################### Sampling at Epoch 74649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74649\n",
      "Mean Log Likelihood -- train: -2.4403343200683594, -- test: -65.10242462158203 \n",
      "Root Mean Squared Error -- train: 0.27654948830604553, -- test: 1.1531355381011963 \n",
      " \n",
      "#################### Sampling at Epoch 74699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74699\n",
      "Mean Log Likelihood -- train: -2.3803303241729736, -- test: -66.16593170166016 \n",
      "Root Mean Squared Error -- train: 0.2743711769580841, -- test: 1.1623215675354004 \n",
      " \n",
      "#################### Sampling at Epoch 74749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74749\n",
      "Mean Log Likelihood -- train: -2.3990063667297363, -- test: -66.20512390136719 \n",
      "Root Mean Squared Error -- train: 0.2750509977340698, -- test: 1.1626588106155396 \n",
      " \n",
      "#################### Sampling at Epoch 74799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74799\n",
      "Mean Log Likelihood -- train: -2.419522762298584, -- test: -67.44763946533203 \n",
      "Root Mean Squared Error -- train: 0.27579590678215027, -- test: 1.1732969284057617 \n",
      " \n",
      "#################### Sampling at Epoch 74849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74849\n",
      "Mean Log Likelihood -- train: -2.4368174076080322, -- test: -68.78683471679688 \n",
      "Root Mean Squared Error -- train: 0.27642226219177246, -- test: 1.1846559047698975 \n",
      " \n",
      "#################### Sampling at Epoch 74899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74899\n",
      "Mean Log Likelihood -- train: -2.4419519901275635, -- test: -67.54476928710938 \n",
      "Root Mean Squared Error -- train: 0.2766079604625702, -- test: 1.1741244792938232 \n",
      " \n",
      "#################### Sampling at Epoch 74949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74949\n",
      "Mean Log Likelihood -- train: -2.391263723373413, -- test: -67.9365463256836 \n",
      "Root Mean Squared Error -- train: 0.2747693657875061, -- test: 1.1774564981460571 \n",
      " \n",
      "#################### Sampling at Epoch 74999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 74999\n",
      "Mean Log Likelihood -- train: -2.47320294380188, -- test: -67.86717987060547 \n",
      "Root Mean Squared Error -- train: 0.27773547172546387, -- test: 1.1768672466278076 \n",
      " \n",
      "#################### Sampling at Epoch 75049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75049\n",
      "Mean Log Likelihood -- train: -2.426823377609253, -- test: -68.88040924072266 \n",
      "Root Mean Squared Error -- train: 0.2760604918003082, -- test: 1.1854455471038818 \n",
      " \n",
      "#################### Sampling at Epoch 75099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75099\n",
      "Mean Log Likelihood -- train: -2.4495913982391357, -- test: -68.30274200439453 \n",
      "Root Mean Squared Error -- train: 0.2768840193748474, -- test: 1.1805624961853027 \n",
      " \n",
      "#################### Sampling at Epoch 75149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75149\n",
      "Mean Log Likelihood -- train: -2.4130218029022217, -- test: -66.61408233642578 \n",
      "Root Mean Squared Error -- train: 0.27556008100509644, -- test: 1.1661709547042847 \n",
      " \n",
      "#################### Sampling at Epoch 75199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75199\n",
      "Mean Log Likelihood -- train: -2.4735262393951416, -- test: -64.6645736694336 \n",
      "Root Mean Squared Error -- train: 0.27774709463119507, -- test: 1.149332046508789 \n",
      " \n",
      "#################### Sampling at Epoch 75249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75249\n",
      "Mean Log Likelihood -- train: -2.4945669174194336, -- test: -65.23626708984375 \n",
      "Root Mean Squared Error -- train: 0.2785036265850067, -- test: 1.1542954444885254 \n",
      " \n",
      "#################### Sampling at Epoch 75299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75299\n",
      "Mean Log Likelihood -- train: -2.3843791484832764, -- test: -63.261329650878906 \n",
      "Root Mean Squared Error -- train: 0.2745186984539032, -- test: 1.1370574235916138 \n",
      " \n",
      "#################### Sampling at Epoch 75349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75349\n",
      "Mean Log Likelihood -- train: -2.424456834793091, -- test: -62.105777740478516 \n",
      "Root Mean Squared Error -- train: 0.27597475051879883, -- test: 1.1268489360809326 \n",
      " \n",
      "#################### Sampling at Epoch 75399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75399\n",
      "Mean Log Likelihood -- train: -2.5522985458374023, -- test: -63.286251068115234 \n",
      "Root Mean Squared Error -- train: 0.2805688977241516, -- test: 1.137276530265808 \n",
      " \n",
      "#################### Sampling at Epoch 75449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75449\n",
      "Mean Log Likelihood -- train: -2.472306728363037, -- test: -64.29784393310547 \n",
      "Root Mean Squared Error -- train: 0.277703195810318, -- test: 1.1461368799209595 \n",
      " \n",
      "#################### Sampling at Epoch 75499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75499\n",
      "Mean Log Likelihood -- train: -2.527564525604248, -- test: -65.26935577392578 \n",
      "Root Mean Squared Error -- train: 0.27968594431877136, -- test: 1.154582142829895 \n",
      " \n",
      "#################### Sampling at Epoch 75549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75549\n",
      "Mean Log Likelihood -- train: -2.557396411895752, -- test: -65.62396240234375 \n",
      "Root Mean Squared Error -- train: 0.2807505130767822, -- test: 1.1576493978500366 \n",
      " \n",
      "#################### Sampling at Epoch 75599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75599\n",
      "Mean Log Likelihood -- train: -2.504862070083618, -- test: -66.2406234741211 \n",
      "Root Mean Squared Error -- train: 0.2788730263710022, -- test: 1.1629639863967896 \n",
      " \n",
      "#################### Sampling at Epoch 75649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75649\n",
      "Mean Log Likelihood -- train: -2.4945547580718994, -- test: -60.53126907348633 \n",
      "Root Mean Squared Error -- train: 0.2785031795501709, -- test: 1.1127885580062866 \n",
      " \n",
      "#################### Sampling at Epoch 75699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75699\n",
      "Mean Log Likelihood -- train: -2.5457942485809326, -- test: -65.43611145019531 \n",
      "Root Mean Squared Error -- train: 0.28033697605133057, -- test: 1.1560255289077759 \n",
      " \n",
      "#################### Sampling at Epoch 75749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75749\n",
      "Mean Log Likelihood -- train: -2.4780631065368652, -- test: -64.62458038330078 \n",
      "Root Mean Squared Error -- train: 0.27791038155555725, -- test: 1.1489841938018799 \n",
      " \n",
      "#################### Sampling at Epoch 75799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75799\n",
      "Mean Log Likelihood -- train: -2.416179895401001, -- test: -61.684410095214844 \n",
      "Root Mean Squared Error -- train: 0.2756746709346771, -- test: 1.123103380203247 \n",
      " \n",
      "#################### Sampling at Epoch 75849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75849\n",
      "Mean Log Likelihood -- train: -2.4460928440093994, -- test: -63.194122314453125 \n",
      "Root Mean Squared Error -- train: 0.2767576277256012, -- test: 1.1364660263061523 \n",
      " \n",
      "#################### Sampling at Epoch 75899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75899\n",
      "Mean Log Likelihood -- train: -2.4180595874786377, -- test: -64.09679412841797 \n",
      "Root Mean Squared Error -- train: 0.2757428288459778, -- test: 1.1443814039230347 \n",
      " \n",
      "#################### Sampling at Epoch 75949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75949\n",
      "Mean Log Likelihood -- train: -2.464203357696533, -- test: -67.27709197998047 \n",
      "Root Mean Squared Error -- train: 0.27741122245788574, -- test: 1.1718424558639526 \n",
      " \n",
      "#################### Sampling at Epoch 75999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 75999\n",
      "Mean Log Likelihood -- train: -2.4117584228515625, -- test: -65.47962188720703 \n",
      "Root Mean Squared Error -- train: 0.27551424503326416, -- test: 1.1564018726348877 \n",
      " \n",
      "#################### Sampling at Epoch 76049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76049\n",
      "Mean Log Likelihood -- train: -2.419854164123535, -- test: -66.43206024169922 \n",
      "Root Mean Squared Error -- train: 0.2758079469203949, -- test: 1.1646089553833008 \n",
      " \n",
      "#################### Sampling at Epoch 76099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76099\n",
      "Mean Log Likelihood -- train: -2.4297146797180176, -- test: -63.872108459472656 \n",
      "Root Mean Squared Error -- train: 0.2761652171611786, -- test: 1.1424163579940796 \n",
      " \n",
      "#################### Sampling at Epoch 76149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76149\n",
      "Mean Log Likelihood -- train: -2.471571445465088, -- test: -67.53500366210938 \n",
      "Root Mean Squared Error -- train: 0.27767670154571533, -- test: 1.1740412712097168 \n",
      " \n",
      "#################### Sampling at Epoch 76199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76199\n",
      "Mean Log Likelihood -- train: -2.475188970565796, -- test: -66.60193634033203 \n",
      "Root Mean Squared Error -- train: 0.27780696749687195, -- test: 1.1660666465759277 \n",
      " \n",
      "#################### Sampling at Epoch 76249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76249\n",
      "Mean Log Likelihood -- train: -2.486686944961548, -- test: -63.5835075378418 \n",
      "Root Mean Squared Error -- train: 0.278220534324646, -- test: 1.1398873329162598 \n",
      " \n",
      "#################### Sampling at Epoch 76299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76299\n",
      "Mean Log Likelihood -- train: -2.5127604007720947, -- test: -70.266845703125 \n",
      "Root Mean Squared Error -- train: 0.2791561484336853, -- test: 1.1970839500427246 \n",
      " \n",
      "#################### Sampling at Epoch 76349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76349\n",
      "Mean Log Likelihood -- train: -2.4393553733825684, -- test: -66.973876953125 \n",
      "Root Mean Squared Error -- train: 0.27651408314704895, -- test: 1.1692521572113037 \n",
      " \n",
      "#################### Sampling at Epoch 76399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76399\n",
      "Mean Log Likelihood -- train: -2.514167308807373, -- test: -66.6440200805664 \n",
      "Root Mean Squared Error -- train: 0.2792065143585205, -- test: 1.166427731513977 \n",
      " \n",
      "#################### Sampling at Epoch 76449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76449\n",
      "Mean Log Likelihood -- train: -2.504904270172119, -- test: -66.52115631103516 \n",
      "Root Mean Squared Error -- train: 0.27887454628944397, -- test: 1.1653738021850586 \n",
      " \n",
      "#################### Sampling at Epoch 76499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76499\n",
      "Mean Log Likelihood -- train: -2.4642679691314697, -- test: -67.09463500976562 \n",
      "Root Mean Squared Error -- train: 0.27741357684135437, -- test: 1.170284390449524 \n",
      " \n",
      "#################### Sampling at Epoch 76549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76549\n",
      "Mean Log Likelihood -- train: -2.460240125656128, -- test: -68.43460083007812 \n",
      "Root Mean Squared Error -- train: 0.27726835012435913, -- test: 1.1816788911819458 \n",
      " \n",
      "#################### Sampling at Epoch 76599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76599\n",
      "Mean Log Likelihood -- train: -2.4846303462982178, -- test: -70.8199234008789 \n",
      "Root Mean Squared Error -- train: 0.2781465947628021, -- test: 1.2016950845718384 \n",
      " \n",
      "#################### Sampling at Epoch 76649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76649\n",
      "Mean Log Likelihood -- train: -2.4023935794830322, -- test: -69.51615142822266 \n",
      "Root Mean Squared Error -- train: 0.2751741111278534, -- test: 1.1907962560653687 \n",
      " \n",
      "#################### Sampling at Epoch 76699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76699\n",
      "Mean Log Likelihood -- train: -2.450503349304199, -- test: -71.7362289428711 \n",
      "Root Mean Squared Error -- train: 0.2769169509410858, -- test: 1.2092963457107544 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 11:49:26.549596: W tensorflow/core/kernels/data/model_dataset_op.cc:205] Optimization loop failed: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Sampling at Epoch 76749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76749\n",
      "Mean Log Likelihood -- train: -2.418269395828247, -- test: -70.49406433105469 \n",
      "Root Mean Squared Error -- train: 0.27575045824050903, -- test: 1.1989805698394775 \n",
      " \n",
      "#################### Sampling at Epoch 76799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76799\n",
      "Mean Log Likelihood -- train: -2.4264259338378906, -- test: -72.76100158691406 \n",
      "Root Mean Squared Error -- train: 0.27604609727859497, -- test: 1.2177408933639526 \n",
      " \n",
      "#################### Sampling at Epoch 76849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76849\n",
      "Mean Log Likelihood -- train: -2.4770123958587646, -- test: -69.83843994140625 \n",
      "Root Mean Squared Error -- train: 0.27787259221076965, -- test: 1.1934996843338013 \n",
      " \n",
      "#################### Sampling at Epoch 76899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76899\n",
      "Mean Log Likelihood -- train: -2.3768181800842285, -- test: -70.14955139160156 \n",
      "Root Mean Squared Error -- train: 0.2742431163787842, -- test: 1.1961036920547485 \n",
      " \n",
      "#################### Sampling at Epoch 76949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76949\n",
      "Mean Log Likelihood -- train: -2.473681688308716, -- test: -68.43920135498047 \n",
      "Root Mean Squared Error -- train: 0.27775269746780396, -- test: 1.181717872619629 \n",
      " \n",
      "#################### Sampling at Epoch 76999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 76999\n",
      "Mean Log Likelihood -- train: -2.4809420108795166, -- test: -69.55082702636719 \n",
      "Root Mean Squared Error -- train: 0.2780139744281769, -- test: 1.1910876035690308 \n",
      " \n",
      "#################### Sampling at Epoch 77049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77049\n",
      "Mean Log Likelihood -- train: -2.398977518081665, -- test: -72.0016098022461 \n",
      "Root Mean Squared Error -- train: 0.27504995465278625, -- test: 1.2114888429641724 \n",
      " \n",
      "#################### Sampling at Epoch 77099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77099\n",
      "Mean Log Likelihood -- train: -2.4300990104675293, -- test: -74.85556030273438 \n",
      "Root Mean Squared Error -- train: 0.27617913484573364, -- test: 1.2348214387893677 \n",
      " \n",
      "#################### Sampling at Epoch 77149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77149\n",
      "Mean Log Likelihood -- train: -2.4466636180877686, -- test: -72.57861328125 \n",
      "Root Mean Squared Error -- train: 0.2767782509326935, -- test: 1.2162423133850098 \n",
      " \n",
      "#################### Sampling at Epoch 77199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77199\n",
      "Mean Log Likelihood -- train: -2.4566383361816406, -- test: -70.95832061767578 \n",
      "Root Mean Squared Error -- train: 0.2771384119987488, -- test: 1.2028464078903198 \n",
      " \n",
      "#################### Sampling at Epoch 77249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77249\n",
      "Mean Log Likelihood -- train: -2.4208149909973145, -- test: -68.2227554321289 \n",
      "Root Mean Squared Error -- train: 0.2758427560329437, -- test: 1.1798847913742065 \n",
      " \n",
      "#################### Sampling at Epoch 77299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77299\n",
      "Mean Log Likelihood -- train: -2.4252874851226807, -- test: -71.20984649658203 \n",
      "Root Mean Squared Error -- train: 0.2760048508644104, -- test: 1.2049355506896973 \n",
      " \n",
      "#################### Sampling at Epoch 77349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77349\n",
      "Mean Log Likelihood -- train: -2.428802490234375, -- test: -68.23780059814453 \n",
      "Root Mean Squared Error -- train: 0.27613216638565063, -- test: 1.1800122261047363 \n",
      " \n",
      "#################### Sampling at Epoch 77399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77399\n",
      "Mean Log Likelihood -- train: -2.480018138885498, -- test: -70.69926452636719 \n",
      "Root Mean Squared Error -- train: 0.2779807448387146, -- test: 1.2006906270980835 \n",
      " \n",
      "#################### Sampling at Epoch 77449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77449\n",
      "Mean Log Likelihood -- train: -2.3747739791870117, -- test: -72.44537353515625 \n",
      "Root Mean Squared Error -- train: 0.27416858077049255, -- test: 1.2151463031768799 \n",
      " \n",
      "#################### Sampling at Epoch 77499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77499\n",
      "Mean Log Likelihood -- train: -2.401339054107666, -- test: -70.06706237792969 \n",
      "Root Mean Squared Error -- train: 0.2751357853412628, -- test: 1.1954137086868286 \n",
      " \n",
      "#################### Sampling at Epoch 77549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77549\n",
      "Mean Log Likelihood -- train: -2.4326634407043457, -- test: -70.76846313476562 \n",
      "Root Mean Squared Error -- train: 0.2762719690799713, -- test: 1.201266884803772 \n",
      " \n",
      "#################### Sampling at Epoch 77599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77599\n",
      "Mean Log Likelihood -- train: -2.4514920711517334, -- test: -71.09038543701172 \n",
      "Root Mean Squared Error -- train: 0.2769526243209839, -- test: 1.2039438486099243 \n",
      " \n",
      "#################### Sampling at Epoch 77649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77649\n",
      "Mean Log Likelihood -- train: -2.4241316318511963, -- test: -72.44259643554688 \n",
      "Root Mean Squared Error -- train: 0.2759629487991333, -- test: 1.2151232957839966 \n",
      " \n",
      "#################### Sampling at Epoch 77699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77699\n",
      "Mean Log Likelihood -- train: -2.4590041637420654, -- test: -69.19363403320312 \n",
      "Root Mean Squared Error -- train: 0.27722376585006714, -- test: 1.1880847215652466 \n",
      " \n",
      "#################### Sampling at Epoch 77749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77749\n",
      "Mean Log Likelihood -- train: -2.4710962772369385, -- test: -66.29475402832031 \n",
      "Root Mean Squared Error -- train: 0.2776595950126648, -- test: 1.1634293794631958 \n",
      " \n",
      "#################### Sampling at Epoch 77799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77799\n",
      "Mean Log Likelihood -- train: -2.420628309249878, -- test: -67.55219268798828 \n",
      "Root Mean Squared Error -- train: 0.2758359909057617, -- test: 1.1741876602172852 \n",
      " \n",
      "#################### Sampling at Epoch 77849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77849\n",
      "Mean Log Likelihood -- train: -2.506944417953491, -- test: -67.45134735107422 \n",
      "Root Mean Squared Error -- train: 0.27894771099090576, -- test: 1.1733285188674927 \n",
      " \n",
      "#################### Sampling at Epoch 77899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77899\n",
      "Mean Log Likelihood -- train: -2.424710988998413, -- test: -66.36146545410156 \n",
      "Root Mean Squared Error -- train: 0.2759839594364166, -- test: 1.1640026569366455 \n",
      " \n",
      "#################### Sampling at Epoch 77949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77949\n",
      "Mean Log Likelihood -- train: -2.452223777770996, -- test: -66.20887756347656 \n",
      "Root Mean Squared Error -- train: 0.2769790589809418, -- test: 1.1626911163330078 \n",
      " \n",
      "#################### Sampling at Epoch 77999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 77999\n",
      "Mean Log Likelihood -- train: -2.410752058029175, -- test: -67.46480560302734 \n",
      "Root Mean Squared Error -- train: 0.27547770738601685, -- test: 1.1734431982040405 \n",
      " \n",
      "#################### Sampling at Epoch 78049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78049\n",
      "Mean Log Likelihood -- train: -2.439448595046997, -- test: -68.12907409667969 \n",
      "Root Mean Squared Error -- train: 0.27651745080947876, -- test: 1.1790904998779297 \n",
      " \n",
      "#################### Sampling at Epoch 78099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78099\n",
      "Mean Log Likelihood -- train: -2.4139764308929443, -- test: -68.91402435302734 \n",
      "Root Mean Squared Error -- train: 0.2755947411060333, -- test: 1.1857290267944336 \n",
      " \n",
      "#################### Sampling at Epoch 78149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78149\n",
      "Mean Log Likelihood -- train: -2.431657075881958, -- test: -66.52108764648438 \n",
      "Root Mean Squared Error -- train: 0.27623552083969116, -- test: 1.1653730869293213 \n",
      " \n",
      "#################### Sampling at Epoch 78199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78199\n",
      "Mean Log Likelihood -- train: -2.479461193084717, -- test: -65.73471069335938 \n",
      "Root Mean Squared Error -- train: 0.2779606878757477, -- test: 1.158605694770813 \n",
      " \n",
      "#################### Sampling at Epoch 78249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78249\n",
      "Mean Log Likelihood -- train: -2.516896963119507, -- test: -67.15689086914062 \n",
      "Root Mean Squared Error -- train: 0.27930426597595215, -- test: 1.1708163022994995 \n",
      " \n",
      "#################### Sampling at Epoch 78299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78299\n",
      "Mean Log Likelihood -- train: -2.4520227909088135, -- test: -66.97834014892578 \n",
      "Root Mean Squared Error -- train: 0.27697181701660156, -- test: 1.1692901849746704 \n",
      " \n",
      "#################### Sampling at Epoch 78349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78349\n",
      "Mean Log Likelihood -- train: -2.4524896144866943, -- test: -66.99925994873047 \n",
      "Root Mean Squared Error -- train: 0.2769886553287506, -- test: 1.1694691181182861 \n",
      " \n",
      "#################### Sampling at Epoch 78399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78399\n",
      "Mean Log Likelihood -- train: -2.44739031791687, -- test: -69.87237548828125 \n",
      "Root Mean Squared Error -- train: 0.27680450677871704, -- test: 1.1937841176986694 \n",
      " \n",
      "#################### Sampling at Epoch 78449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78449\n",
      "Mean Log Likelihood -- train: -2.460601329803467, -- test: -69.85920715332031 \n",
      "Root Mean Squared Error -- train: 0.27728137373924255, -- test: 1.193673849105835 \n",
      " \n",
      "#################### Sampling at Epoch 78499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78499\n",
      "Mean Log Likelihood -- train: -2.4634602069854736, -- test: -71.60903930664062 \n",
      "Root Mean Squared Error -- train: 0.2773844599723816, -- test: 1.2082439661026 \n",
      " \n",
      "#################### Sampling at Epoch 78549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78549\n",
      "Mean Log Likelihood -- train: -2.5637471675872803, -- test: -69.6702651977539 \n",
      "Root Mean Squared Error -- train: 0.28097665309906006, -- test: 1.1920897960662842 \n",
      " \n",
      "#################### Sampling at Epoch 78599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78599\n",
      "Mean Log Likelihood -- train: -2.4165427684783936, -- test: -71.47972869873047 \n",
      "Root Mean Squared Error -- train: 0.2756878435611725, -- test: 1.2071733474731445 \n",
      " \n",
      "#################### Sampling at Epoch 78649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78649\n",
      "Mean Log Likelihood -- train: -2.425217628479004, -- test: -71.1235122680664 \n",
      "Root Mean Squared Error -- train: 0.27600231766700745, -- test: 1.204218864440918 \n",
      " \n",
      "#################### Sampling at Epoch 78699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78699\n",
      "Mean Log Likelihood -- train: -2.497915506362915, -- test: -69.98359680175781 \n",
      "Root Mean Squared Error -- train: 0.2786238491535187, -- test: 1.1947153806686401 \n",
      " \n",
      "#################### Sampling at Epoch 78749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78749\n",
      "Mean Log Likelihood -- train: -2.4936201572418213, -- test: -73.06559753417969 \n",
      "Root Mean Squared Error -- train: 0.27846962213516235, -- test: 1.2202396392822266 \n",
      " \n",
      "#################### Sampling at Epoch 78799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78799\n",
      "Mean Log Likelihood -- train: -2.415616512298584, -- test: -71.65137481689453 \n",
      "Root Mean Squared Error -- train: 0.27565425634384155, -- test: 1.2085943222045898 \n",
      " \n",
      "#################### Sampling at Epoch 78849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78849\n",
      "Mean Log Likelihood -- train: -2.418236017227173, -- test: -73.09141540527344 \n",
      "Root Mean Squared Error -- train: 0.2757492661476135, -- test: 1.2204512357711792 \n",
      " \n",
      "#################### Sampling at Epoch 78899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78899\n",
      "Mean Log Likelihood -- train: -2.473565101623535, -- test: -72.69062805175781 \n",
      "Root Mean Squared Error -- train: 0.2777484953403473, -- test: 1.2171629667282104 \n",
      " \n",
      "#################### Sampling at Epoch 78949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78949\n",
      "Mean Log Likelihood -- train: -2.5025596618652344, -- test: -72.74971008300781 \n",
      "Root Mean Squared Error -- train: 0.2787904441356659, -- test: 1.2176482677459717 \n",
      " \n",
      "#################### Sampling at Epoch 78999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 78999\n",
      "Mean Log Likelihood -- train: -2.511568784713745, -- test: -70.79751586914062 \n",
      "Root Mean Squared Error -- train: 0.27911344170570374, -- test: 1.2015087604522705 \n",
      " \n",
      "#################### Sampling at Epoch 82499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82499\n",
      "Mean Log Likelihood -- train: -2.4797980785369873, -- test: -68.94359588623047 \n",
      "Root Mean Squared Error -- train: 0.2779728174209595, -- test: 1.1859784126281738 \n",
      " \n",
      "#################### Sampling at Epoch 82549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82549\n",
      "Mean Log Likelihood -- train: -2.5906178951263428, -- test: -67.90167999267578 \n",
      "Root Mean Squared Error -- train: 0.2819313406944275, -- test: 1.1771602630615234 \n",
      " \n",
      "#################### Sampling at Epoch 82599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82599\n",
      "Mean Log Likelihood -- train: -2.6099050045013428, -- test: -66.41850280761719 \n",
      "Root Mean Squared Error -- train: 0.2826146185398102, -- test: 1.1644926071166992 \n",
      " \n",
      "#################### Sampling at Epoch 82649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82649\n",
      "Mean Log Likelihood -- train: -2.608952760696411, -- test: -68.69213104248047 \n",
      "Root Mean Squared Error -- train: 0.2825809121131897, -- test: 1.1838562488555908 \n",
      " \n",
      "#################### Sampling at Epoch 82699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82699\n",
      "Mean Log Likelihood -- train: -2.447240114212036, -- test: -67.42700958251953 \n",
      "Root Mean Squared Error -- train: 0.2767990827560425, -- test: 1.1731210947036743 \n",
      " \n",
      "#################### Sampling at Epoch 82749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82749\n",
      "Mean Log Likelihood -- train: -2.479870080947876, -- test: -68.56642150878906 \n",
      "Root Mean Squared Error -- train: 0.2779754102230072, -- test: 1.1827937364578247 \n",
      " \n",
      "#################### Sampling at Epoch 82799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82799\n",
      "Mean Log Likelihood -- train: -2.5154364109039307, -- test: -67.59481048583984 \n",
      "Root Mean Squared Error -- train: 0.27925193309783936, -- test: 1.1745506525039673 \n",
      " \n",
      "#################### Sampling at Epoch 82849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82849\n",
      "Mean Log Likelihood -- train: -2.524134874343872, -- test: -71.2088394165039 \n",
      "Root Mean Squared Error -- train: 0.2795632779598236, -- test: 1.2049272060394287 \n",
      " \n",
      "#################### Sampling at Epoch 82899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82899\n",
      "Mean Log Likelihood -- train: -2.5142998695373535, -- test: -70.09107208251953 \n",
      "Root Mean Squared Error -- train: 0.27921125292778015, -- test: 1.1956145763397217 \n",
      " \n",
      "#################### Sampling at Epoch 82949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82949\n",
      "Mean Log Likelihood -- train: -2.591500997543335, -- test: -70.7015609741211 \n",
      "Root Mean Squared Error -- train: 0.28196266293525696, -- test: 1.2007098197937012 \n",
      " \n",
      "#################### Sampling at Epoch 82999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 82999\n",
      "Mean Log Likelihood -- train: -2.5261001586914062, -- test: -69.11636352539062 \n",
      "Root Mean Squared Error -- train: 0.2796335816383362, -- test: 1.1874343156814575 \n",
      " \n",
      "#################### Sampling at Epoch 83049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83049\n",
      "Mean Log Likelihood -- train: -2.5270090103149414, -- test: -72.90103912353516 \n",
      "Root Mean Squared Error -- train: 0.2796660363674164, -- test: 1.2188903093338013 \n",
      " \n",
      "#################### Sampling at Epoch 83099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83099\n",
      "Mean Log Likelihood -- train: -2.4983253479003906, -- test: -69.54402160644531 \n",
      "Root Mean Squared Error -- train: 0.2786385416984558, -- test: 1.1910303831100464 \n",
      " \n",
      "#################### Sampling at Epoch 83149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83149\n",
      "Mean Log Likelihood -- train: -2.4476072788238525, -- test: -67.39521026611328 \n",
      "Root Mean Squared Error -- train: 0.276812344789505, -- test: 1.1728498935699463 \n",
      " \n",
      "#################### Sampling at Epoch 83199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83199\n",
      "Mean Log Likelihood -- train: -2.468541145324707, -- test: -67.49816131591797 \n",
      "Root Mean Squared Error -- train: 0.2775675654411316, -- test: 1.1737275123596191 \n",
      " \n",
      "#################### Sampling at Epoch 83249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83249\n",
      "Mean Log Likelihood -- train: -2.5342941284179688, -- test: -68.95531463623047 \n",
      "Root Mean Squared Error -- train: 0.2799264192581177, -- test: 1.1860772371292114 \n",
      " \n",
      "#################### Sampling at Epoch 83299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83299\n",
      "Mean Log Likelihood -- train: -2.5417215824127197, -- test: -68.95121765136719 \n",
      "Root Mean Squared Error -- train: 0.2801916301250458, -- test: 1.1860426664352417 \n",
      " \n",
      "#################### Sampling at Epoch 83349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83349\n",
      "Mean Log Likelihood -- train: -2.455319404602051, -- test: -67.72513580322266 \n",
      "Root Mean Squared Error -- train: 0.27709081768989563, -- test: 1.1756596565246582 \n",
      " \n",
      "#################### Sampling at Epoch 83399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83399\n",
      "Mean Log Likelihood -- train: -2.496427059173584, -- test: -66.17178344726562 \n",
      "Root Mean Squared Error -- train: 0.27857041358947754, -- test: 1.1623719930648804 \n",
      " \n",
      "#################### Sampling at Epoch 83449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83449\n",
      "Mean Log Likelihood -- train: -2.4418342113494873, -- test: -67.27742004394531 \n",
      "Root Mean Squared Error -- train: 0.27660369873046875, -- test: 1.1718453168869019 \n",
      " \n",
      "#################### Sampling at Epoch 83499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83499\n",
      "Mean Log Likelihood -- train: -2.4261293411254883, -- test: -69.12515258789062 \n",
      "Root Mean Squared Error -- train: 0.276035338640213, -- test: 1.187508225440979 \n",
      " \n",
      "#################### Sampling at Epoch 83549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83549\n",
      "Mean Log Likelihood -- train: -2.4519150257110596, -- test: -68.87523651123047 \n",
      "Root Mean Squared Error -- train: 0.2769679129123688, -- test: 1.1854019165039062 \n",
      " \n",
      "#################### Sampling at Epoch 83599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83599\n",
      "Mean Log Likelihood -- train: -2.4660184383392334, -- test: -64.44558715820312 \n",
      "Root Mean Squared Error -- train: 0.2774766683578491, -- test: 1.1474252939224243 \n",
      " \n",
      "#################### Sampling at Epoch 83649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83649\n",
      "Mean Log Likelihood -- train: -2.482510566711426, -- test: -66.59375762939453 \n",
      "Root Mean Squared Error -- train: 0.2780703604221344, -- test: 1.1659965515136719 \n",
      " \n",
      "#################### Sampling at Epoch 83699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83699\n",
      "Mean Log Likelihood -- train: -2.5188238620758057, -- test: -62.88652420043945 \n",
      "Root Mean Squared Error -- train: 0.2793732285499573, -- test: 1.1337562799453735 \n",
      " \n",
      "#################### Sampling at Epoch 83749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83749\n",
      "Mean Log Likelihood -- train: -2.4457476139068604, -- test: -63.000221252441406 \n",
      "Root Mean Squared Error -- train: 0.27674514055252075, -- test: 1.1347585916519165 \n",
      " \n",
      "#################### Sampling at Epoch 83799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83799\n",
      "Mean Log Likelihood -- train: -2.475787878036499, -- test: -60.917755126953125 \n",
      "Root Mean Squared Error -- train: 0.27782851457595825, -- test: 1.1162562370300293 \n",
      " \n",
      "#################### Sampling at Epoch 83849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83849\n",
      "Mean Log Likelihood -- train: -2.4218246936798096, -- test: -63.12808609008789 \n",
      "Root Mean Squared Error -- train: 0.2758793532848358, -- test: 1.1358850002288818 \n",
      " \n",
      "#################### Sampling at Epoch 83899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83899\n",
      "Mean Log Likelihood -- train: -2.4369709491729736, -- test: -63.461978912353516 \n",
      "Root Mean Squared Error -- train: 0.27642783522605896, -- test: 1.1388206481933594 \n",
      " \n",
      "#################### Sampling at Epoch 83949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83949\n",
      "Mean Log Likelihood -- train: -2.451953649520874, -- test: -59.06009292602539 \n",
      "Root Mean Squared Error -- train: 0.276969313621521, -- test: 1.0994884967803955 \n",
      " \n",
      "#################### Sampling at Epoch 83999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 83999\n",
      "Mean Log Likelihood -- train: -2.4532551765441895, -- test: -59.026763916015625 \n",
      "Root Mean Squared Error -- train: 0.2770163118839264, -- test: 1.0991852283477783 \n",
      " \n",
      "#################### Sampling at Epoch 84049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84049\n",
      "Mean Log Likelihood -- train: -2.4168970584869385, -- test: -60.93132781982422 \n",
      "Root Mean Squared Error -- train: 0.2757006883621216, -- test: 1.116377830505371 \n",
      " \n",
      "#################### Sampling at Epoch 84099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84099\n",
      "Mean Log Likelihood -- train: -2.4664723873138428, -- test: -60.91728973388672 \n",
      "Root Mean Squared Error -- train: 0.27749302983283997, -- test: 1.116252064704895 \n",
      " \n",
      "#################### Sampling at Epoch 84149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84149\n",
      "Mean Log Likelihood -- train: -2.5075347423553467, -- test: -68.77577209472656 \n",
      "Root Mean Squared Error -- train: 0.278968870639801, -- test: 1.1845625638961792 \n",
      " \n",
      "#################### Sampling at Epoch 84199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84199\n",
      "Mean Log Likelihood -- train: -2.4884986877441406, -- test: -65.63790893554688 \n",
      "Root Mean Squared Error -- train: 0.2782856225967407, -- test: 1.1577699184417725 \n",
      " \n",
      "#################### Sampling at Epoch 84249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84249\n",
      "Mean Log Likelihood -- train: -2.4415197372436523, -- test: -66.78959655761719 \n",
      "Root Mean Squared Error -- train: 0.27659231424331665, -- test: 1.1676748991012573 \n",
      " \n",
      "#################### Sampling at Epoch 84299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84299\n",
      "Mean Log Likelihood -- train: -2.4587016105651855, -- test: -69.14344024658203 \n",
      "Root Mean Squared Error -- train: 0.27721285820007324, -- test: 1.1876622438430786 \n",
      " \n",
      "#################### Sampling at Epoch 84349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84349\n",
      "Mean Log Likelihood -- train: -2.4867446422576904, -- test: -68.73729705810547 \n",
      "Root Mean Squared Error -- train: 0.27822259068489075, -- test: 1.1842377185821533 \n",
      " \n",
      "#################### Sampling at Epoch 84399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84399\n",
      "Mean Log Likelihood -- train: -2.476043701171875, -- test: -63.8646354675293 \n",
      "Root Mean Squared Error -- train: 0.27783775329589844, -- test: 1.1423509120941162 \n",
      " \n",
      "#################### Sampling at Epoch 84449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84449\n",
      "Mean Log Likelihood -- train: -2.4820964336395264, -- test: -65.91161346435547 \n",
      "Root Mean Squared Error -- train: 0.27805548906326294, -- test: 1.1601314544677734 \n",
      " \n",
      "#################### Sampling at Epoch 84499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84499\n",
      "Mean Log Likelihood -- train: -2.500828742980957, -- test: -64.19048309326172 \n",
      "Root Mean Squared Error -- train: 0.2787283957004547, -- test: 1.1451998949050903 \n",
      " \n",
      "#################### Sampling at Epoch 84549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84549\n",
      "Mean Log Likelihood -- train: -2.471087694168091, -- test: -64.84719848632812 \n",
      "Root Mean Squared Error -- train: 0.2776592969894409, -- test: 1.150920033454895 \n",
      " \n",
      "#################### Sampling at Epoch 84599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84599\n",
      "Mean Log Likelihood -- train: -2.483182668685913, -- test: -65.29208374023438 \n",
      "Root Mean Squared Error -- train: 0.2780945599079132, -- test: 1.1547789573669434 \n",
      " \n",
      "#################### Sampling at Epoch 84649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84649\n",
      "Mean Log Likelihood -- train: -2.420403003692627, -- test: -63.717864990234375 \n",
      "Root Mean Squared Error -- train: 0.2758278548717499, -- test: 1.1410653591156006 \n",
      " \n",
      "#################### Sampling at Epoch 84699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84699\n",
      "Mean Log Likelihood -- train: -2.417280912399292, -- test: -64.89228057861328 \n",
      "Root Mean Squared Error -- train: 0.27571460604667664, -- test: 1.1513116359710693 \n",
      " \n",
      "#################### Sampling at Epoch 84749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84749\n",
      "Mean Log Likelihood -- train: -2.39479923248291, -- test: -62.34186935424805 \n",
      "Root Mean Squared Error -- train: 0.2748979926109314, -- test: 1.1289421319961548 \n",
      " \n",
      "#################### Sampling at Epoch 84799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84799\n",
      "Mean Log Likelihood -- train: -2.44937801361084, -- test: -62.13532638549805 \n",
      "Root Mean Squared Error -- train: 0.276876300573349, -- test: 1.1271110773086548 \n",
      " \n",
      "#################### Sampling at Epoch 84849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84849\n",
      "Mean Log Likelihood -- train: -2.411807060241699, -- test: -60.449527740478516 \n",
      "Root Mean Squared Error -- train: 0.27551600337028503, -- test: 1.112053632736206 \n",
      " \n",
      "#################### Sampling at Epoch 84899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84899\n",
      "Mean Log Likelihood -- train: -2.411802053451538, -- test: -63.19381332397461 \n",
      "Root Mean Squared Error -- train: 0.2755158543586731, -- test: 1.1364634037017822 \n",
      " \n",
      "#################### Sampling at Epoch 84949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84949\n",
      "Mean Log Likelihood -- train: -2.389969825744629, -- test: -61.610904693603516 \n",
      "Root Mean Squared Error -- train: 0.27472227811813354, -- test: 1.1224486827850342 \n",
      " \n",
      "#################### Sampling at Epoch 84999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 84999\n",
      "Mean Log Likelihood -- train: -2.369781017303467, -- test: -61.067665100097656 \n",
      "Root Mean Squared Error -- train: 0.2739863991737366, -- test: 1.1175984144210815 \n",
      " \n",
      "#################### Sampling at Epoch 85049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85049\n",
      "Mean Log Likelihood -- train: -2.419423818588257, -- test: -57.67618179321289 \n",
      "Root Mean Squared Error -- train: 0.27579233050346375, -- test: 1.0868287086486816 \n",
      " \n",
      "#################### Sampling at Epoch 85099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85099\n",
      "Mean Log Likelihood -- train: -2.4384806156158447, -- test: -58.86616516113281 \n",
      "Root Mean Squared Error -- train: 0.27648240327835083, -- test: 1.097723126411438 \n",
      " \n",
      "#################### Sampling at Epoch 85149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85149\n",
      "Mean Log Likelihood -- train: -2.3976211547851562, -- test: -57.42655944824219 \n",
      "Root Mean Squared Error -- train: 0.2750006318092346, -- test: 1.0845293998718262 \n",
      " \n",
      "#################### Sampling at Epoch 85199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85199\n",
      "Mean Log Likelihood -- train: -2.4249961376190186, -- test: -56.219215393066406 \n",
      "Root Mean Squared Error -- train: 0.27599427103996277, -- test: 1.0733392238616943 \n",
      " \n",
      "#################### Sampling at Epoch 85249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85249\n",
      "Mean Log Likelihood -- train: -2.4117300510406494, -- test: -57.929298400878906 \n",
      "Root Mean Squared Error -- train: 0.2755132019519806, -- test: 1.0891550779342651 \n",
      " \n",
      "#################### Sampling at Epoch 85299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85299\n",
      "Mean Log Likelihood -- train: -2.462345600128174, -- test: -55.601932525634766 \n",
      "Root Mean Squared Error -- train: 0.2773442566394806, -- test: 1.0675727128982544 \n",
      " \n",
      "#################### Sampling at Epoch 85349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85349\n",
      "Mean Log Likelihood -- train: -2.3949358463287354, -- test: -59.139122009277344 \n",
      "Root Mean Squared Error -- train: 0.27490296959877014, -- test: 1.100206971168518 \n",
      " \n",
      "#################### Sampling at Epoch 85399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85399\n",
      "Mean Log Likelihood -- train: -2.4240384101867676, -- test: -59.90114212036133 \n",
      "Root Mean Squared Error -- train: 0.2759595811367035, -- test: 1.1071114540100098 \n",
      " \n",
      "#################### Sampling at Epoch 85449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85449\n",
      "Mean Log Likelihood -- train: -2.417185068130493, -- test: -59.864540100097656 \n",
      "Root Mean Squared Error -- train: 0.27571114897727966, -- test: 1.106780767440796 \n",
      " \n",
      "#################### Sampling at Epoch 85499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85499\n",
      "Mean Log Likelihood -- train: -2.448333501815796, -- test: -58.5634880065918 \n",
      "Root Mean Squared Error -- train: 0.27683860063552856, -- test: 1.0949623584747314 \n",
      " \n",
      "#################### Sampling at Epoch 85549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85549\n",
      "Mean Log Likelihood -- train: -2.453995943069458, -- test: -61.72114181518555 \n",
      "Root Mean Squared Error -- train: 0.27704304456710815, -- test: 1.1234303712844849 \n",
      " \n",
      "#################### Sampling at Epoch 85599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85599\n",
      "Mean Log Likelihood -- train: -2.4321863651275635, -- test: -59.736019134521484 \n",
      "Root Mean Squared Error -- train: 0.27625468373298645, -- test: 1.105618953704834 \n",
      " \n",
      "#################### Sampling at Epoch 85649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85649\n",
      "Mean Log Likelihood -- train: -2.4064888954162598, -- test: -58.99886703491211 \n",
      "Root Mean Squared Error -- train: 0.27532291412353516, -- test: 1.0989314317703247 \n",
      " \n",
      "#################### Sampling at Epoch 85699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85699\n",
      "Mean Log Likelihood -- train: -2.423297882080078, -- test: -58.38740158081055 \n",
      "Root Mean Squared Error -- train: 0.27593275904655457, -- test: 1.093353033065796 \n",
      " \n",
      "#################### Sampling at Epoch 85749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85749\n",
      "Mean Log Likelihood -- train: -2.423121213912964, -- test: -58.68742752075195 \n",
      "Root Mean Squared Error -- train: 0.2759263515472412, -- test: 1.096093773841858 \n",
      " \n",
      "#################### Sampling at Epoch 85799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85799\n",
      "Mean Log Likelihood -- train: -2.4472012519836426, -- test: -60.16971206665039 \n",
      "Root Mean Squared Error -- train: 0.27679768204689026, -- test: 1.1095346212387085 \n",
      " \n",
      "#################### Sampling at Epoch 85849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85849\n",
      "Mean Log Likelihood -- train: -2.4182257652282715, -- test: -58.724205017089844 \n",
      "Root Mean Squared Error -- train: 0.2757488787174225, -- test: 1.0964292287826538 \n",
      " \n",
      "#################### Sampling at Epoch 85899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85899\n",
      "Mean Log Likelihood -- train: -2.4589285850524902, -- test: -60.83993148803711 \n",
      "Root Mean Squared Error -- train: 0.27722102403640747, -- test: 1.1155588626861572 \n",
      " \n",
      "#################### Sampling at Epoch 85949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85949\n",
      "Mean Log Likelihood -- train: -2.4827420711517334, -- test: -57.54373550415039 \n",
      "Root Mean Squared Error -- train: 0.27807870507240295, -- test: 1.0856091976165771 \n",
      " \n",
      "#################### Sampling at Epoch 85999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 85999\n",
      "Mean Log Likelihood -- train: -2.474994659423828, -- test: -59.122718811035156 \n",
      "Root Mean Squared Error -- train: 0.27779996395111084, -- test: 1.10005784034729 \n",
      " \n",
      "#################### Sampling at Epoch 86049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86049\n",
      "Mean Log Likelihood -- train: -2.4560060501098633, -- test: -61.150962829589844 \n",
      "Root Mean Squared Error -- train: 0.2771156132221222, -- test: 1.1183433532714844 \n",
      " \n",
      "#################### Sampling at Epoch 86099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86099\n",
      "Mean Log Likelihood -- train: -2.398709297180176, -- test: -60.26754379272461 \n",
      "Root Mean Squared Error -- train: 0.2750402092933655, -- test: 1.110416054725647 \n",
      " \n",
      "#################### Sampling at Epoch 86149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86149\n",
      "Mean Log Likelihood -- train: -2.407445192337036, -- test: -57.27756881713867 \n",
      "Root Mean Squared Error -- train: 0.2753576636314392, -- test: 1.0831546783447266 \n",
      " \n",
      "#################### Sampling at Epoch 86199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86199\n",
      "Mean Log Likelihood -- train: -2.401642322540283, -- test: -59.534423828125 \n",
      "Root Mean Squared Error -- train: 0.27514681220054626, -- test: 1.1037940979003906 \n",
      " \n",
      "#################### Sampling at Epoch 86249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86249\n",
      "Mean Log Likelihood -- train: -2.4350039958953857, -- test: -57.49406433105469 \n",
      "Root Mean Squared Error -- train: 0.27635666728019714, -- test: 1.0851516723632812 \n",
      " \n",
      "#################### Sampling at Epoch 86299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86299\n",
      "Mean Log Likelihood -- train: -2.4492268562316895, -- test: -60.48064422607422 \n",
      "Root Mean Squared Error -- train: 0.27687084674835205, -- test: 1.1123335361480713 \n",
      " \n",
      "#################### Sampling at Epoch 86349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86349\n",
      "Mean Log Likelihood -- train: -2.3957808017730713, -- test: -61.651756286621094 \n",
      "Root Mean Squared Error -- train: 0.27493369579315186, -- test: 1.1228126287460327 \n",
      " \n",
      "#################### Sampling at Epoch 86399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86399\n",
      "Mean Log Likelihood -- train: -2.365278720855713, -- test: -60.39103698730469 \n",
      "Root Mean Squared Error -- train: 0.27382200956344604, -- test: 1.1115275621414185 \n",
      " \n",
      "#################### Sampling at Epoch 86449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86449\n",
      "Mean Log Likelihood -- train: -2.430152177810669, -- test: -58.848087310791016 \n",
      "Root Mean Squared Error -- train: 0.27618104219436646, -- test: 1.0975584983825684 \n",
      " \n",
      "#################### Sampling at Epoch 86499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86499\n",
      "Mean Log Likelihood -- train: -2.542306661605835, -- test: -57.18461608886719 \n",
      "Root Mean Squared Error -- train: 0.28021252155303955, -- test: 1.0822962522506714 \n",
      " \n",
      "#################### Sampling at Epoch 86549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86549\n",
      "Mean Log Likelihood -- train: -2.575761318206787, -- test: -58.96073913574219 \n",
      "Root Mean Squared Error -- train: 0.28140389919281006, -- test: 1.0985844135284424 \n",
      " \n",
      "#################### Sampling at Epoch 86599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86599\n",
      "Mean Log Likelihood -- train: -2.4569694995880127, -- test: -58.30974197387695 \n",
      "Root Mean Squared Error -- train: 0.27715033292770386, -- test: 1.0926425457000732 \n",
      " \n",
      "#################### Sampling at Epoch 86649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86649\n",
      "Mean Log Likelihood -- train: -2.502774715423584, -- test: -56.68235778808594 \n",
      "Root Mean Squared Error -- train: 0.2787981927394867, -- test: 1.0776455402374268 \n",
      " \n",
      "#################### Sampling at Epoch 86699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86699\n",
      "Mean Log Likelihood -- train: -2.4415345191955566, -- test: -58.9632682800293 \n",
      "Root Mean Squared Error -- train: 0.276592880487442, -- test: 1.0986074209213257 \n",
      " \n",
      "#################### Sampling at Epoch 86749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86749\n",
      "Mean Log Likelihood -- train: -2.4077463150024414, -- test: -58.175086975097656 \n",
      "Root Mean Squared Error -- train: 0.2753685712814331, -- test: 1.0914093255996704 \n",
      " \n",
      "#################### Sampling at Epoch 86799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86799\n",
      "Mean Log Likelihood -- train: -2.493290424346924, -- test: -63.1063346862793 \n",
      "Root Mean Squared Error -- train: 0.27845779061317444, -- test: 1.1356934309005737 \n",
      " \n",
      "#################### Sampling at Epoch 86849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86849\n",
      "Mean Log Likelihood -- train: -2.4693543910980225, -- test: -62.60775375366211 \n",
      "Root Mean Squared Error -- train: 0.2775968909263611, -- test: 1.131294846534729 \n",
      " \n",
      "#################### Sampling at Epoch 86899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86899\n",
      "Mean Log Likelihood -- train: -2.4547579288482666, -- test: -62.23591232299805 \n",
      "Root Mean Squared Error -- train: 0.277070552110672, -- test: 1.1280031204223633 \n",
      " \n",
      "#################### Sampling at Epoch 86949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86949\n",
      "Mean Log Likelihood -- train: -2.4061906337738037, -- test: -62.19156265258789 \n",
      "Root Mean Squared Error -- train: 0.2753120958805084, -- test: 1.1276099681854248 \n",
      " \n",
      "#################### Sampling at Epoch 86999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 86999\n",
      "Mean Log Likelihood -- train: -2.461261749267578, -- test: -59.18986511230469 \n",
      "Root Mean Squared Error -- train: 0.2773052155971527, -- test: 1.1006680727005005 \n",
      " \n",
      "#################### Sampling at Epoch 87049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87049\n",
      "Mean Log Likelihood -- train: -2.4555439949035645, -- test: -62.610076904296875 \n",
      "Root Mean Squared Error -- train: 0.2770989239215851, -- test: 1.1313153505325317 \n",
      " \n",
      "#################### Sampling at Epoch 87099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87099\n",
      "Mean Log Likelihood -- train: -2.420285940170288, -- test: -63.54167938232422 \n",
      "Root Mean Squared Error -- train: 0.27582359313964844, -- test: 1.139520287513733 \n",
      " \n",
      "#################### Sampling at Epoch 87149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87149\n",
      "Mean Log Likelihood -- train: -2.4222493171691895, -- test: -64.86361694335938 \n",
      "Root Mean Squared Error -- train: 0.27589473128318787, -- test: 1.1510626077651978 \n",
      " \n",
      "#################### Sampling at Epoch 87199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87199\n",
      "Mean Log Likelihood -- train: -2.458512306213379, -- test: -68.73695373535156 \n",
      "Root Mean Squared Error -- train: 0.2772060036659241, -- test: 1.1842347383499146 \n",
      " \n",
      "#################### Sampling at Epoch 87249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87249\n",
      "Mean Log Likelihood -- train: -2.433802366256714, -- test: -64.8026351928711 \n",
      "Root Mean Squared Error -- train: 0.2763131856918335, -- test: 1.1505327224731445 \n",
      " \n",
      "#################### Sampling at Epoch 87299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87299\n",
      "Mean Log Likelihood -- train: -2.4423089027404785, -- test: -63.492889404296875 \n",
      "Root Mean Squared Error -- train: 0.27662086486816406, -- test: 1.139091968536377 \n",
      " \n",
      "#################### Sampling at Epoch 87349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87349\n",
      "Mean Log Likelihood -- train: -2.3955705165863037, -- test: -65.18962097167969 \n",
      "Root Mean Squared Error -- train: 0.2749260663986206, -- test: 1.1538913249969482 \n",
      " \n",
      "#################### Sampling at Epoch 87399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87399\n",
      "Mean Log Likelihood -- train: -2.4671404361724854, -- test: -66.34645080566406 \n",
      "Root Mean Squared Error -- train: 0.2775171101093292, -- test: 1.1638737916946411 \n",
      " \n",
      "#################### Sampling at Epoch 87449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87449\n",
      "Mean Log Likelihood -- train: -2.4689974784851074, -- test: -66.59490966796875 \n",
      "Root Mean Squared Error -- train: 0.2775839865207672, -- test: 1.1660064458847046 \n",
      " \n",
      "#################### Sampling at Epoch 87499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87499\n",
      "Mean Log Likelihood -- train: -2.446162223815918, -- test: -65.38509368896484 \n",
      "Root Mean Squared Error -- train: 0.27676013112068176, -- test: 1.1555840969085693 \n",
      " \n",
      "#################### Sampling at Epoch 87549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87549\n",
      "Mean Log Likelihood -- train: -2.4834654331207275, -- test: -63.357479095458984 \n",
      "Root Mean Squared Error -- train: 0.2781047224998474, -- test: 1.1379026174545288 \n",
      " \n",
      "#################### Sampling at Epoch 87599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87599\n",
      "Mean Log Likelihood -- train: -2.50913143157959, -- test: -67.71304321289062 \n",
      "Root Mean Squared Error -- train: 0.2790261209011078, -- test: 1.1755567789077759 \n",
      " \n",
      "#################### Sampling at Epoch 87649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87649\n",
      "Mean Log Likelihood -- train: -2.4827256202697754, -- test: -62.071781158447266 \n",
      "Root Mean Squared Error -- train: 0.2780781090259552, -- test: 1.12654709815979 \n",
      " \n",
      "#################### Sampling at Epoch 87699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87699\n",
      "Mean Log Likelihood -- train: -2.4053993225097656, -- test: -62.67056655883789 \n",
      "Root Mean Squared Error -- train: 0.2752833366394043, -- test: 1.1318498849868774 \n",
      " \n",
      "#################### Sampling at Epoch 87749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87749\n",
      "Mean Log Likelihood -- train: -2.4501953125, -- test: -62.24620056152344 \n",
      "Root Mean Squared Error -- train: 0.2769058346748352, -- test: 1.1280943155288696 \n",
      " \n",
      "#################### Sampling at Epoch 87799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87799\n",
      "Mean Log Likelihood -- train: -2.5662953853607178, -- test: -65.4276123046875 \n",
      "Root Mean Squared Error -- train: 0.2810673117637634, -- test: 1.1559520959854126 \n",
      " \n",
      "#################### Sampling at Epoch 87849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87849\n",
      "Mean Log Likelihood -- train: -2.464085340499878, -- test: -60.883995056152344 \n",
      "Root Mean Squared Error -- train: 0.2774069905281067, -- test: 1.115953803062439 \n",
      " \n",
      "#################### Sampling at Epoch 87899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87899\n",
      "Mean Log Likelihood -- train: -2.4719738960266113, -- test: -62.13871765136719 \n",
      "Root Mean Squared Error -- train: 0.27769121527671814, -- test: 1.1271411180496216 \n",
      " \n",
      "#################### Sampling at Epoch 87949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87949\n",
      "Mean Log Likelihood -- train: -2.456092357635498, -- test: -60.87897491455078 \n",
      "Root Mean Squared Error -- train: 0.2771187126636505, -- test: 1.1159088611602783 \n",
      " \n",
      "#################### Sampling at Epoch 87999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 87999\n",
      "Mean Log Likelihood -- train: -2.4403491020202637, -- test: -60.25287628173828 \n",
      "Root Mean Squared Error -- train: 0.2765499949455261, -- test: 1.1102838516235352 \n",
      " \n",
      "#################### Sampling at Epoch 88049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88049\n",
      "Mean Log Likelihood -- train: -2.4472458362579346, -- test: -58.16960906982422 \n",
      "Root Mean Squared Error -- train: 0.2767992913722992, -- test: 1.0913591384887695 \n",
      " \n",
      "#################### Sampling at Epoch 88099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88099\n",
      "Mean Log Likelihood -- train: -2.45450758934021, -- test: -61.35466766357422 \n",
      "Root Mean Squared Error -- train: 0.2770615220069885, -- test: 1.1201635599136353 \n",
      " \n",
      "#################### Sampling at Epoch 88149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88149\n",
      "Mean Log Likelihood -- train: -2.448071002960205, -- test: -60.71379470825195 \n",
      "Root Mean Squared Error -- train: 0.2768290936946869, -- test: 1.1144275665283203 \n",
      " \n",
      "#################### Sampling at Epoch 88199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88199\n",
      "Mean Log Likelihood -- train: -2.4398696422576904, -- test: -61.041263580322266 \n",
      "Root Mean Squared Error -- train: 0.27653267979621887, -- test: 1.117362141609192 \n",
      " \n",
      "#################### Sampling at Epoch 88249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88249\n",
      "Mean Log Likelihood -- train: -2.4001970291137695, -- test: -62.2437744140625 \n",
      "Root Mean Squared Error -- train: 0.27509430050849915, -- test: 1.1280728578567505 \n",
      " \n",
      "#################### Sampling at Epoch 88299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88299\n",
      "Mean Log Likelihood -- train: -2.4614713191986084, -- test: -58.15650939941406 \n",
      "Root Mean Squared Error -- train: 0.2773127555847168, -- test: 1.091239094734192 \n",
      " \n",
      "#################### Sampling at Epoch 88349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88349\n",
      "Mean Log Likelihood -- train: -2.445324659347534, -- test: -59.9825553894043 \n",
      "Root Mean Squared Error -- train: 0.27672988176345825, -- test: 1.1078464984893799 \n",
      " \n",
      "#################### Sampling at Epoch 88399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88399\n",
      "Mean Log Likelihood -- train: -2.47560977935791, -- test: -58.5859375 \n",
      "Root Mean Squared Error -- train: 0.2778221070766449, -- test: 1.0951673984527588 \n",
      " \n",
      "#################### Sampling at Epoch 88449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88449\n",
      "Mean Log Likelihood -- train: -2.465625047683716, -- test: -56.641971588134766 \n",
      "Root Mean Squared Error -- train: 0.2774624824523926, -- test: 1.0772708654403687 \n",
      " \n",
      "#################### Sampling at Epoch 88499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88499\n",
      "Mean Log Likelihood -- train: -2.4025886058807373, -- test: -57.8557243347168 \n",
      "Root Mean Squared Error -- train: 0.27518120408058167, -- test: 1.0884793996810913 \n",
      " \n",
      "#################### Sampling at Epoch 88549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88549\n",
      "Mean Log Likelihood -- train: -2.5185210704803467, -- test: -58.748653411865234 \n",
      "Root Mean Squared Error -- train: 0.27936241030693054, -- test: 1.0966521501541138 \n",
      " \n",
      "#################### Sampling at Epoch 88599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88599\n",
      "Mean Log Likelihood -- train: -2.4319403171539307, -- test: -56.261470794677734 \n",
      "Root Mean Squared Error -- train: 0.27624577283859253, -- test: 1.073732852935791 \n",
      " \n",
      "#################### Sampling at Epoch 88649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88649\n",
      "Mean Log Likelihood -- train: -2.4197487831115723, -- test: -53.991416931152344 \n",
      "Root Mean Squared Error -- train: 0.2758041024208069, -- test: 1.0523788928985596 \n",
      " \n",
      "#################### Sampling at Epoch 88699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88699\n",
      "Mean Log Likelihood -- train: -2.438385009765625, -- test: -52.99419403076172 \n",
      "Root Mean Squared Error -- train: 0.27647900581359863, -- test: 1.0428599119186401 \n",
      " \n",
      "#################### Sampling at Epoch 88749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88749\n",
      "Mean Log Likelihood -- train: -2.380251884460449, -- test: -54.572174072265625 \n",
      "Root Mean Squared Error -- train: 0.2743682861328125, -- test: 1.0578829050064087 \n",
      " \n",
      "#################### Sampling at Epoch 88799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88799\n",
      "Mean Log Likelihood -- train: -2.39060115814209, -- test: -53.946659088134766 \n",
      "Root Mean Squared Error -- train: 0.27474525570869446, -- test: 1.0519534349441528 \n",
      " \n",
      "#################### Sampling at Epoch 88849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88849\n",
      "Mean Log Likelihood -- train: -2.4395511150360107, -- test: -56.73931121826172 \n",
      "Root Mean Squared Error -- train: 0.27652114629745483, -- test: 1.0781739950180054 \n",
      " \n",
      "#################### Sampling at Epoch 88899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88899\n",
      "Mean Log Likelihood -- train: -2.43986439704895, -- test: -54.552696228027344 \n",
      "Root Mean Squared Error -- train: 0.27653247117996216, -- test: 1.0576988458633423 \n",
      " \n",
      "#################### Sampling at Epoch 88949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88949\n",
      "Mean Log Likelihood -- train: -2.446636199951172, -- test: -53.8254508972168 \n",
      "Root Mean Squared Error -- train: 0.2767772674560547, -- test: 1.0508006811141968 \n",
      " \n",
      "#################### Sampling at Epoch 88999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 88999\n",
      "Mean Log Likelihood -- train: -2.417773485183716, -- test: -56.066200256347656 \n",
      "Root Mean Squared Error -- train: 0.27573248744010925, -- test: 1.0719127655029297 \n",
      " \n",
      "#################### Sampling at Epoch 89049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89049\n",
      "Mean Log Likelihood -- train: -2.4217522144317627, -- test: -55.7563362121582 \n",
      "Root Mean Squared Error -- train: 0.2758767306804657, -- test: 1.0690181255340576 \n",
      " \n",
      "#################### Sampling at Epoch 89099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89099\n",
      "Mean Log Likelihood -- train: -2.420750141143799, -- test: -55.60639190673828 \n",
      "Root Mean Squared Error -- train: 0.2758404016494751, -- test: 1.0676144361495972 \n",
      " \n",
      "#################### Sampling at Epoch 89149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89149\n",
      "Mean Log Likelihood -- train: -2.4190123081207275, -- test: -53.02268981933594 \n",
      "Root Mean Squared Error -- train: 0.2757773995399475, -- test: 1.0431331396102905 \n",
      " \n",
      "#################### Sampling at Epoch 89199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89199\n",
      "Mean Log Likelihood -- train: -2.5238215923309326, -- test: -50.87205123901367 \n",
      "Root Mean Squared Error -- train: 0.27955207228660583, -- test: 1.022308111190796 \n",
      " \n",
      "#################### Sampling at Epoch 89249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89249\n",
      "Mean Log Likelihood -- train: -2.4430572986602783, -- test: -52.673221588134766 \n",
      "Root Mean Squared Error -- train: 0.2766478955745697, -- test: 1.0397775173187256 \n",
      " \n",
      "#################### Sampling at Epoch 89299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89299\n",
      "Mean Log Likelihood -- train: -2.4409995079040527, -- test: -53.623104095458984 \n",
      "Root Mean Squared Error -- train: 0.2765735387802124, -- test: 1.0488733053207397 \n",
      " \n",
      "#################### Sampling at Epoch 89349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89349\n",
      "Mean Log Likelihood -- train: -2.477130174636841, -- test: -55.15678787231445 \n",
      "Root Mean Squared Error -- train: 0.2778768241405487, -- test: 1.0633949041366577 \n",
      " \n",
      "#################### Sampling at Epoch 89399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89399\n",
      "Mean Log Likelihood -- train: -2.456855297088623, -- test: -53.20600128173828 \n",
      "Root Mean Squared Error -- train: 0.27714625000953674, -- test: 1.044888973236084 \n",
      " \n",
      "#################### Sampling at Epoch 89449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89449\n",
      "Mean Log Likelihood -- train: -2.4962246417999268, -- test: -54.41486358642578 \n",
      "Root Mean Squared Error -- train: 0.27856314182281494, -- test: 1.0563949346542358 \n",
      " \n",
      "#################### Sampling at Epoch 89499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89499\n",
      "Mean Log Likelihood -- train: -2.4359238147735596, -- test: -54.86465835571289 \n",
      "Root Mean Squared Error -- train: 0.2763899266719818, -- test: 1.0606441497802734 \n",
      " \n",
      "#################### Sampling at Epoch 89549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89549\n",
      "Mean Log Likelihood -- train: -2.4710206985473633, -- test: -55.30559158325195 \n",
      "Root Mean Squared Error -- train: 0.2776568830013275, -- test: 1.0647932291030884 \n",
      " \n",
      "#################### Sampling at Epoch 89599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89599\n",
      "Mean Log Likelihood -- train: -2.392974376678467, -- test: -55.573577880859375 \n",
      "Root Mean Squared Error -- train: 0.274831622838974, -- test: 1.0673071146011353 \n",
      " \n",
      "#################### Sampling at Epoch 89649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89649\n",
      "Mean Log Likelihood -- train: -2.440554141998291, -- test: -54.56351089477539 \n",
      "Root Mean Squared Error -- train: 0.27655741572380066, -- test: 1.0578011274337769 \n",
      " \n",
      "#################### Sampling at Epoch 89699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89699\n",
      "Mean Log Likelihood -- train: -2.449248790740967, -- test: -54.34660339355469 \n",
      "Root Mean Squared Error -- train: 0.27687162160873413, -- test: 1.0557485818862915 \n",
      " \n",
      "#################### Sampling at Epoch 89749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89749\n",
      "Mean Log Likelihood -- train: -2.4367878437042236, -- test: -56.3432502746582 \n",
      "Root Mean Squared Error -- train: 0.2764212191104889, -- test: 1.0744942426681519 \n",
      " \n",
      "#################### Sampling at Epoch 89799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89799\n",
      "Mean Log Likelihood -- train: -2.4330694675445557, -- test: -56.050838470458984 \n",
      "Root Mean Squared Error -- train: 0.27628666162490845, -- test: 1.0717694759368896 \n",
      " \n",
      "#################### Sampling at Epoch 89849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89849\n",
      "Mean Log Likelihood -- train: -2.5964760780334473, -- test: -52.47331619262695 \n",
      "Root Mean Squared Error -- train: 0.2821390628814697, -- test: 1.0378532409667969 \n",
      " \n",
      "#################### Sampling at Epoch 89899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89899\n",
      "Mean Log Likelihood -- train: -2.4714176654815674, -- test: -56.51536178588867 \n",
      "Root Mean Squared Error -- train: 0.2776711881160736, -- test: 1.0760948657989502 \n",
      " \n",
      "#################### Sampling at Epoch 89949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89949\n",
      "Mean Log Likelihood -- train: -2.457106590270996, -- test: -54.24692916870117 \n",
      "Root Mean Squared Error -- train: 0.2771553099155426, -- test: 1.0548039674758911 \n",
      " \n",
      "#################### Sampling at Epoch 89999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 89999\n",
      "Mean Log Likelihood -- train: -2.49859881401062, -- test: -55.748130798339844 \n",
      "Root Mean Squared Error -- train: 0.27864834666252136, -- test: 1.068941354751587 \n",
      " \n",
      "#################### Sampling at Epoch 90049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90049\n",
      "Mean Log Likelihood -- train: -2.428093194961548, -- test: -53.395668029785156 \n",
      "Root Mean Squared Error -- train: 0.27610647678375244, -- test: 1.0467026233673096 \n",
      " \n",
      "#################### Sampling at Epoch 90099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90099\n",
      "Mean Log Likelihood -- train: -2.497931957244873, -- test: -54.04789733886719 \n",
      "Root Mean Squared Error -- train: 0.27862441539764404, -- test: 1.052915334701538 \n",
      " \n",
      "#################### Sampling at Epoch 90149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90149\n",
      "Mean Log Likelihood -- train: -2.4250802993774414, -- test: -56.65932083129883 \n",
      "Root Mean Squared Error -- train: 0.2759973108768463, -- test: 1.0774317979812622 \n",
      " \n",
      "#################### Sampling at Epoch 90199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90199\n",
      "Mean Log Likelihood -- train: -2.4439167976379395, -- test: -54.637786865234375 \n",
      "Root Mean Squared Error -- train: 0.27667900919914246, -- test: 1.0585030317306519 \n",
      " \n",
      "#################### Sampling at Epoch 90249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90249\n",
      "Mean Log Likelihood -- train: -2.516862630844116, -- test: -56.84342956542969 \n",
      "Root Mean Squared Error -- train: 0.27930304408073425, -- test: 1.079139232635498 \n",
      " \n",
      "#################### Sampling at Epoch 90299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90299\n",
      "Mean Log Likelihood -- train: -2.508626699447632, -- test: -55.4602165222168 \n",
      "Root Mean Squared Error -- train: 0.27900800108909607, -- test: 1.06624436378479 \n",
      " \n",
      "#################### Sampling at Epoch 90349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90349\n",
      "Mean Log Likelihood -- train: -2.489267587661743, -- test: -55.52165603637695 \n",
      "Root Mean Squared Error -- train: 0.2783132791519165, -- test: 1.066820502281189 \n",
      " \n",
      "#################### Sampling at Epoch 90399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90399\n",
      "Mean Log Likelihood -- train: -2.471935510635376, -- test: -53.92683410644531 \n",
      "Root Mean Squared Error -- train: 0.2776898145675659, -- test: 1.0517650842666626 \n",
      " \n",
      "#################### Sampling at Epoch 90449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90449\n",
      "Mean Log Likelihood -- train: -2.4336230754852295, -- test: -54.20992660522461 \n",
      "Root Mean Squared Error -- train: 0.276306688785553, -- test: 1.0544532537460327 \n",
      " \n",
      "#################### Sampling at Epoch 90499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90499\n",
      "Mean Log Likelihood -- train: -2.4682233333587646, -- test: -54.52647018432617 \n",
      "Root Mean Squared Error -- train: 0.2775561213493347, -- test: 1.0574508905410767 \n",
      " \n",
      "#################### Sampling at Epoch 90549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90549\n",
      "Mean Log Likelihood -- train: -2.433652400970459, -- test: -52.565006256103516 \n",
      "Root Mean Squared Error -- train: 0.27630776166915894, -- test: 1.0387362241744995 \n",
      " \n",
      "#################### Sampling at Epoch 90599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90599\n",
      "Mean Log Likelihood -- train: -2.5074656009674072, -- test: -51.20303726196289 \n",
      "Root Mean Squared Error -- train: 0.27896636724472046, -- test: 1.0255405902862549 \n",
      " \n",
      "#################### Sampling at Epoch 90649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90649\n",
      "Mean Log Likelihood -- train: -2.4957308769226074, -- test: -52.194637298583984 \n",
      "Root Mean Squared Error -- train: 0.2785453796386719, -- test: 1.0351645946502686 \n",
      " \n",
      "#################### Sampling at Epoch 90699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90699\n",
      "Mean Log Likelihood -- train: -2.507415771484375, -- test: -51.28474426269531 \n",
      "Root Mean Squared Error -- train: 0.2789645791053772, -- test: 1.0263370275497437 \n",
      " \n",
      "#################### Sampling at Epoch 90749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90749\n",
      "Mean Log Likelihood -- train: -2.564952850341797, -- test: -52.023765563964844 \n",
      "Root Mean Squared Error -- train: 0.28101956844329834, -- test: 1.0335125923156738 \n",
      " \n",
      "#################### Sampling at Epoch 90799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90799\n",
      "Mean Log Likelihood -- train: -2.487105369567871, -- test: -53.397613525390625 \n",
      "Root Mean Squared Error -- train: 0.2782355546951294, -- test: 1.04672110080719 \n",
      " \n",
      "#################### Sampling at Epoch 90849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90849\n",
      "Mean Log Likelihood -- train: -2.4275052547454834, -- test: -53.29502868652344 \n",
      "Root Mean Squared Error -- train: 0.2760851979255676, -- test: 1.0457407236099243 \n",
      " \n",
      "#################### Sampling at Epoch 90899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90899\n",
      "Mean Log Likelihood -- train: -2.4217960834503174, -- test: -56.3598747253418 \n",
      "Root Mean Squared Error -- train: 0.27587831020355225, -- test: 1.0746489763259888 \n",
      " \n",
      "#################### Sampling at Epoch 90949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90949\n",
      "Mean Log Likelihood -- train: -2.439382314682007, -- test: -54.66767883300781 \n",
      "Root Mean Squared Error -- train: 0.27651503682136536, -- test: 1.0587854385375977 \n",
      " \n",
      "#################### Sampling at Epoch 90999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 90999\n",
      "Mean Log Likelihood -- train: -2.479870557785034, -- test: -54.306724548339844 \n",
      "Root Mean Squared Error -- train: 0.2779754400253296, -- test: 1.0553706884384155 \n",
      " \n",
      "#################### Sampling at Epoch 91049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91049\n",
      "Mean Log Likelihood -- train: -2.4676687717437744, -- test: -53.56081008911133 \n",
      "Root Mean Squared Error -- train: 0.2775361239910126, -- test: 1.048279047012329 \n",
      " \n",
      "#################### Sampling at Epoch 91099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91099\n",
      "Mean Log Likelihood -- train: -2.496797800064087, -- test: -53.858516693115234 \n",
      "Root Mean Squared Error -- train: 0.27858370542526245, -- test: 1.0511152744293213 \n",
      " \n",
      "#################### Sampling at Epoch 91149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91149\n",
      "Mean Log Likelihood -- train: -2.4796905517578125, -- test: -53.94100570678711 \n",
      "Root Mean Squared Error -- train: 0.2779689431190491, -- test: 1.0518996715545654 \n",
      " \n",
      "#################### Sampling at Epoch 91199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91199\n",
      "Mean Log Likelihood -- train: -2.4990975856781006, -- test: -53.888275146484375 \n",
      "Root Mean Squared Error -- train: 0.27866625785827637, -- test: 1.0513982772827148 \n",
      " \n",
      "#################### Sampling at Epoch 91249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91249\n",
      "Mean Log Likelihood -- train: -2.5382485389709473, -- test: -62.36954116821289 \n",
      "Root Mean Squared Error -- train: 0.28006765246391296, -- test: 1.1291872262954712 \n",
      " \n",
      "#################### Sampling at Epoch 91299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91299\n",
      "Mean Log Likelihood -- train: -2.4484810829162598, -- test: -60.324344635009766 \n",
      "Root Mean Squared Error -- train: 0.2768438756465912, -- test: 1.1109274625778198 \n",
      " \n",
      "#################### Sampling at Epoch 91349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91349\n",
      "Mean Log Likelihood -- train: -2.479388475418091, -- test: -59.3796272277832 \n",
      "Root Mean Squared Error -- train: 0.27795809507369995, -- test: 1.1023907661437988 \n",
      " \n",
      "#################### Sampling at Epoch 91399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91399\n",
      "Mean Log Likelihood -- train: -2.4314966201782227, -- test: -59.48857498168945 \n",
      "Root Mean Squared Error -- train: 0.27622970938682556, -- test: 1.1033786535263062 \n",
      " \n",
      "#################### Sampling at Epoch 91449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91449\n",
      "Mean Log Likelihood -- train: -2.4673995971679688, -- test: -56.980342864990234 \n",
      "Root Mean Squared Error -- train: 0.2775264382362366, -- test: 1.0804071426391602 \n",
      " \n",
      "#################### Sampling at Epoch 91499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91499\n",
      "Mean Log Likelihood -- train: -2.483015537261963, -- test: -60.8868293762207 \n",
      "Root Mean Squared Error -- train: 0.2780885398387909, -- test: 1.1159791946411133 \n",
      " \n",
      "#################### Sampling at Epoch 91549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91549\n",
      "Mean Log Likelihood -- train: -2.4485976696014404, -- test: -54.954959869384766 \n",
      "Root Mean Squared Error -- train: 0.27684810757637024, -- test: 1.0614951848983765 \n",
      " \n",
      "#################### Sampling at Epoch 91599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91599\n",
      "Mean Log Likelihood -- train: -2.4494364261627197, -- test: -58.669368743896484 \n",
      "Root Mean Squared Error -- train: 0.2768784165382385, -- test: 1.0959290266036987 \n",
      " \n",
      "#################### Sampling at Epoch 91649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91649\n",
      "Mean Log Likelihood -- train: -2.4558141231536865, -- test: -57.36476135253906 \n",
      "Root Mean Squared Error -- train: 0.27710866928100586, -- test: 1.0839593410491943 \n",
      " \n",
      "#################### Sampling at Epoch 91699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91699\n",
      "Mean Log Likelihood -- train: -2.403268337249756, -- test: -56.928070068359375 \n",
      "Root Mean Squared Error -- train: 0.27520591020584106, -- test: 1.0799232721328735 \n",
      " \n",
      "#################### Sampling at Epoch 91749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91749\n",
      "Mean Log Likelihood -- train: -2.4397032260894775, -- test: -59.25896453857422 \n",
      "Root Mean Squared Error -- train: 0.27652668952941895, -- test: 1.1012955904006958 \n",
      " \n",
      "#################### Sampling at Epoch 91799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91799\n",
      "Mean Log Likelihood -- train: -2.4055256843566895, -- test: -58.971275329589844 \n",
      "Root Mean Squared Error -- train: 0.275287926197052, -- test: 1.0986802577972412 \n",
      " \n",
      "#################### Sampling at Epoch 91849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91849\n",
      "Mean Log Likelihood -- train: -2.442876100540161, -- test: -59.07634735107422 \n",
      "Root Mean Squared Error -- train: 0.2766413688659668, -- test: 1.099636197090149 \n",
      " \n",
      "#################### Sampling at Epoch 91899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91899\n",
      "Mean Log Likelihood -- train: -2.4047248363494873, -- test: -58.09189987182617 \n",
      "Root Mean Squared Error -- train: 0.2752588093280792, -- test: 1.0906469821929932 \n",
      " \n",
      "#################### Sampling at Epoch 91949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91949\n",
      "Mean Log Likelihood -- train: -2.4195892810821533, -- test: -54.772499084472656 \n",
      "Root Mean Squared Error -- train: 0.27579832077026367, -- test: 1.0597749948501587 \n",
      " \n",
      "#################### Sampling at Epoch 91999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 91999\n",
      "Mean Log Likelihood -- train: -2.4176976680755615, -- test: -56.56254959106445 \n",
      "Root Mean Squared Error -- train: 0.2757297456264496, -- test: 1.0765331983566284 \n",
      " \n",
      "#################### Sampling at Epoch 92049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92049\n",
      "Mean Log Likelihood -- train: -2.420619249343872, -- test: -56.424659729003906 \n",
      "Root Mean Squared Error -- train: 0.27583566308021545, -- test: 1.075251579284668 \n",
      " \n",
      "#################### Sampling at Epoch 92099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92099\n",
      "Mean Log Likelihood -- train: -2.4054219722747803, -- test: -56.21224594116211 \n",
      "Root Mean Squared Error -- train: 0.27528414130210876, -- test: 1.0732743740081787 \n",
      " \n",
      "#################### Sampling at Epoch 92149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92149\n",
      "Mean Log Likelihood -- train: -2.403035879135132, -- test: -55.348567962646484 \n",
      "Root Mean Squared Error -- train: 0.27519747614860535, -- test: 1.0651967525482178 \n",
      " \n",
      "#################### Sampling at Epoch 92199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92199\n",
      "Mean Log Likelihood -- train: -2.4499006271362305, -- test: -53.7357292175293 \n",
      "Root Mean Squared Error -- train: 0.2768951654434204, -- test: 1.0499464273452759 \n",
      " \n",
      "#################### Sampling at Epoch 92249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92249\n",
      "Mean Log Likelihood -- train: -2.415445566177368, -- test: -55.59423828125 \n",
      "Root Mean Squared Error -- train: 0.2756480276584625, -- test: 1.0675005912780762 \n",
      " \n",
      "#################### Sampling at Epoch 92299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92299\n",
      "Mean Log Likelihood -- train: -2.4171910285949707, -- test: -58.80079650878906 \n",
      "Root Mean Squared Error -- train: 0.2757113575935364, -- test: 1.0971274375915527 \n",
      " \n",
      "#################### Sampling at Epoch 92349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92349\n",
      "Mean Log Likelihood -- train: -2.3841826915740967, -- test: -57.543601989746094 \n",
      "Root Mean Squared Error -- train: 0.27451151609420776, -- test: 1.0856081247329712 \n",
      " \n",
      "#################### Sampling at Epoch 92399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92399\n",
      "Mean Log Likelihood -- train: -2.3946032524108887, -- test: -56.0378532409668 \n",
      "Root Mean Squared Error -- train: 0.27489086985588074, -- test: 1.0716482400894165 \n",
      " \n",
      "#################### Sampling at Epoch 92449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92449\n",
      "Mean Log Likelihood -- train: -2.3890843391418457, -- test: -58.616207122802734 \n",
      "Root Mean Squared Error -- train: 0.27469003200531006, -- test: 1.0954437255859375 \n",
      " \n",
      "#################### Sampling at Epoch 92499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92499\n",
      "Mean Log Likelihood -- train: -2.420457363128662, -- test: -57.4560661315918 \n",
      "Root Mean Squared Error -- train: 0.27582982182502747, -- test: 1.0848015546798706 \n",
      " \n",
      "#################### Sampling at Epoch 92549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92549\n",
      "Mean Log Likelihood -- train: -2.40160870552063, -- test: -57.618621826171875 \n",
      "Root Mean Squared Error -- train: 0.27514559030532837, -- test: 1.086298942565918 \n",
      " \n",
      "#################### Sampling at Epoch 92599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92599\n",
      "Mean Log Likelihood -- train: -2.437472105026245, -- test: -59.00056076049805 \n",
      "Root Mean Squared Error -- train: 0.2764459550380707, -- test: 1.0989468097686768 \n",
      " \n",
      "#################### Sampling at Epoch 92649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92649\n",
      "Mean Log Likelihood -- train: -2.379047155380249, -- test: -60.87456130981445 \n",
      "Root Mean Squared Error -- train: 0.2743243873119354, -- test: 1.1158692836761475 \n",
      " \n",
      "#################### Sampling at Epoch 92699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92699\n",
      "Mean Log Likelihood -- train: -2.4616990089416504, -- test: -60.13938903808594 \n",
      "Root Mean Squared Error -- train: 0.2773209512233734, -- test: 1.1092612743377686 \n",
      " \n",
      "#################### Sampling at Epoch 92749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92749\n",
      "Mean Log Likelihood -- train: -2.4047422409057617, -- test: -65.28521728515625 \n",
      "Root Mean Squared Error -- train: 0.27525946497917175, -- test: 1.1547194719314575 \n",
      " \n",
      "#################### Sampling at Epoch 92799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92799\n",
      "Mean Log Likelihood -- train: -2.442342519760132, -- test: -62.10231399536133 \n",
      "Root Mean Squared Error -- train: 0.27662208676338196, -- test: 1.1268181800842285 \n",
      " \n",
      "#################### Sampling at Epoch 92849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92849\n",
      "Mean Log Likelihood -- train: -2.466418743133545, -- test: -67.24761962890625 \n",
      "Root Mean Squared Error -- train: 0.27749109268188477, -- test: 1.17159104347229 \n",
      " \n",
      "#################### Sampling at Epoch 92899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92899\n",
      "Mean Log Likelihood -- train: -2.4785397052764893, -- test: -64.5016098022461 \n",
      "Root Mean Squared Error -- train: 0.27792754769325256, -- test: 1.1479133367538452 \n",
      " \n",
      "#################### Sampling at Epoch 92949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92949\n",
      "Mean Log Likelihood -- train: -2.4751760959625244, -- test: -63.2706298828125 \n",
      "Root Mean Squared Error -- train: 0.27780649065971375, -- test: 1.1371392011642456 \n",
      " \n",
      "#################### Sampling at Epoch 92999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 92999\n",
      "Mean Log Likelihood -- train: -2.418998956680298, -- test: -68.35397338867188 \n",
      "Root Mean Squared Error -- train: 0.2757768929004669, -- test: 1.1809961795806885 \n",
      " \n",
      "#################### Sampling at Epoch 93049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93049\n",
      "Mean Log Likelihood -- train: -2.4037458896636963, -- test: -67.57787322998047 \n",
      "Root Mean Squared Error -- train: 0.2752232551574707, -- test: 1.1744064092636108 \n",
      " \n",
      "#################### Sampling at Epoch 93099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93099\n",
      "Mean Log Likelihood -- train: -2.4088501930236816, -- test: -67.9591293334961 \n",
      "Root Mean Squared Error -- train: 0.27540865540504456, -- test: 1.1776483058929443 \n",
      " \n",
      "#################### Sampling at Epoch 93149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93149\n",
      "Mean Log Likelihood -- train: -2.4134879112243652, -- test: -66.52481842041016 \n",
      "Root Mean Squared Error -- train: 0.27557700872421265, -- test: 1.1654051542282104 \n",
      " \n",
      "#################### Sampling at Epoch 93199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93199\n",
      "Mean Log Likelihood -- train: -2.53136944770813, -- test: -70.87606048583984 \n",
      "Root Mean Squared Error -- train: 0.2798219323158264, -- test: 1.202162265777588 \n",
      " \n",
      "#################### Sampling at Epoch 93249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93249\n",
      "Mean Log Likelihood -- train: -2.4323456287384033, -- test: -65.53070068359375 \n",
      "Root Mean Squared Error -- train: 0.27626046538352966, -- test: 1.1568435430526733 \n",
      " \n",
      "#################### Sampling at Epoch 93299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93299\n",
      "Mean Log Likelihood -- train: -2.468876838684082, -- test: -66.39696502685547 \n",
      "Root Mean Squared Error -- train: 0.277579665184021, -- test: 1.1643075942993164 \n",
      " \n",
      "#################### Sampling at Epoch 93349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93349\n",
      "Mean Log Likelihood -- train: -2.4737114906311035, -- test: -66.22416687011719 \n",
      "Root Mean Squared Error -- train: 0.2777537405490875, -- test: 1.1628226041793823 \n",
      " \n",
      "#################### Sampling at Epoch 93399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93399\n",
      "Mean Log Likelihood -- train: -2.486499071121216, -- test: -67.60855865478516 \n",
      "Root Mean Squared Error -- train: 0.278213769197464, -- test: 1.1746675968170166 \n",
      " \n",
      "#################### Sampling at Epoch 93449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93449\n",
      "Mean Log Likelihood -- train: -2.4255738258361816, -- test: -65.9509048461914 \n",
      "Root Mean Squared Error -- train: 0.2760152220726013, -- test: 1.1604701280593872 \n",
      " \n",
      "#################### Sampling at Epoch 93499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93499\n",
      "Mean Log Likelihood -- train: -2.4910995960235596, -- test: -67.11673736572266 \n",
      "Root Mean Squared Error -- train: 0.27837908267974854, -- test: 1.1704732179641724 \n",
      " \n",
      "#################### Sampling at Epoch 93549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93549\n",
      "Mean Log Likelihood -- train: -2.4027581214904785, -- test: -64.61383819580078 \n",
      "Root Mean Squared Error -- train: 0.2751873731613159, -- test: 1.1488906145095825 \n",
      " \n",
      "#################### Sampling at Epoch 93599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93599\n",
      "Mean Log Likelihood -- train: -2.462959051132202, -- test: -68.13689422607422 \n",
      "Root Mean Squared Error -- train: 0.27736636996269226, -- test: 1.17915678024292 \n",
      " \n",
      "#################### Sampling at Epoch 93649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93649\n",
      "Mean Log Likelihood -- train: -2.427659273147583, -- test: -66.13343048095703 \n",
      "Root Mean Squared Error -- train: 0.2760907709598541, -- test: 1.1620419025421143 \n",
      " \n",
      "#################### Sampling at Epoch 93699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93699\n",
      "Mean Log Likelihood -- train: -2.408255100250244, -- test: -67.01678466796875 \n",
      "Root Mean Squared Error -- train: 0.27538707852363586, -- test: 1.169619083404541 \n",
      " \n",
      "#################### Sampling at Epoch 93749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93749\n",
      "Mean Log Likelihood -- train: -2.504754066467285, -- test: -67.21684265136719 \n",
      "Root Mean Squared Error -- train: 0.2788691818714142, -- test: 1.1713283061981201 \n",
      " \n",
      "#################### Sampling at Epoch 93799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93799\n",
      "Mean Log Likelihood -- train: -2.498883008956909, -- test: -65.00120544433594 \n",
      "Root Mean Squared Error -- train: 0.27865853905677795, -- test: 1.1522574424743652 \n",
      " \n",
      "#################### Sampling at Epoch 93849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93849\n",
      "Mean Log Likelihood -- train: -2.5560998916625977, -- test: -65.86432647705078 \n",
      "Root Mean Squared Error -- train: 0.2807043492794037, -- test: 1.1597237586975098 \n",
      " \n",
      "#################### Sampling at Epoch 93899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93899\n",
      "Mean Log Likelihood -- train: -2.393467903137207, -- test: -67.41366577148438 \n",
      "Root Mean Squared Error -- train: 0.2748495638370514, -- test: 1.1730073690414429 \n",
      " \n",
      "#################### Sampling at Epoch 93949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93949\n",
      "Mean Log Likelihood -- train: -2.412780523300171, -- test: -66.3278579711914 \n",
      "Root Mean Squared Error -- train: 0.27555134892463684, -- test: 1.1637139320373535 \n",
      " \n",
      "#################### Sampling at Epoch 93999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 93999\n",
      "Mean Log Likelihood -- train: -2.437678575515747, -- test: -66.04039764404297 \n",
      "Root Mean Squared Error -- train: 0.2764534056186676, -- test: 1.161241054534912 \n",
      " \n",
      "#################### Sampling at Epoch 94049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94049\n",
      "Mean Log Likelihood -- train: -2.437340021133423, -- test: -65.83023071289062 \n",
      "Root Mean Squared Error -- train: 0.27644115686416626, -- test: 1.1594297885894775 \n",
      " \n",
      "#################### Sampling at Epoch 94099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94099\n",
      "Mean Log Likelihood -- train: -2.41152024269104, -- test: -65.13259887695312 \n",
      "Root Mean Squared Error -- train: 0.27550560235977173, -- test: 1.1533970832824707 \n",
      " \n",
      "#################### Sampling at Epoch 94149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94149\n",
      "Mean Log Likelihood -- train: -2.4878430366516113, -- test: -66.4626693725586 \n",
      "Root Mean Squared Error -- train: 0.27826207876205444, -- test: 1.1648718118667603 \n",
      " \n",
      "#################### Sampling at Epoch 94199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94199\n",
      "Mean Log Likelihood -- train: -2.5283830165863037, -- test: -67.82523345947266 \n",
      "Root Mean Squared Error -- train: 0.2797151803970337, -- test: 1.1765106916427612 \n",
      " \n",
      "#################### Sampling at Epoch 94249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94249\n",
      "Mean Log Likelihood -- train: -2.436187267303467, -- test: -65.30672454833984 \n",
      "Root Mean Squared Error -- train: 0.2763994634151459, -- test: 1.1549056768417358 \n",
      " \n",
      "#################### Sampling at Epoch 94299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94299\n",
      "Mean Log Likelihood -- train: -2.4448800086975098, -- test: -66.96269989013672 \n",
      "Root Mean Squared Error -- train: 0.2767137885093689, -- test: 1.1691564321517944 \n",
      " \n",
      "#################### Sampling at Epoch 94349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94349\n",
      "Mean Log Likelihood -- train: -2.4652109146118164, -- test: -64.93921661376953 \n",
      "Root Mean Squared Error -- train: 0.27744755148887634, -- test: 1.1517192125320435 \n",
      " \n",
      "#################### Sampling at Epoch 94399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94399\n",
      "Mean Log Likelihood -- train: -2.4878768920898438, -- test: -64.29252624511719 \n",
      "Root Mean Squared Error -- train: 0.27826330065727234, -- test: 1.1460905075073242 \n",
      " \n",
      "#################### Sampling at Epoch 94449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94449\n",
      "Mean Log Likelihood -- train: -2.511444568634033, -- test: -64.84858703613281 \n",
      "Root Mean Squared Error -- train: 0.27910900115966797, -- test: 1.1509321928024292 \n",
      " \n",
      "#################### Sampling at Epoch 94499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94499\n",
      "Mean Log Likelihood -- train: -2.5164144039154053, -- test: -61.55374526977539 \n",
      "Root Mean Squared Error -- train: 0.2792869806289673, -- test: 1.1219393014907837 \n",
      " \n",
      "#################### Sampling at Epoch 94549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94549\n",
      "Mean Log Likelihood -- train: -2.5645105838775635, -- test: -63.76409149169922 \n",
      "Root Mean Squared Error -- train: 0.28100383281707764, -- test: 1.1414704322814941 \n",
      " \n",
      "#################### Sampling at Epoch 94599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94599\n",
      "Mean Log Likelihood -- train: -2.4078521728515625, -- test: -63.328426361083984 \n",
      "Root Mean Squared Error -- train: 0.2753724157810211, -- test: 1.1376473903656006 \n",
      " \n",
      "#################### Sampling at Epoch 94649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94649\n",
      "Mean Log Likelihood -- train: -2.391953706741333, -- test: -60.55191421508789 \n",
      "Root Mean Squared Error -- train: 0.27479445934295654, -- test: 1.1129740476608276 \n",
      " \n",
      "#################### Sampling at Epoch 94699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94699\n",
      "Mean Log Likelihood -- train: -2.429389476776123, -- test: -58.452980041503906 \n",
      "Root Mean Squared Error -- train: 0.27615341544151306, -- test: 1.0939527750015259 \n",
      " \n",
      "#################### Sampling at Epoch 94749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94749\n",
      "Mean Log Likelihood -- train: -2.39764404296875, -- test: -58.50845718383789 \n",
      "Root Mean Squared Error -- train: 0.2750014662742615, -- test: 1.0944596529006958 \n",
      " \n",
      "#################### Sampling at Epoch 94799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94799\n",
      "Mean Log Likelihood -- train: -2.3886072635650635, -- test: -58.863162994384766 \n",
      "Root Mean Squared Error -- train: 0.27467265725135803, -- test: 1.0976958274841309 \n",
      " \n",
      "#################### Sampling at Epoch 94849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94849\n",
      "Mean Log Likelihood -- train: -2.454087734222412, -- test: -59.56291961669922 \n",
      "Root Mean Squared Error -- train: 0.2770463526248932, -- test: 1.1040523052215576 \n",
      " \n",
      "#################### Sampling at Epoch 94899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94899\n",
      "Mean Log Likelihood -- train: -2.3859853744506836, -- test: -60.34943389892578 \n",
      "Root Mean Squared Error -- train: 0.27457717061042786, -- test: 1.1111531257629395 \n",
      " \n",
      "#################### Sampling at Epoch 94949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94949\n",
      "Mean Log Likelihood -- train: -2.4279351234436035, -- test: -59.9324836730957 \n",
      "Root Mean Squared Error -- train: 0.276100754737854, -- test: 1.1073944568634033 \n",
      " \n",
      "#################### Sampling at Epoch 94999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 94999\n",
      "Mean Log Likelihood -- train: -2.384683847427368, -- test: -59.383365631103516 \n",
      "Root Mean Squared Error -- train: 0.2745297849178314, -- test: 1.1024247407913208 \n",
      " \n",
      "#################### Sampling at Epoch 95049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95049\n",
      "Mean Log Likelihood -- train: -2.4045777320861816, -- test: -60.28200149536133 \n",
      "Root Mean Squared Error -- train: 0.2752534747123718, -- test: 1.1105462312698364 \n",
      " \n",
      "#################### Sampling at Epoch 95099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95099\n",
      "Mean Log Likelihood -- train: -2.4406886100769043, -- test: -59.68717956542969 \n",
      "Root Mean Squared Error -- train: 0.27656227350234985, -- test: 1.1051770448684692 \n",
      " \n",
      "#################### Sampling at Epoch 95149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95149\n",
      "Mean Log Likelihood -- train: -2.4252634048461914, -- test: -62.41897964477539 \n",
      "Root Mean Squared Error -- train: 0.27600398659706116, -- test: 1.1296249628067017 \n",
      " \n",
      "#################### Sampling at Epoch 95199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95199\n",
      "Mean Log Likelihood -- train: -2.4014203548431396, -- test: -62.012413024902344 \n",
      "Root Mean Squared Error -- train: 0.2751387357711792, -- test: 1.126020073890686 \n",
      " \n",
      "#################### Sampling at Epoch 95249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95249\n",
      "Mean Log Likelihood -- train: -2.403806209564209, -- test: -62.4382209777832 \n",
      "Root Mean Squared Error -- train: 0.2752254605293274, -- test: 1.1297951936721802 \n",
      " \n",
      "#################### Sampling at Epoch 95299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95299\n",
      "Mean Log Likelihood -- train: -2.484588623046875, -- test: -61.3786735534668 \n",
      "Root Mean Squared Error -- train: 0.27814510464668274, -- test: 1.1203776597976685 \n",
      " \n",
      "#################### Sampling at Epoch 95349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95349\n",
      "Mean Log Likelihood -- train: -2.433953046798706, -- test: -62.40127944946289 \n",
      "Root Mean Squared Error -- train: 0.27631863951683044, -- test: 1.1294682025909424 \n",
      " \n",
      "#################### Sampling at Epoch 95399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95399\n",
      "Mean Log Likelihood -- train: -2.45755672454834, -- test: -65.05722045898438 \n",
      "Root Mean Squared Error -- train: 0.2771715223789215, -- test: 1.1527434587478638 \n",
      " \n",
      "#################### Sampling at Epoch 95449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95449\n",
      "Mean Log Likelihood -- train: -2.526746988296509, -- test: -60.83846664428711 \n",
      "Root Mean Squared Error -- train: 0.27965670824050903, -- test: 1.1155457496643066 \n",
      " \n",
      "#################### Sampling at Epoch 95499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95499\n",
      "Mean Log Likelihood -- train: -2.5144765377044678, -- test: -65.93055725097656 \n",
      "Root Mean Squared Error -- train: 0.27921757102012634, -- test: 1.160294771194458 \n",
      " \n",
      "#################### Sampling at Epoch 95549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95549\n",
      "Mean Log Likelihood -- train: -2.4496352672576904, -- test: -66.18756866455078 \n",
      "Root Mean Squared Error -- train: 0.27688559889793396, -- test: 1.1625076532363892 \n",
      " \n",
      "#################### Sampling at Epoch 95599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95599\n",
      "Mean Log Likelihood -- train: -2.527705669403076, -- test: -66.94125366210938 \n",
      "Root Mean Squared Error -- train: 0.2796909809112549, -- test: 1.1689729690551758 \n",
      " \n",
      "#################### Sampling at Epoch 95649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95649\n",
      "Mean Log Likelihood -- train: -2.438438892364502, -- test: -67.12511444091797 \n",
      "Root Mean Squared Error -- train: 0.27648094296455383, -- test: 1.1705447435379028 \n",
      " \n",
      "#################### Sampling at Epoch 95699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95699\n",
      "Mean Log Likelihood -- train: -2.416196584701538, -- test: -65.03691101074219 \n",
      "Root Mean Squared Error -- train: 0.27567529678344727, -- test: 1.1525671482086182 \n",
      " \n",
      "#################### Sampling at Epoch 95749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95749\n",
      "Mean Log Likelihood -- train: -2.467860460281372, -- test: -62.1655158996582 \n",
      "Root Mean Squared Error -- train: 0.2775430381298065, -- test: 1.1273789405822754 \n",
      " \n",
      "#################### Sampling at Epoch 95799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95799\n",
      "Mean Log Likelihood -- train: -2.5300588607788086, -- test: -66.71209716796875 \n",
      "Root Mean Squared Error -- train: 0.27977508306503296, -- test: 1.1670111417770386 \n",
      " \n",
      "#################### Sampling at Epoch 95849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95849\n",
      "Mean Log Likelihood -- train: -2.4327046871185303, -- test: -63.658363342285156 \n",
      "Root Mean Squared Error -- train: 0.2762734293937683, -- test: 1.140543818473816 \n",
      " \n",
      "#################### Sampling at Epoch 95899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95899\n",
      "Mean Log Likelihood -- train: -2.4180116653442383, -- test: -62.841426849365234 \n",
      "Root Mean Squared Error -- train: 0.2757411003112793, -- test: 1.133358359336853 \n",
      " \n",
      "#################### Sampling at Epoch 95949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95949\n",
      "Mean Log Likelihood -- train: -2.4303817749023438, -- test: -63.52676773071289 \n",
      "Root Mean Squared Error -- train: 0.276189386844635, -- test: 1.1393893957138062 \n",
      " \n",
      "#################### Sampling at Epoch 95999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 95999\n",
      "Mean Log Likelihood -- train: -2.4955663681030273, -- test: -63.41015625 \n",
      "Root Mean Squared Error -- train: 0.2785395085811615, -- test: 1.1383655071258545 \n",
      " \n",
      "#################### Sampling at Epoch 96049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96049\n",
      "Mean Log Likelihood -- train: -2.430947780609131, -- test: -64.147216796875 \n",
      "Root Mean Squared Error -- train: 0.27620986104011536, -- test: 1.1448218822479248 \n",
      " \n",
      "#################### Sampling at Epoch 96099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96099\n",
      "Mean Log Likelihood -- train: -2.5041284561157227, -- test: -61.78998947143555 \n",
      "Root Mean Squared Error -- train: 0.27884671092033386, -- test: 1.1240429878234863 \n",
      " \n",
      "#################### Sampling at Epoch 96149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96149\n",
      "Mean Log Likelihood -- train: -2.431535243988037, -- test: -62.58894348144531 \n",
      "Root Mean Squared Error -- train: 0.2762311100959778, -- test: 1.1311285495758057 \n",
      " \n",
      "#################### Sampling at Epoch 96199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96199\n",
      "Mean Log Likelihood -- train: -2.437960147857666, -- test: -59.33869171142578 \n",
      "Root Mean Squared Error -- train: 0.2764635980129242, -- test: 1.1020193099975586 \n",
      " \n",
      "#################### Sampling at Epoch 96249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96249\n",
      "Mean Log Likelihood -- train: -2.4487154483795166, -- test: -60.368473052978516 \n",
      "Root Mean Squared Error -- train: 0.2768523693084717, -- test: 1.1113245487213135 \n",
      " \n",
      "#################### Sampling at Epoch 96299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96299\n",
      "Mean Log Likelihood -- train: -2.377920627593994, -- test: -61.595428466796875 \n",
      "Root Mean Squared Error -- train: 0.2742833197116852, -- test: 1.122310757637024 \n",
      " \n",
      "#################### Sampling at Epoch 96349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96349\n",
      "Mean Log Likelihood -- train: -2.4088447093963623, -- test: -62.443153381347656 \n",
      "Root Mean Squared Error -- train: 0.27540847659111023, -- test: 1.1298389434814453 \n",
      " \n",
      "#################### Sampling at Epoch 96399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96399\n",
      "Mean Log Likelihood -- train: -2.423994541168213, -- test: -63.620094299316406 \n",
      "Root Mean Squared Error -- train: 0.27595800161361694, -- test: 1.1402082443237305 \n",
      " \n",
      "#################### Sampling at Epoch 96449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96449\n",
      "Mean Log Likelihood -- train: -2.411994218826294, -- test: -62.664825439453125 \n",
      "Root Mean Squared Error -- train: 0.27552279829978943, -- test: 1.1317991018295288 \n",
      " \n",
      "#################### Sampling at Epoch 96499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96499\n",
      "Mean Log Likelihood -- train: -2.424492835998535, -- test: -64.36543273925781 \n",
      "Root Mean Squared Error -- train: 0.2759760618209839, -- test: 1.1467264890670776 \n",
      " \n",
      "#################### Sampling at Epoch 96549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96549\n",
      "Mean Log Likelihood -- train: -2.4505600929260254, -- test: -63.521053314208984 \n",
      "Root Mean Squared Error -- train: 0.2769189774990082, -- test: 1.1393392086029053 \n",
      " \n",
      "#################### Sampling at Epoch 96599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96599\n",
      "Mean Log Likelihood -- train: -2.449822425842285, -- test: -65.42575073242188 \n",
      "Root Mean Squared Error -- train: 0.27689236402511597, -- test: 1.1559360027313232 \n",
      " \n",
      "#################### Sampling at Epoch 96649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96649\n",
      "Mean Log Likelihood -- train: -2.4400553703308105, -- test: -63.11870574951172 \n",
      "Root Mean Squared Error -- train: 0.2765393853187561, -- test: 1.1358023881912231 \n",
      " \n",
      "#################### Sampling at Epoch 96699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96699\n",
      "Mean Log Likelihood -- train: -2.4022116661071777, -- test: -67.3583984375 \n",
      "Root Mean Squared Error -- train: 0.2751675248146057, -- test: 1.1725361347198486 \n",
      " \n",
      "#################### Sampling at Epoch 96749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96749\n",
      "Mean Log Likelihood -- train: -2.4477434158325195, -- test: -66.57923889160156 \n",
      "Root Mean Squared Error -- train: 0.276817262172699, -- test: 1.1658720970153809 \n",
      " \n",
      "#################### Sampling at Epoch 96799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96799\n",
      "Mean Log Likelihood -- train: -2.435375690460205, -- test: -66.90190124511719 \n",
      "Root Mean Squared Error -- train: 0.276370108127594, -- test: 1.1686363220214844 \n",
      " \n",
      "#################### Sampling at Epoch 96849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96849\n",
      "Mean Log Likelihood -- train: -2.4123754501342773, -- test: -67.7724380493164 \n",
      "Root Mean Squared Error -- train: 0.2755366265773773, -- test: 1.176061987876892 \n",
      " \n",
      "#################### Sampling at Epoch 96899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96899\n",
      "Mean Log Likelihood -- train: -2.401479482650757, -- test: -66.9765396118164 \n",
      "Root Mean Squared Error -- train: 0.2751409113407135, -- test: 1.1692748069763184 \n",
      " \n",
      "#################### Sampling at Epoch 96949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96949\n",
      "Mean Log Likelihood -- train: -2.399158000946045, -- test: -67.8699722290039 \n",
      "Root Mean Squared Error -- train: 0.27505648136138916, -- test: 1.1768909692764282 \n",
      " \n",
      "#################### Sampling at Epoch 96999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 96999\n",
      "Mean Log Likelihood -- train: -2.4128453731536865, -- test: -66.94342041015625 \n",
      "Root Mean Squared Error -- train: 0.2755536735057831, -- test: 1.1689915657043457 \n",
      " \n",
      "#################### Sampling at Epoch 97049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97049\n",
      "Mean Log Likelihood -- train: -2.5144877433776855, -- test: -69.19743347167969 \n",
      "Root Mean Squared Error -- train: 0.27921798825263977, -- test: 1.1881167888641357 \n",
      " \n",
      "#################### Sampling at Epoch 97099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97099\n",
      "Mean Log Likelihood -- train: -2.4009947776794434, -- test: -70.51863861083984 \n",
      "Root Mean Squared Error -- train: 0.2751232981681824, -- test: 1.1991853713989258 \n",
      " \n",
      "#################### Sampling at Epoch 97149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97149\n",
      "Mean Log Likelihood -- train: -2.4507155418395996, -- test: -72.42406463623047 \n",
      "Root Mean Squared Error -- train: 0.27692461013793945, -- test: 1.2149708271026611 \n",
      " \n",
      "#################### Sampling at Epoch 97199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97199\n",
      "Mean Log Likelihood -- train: -2.4239189624786377, -- test: -70.9285659790039 \n",
      "Root Mean Squared Error -- train: 0.2759552597999573, -- test: 1.2025989294052124 \n",
      " \n",
      "#################### Sampling at Epoch 97249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97249\n",
      "Mean Log Likelihood -- train: -2.5827813148498535, -- test: -72.61137390136719 \n",
      "Root Mean Squared Error -- train: 0.2816532552242279, -- test: 1.216511607170105 \n",
      " \n",
      "#################### Sampling at Epoch 97299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97299\n",
      "Mean Log Likelihood -- train: -2.415085792541504, -- test: -69.17010498046875 \n",
      "Root Mean Squared Error -- train: 0.2756350040435791, -- test: 1.1878867149353027 \n",
      " \n",
      "#################### Sampling at Epoch 97349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97349\n",
      "Mean Log Likelihood -- train: -2.4860520362854004, -- test: -68.49495697021484 \n",
      "Root Mean Squared Error -- train: 0.2781977355480194, -- test: 1.1821895837783813 \n",
      " \n",
      "#################### Sampling at Epoch 97399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97399\n",
      "Mean Log Likelihood -- train: -2.3803186416625977, -- test: -66.59475708007812 \n",
      "Root Mean Squared Error -- train: 0.2743707299232483, -- test: 1.166005253791809 \n",
      " \n",
      "#################### Sampling at Epoch 97449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97449\n",
      "Mean Log Likelihood -- train: -2.441006660461426, -- test: -66.43961334228516 \n",
      "Root Mean Squared Error -- train: 0.2765737771987915, -- test: 1.164673924446106 \n",
      " \n",
      "#################### Sampling at Epoch 97499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97499\n",
      "Mean Log Likelihood -- train: -2.408794403076172, -- test: -67.61036682128906 \n",
      "Root Mean Squared Error -- train: 0.2754066288471222, -- test: 1.1746829748153687 \n",
      " \n",
      "#################### Sampling at Epoch 97549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97549\n",
      "Mean Log Likelihood -- train: -2.388061761856079, -- test: -65.30709838867188 \n",
      "Root Mean Squared Error -- train: 0.2746528387069702, -- test: 1.1549090147018433 \n",
      " \n",
      "#################### Sampling at Epoch 97599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97599\n",
      "Mean Log Likelihood -- train: -2.4059388637542725, -- test: -67.00981140136719 \n",
      "Root Mean Squared Error -- train: 0.2753029465675354, -- test: 1.169559359550476 \n",
      " \n",
      "#################### Sampling at Epoch 97649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97649\n",
      "Mean Log Likelihood -- train: -2.4409220218658447, -- test: -66.40875244140625 \n",
      "Root Mean Squared Error -- train: 0.27657073736190796, -- test: 1.1644089221954346 \n",
      " \n",
      "#################### Sampling at Epoch 97699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97699\n",
      "Mean Log Likelihood -- train: -2.4544732570648193, -- test: -68.81246185302734 \n",
      "Root Mean Squared Error -- train: 0.27706027030944824, -- test: 1.1848721504211426 \n",
      " \n",
      "#################### Sampling at Epoch 97749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97749\n",
      "Mean Log Likelihood -- train: -2.4007766246795654, -- test: -68.39555358886719 \n",
      "Root Mean Squared Error -- train: 0.27511537075042725, -- test: 1.181348443031311 \n",
      " \n",
      "#################### Sampling at Epoch 97799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97799\n",
      "Mean Log Likelihood -- train: -2.39205265045166, -- test: -64.6991958618164 \n",
      "Root Mean Squared Error -- train: 0.27479806542396545, -- test: 1.1496332883834839 \n",
      " \n",
      "#################### Sampling at Epoch 97849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97849\n",
      "Mean Log Likelihood -- train: -2.4555370807647705, -- test: -65.0199966430664 \n",
      "Root Mean Squared Error -- train: 0.2770986557006836, -- test: 1.1524204015731812 \n",
      " \n",
      "#################### Sampling at Epoch 97899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97899\n",
      "Mean Log Likelihood -- train: -2.3947434425354004, -- test: -66.33484649658203 \n",
      "Root Mean Squared Error -- train: 0.2748959958553314, -- test: 1.163774013519287 \n",
      " \n",
      "#################### Sampling at Epoch 97949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97949\n",
      "Mean Log Likelihood -- train: -2.420245885848999, -- test: -64.33556365966797 \n",
      "Root Mean Squared Error -- train: 0.27582213282585144, -- test: 1.1464658975601196 \n",
      " \n",
      "#################### Sampling at Epoch 97999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 97999\n",
      "Mean Log Likelihood -- train: -2.3979694843292236, -- test: -64.88249206542969 \n",
      "Root Mean Squared Error -- train: 0.2750132977962494, -- test: 1.1512266397476196 \n",
      " \n",
      "#################### Sampling at Epoch 98049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98049\n",
      "Mean Log Likelihood -- train: -2.455188751220703, -- test: -63.89985656738281 \n",
      "Root Mean Squared Error -- train: 0.2770861089229584, -- test: 1.1426591873168945 \n",
      " \n",
      "#################### Sampling at Epoch 98099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98099\n",
      "Mean Log Likelihood -- train: -2.4796862602233887, -- test: -61.997867584228516 \n",
      "Root Mean Squared Error -- train: 0.27796879410743713, -- test: 1.1258907318115234 \n",
      " \n",
      "#################### Sampling at Epoch 98149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98149\n",
      "Mean Log Likelihood -- train: -2.4699294567108154, -- test: -62.4147834777832 \n",
      "Root Mean Squared Error -- train: 0.27761760354042053, -- test: 1.1295877695083618 \n",
      " \n",
      "#################### Sampling at Epoch 98199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98199\n",
      "Mean Log Likelihood -- train: -2.4482951164245605, -- test: -62.38094711303711 \n",
      "Root Mean Squared Error -- train: 0.27683717012405396, -- test: 1.1292881965637207 \n",
      " \n",
      "#################### Sampling at Epoch 98249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98249\n",
      "Mean Log Likelihood -- train: -2.4115078449249268, -- test: -58.87480926513672 \n",
      "Root Mean Squared Error -- train: 0.2755051553249359, -- test: 1.097801923751831 \n",
      " \n",
      "#################### Sampling at Epoch 98299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98299\n",
      "Mean Log Likelihood -- train: -2.4232771396636963, -- test: -59.490047454833984 \n",
      "Root Mean Squared Error -- train: 0.2759319841861725, -- test: 1.1033918857574463 \n",
      " \n",
      "#################### Sampling at Epoch 98349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98349\n",
      "Mean Log Likelihood -- train: -2.4391555786132812, -- test: -60.268856048583984 \n",
      "Root Mean Squared Error -- train: 0.27650687098503113, -- test: 1.1104278564453125 \n",
      " \n",
      "#################### Sampling at Epoch 98399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98399\n",
      "Mean Log Likelihood -- train: -2.4683291912078857, -- test: -60.74811935424805 \n",
      "Root Mean Squared Error -- train: 0.27755990624427795, -- test: 1.1147356033325195 \n",
      " \n",
      "#################### Sampling at Epoch 98449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98449\n",
      "Mean Log Likelihood -- train: -2.4457743167877197, -- test: -61.375274658203125 \n",
      "Root Mean Squared Error -- train: 0.27674612402915955, -- test: 1.1203473806381226 \n",
      " \n",
      "#################### Sampling at Epoch 98499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98499\n",
      "Mean Log Likelihood -- train: -2.388012647628784, -- test: -64.46755981445312 \n",
      "Root Mean Squared Error -- train: 0.27465102076530457, -- test: 1.1476167440414429 \n",
      " \n",
      "#################### Sampling at Epoch 98549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98549\n",
      "Mean Log Likelihood -- train: -2.3973186016082764, -- test: -61.834529876708984 \n",
      "Root Mean Squared Error -- train: 0.27498963475227356, -- test: 1.1244391202926636 \n",
      " \n",
      "#################### Sampling at Epoch 98599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98599\n",
      "Mean Log Likelihood -- train: -2.463453531265259, -- test: -60.52754211425781 \n",
      "Root Mean Squared Error -- train: 0.2773841917514801, -- test: 1.1127549409866333 \n",
      " \n",
      "#################### Sampling at Epoch 98649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98649\n",
      "Mean Log Likelihood -- train: -2.4307072162628174, -- test: -61.28982925415039 \n",
      "Root Mean Squared Error -- train: 0.27620112895965576, -- test: 1.119584560394287 \n",
      " \n",
      "#################### Sampling at Epoch 98699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98699\n",
      "Mean Log Likelihood -- train: -2.429583787918091, -- test: -62.193748474121094 \n",
      "Root Mean Squared Error -- train: 0.27616044878959656, -- test: 1.127629280090332 \n",
      " \n",
      "#################### Sampling at Epoch 98749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98749\n",
      "Mean Log Likelihood -- train: -2.4298348426818848, -- test: -62.254459381103516 \n",
      "Root Mean Squared Error -- train: 0.2761695384979248, -- test: 1.1281675100326538 \n",
      " \n",
      "#################### Sampling at Epoch 98799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98799\n",
      "Mean Log Likelihood -- train: -2.4500575065612793, -- test: -59.597808837890625 \n",
      "Root Mean Squared Error -- train: 0.27690085768699646, -- test: 1.1043682098388672 \n",
      " \n",
      "#################### Sampling at Epoch 98849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98849\n",
      "Mean Log Likelihood -- train: -2.4485392570495605, -- test: -61.93260192871094 \n",
      "Root Mean Squared Error -- train: 0.2768460214138031, -- test: 1.125311017036438 \n",
      " \n",
      "#################### Sampling at Epoch 98899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98899\n",
      "Mean Log Likelihood -- train: -2.4365861415863037, -- test: -60.93842697143555 \n",
      "Root Mean Squared Error -- train: 0.2764139175415039, -- test: 1.1164413690567017 \n",
      " \n",
      "#################### Sampling at Epoch 98949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98949\n",
      "Mean Log Likelihood -- train: -2.415952444076538, -- test: -62.40816879272461 \n",
      "Root Mean Squared Error -- train: 0.27566641569137573, -- test: 1.1295292377471924 \n",
      " \n",
      "#################### Sampling at Epoch 98999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 98999\n",
      "Mean Log Likelihood -- train: -2.4566457271575928, -- test: -63.54512023925781 \n",
      "Root Mean Squared Error -- train: 0.27713868021965027, -- test: 1.1395504474639893 \n",
      " \n",
      "#################### Sampling at Epoch 99049  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99049\n",
      "Mean Log Likelihood -- train: -2.444154977798462, -- test: -60.4875373840332 \n",
      "Root Mean Squared Error -- train: 0.2766875922679901, -- test: 1.1123954057693481 \n",
      " \n",
      "#################### Sampling at Epoch 99099  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99099\n",
      "Mean Log Likelihood -- train: -2.431542158126831, -- test: -60.648929595947266 \n",
      "Root Mean Squared Error -- train: 0.2762313485145569, -- test: 1.1138453483581543 \n",
      " \n",
      "#################### Sampling at Epoch 99149  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99149\n",
      "Mean Log Likelihood -- train: -2.4052796363830566, -- test: -61.242042541503906 \n",
      "Root Mean Squared Error -- train: 0.2752789855003357, -- test: 1.1191575527191162 \n",
      " \n",
      "#################### Sampling at Epoch 99199  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99199\n",
      "Mean Log Likelihood -- train: -2.406660556793213, -- test: -66.40660095214844 \n",
      "Root Mean Squared Error -- train: 0.2753291726112366, -- test: 1.1643903255462646 \n",
      " \n",
      "#################### Sampling at Epoch 99249  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99249\n",
      "Mean Log Likelihood -- train: -2.4132730960845947, -- test: -66.2448501586914 \n",
      "Root Mean Squared Error -- train: 0.27556920051574707, -- test: 1.1630003452301025 \n",
      " \n",
      "#################### Sampling at Epoch 99299  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99299\n",
      "Mean Log Likelihood -- train: -2.42311954498291, -- test: -63.407508850097656 \n",
      "Root Mean Squared Error -- train: 0.27592629194259644, -- test: 1.138342261314392 \n",
      " \n",
      "#################### Sampling at Epoch 99349  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99349\n",
      "Mean Log Likelihood -- train: -2.4406120777130127, -- test: -60.71506881713867 \n",
      "Root Mean Squared Error -- train: 0.2765595316886902, -- test: 1.1144390106201172 \n",
      " \n",
      "#################### Sampling at Epoch 99399  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99399\n",
      "Mean Log Likelihood -- train: -2.461968421936035, -- test: -62.620933532714844 \n",
      "Root Mean Squared Error -- train: 0.2773306667804718, -- test: 1.1314111948013306 \n",
      " \n",
      "#################### Sampling at Epoch 99449  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99449\n",
      "Mean Log Likelihood -- train: -2.4034647941589355, -- test: -64.80308532714844 \n",
      "Root Mean Squared Error -- train: 0.2752130627632141, -- test: 1.1505366563796997 \n",
      " \n",
      "#################### Sampling at Epoch 99499  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99499\n",
      "Mean Log Likelihood -- train: -2.4392292499542236, -- test: -63.02687454223633 \n",
      "Root Mean Squared Error -- train: 0.27650952339172363, -- test: 1.134993553161621 \n",
      " \n",
      "#################### Sampling at Epoch 99549  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99549\n",
      "Mean Log Likelihood -- train: -2.4259021282196045, -- test: -64.02677154541016 \n",
      "Root Mean Squared Error -- train: 0.276027113199234, -- test: 1.143769383430481 \n",
      " \n",
      "#################### Sampling at Epoch 99599  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99599\n",
      "Mean Log Likelihood -- train: -2.5388917922973633, -- test: -62.500587463378906 \n",
      "Root Mean Squared Error -- train: 0.28009065985679626, -- test: 1.1303471326828003 \n",
      " \n",
      "#################### Sampling at Epoch 99649  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99649\n",
      "Mean Log Likelihood -- train: -2.4471373558044434, -- test: -62.872802734375 \n",
      "Root Mean Squared Error -- train: 0.276795357465744, -- test: 1.1336352825164795 \n",
      " \n",
      "#################### Sampling at Epoch 99699  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99699\n",
      "Mean Log Likelihood -- train: -2.449976921081543, -- test: -63.51093292236328 \n",
      "Root Mean Squared Error -- train: 0.27689793705940247, -- test: 1.13925039768219 \n",
      " \n",
      "#################### Sampling at Epoch 99749  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99749\n",
      "Mean Log Likelihood -- train: -2.433621644973755, -- test: -68.13268280029297 \n",
      "Root Mean Squared Error -- train: 0.2763066291809082, -- test: 1.1791211366653442 \n",
      " \n",
      "#################### Sampling at Epoch 99799  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99799\n",
      "Mean Log Likelihood -- train: -2.4483799934387207, -- test: -67.99364471435547 \n",
      "Root Mean Squared Error -- train: 0.2768402397632599, -- test: 1.1779414415359497 \n",
      " \n",
      "#################### Sampling at Epoch 99849  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99849\n",
      "Mean Log Likelihood -- train: -2.4032044410705566, -- test: -68.20645141601562 \n",
      "Root Mean Squared Error -- train: 0.2752035856246948, -- test: 1.1797466278076172 \n",
      " \n",
      "#################### Sampling at Epoch 99899  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99899\n",
      "Mean Log Likelihood -- train: -2.436218500137329, -- test: -71.62144470214844 \n",
      "Root Mean Squared Error -- train: 0.276400625705719, -- test: 1.2083467245101929 \n",
      " \n",
      "#################### Sampling at Epoch 99949  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99949\n",
      "Mean Log Likelihood -- train: -2.440321922302246, -- test: -69.51188659667969 \n",
      "Root Mean Squared Error -- train: 0.27654901146888733, -- test: 1.1907604932785034 \n",
      " \n",
      "#################### Sampling at Epoch 99999  lr = 2.404305921022143e-10 ####################\n",
      "Epoch: 99999\n",
      "Mean Log Likelihood -- train: -2.416407823562622, -- test: -66.82799530029297 \n",
      "Root Mean Squared Error -- train: 0.2756829261779785, -- test: 1.1680036783218384 \n",
      " \n",
      "Number of sampled models: 2000 \n",
      "Test Log Likelihood of all sampled models: -1.5505191087722778\n",
      "Test Root MSE of all sampled models: 0.9714861512184143\n"
     ]
    }
   ],
   "source": [
    "_, _, lines, W = regression_train_demo(model, ds_train, ds_test, num_training, batch_size, X_test,\n",
    "                                                              lr_0=lr_0, momentum_decay=beta,\n",
    "                                                              resample_in_cycle_head=False, total_epochs=total_epochs,\n",
    "                                                              start_sampling_epoch=start_sampling_epoch,\n",
    "                                                              epochs_per_cycle=epochs_per_cycle,\n",
    "                                                              print_epoch_cycle=print_epoch_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print sampled lines\n",
    "fig, ax = plt.subplots(1, model.n_hidden_layers+1, figsize=((model.n_hidden_layers+1)*5, 5))\n",
    "ax = ax.flatten()\n",
    "for i in range(model.n_hidden_layers):\n",
    "    for model_line in lines[::]: # hidden outputs of each sampled model\n",
    "        line = model_line[i]\n",
    "        ax[i].plot(X_test[:,0], line.numpy()[:,0])\n",
    "    # for model_line in lines[690:701]: # hidden outputs of each sampled model\n",
    "    #     line = model_line[i]\n",
    "    #     ax[i].plot(X_test.numpy()[:,0], line.numpy()[:,0], 'b')\n",
    "for x, y in ds_train:\n",
    "    ax[-2].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "# for x, y in ds_test:\n",
    "    # ax[-1].plot(x[:,0], y[:,0], '*', label='ground truth')\n",
    "ax[-2].legend()\n",
    "\n",
    "# compute the mean of the sampled lines\n",
    "line_output = []\n",
    "for model_line in lines[::]:\n",
    "    line_output.append(model_line[-1]) #the final layer\n",
    "line_mean = tf.reduce_mean(tf.concat(line_output, axis=-1), axis=-1)\n",
    "ax[-1].plot(X_test[:,0], line_mean.numpy(), label='mean')\n",
    "for x, y in ds_train:\n",
    "    ax[-1].plot(x[:,0], y[:,0], 'o', label='training points')\n",
    "ax[-1].legend()\n",
    "fig.savefig(\"2layers-square.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 65, X_test = 0.939393937587738\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_index = 65\n",
    "print(f'index {input_index}, X_test = {X_test[input_index,0]}')\n",
    "points = []\n",
    "for model_line in lines[:]:\n",
    "    line = model_line[0]\n",
    "    point = line[input_index,0].numpy()\n",
    "    points.append(point)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(points, bins=90, density=True, label=f'point density at {X_test[input_index,0]}')\n",
    "ax.legend()\n",
    "fig.savefig('point-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_index = (69,0)\n",
    "fig, ax = plt.subplots(1, model.n_hidden_layers, figsize=(model.n_hidden_layers*5,5))\n",
    "ax = ax.flatten()\n",
    "for i in range(model.n_hidden_layers):\n",
    "    W_print = []\n",
    "    for W_model in W['W_'+str(i)][10:]:\n",
    "        W_print.append(W_model[print_index])\n",
    "    ax[i].hist(W_print, bins=100, density=True, label='W_'+str(i))\n",
    "    ax[i].legend()\n",
    "# fig.savefig(\"2w-sq-3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try to show the correlation of two weights\n",
    "print_index_1 = (25,0)\n",
    "print_index_2 = (69,0)\n",
    "W_print_1 = []\n",
    "W_print_2 = []\n",
    "for W_model in W['W_'+ str(1)][20:]:\n",
    "    W_print_1.append(W_model[print_index_1])\n",
    "    W_print_2.append(W_model[print_index_2])\n",
    "plt.hist2d(W_print_1, W_print_2, bins=90, density=True)\n",
    "plt.xlabel(f'W_1{print_index_1}')\n",
    "plt.ylabel(f'W_1{print_index_2}')\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('probability')\n",
    "# plt.savefig('correlation-sq-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
